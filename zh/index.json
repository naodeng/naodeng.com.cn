[{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n组合测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/combinatorial-testing.md\n组合测试一段简要说明 组合测试 是一种经过验证的、成本较低的、更为有效的软件测试方法。 这种测试的关键思想是，并非每个参数都对每次故障都有影响，而是大多数故障是由相对较少的参数之间的相互作用引起的。 与传统方法相比，测试参数组合可以更有效地检测故障。 美国国家标准与技术研究院NIST 在 1999 年到 2004 年进行的一系列研究表明，大多数软件缺陷和故障是由一个或两个参数引起的，逐渐减少到由三个或更多参数引起的。这一发现被称为“交互规则”，对软件测试具有重要意义，因为这意味着测试参数组合可以比传统方法更有效地检测故障。NIST 和其他机构收集的数据表明，软件故障仅由少数几个变量的相互作用引发（不超过六个）。有时使用成对（2 路组合）测试可以以较低的成本获得相当不错的结果，通常不低于 60% 的故障覆盖率，但这可能对于关键任务的软件来说可能不足够。\n(1) 代码示例 – 产品负责人问题 一位产品负责人曾提出一个问题：\n\u0026ldquo;从最佳实践或实际角度来看，你是否应该在每种可能的配置下测试系统？ 例如，假设你有 A、B、C、D、E 五个功能，客户 1 拥有 A/B，客户 2 拥有 A/B/C，客户 3 拥有 A/D，客户 4 拥有 B/D，客户 5 拥有 A/B/C/D/E\u0026hellip;. 你是否应该测试每种可能的功能组合，还是测试每个功能单独，如果它们在独立测试中能够正常工作，就相信它们整体上也能正常工作？\u0026rdquo;\n5 个客户和 5 个功能，详尽无遗将需要 25 个测试。 在描述的约束条件下，只需要 14 个测试。 为了提供一个代码示例，我们将使用描述规格的CTWedge脚本化组合模型。还有许多其他列在pairwise.org上的 CT 工具。我们（在西门子）使用过的其他一些工具包括ACTs和CAgen。\nModel POquestion Parameters: features : {A, B, C, D, E} customer: {1, 2, 3, 4, 5} Constraints: # customer = 1 =\u0026gt; features = A || features = B # # customer = 2 =\u0026gt; features = A || features = B || features = C # # customer = 3 =\u0026gt; features = A || features = D # # customer = 4 =\u0026gt; features = B || features = D # # customer = 5 =\u0026gt; features = A || features = B || features = C || features = D || features = E # 在这里粘贴脚本以生成结果 这里。\n测试的目标是检验参数之间的双向（或更多）相互作用。当只有两个参数时，收益并不太明显，因为这是一种穷举的方法。\n如果参数数量超过两个，对它们之间的双向交互进行覆盖将确保找到该领域可能存在的 60-99% 的所有潜在缺陷。三向交互为 90%，四向为 95%，五向为 97%，六向为 100%。\n在这个例子中，通过添加另一个参数，我们称之为 configuration，并假设有 5 种可能的配置 / 参数值。这将生成一个包含 125 个测试的详尽套件。\nModel POquestion Parameters: features : {A, B, C, D, E} customer: {1, 2, 3, 4, 5} configuration: {config1, config2, config3, config4, config5} Constraints: # customer = 1 =\u0026gt; features = A || features = B # # customer = 2 =\u0026gt; features = A || features = B || features = C # # customer = 3 =\u0026gt; features = A || features = D # # customer = 4 =\u0026gt; features = B || features = D # # customer = 5 =\u0026gt; features = A || features = B || features = C || features = D || features = E # 将其粘贴到 CTWedge 上，这将生成一个包含 31 个测试的测试套件。如果添加一些约束，表明某些特性不应该与某些配置一起工作，甚至可以进一步精简。\n请注意，组合测试的建模可以并且确实包含等价分区、边界值分析和其他技术。模型越准确，测试套件的故障检测能力就越强。\n(2) 代码示例 – NASA 的开关板共有 34 个开关 以 NASA 的一个例子为参考，有 34 个开关，每个开关可以处于打开或关闭的状态。要进行详尽的测试，有 170 亿种可能的组合方式。\n不必测试所有的 2^34 种可能性。通过使用组合测试进行建模，你可以根据风险做出经过计算的决策。\nModel NASAswitches Parameters: switch1: Boolean switch2: Boolean switch3: Boolean switch4: Boolean switch5: Boolean switch6: Boolean switch7: Boolean switch8: Boolean switch9: Boolean switch10: Boolean switch11: Boolean switch12: Boolean switch13: Boolean switch14: Boolean switch15: Boolean switch16: Boolean switch17: Boolean switch18: Boolean switch19: Boolean switch20: Boolean switch21: Boolean switch22: Boolean switch23: Boolean switch24: Boolean switch25: Boolean switch26: Boolean switch27: Boolean switch28: Boolean switch29: Boolean switch30: Boolean switch31: Boolean switch32: Boolean switch33: Boolean switch34: Boolean 在 CTWedge 中通过下拉菜单开关测试的相互作用次数。\n14 次测试：通过开关之间的 2 次相互作用引起的故障 - 可根据产品找到 60-99% 的所有潜在故障 33 次测试：通过开关之间的 3 次相互作用引起的故障 - 可根据产品找到 90-99% 的所有潜在故障 85 次测试：通过开关之间的 4 次相互作用引起的故障 - 可根据产品找到 95-99% 的所有潜在故障 220 次测试：通过开关之间的 5 次相互作用引起的故障 - 可找到超过 99% 的所有潜在故障 538 次测试：通过开关之间的 6 次相互作用引起的故障 - 可找到所有潜在故障的 100% (2) 代码示例 - 西门子楼宇操作员 CI 配置 参考上面的幻灯片链接或直播视频以获取有关如何使用CAMetrics测量组合覆盖率的详细说明。基本上，你可以使用任何组合测试工具生成一个 CSV 文件，然后将其拖放到 CAMetrics 中。之后，CAMetrics 可以为你提供各种组合覆盖率报告。\n请注意，将 CSV 转换为 JSON 非常简单，然后可以使用 JSON 文件在所选的任何测试框架中进行数据驱动测试。\nModel CI Parameters: deployment_UI : { branch, development, staging } deployment_API: { development, staging } spec_suite: { ui_services_stubbed, ui_services, ui_services_hardware, spot_check} browser: { chrome, electron, firefox } Constraints: // one extra constraint for firefox spot checks # browser=firefox \u0026lt;=\u0026gt; spec_suite=spot_check # // on staging, run all tests # spec_suite=ui_services_hardware \u0026lt;=\u0026gt; deployment_API=staging # // match dev vs dev, staging vs staging, and when on staging use Chrome # deployment_UI=development =\u0026gt; deployment_API=development # # deployment_UI=staging =\u0026gt; deployment_API=staging # # deployment_UI=staging \u0026amp;\u0026amp; deployment_API=staging =\u0026gt; browser=chrome # // when on branch, stub the services # deployment_UI=branch =\u0026gt; spec_suite=ui_services_stubbed # // do not stub the services when on UI development # deployment_UI=development =\u0026gt; spec_suite!=ui_services_stubbed # 组合测试参考资料和延伸阅读 自动化组合测试软件\n幻灯片 16-50：探讨自动化和组合纪律在辅助探索性测试方面的应用\n西门子工业公司建筑技术部实际组合测试方法的应用\n现代 Web 开发中组合测试的工业研究\n在大型组织中引入组合测试\n组合策略的输入参数建模\n组合模型中的常见模式\n等效类和两层覆盖阵的高效验证和同时测试\n性能测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/performance-testing.md\n性能测试一段简要说明 虽然性能测试是一个庞大的话题，但作为 Web 开发者，我们可以迅速从其核心原则中获益，以提升用户体验、满足功能和非功能需求（NFRs），并检测可能泄漏到生产环境中的不明确系统问题。\n(1) 通过 Lighthouse 确保用户体验 作为 Web 开发者，我们最关心的是用户对性能的感知。谢天谢地，Google 已经让这变得简单，并为我们提供了一个第三方权威评估我们 Web 应用程序的工具 - Lighthouse。\n\u0026ldquo;Lighthouse 是一个用于提高网页质量的开源自动化工具。你可以对任何网页运行它，无论是公开的还是需要身份验证的。它可以进行性能、可访问性、渐进式 Web 应用、SEO 等方面的审计。\u0026rdquo;\n在这个话题中，我们只关注性能，但你也应该考虑从 Lighthouse 的审计中获得关于渐进式 Web 应用、可访问性、搜索引擎优化和最佳实践的评估。\n入门很简单：Chrome \u0026gt; 开发者工具 \u0026gt; 审计 \u0026gt; Lighthouse。然后，生成报告。它会显示如下，并为你提供有关如何改善用户体验的详细指南。\n一旦进行了改进并达成了基线评级，您可以通过将 Lighthouse 纳入您的 CI 来防止回归。\n将 Lighthouse 添加为 node_module；npm i -D lighthouse 或 yarn add --dev lighthouse。 参考 Lighthouse Git 存储库 上的工作流示例。 防止性能评级（和/或其他评级）在开发人员提交代码时出现回归！ 使用 Cypress 集成 Lighthouse 如果你是 Cypress 用户，通过 cypress-audit 插件，你可以在 Cypress 测试中执行 Lighthouse 审计，以及 Pa11y 进行自动化的可访问性测试。\n除了通常的插件设置之外，你可能需要解决你的应用程序的跨域问题，直到 Cypress 官方支持它。\n以下是一个带有内联说明的示例测试。\n// Pass in optional configuration parameters for the Cypress test: // you may need to increase default timeout for the overall task, if you have a slow app. Mind that Lighthouse is only for Chromium based browsers describe(\u0026#39;Lighthouse audit \u0026#39;, { taskTimeout: 90000, browser: \u0026#39;chrome\u0026#39; }, () =\u0026gt; { before(() =\u0026gt; { // if you are using programmatic login, you might not need to use the cy.forceVisit(\u0026#39;/\u0026#39;) workaround for cross-origin (linked above) cy.login(Cypress.env(\u0026#39;USERNAME\u0026#39;), Cypress.env(\u0026#39;PASSWORD\u0026#39;)); }); // thresholds is the first argument to cy.lighthouse(), most of the performance configuration is done here. // a complete list of Lighthouse parameters to use as thresholds can be found at https://github.com/mfrachet/cypress-audit/blob/master/docs/lighthouse.md // for an explanation of the parameters, refer to https://web.dev/lighthouse-performance/ const thresholds = { \u0026#39;first-contentful-paint\u0026#39;: 20000, \u0026#39;largest-contentful-paint\u0026#39;: 35000, \u0026#39;first-meaningful-paint\u0026#39;: 20000, \u0026#39;speed-index\u0026#39;: 25000, interactive: 40000, performance: 5, accessibility: 50, \u0026#39;best-practices\u0026#39;: 50, seo: 50, pwa: 20 }; // the 2nd, and optional argument to cy.lighthouse() replicates Lighthouse CLI commands https://github.com/GoogleChrome/lighthouse#cli-options const desktopConfig = { formFactor: \u0026#39;desktop\u0026#39;, screenEmulation: { disabled: true } }; // your app may need this beforeEach and afterEach workaround for cross-origin (linked above) beforeEach(() =\u0026gt; { cy.restoreLocalStorage(); // Preserve Cookies between tests Cypress.Cookies.defaults({ preserve: /[\\s\\S]*/ }); }); afterEach(() =\u0026gt; { cy.saveLocalStorage(); }); it(\u0026#39;should pass audit for main page \u0026#39;, () =\u0026gt; { cy.lighthouse(thresholds, desktopConfig); }); it(\u0026#39;should pass audit for another page\u0026#39;, () =\u0026gt; { cy.forceVisit(\u0026#39;anotherUrl\u0026#39;); cy.lighthouse(thresholds, desktopConfig); }); }); // Commands for working around cross origin, if needed // -- Save localStorage between tests let LOCAL_STORAGE_MEMORY = {}; Cypress.Commands.add(\u0026#39;saveLocalStorage\u0026#39;, () =\u0026gt; { Object.keys(localStorage).forEach(key =\u0026gt; { LOCAL_STORAGE_MEMORY[key] = localStorage[key]; }); }); Cypress.Commands.add(\u0026#39;restoreLocalStorage\u0026#39;, () =\u0026gt; { Object.keys(LOCAL_STORAGE_MEMORY).forEach(key =\u0026gt; { localStorage.setItem(key, LOCAL_STORAGE_MEMORY[key]); }); }); // -- Visit multiple domains in one test Cypress.Commands.add(\u0026#39;forceVisit\u0026#39;, url =\u0026gt; { cy.window().then(win =\u0026gt; win.open(url, \u0026#39;_self\u0026#39;)); }); (2) 性能作为一种非功能性需求和 Kano 模型 我们可以通过Kano 模型开始建立对性能需求的理解。\n\u0026ldquo;Kano 模型是在 1980 年代由日本学者狩野纪明教授开发的产品开发和客户满意度理论，将客户偏好分为五类。\u0026rdquo;\n从高层次上看，卡诺模型总结了性能特性是标准要求，是任何竞争性产品所期望的。这与我们使用 Lighthouse 的方式重叠；通过它，我们确保满足客户偏好，并确保我们不会回退。\n在这一点上，我们已经满足了明确说明的性能要求。然而，在复杂的应用程序中，我们还需要注意非功能性需求（NFRs）。但是，什么是 NFRs 呢？下面是它们在一瞥之下的高层次视图 - 来自双重标准的ISO/IEC 25010 产品质量模型。\n在下一节中，让我们专注于 NFRs 如何帮助我们进行非功能性能测试的方法。\n(3) 性能测试的类型 为了实际应用，我们可以将非功能性能测试分为 3 个类别\nLoad 负载测试 Spike 尖峰测试 Endurance 耐久测试 这张图总结了它们的上下文：\n关于基准测试和压力测试的额外说明: 本质上，基准测试归结为逐步的步骤，因为我们逐渐了解我们的系统，这成为了初始工作流程的一部分，其中使用自动化工具；\u0026ldquo;我的系统已经崩溃了吗？没有？那我再增加一点\u0026rdquo;。而压力测试，简而言之，就是做得过火了。\n那么可扩展性测试的区别是什么？它是相关的；区别在于系统何时开始以不令人满意的方式不响应的评估。通常情况下，使用自动化工具的方法足够接近，并且可以在负载测试中分析图表时实现。\n这是可扩展性测试意图的高层次图：\n(4) 使用 k6-loadImpact 进行性能测试的实际应用 k6-loadImpact在 Web 开发领域有两个显著的特点。\n使用 JS（ES6） 专为 CI 构建 额外的好处：如果你习惯使用 Postman，你可以轻松地将这些测试转换为 k6。 K6 可以 进行 DOM 测试，但我们认为 Lighthouse 已经处理了这方面的问题。K6 真正强大的地方在于测试 API 时。\n你可以在这里找到使用 k6 的快速入门示例。 这些示例从非常简单的开始，旨在快速建立理解。它们已经准备好直接运行和调整。我们将不会在这里重复这些知识。\n相反，在本节中，我们将概述 k6 测试的概览，并稍后展示一个代码示例，演示如何配置 k6 以适应不同类型的性能测试。\n// k6 lifecycle overview: // 1. init code -\u0026gt; runs once // this is where we configure the type of performance testing (there are also // additional options we do not cover here) export let options = { // there will be 1 virtual user vus: 1, // default function() will execute 1 time. This simple config // is best when trying to get things to work iterations: 1, } // 2. (optional) setup code -\u0026gt; runs once export function setup() { // for example getting a token so you can run API tests in the default // function that comes in (3) virtual user code // what gets returned from this function is passed as an argument to the next // function. For example: `token` return getTokenForUser(); } // 3. virtual user code -\u0026gt; runs once or many times based on // `export let options = { ... } ` export default function(token) { // http.get is a k6 function that hits a URL with optional test parameters // note that we do not need a token for this url http.get(\u0026#34;http://test.loadimpact.com\u0026#34;); } // 4. (optional) teardown code -\u0026gt; runs once export function teardown(data) { // this is in case you need to clean up, for instance if failed test may // leave residue an impact state } 耐久测试配置：\nexport let options = { // endurance test for 30 seconds with 50 virtual users. Adds users immediately vus: 50, duration: \u0026#34;30s\u0026#34;, // alternative to duration, you can specify the exact number of iterations // the test will run // iterations: 500, } 负载测试配置：\nexport let options = { // for 15 seconds ramps up 10 users, adds users gradually // adds a total of 40 users in the next 15 seconds, and up to 50 in the next // 30 seconds.. // lowers down the users to 10 and 5 in the next 15 second iterations stages: [ { duration: \u0026#34;15s\u0026#34;, target: 10 }, { duration: \u0026#34;15s\u0026#34;, target: 40 }, { duration: \u0026#34;30s\u0026#34;, target: 50 }, { duration: \u0026#34;15s\u0026#34;, target: 10 }, { duration: \u0026#34;15s\u0026#34;, target: 5 }, ] } 尖锋测试配置：\nexport let options = { // starts slow and builds up the load rapidly, and then drops the load stages: [ { duration: \u0026#34;5s\u0026#34;, target: 1 }, { duration: \u0026#34;5s\u0026#34;, target: 5 }, { duration: \u0026#34;5s\u0026#34;, target: 25 }, { duration: \u0026#34;3s\u0026#34;, target: 200 }, { duration: \u0026#34;3s\u0026#34;, target: 20 }, { duration: \u0026#34;3s\u0026#34;, target: 10 }, { duration: \u0026#34;3s\u0026#34;, target: 5 }, { duration: \u0026#34;3s\u0026#34;, target: 1 }, ] } 正如你所看到的，stages 是配置性能测试类型的实用工具。\n我们如何分析测试结果？ K6 提供了一个简单的CLI 输出。我们认为这里最重要的两个高级数值是 http_req_duration，它详细说明了响应持续时间，以及 http_req，它显示发送的请求数量。如果这些数值在可接受的范围内，CLI 就达到了其目的。\n如果需要进行更深入的诊断，图形化的insights非常有价值。在这样的图表中，关键是 响应时间 和 请求速率 跟随 虚拟用户 的趋势。任何趋势上的变化都可能提示潜在问题。\n(5) 通过性能测试来防止不稳定的问题进入生产环境 可参考章节 不稳定的测试 \u0026gt; 第三步：识别零星的系统问题 - 不稳定的系统\n性能测试参考资料和延伸阅读 Lighthouse 文档\nLighthouse 代码库\nKano 模型\nISO/IEC 25010 产品质量模型\nk6-loadImpact 文档\n使用 K6 的快速启动示例\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-advanced-combinatorial-testing-and-performance-testing/","summary":"这篇博文是 UI 测试最佳实践的进阶篇，第二篇深入讨论组合测试和性能测试。文章详细介绍了如何有效地进行组合测试，覆盖多个交互元素的不同组合，以提高测试的全面性。此外，博文探讨了 UI 性能测试的重要性，并提供了一些性能测试的最佳实践，确保应用程序在各种负载下的高性能和稳定性。通过学习这些进阶实践，读者将能够更全面地应对复杂的 UI 测试场景，确保系统的质量和性能。","title":"UI 测试最佳实践的进阶篇（二）：组合测试和性能测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n测试状态 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/test-states.md\n一段简要说明 测试应该是可重复的、模块化的，并且应该自己处理状态设置。为了为其他测试实现状态，不应该重复执行 UI 测试。\n我们希望测试是无状态的，具有可扩展性：\n测试应该独立处理其状态。 没有对外部产生不受控制的副作用，或者具有测试自身能够处理的可管理副作用。 测试应该能够被 n 个实体同时执行。 代码示例 – 解释说明 可重复性: 测试必须能够设置状态、执行测试，并在不影响下一个测试执行的前提下使环境保持干净。如果一个测试在每次执行时都使系统混乱，将其留在无法重置的状态，那么这个测试就适合作为手动测试。测试还不能互相冲突：多个测试者和流水线必须能够同时执行相同的测试。如果这不可行，这些测试组应该每天在流水线中执行一次，最好在非工作时间执行 cron 作业。\n每个需要更改环境状态的测试都必须被用作设置 - 状态 - 测试，并确保在下一个测试之前能够清理测试环境。\n最好是 UI 测试不要重复作为设置测试；在必须将 UI 测试用作另一个测试的设置的情况下，应该使用 API 测试、应用程序操作或数据库初始化。\n设置 vs 清理: 设置（之前全部）优于清理（之后全部）。在可能的情况下，测试本身应该负责在一个干净的环境中开始。然而，正如上面强调的，测试不能使得在它们执行后下一个测试无法清理环境。\n登录: UI 登录的各种形式应仅在其各自的测试用例中使用。任何其他需要登录的测试应该使用内部的 API 登录和/或具有预配置的测试用户。\n测试状态设置: 鼓励测试是隔离的，以便它们在执行之前不依赖于整个设置。例如：如果一组测试可能需要创建用户，可以利用一个测试用户在隔离中使用这些测试。另一方面，设置用户的测试应该是独立的和隔离的。\n模块化: 每个测试应该能够独立运行，不依赖于其他测试来为其设置状态。如果需要进行这样的设置，应该在 beforeAll 或 beforeEach 部分进行。测试这一点的一个好方法是在隔离中运行测试：it.only()，fit()，等等。\ndescribe(\u0026#39;..\u0026#39;, function () { // setup (before/beforeEach) is preferred over cleanup (after/afterEach) before(function () { // login with UI once in an isolated test // for login here and all other tests, use a faster login method: use API, App Actions or DB seeding }); beforeEach(function () { // setup additional state... // have one UI test to ensure this state can be achieved // however for the state set up here, utilize API, Application Actions or DB seeding; do not repeat UI tests }); // test each test once with .only to ensure modularity it(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); it.only(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); }); 测试状态参考资料 放弃使用页面对象，转而使用应用动作\nCypress 文档：测试组织、登录、状态控制\n不稳定的测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/test-flake.md\n一段简要说明 每次测试都必须产生一致的结果，而可重复的流水线执行结果则是至关重要的。如果测试无法产生可靠的结果，将降低对测试的信心，还需要进行维护，这将降低所有价值。在这些情况下，最好进行手动功能测试。\n并请自问以下几个问题：\n如何解决测试波动，通过成长的过程确保测试的可信度？ 如何处理流水线、基础设施、共享资源等方面的假阴性，并在没有控制的情况下解决？ 如何发现零星缺陷？ 第一步：本地识别不稳定的测试 推荐在模拟流水线 CI 机器的操作系统中进行无头模式执行；Linux 和 MacOS 与流水线的行为更为相似，而 Windows 则是个例外，除非你正在使用 Windows Docker 容器。无头执行将更容易暴露测试波动。有多种方法可以重复执行测试规范，Cypress 提供的一个例子是使用 Lodash 库（Cypress 已经内置了）Cypress._.times( \u0026lt;重复次数\u0026gt;, () =\u0026gt; { \u0026lt;你的测试规范代码\u0026gt; })。在提交代码合并请求之前，务必使用此方法。\n第一步的代码示例 // will repeat the full suite 10 times Cypress._.times( 10, function { describe(\u0026#39;..\u0026#39;, function () { before(function () { }); beforeEach(function () { }); // you can place it anywhere to repeat 1 test, or another describe / context block Cypress._.times( 3, function { it(\u0026#39;..\u0026#39;, function () {..}); } it(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); }); }); // this will result in 6 tests per run x 10 runs = 60 executions 第二步：在流水线中识别不稳定的测试并进行重试 在初始的流水线顺利通过并合并代码后，有时测试会出现失败的情况。\n为什么测试在没有可重现的缺陷且测试代码已经完全优化的情况下仍然失败呢？\n为了解决这种零星的失败问题，以及避免测试被忽略或降低团队对其的信心，我们可以采用重试机制：\n用以解决团队无法掌控的不可靠流水线基础设施问题 在开发中遇到的问题，或者依赖于正在开发中的外部服务 最为重要的是，用于锁定零星的系统问题 第二步的代码示例 许多框架都提供了重试实用工具。下面是一个例子来自于 Cypress 文档:\n在一个测试中：\nit(\u0026#39;allows user to login\u0026#39;, { // can also be in a context or describe block retries: { runMode: 2, // for CI usage openMode: 1 // for local usage } }, () =\u0026gt; { // ... }) 在配置文件中，例如 cypress.json:\n{ \u0026#34;retries\u0026#34;: { \u0026#34;runMode\u0026#34;: 1, \u0026#34;openMode\u0026#34;: 3 } } 第三步：识别零星的系统问题 - 不稳定的系统 鉴于以下情况：\n不存在可重现的缺陷 测试代码已经充分优化 已知并通过测试重试有效解决了流水线问题 已知、认可并通过测试重试解决了外部依赖和成长痛苦 \u0026hellip; 我们如何检测系统存在的更深层次问题，这可能表明存在不稳定的系统？以下是团队Cypress 仪表板上的一个示例快照：\n“在周末的 40 次执行中，它以 10% 的错误率失败\u0026hellip; 我们运行了测试套件 40 次，在其中的一次执行中看到该规范重试了 2 次，直到通过\u0026hellip;” 请注意：相机图标表示一些测试失败，因为 Cypress 在失败时会拍摄视频和截图。\n在这些情况下，可以通过每晚或周末的 cron 任务 进行一致性测试，作为更深层次系统问题的初始指标。这些通常是那些容易泄漏到生产环境中、在实际使用中被发现并具有昂贵后果的模糊缺陷。\n代码示例 - cron 任务 at minute 0 at midnight and 2 am, every day-of-week from Monday through Friday: 0 0,2 * * 1-5 At minute 0 past hour 2, 6, 8, 10, 12, 14, 16, 18, and 20 on every day-of-week from Saturday through Sunday: 0 2,6,8,10,12,14,16,18,20 * * 6-7 一旦排除了所有其他因素，并且在管道中使用 cron 任务自动化测试初步指示了“系统波动”，这些问题就是性能测试的理想候选项，因为这种测试方法可以直接指出可能导致“不稳定的系统”的系统缺陷。\n性能测试的要点如下： 有许多性能测试工具，其中一个我们认为比较易于使用的是 k6-loadImpact，因为它采用了 ES6 语法，并且与流水线兼容。 你可以在 这里 找到一个包含代码示例的简单教程。\n不稳定的测试参考资料 Google 测试博客：我们的测试中哪些是不稳定的，是从哪些方面产生的\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-advanced-test-states-and-test-flake/","summary":"这篇博文是 UI 测试最佳实践的进阶篇，首篇介绍测试状态和处理不稳定测试的方法。文章深入探讨了在 UI 测试中如何有效处理测试状态，以及应对测试不稳定性的最佳实践。读者将学到确保测试脚本可靠性的策略，包括等待机制、测试数据管理等方面的技巧。通过这个进阶篇的指南，读者能够更灵活地应对复杂的 UI 测试场景，确保测试结果的一致性和可信度。","title":"UI 测试最佳实践的进阶篇（一）：测试状态和不稳定的测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n视觉回归测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/tools/visual-regression-testing.md\n一段简要说明 视觉回归测试是通过比较代码更改后用户将看到的屏幕截图来验证 CSS 中的回归问题的一种方法。这主要用于覆盖 CSS 的回归问题，但也适用于涵盖窗口、跨浏览器/设备组合以及本地化问题。可以将其类比为 Jest 快照，但与将 DOM 作为文本进行比较不同，它实际上是通过实际屏幕截图的比较来实现的。\n视觉回归测试的过程包括：\n记录基准快照（初始执行）。\n再次执行视觉测试，并将其与基准快照进行比较（后续执行）。\n如果新的快照与基准快照匹配，则接受。\n否则，设置新的基准快照，或者这是一个视觉回归缺陷。\n视觉回归工具会找到任何像素差异。随着快照的增加和数量的增多，这可能变得复杂。视觉快照服务的一个主要优势是其具有 AI 功能；AI 可以随着时间的推移进行训练，我们可以训练它忽略我们可能不关心的微小快照差异。需要注意的是，通过给定快照名称，我们可以训练 AI 变得非常宽松，接受任何差异\n。因此，我们需要谨慎处理，以免误将有效的失败结果标记为通过。我们可以通过更改快照名称、窗口或代码的任何部分来重置训练。\n如果没有 AI，我们将不得不手动处理每一个微小的误差，接受或拒绝每一个不必要的负面结果。如果没有内置的跨浏览器和跨窗口测试，我们的测试套件将在本地或 CI 中呈指数增长。可以观看 Gil Tayar 的演讲为 CSS 编写测试以获取更多信息。\n服务的第二大优势在于它们可以通过单个测试解决跨窗口和浏览器的问题，因此我们无需在 CI 中重复执行相同的测试以涵盖不同的变体。\n使用 Percy 和 Applitools 的 Cypress 示例 所有的代码示例都可以在这个仓库中找到，里面包含一个带有 Percy 以及 Applitools 镜像的 ReactJS 应用程序，用于视觉测试。\n我们将深入了解两个流行的服务，Percy 和 Applitools，并演示这些服务如何通过维护视觉快照来节省带宽。我们还将讨论它们在涉及跨浏览器和窗口组合时如何成为一种增强力。\n使用服务进行视觉回归测试有一个共同的流程：\n记录默认快照并将其与后续测试执行中的新快照进行比较。我们必须首次接受初始快照。\n从那时起，与默认匹配的新快照将自动被接受。\n不匹配的新快照会在 Web 界面上触发通知；我们要么拒绝，要么接受这个新的基线。如果我们拒绝，那就是一个缺陷。如果我们接受，就有了一个新的基线，循环继续。\n假设我们想要验证用户的头像。\nPercy 流程 一个简单的测试，用于验证用户的头像。 // cypress/e2e/ui-integration/user-context-retainment.spec.js describe(\u0026#34;User selection retainment between routes\u0026#34;, () =\u0026gt; { before(() =\u0026gt; { cy.stubNetwork(); cy.visit(\u0026#34;/\u0026#34;); }); it(\u0026#34;Should keep the user context between routes - full snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // the visual test - full snapshot cy.percySnapshot(\u0026#34;User selection retainment between routes\u0026#34;); // \u0026lt;-- }); }); it(\u0026#34;Should keep the user context between routes - css-focused snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // the visual test - using custom command for css selector focus // \u0026lt;-- cy.get(\u0026#39;[data-cy=\u0026#34;user-details\u0026#34;]\u0026#39;).percySnapshotElement( \u0026#34;user details with custom selector\u0026#34; ); }); }); }); 在第一个测试中，我们看到了第一行代码，它截取了整个屏幕的截图。在后续的测试中，我们看到了 user-details 选择器的快照。由于 Percy 不支持直接的选择器快照，因此使用了自定义命令 percySnapshotElement。\n为了执行视觉差异测试，我们需要一个 Percy 账户和令牌。只有连接到该账户并通过 cy run 执行时，视觉测试才会运行。这主要用于 CI。详细信息请查看注册部分。\n一旦我们执行测试，Percy 界面中的初始快照如下。我们引入了一行测试代码，它在 4 个浏览器和 2 个窗口上运行；这是 8 个组合，在 CI 中我们无需担心。请注意，每个分辨率 x 浏览器都会消耗配额；如果我们测试了 2 个窗口和 4 个浏览器，这个一行测试代码将消耗 8 个配额。\n在后续的测试中，如果存在视觉差异（例如，如果我们关闭后端并且无法渲染图像），我们将在 Percy 界面中看到视觉差异的指示器。在这里，我们还可以验证不同浏览器和窗口之间的差异。\n到了这一步，我们可以训练 AI 不太聪明，自动接受将来可能出现的损坏的头像图像。然而，你可以想象到一些微不足道的像素差异，而我们并不关心这些。这就是视觉回归服务节省带宽的地方；维护视觉快照。\nPercy 的优势在于保持事情简单。然而，CI 设置是我们必须处理的额外工作。请参考博文指南获取有关设置 Percy 的所有详细信息。\nApplitools 流程 这是 使用 Applitools 编写的相同测试.\n// Applitools version of the visual test // cypress/e2e/ui-integration/user-context-retainment-applitools.spec.js describe(\u0026#34;User selection retainment between routes\u0026#34;, () =\u0026gt; { before(() =\u0026gt; { // Each test should open its own Eyes for its own snapshots cy.eyesOpen({ appName: \u0026#34;hooks-in-action\u0026#34;, testName: Cypress.currentTest.title, }); cy.stubNetwork(); cy.visit(\u0026#34;/\u0026#34;); }); it(\u0026#34;Should keep the user context between routes - full snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // full page test // \u0026lt;-- cy.eyesCheckWindow({ tag: \u0026#34;User selection retainment between routes\u0026#34;, target: \u0026#34;window\u0026#34;, matchLevel: \u0026#34;Layout\u0026#34;, }); }); }); it(\u0026#34;Should keep the user context between routes - css focused snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // partial page test // \u0026lt;-- cy.eyesCheckWindow({ tag: \u0026#34;user details with custom selector\u0026#34;, target: \u0026#34;region\u0026#34;, selector: \u0026#39;[data-cy=\u0026#34;user-details\u0026#34;]\u0026#39;, // if fully is true (default) then the snapshot is of the entire page, // if fully is false then snapshot is of the viewport. fully: false, }); }); }); afterEach(() =\u0026gt; { cy.eyesClose(); }); }); 我们注意到在测试开始和结束时需要执行的额外命令 cy.eyesOpen 和 cy.eyesClose。此外，我们还看到 cy.eyesCheckWindow 是非常可定制的，不像 Percy 中那样需要自定义命令。\n有关设置 Applitools 的详细信息以及与 Percy 的比较，请查看这篇博客文章。\n与 Percy 类似，使用 Applitools，我们的测试在不同的浏览器和窗口中执行，并记录基准快照。\n如果存在视觉差异，Web 界面上会有清晰的指示器。\n下面是 Percy 与 Applitools 代码的对比。\n总的来说，Applitools 在可配置性方面更强大，而 Percy 更注重简单性。Percy 的用户界面更为精简，更易于使用，而 Applitools 的用户界面相对较为繁忙，但经过多年的改进已经有了很大的提升。从代码数量的角度来看，Percy 显然更为简洁，因为它不需要执行 \u0026ldquo;打开\u0026rdquo; 和 \u0026ldquo;关闭\u0026rdquo; 操作，而是可以直接执行主要命令。对于本地开发体验而言，Applitools 更胜一筹；能够在 Cypress 的开放模式下执行测试，而不是通过繁琐的命令行命令，是一个很大的优势。在测试运行器中直接显示实际的视觉差异，相对于 Percy 的情况，Percy 中的视觉失败只在 Web 用户界面上显示，这也是 Applitools 的一个优势。在 CI 环境中，不需要配置任何 yml 文件，这也使 Applitools 更具竞争力。另一个优势是能够通过选择器拍摄 UI 的子部分的快照；这个功能在 Applitools 中是内置的，而在 Percy 中则需要使用自定义命令，而且不能确保在实际环境中的普适性。\n| | Percy | Applitools |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; |\n| 代码 | 代码量较少 | 更具配置性 |\n| 用户体验 | 精简易用 | 较为繁琐，但有较大改善 |\n| 本地开发 | 仅支持无头模式 | 同时支持 Cypress 开放模式 |\n| CI | 需要 yml 文件 | 无需 yml 文件 |\n| 配置 | 主要在 Web 应用上，视口配置为本地文件 | 本地文件 |\n| 子部分快照 | 需要使用自定义命令，可能不适用于所有场景 | 内置支持 |\n| 视觉差异 AI | 需要更多时间形成观点 | 需要更多时间形成观点 |\n视觉测试并非无成本；在没有服务的情况下，执行视觉测试需要持续的工程师资源。在 CI 中，服务为我们在不同视口和浏览器组合上节省了成本，我们测试的所有服务在这方面都表现得很一致。视觉服务之间的最大区别在于 AI 在多大程度上帮助我们省去视觉测试的维护成本。我们认为最关键的决策因素是在内部应用中长期使用这两个工具（4-8 周），并进行并行比较。这将有助于评估哪个工具的 AI 更好，能够降低视觉测试的维护工作，而这正是对技术娴熟的团队将该测试策略纳入其组合中的最大挑战。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-tools-visual-regression-testing/","summary":"这篇博文聚焦于 UI 测试最佳实践的工具，第二篇介绍了视觉回归测试。文章详细解释了视觉回归测试在 UI 开发中的重要性，以及如何利用相关工具进行自动化视觉测试。读者将了解如何捕捉和比较页面截图，以确保界面在开发过程中的变化不影响现有的设计。通过视觉回归测试，读者能够更全面地验证 UI 的外观和布局，提高测试的全面性和准确性。","title":"UI 测试最佳实践的工具篇（二）：视觉回归测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n一些 UI 测试问题及 Cypress 的解决方案 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/tools/ui-testing-problems-cypress.md\n招募贡献者：你是否是 TestCafé 专家？我希望将“问题”部分与“Cypress 如何解决它们”部分分开，并添加一个专门介绍 TestCafé 如何解决问题的章节！\n在测试前端应用程序时会面临一些“传统”测试不具备的挑战：你需要协调一个真实的浏览器。浏览器本质上是庞大的应用程序，你需要启动它们，通过专门的库进行管理，利用一些 API 来模拟用户可能执行的相同类型的交互，然后检查前端应用程序的状态（基本上是显示的内容）是否符合你的期望。\n这个过程及其涉及的步骤是使 UI 测试变得困难的原因。主要问题包括：\n一切都是异步的：用户模拟的交互是异步的，UI 异步响应，浏览器异步响应，你用于协调和与浏览器通信的工具也是异步的。 await page.goto(url); await page.click(\u0026#39;[data-test=\u0026#34;contact-us-button\u0026#34;]\u0026#39;); await expect(page).toMatch(\u0026#34;Contact Us\u0026#34;); 而一旦你需要处理更加复杂的情况，等待所有事情就会导致你深陷于管理承诺和递归承诺之中。\n你要自动化用户流程：因此，你需要复制用户流程，检查自动用户流程，调试失败的（还有自动的、超级快的）用户流程。 想象一下，你与同事并排工作，他遇到了问题，你要求他执行某个操作，以便你可以直接使用他的浏览器 DevTools 检查问题，但是当你需要检查问题时，他却不停地点击/输入。这就是在 UI 测试中遇到问题时需要面对的情况。暂停/停止正在运行的流程很困难，你需要多次重新运行相同的测试。\n在 Web 应用程序中，有很多情况可能会干扰元素的交互性：它的内部状态、标记属性、视觉外观、其他元素的外观等。其中一些很容易发现（例如，“禁用”属性），但有些则不是（具有更高 z-index 值的另一个元素）。总的来说，很难调试问题的原因，因为你需要仔细检查元素本身、整个页面、自动化交互的工具等。\n自动化和测试前端应用程序确实很有挑战，但有一些工具不能减轻痛苦，还有一些工具能为你赋予超能力，继续前进吧！\n常用工具 要自动化和测试前端应用程序，你需要两种不同的工具：\n一个测试运行器：负责执行测试本身的工具\n一个浏览器自动化工具：提供一些 API 与专门启动的浏览器进行交互的工具\n这两个工具是独立的，你选择的测试运行器（例如 Jest）在终端中运行（并提供所有测试反馈），而第二个工具（如 Selenium 或 Puppeteer）则打开一个浏览器，执行测试中编写的命令，并返回结果。\n基于终端的测试运行程序和浏览器自动化工具之间可以进行双向通信。\n这两个工具是相互独立的，这使得很多事情变得复杂！在浏览器中执行的操作非常快速！你可以减缓它们的速度，但无法暂停或停止它们！或者更确切地说，至少不能通过交互方式实现\u0026hellip; 因为你显然可以在代码编辑器中来回跳转，在你想要检查的步骤之后注释掉所有内容，重新运行测试并检查发生了什么。但这并不是一个理想的流程。而且由于测试是一个小程序，你知道你需要重复这个步骤很多次……\n在以上描述的方式中运行测试时，另一个问题出现了：通常你在终端登录（测试运行器工作的地方），而操作则发生在浏览器中。**你如何将它们连接起来？**你是否在终端和浏览器控制台中都添加时间戳记录？是否在你的前端应用程序上方添加一个固定的 DIV，显示正在运行的测试名称？在终端中发生的事情与通过终端执行（或记录）的事情之间的连接也很困难。\n最后但同样重要的是：在终端中调试测试时，你并不是在调试真实的 DOM 元素，而是在调试序列化/引用的元素。终端和浏览器之间没有任何双向交互性，因此你不能像你习惯的那样充分利用浏览器的 DevTools。\n相信我，以这种方式理解为什么测试失败或为什么浏览器不如你期望的那样工作真的很困难。但你必须在测试消耗过程的所有三个不同阶段面对这个问题：\n1：当你最初编写测试时\n2：当测试失败时，你不能将任何东西发送到生产环境\n3：当你需要更新它们因为规格发生了变化\n步骤 #1 和 #3 相当相似，#3 可能更快，但 #1 可能会令人筋疲力尽。如果你使用的工具不帮助你，#2 将使你对 UI 测试产生厌恶…\n测试运行器的用途 停下来，思考一下所提到的工具试图达到的目标，从测试运行器开始。\n测试运行器用于管理单元测试。当然，你可以按照自己的方式使用/插入它们，但它们基本上是为了超快速（并行化）的小型功能调用而设计的。它们没有类似浏览器 DevTools 的功能，但主要问题是测试超时。每个测试都有一个超时，这是完全合理的。由于超时，如果一个测试运行时间太长，测试运行器会将其终止。\n但是当你将测试超时与 UI 测试的需求结合在一起时，会发生什么呢？正如你所知，用户流程可能会非常漫长。有很多原因：\n交互本身可能会非常漫长，并涉及大量的点击、输入、计算、等待等。\n有很多东西根本无法（从时间角度）受控制，尤其是 XHR 请求！你无法知道 Docker 容器（或者暂存服务器）响应需要多长时间。如果后端没有使用 Docker，你还必须面对网络缓慢的问题。\n这些例子展示了 UI 测试可能会有多么不可预测。解决方案似乎很方便：增加测试超时时间！但这是最糟糕的解决方案，因为：\n测试超时是在出现问题时可以节省大量时间的“绞刑”。如果将超时设置为一分钟，如果单个测试未按预期工作，你将等待一分钟（60 秒！！！）。测试持续时间过长是开发人员讨厌测试的主要原因之一，因为流水线永远无法结束。尽管如此：在某些特定场景中，你无法确定 60 秒是否足够…… 想想 AWS Lambda 在慢服务器唤醒时所需的时间，再加上网络问题……\n调试过程怎么办？请记住，当由于超时而终止测试时，自动化浏览器会被自动关闭……\n最后但同样重要的是，记住你需要进行与 DOM 相关的断言。在 UI 测试中，你不处理对象、数组和基元，而是基本上处理 DOM 元素。像“我期望元素等于…”这样的断言是无效的，尽管对于单元测试而言是有效的，当然，这个问题通常通过外部插件来解决。\n浏览器自动化工具的用途 Selenium 和 Puppeteer 旨在提供一种简单、不依赖于魔法的 UI 自动化体验。它们并不是用于测试 UI，而只是为了自动执行用户交互。自动化和测试在某些方面有重叠，但它们并不相同。两者都试图理解按钮是否可点击，并尝试点击它，但前者在失败时会失败，而后者会尝试告诉你为什么失败。前者告诉你一个元素不在页面上，而后者告诉你它不在页面上是因为先前的 XHR 请求失败了。\n我们习惯于将测试运行器与浏览器自动化工具组合在一起，并尝试充分利用它们，但由于两个非集成且不同的工具无法提供的问题而感到困扰。\n再谈论测试（和待测试的应用程序）的可调试性：为了减速/调试/暂停/停止/使它们工作等等，你需要经常“休眠”测试。这是一种常见的实践，既因为它在短期内解决了问题，有时因为你没有其他选择（请阅读 等待，不要休眠 部分）。不幸的是，添加一些**“休眠”步骤会使测试变得越来越糟糕**，越来越慢。正如我之前所写的：测试的缓慢是导致开发人员讨厌 UI 测试的最常见缺陷之一。\n此外：**测试失败时会发生什么？**在理解如何修复错误之前，你可以采取什么措施了解问题？如果你足够幸运地在本地发现了有问题的测试，那么你的痛苦是有限的。但如果测试在流水线中失败，如果你没有界面，你怎么知道发生了什么？你是否添加了一些自动截图的保险伞？有什么比截图更直观的吗？不幸的是……\n你甚至需要利用第三方调试工具（React DevTools、Vue DevTools 等），但将它们安装到受控浏览器上的过程并不是世界上最方便的。\n最后但同样重要的是：对服务器进行存根化并断言关于 XHR 请求的内容可能被视为测试实现细节… 但我不这么认为，有两个原因：\n在谈到黑盒测试时，我们提到了（好的）实践，即避免测试某些东西的工作方式，只集中在它做了什么上。应用于前端应用程序时，意味着只测试应用程序向用户公开的功能，而不是它是如何公开的（它是否使用 React 或 Vue.js、是否将数据保存到 localStorage 或 sessionStorage 并不重要）。相同的原则也可以应用于客户端/服务器通信，但了解某事之所以没有发生是因为错误的 XHR 请求可能很困难（特别是当你以无头模式运行自动化浏览器时）。而通过断言请求负载、响应负载、响应状态等，你得到的帮助是无价的（始终关注测试在失败情况下如何引导你识别问题）。\n如果你使用 Pact 或类似的工具测试客户端/服务器合同，那么你就不需要这样做，但在你的工作流中是否有这类测试？\n如果你是前端开发人员，你知道你不能总是在后端工作完成后才开始工作。但如果他们为你提供了完整的 JSON 响应，存根化后端可以让你完成所有前端编码工作，只需在集成前端与后端时检查一切是否按预期工作。这涉及到生产力问题。\n隐性测试挑战 上述考虑带来了另一个问题：测试代码应该尽可能简单。测试允许你检查一切是否按预期工作，但它们毕竟是小型程序。因此，你需要随着时间来维护它们。由于你需要在一段时间后理解它们（如果你需要花费数小时来理解为什么和如何测试工作，那是不可行的，测试应该帮助你，而不是像糟糕的代码那样使你的生活变得复杂），因此它们的代码不应该很复杂（请阅读 将软件测试视为文档工具 部分）。\n然而，并非为像 UI 测试这样困难的任务而创建的工具并不帮助你编写简单的测试代码。因此，你的测试生活再次变得更加困难…… 因此，你注定要花费大量时间调试失败的测试，而不是理解前端应用程序中到底发生了什么问题（假设确实出现了问题……）。结果是测试的可信度降低……\nCypress 助力解决 别担心，我并不是为了让你感到悲伤而描述这种戏剧性的情况😉，而只是为了让你意识到你不需要混合使用通用工具，你需要一些专门设计的工具！我想到了两个工具：Cypress 和 TestCafé。两者都非常出色，因为它们只有一个目标：重新发明（或修复？）UI 测试领域。\n我将专注于 Cypress，并稍后将它们进行比较。 Cypress 是如何解决上述所有问题的？首先…\nCCypress 拥有用户界面 是的，你通过终端启动 Cypress，但是你是通过它的用户界面 来使用它的！而且该用户界面是与你的应用程序并排的！请看这个预览\n命令日志用户界面（左侧）与你的前端应用程序（右侧）并排运行。\n这是什么意思？命令日志用户界面 的主要特点有哪些？\n你直接获得 Cypress 正在执行的反馈。每次通过其命令（cy.click、cy.type 等）要求 Cypress 与页面交互时，Cypress 都会向测试运行器添加一个日志。这种冗长的自动日志记录在编写测试和调试测试时非常有帮助。它极大地提高了你的生产力，既因为它是自动的，又因为它与你的应用程序并排。 但是，正如我告诉过你的，当编写 UI 测试时，缺少追溯性的调试性是一个很大的缺陷…让我向你介绍…\n交互式时间旅行：不确定应用程序是如何达到特定命令或测试失败的？你想查看一下前一个步骤的 UI 吗？这就是命令日志是交互式的原因！你可以悬停在各个记录的步骤上，看看应用程序在特定步骤的外观！或者，显然，你可以固定一个步骤并检查 DOM，检查应用程序在该步骤之前/之后的外观等。这是另一个拯救生命的功能，无论是在初次接触时（在你不了解测试工具的情况下调试测试可能是一场噩梦）还是在日常测试工作中。它使测试检查变得如此方便，以至于你完全忘记了没有它是如何进行测试的。在 此视频 中查看其实际效果。 其他命令日志实用工具包括：\n命令详细日志：单击命令会在浏览器 DevTools 中显示更详细的日志\n断言检查：单击断言会在浏览器 DevTools 中显示预期值和结果。你无需以更详细的日志记录重新启动测试\n如果你监视 XHR 调用，则命令日志会显示受监视/存根调用的摘要以及它们被调用的次数\n… 还有更多，详见 Cypress 官方文档中的其功能。\nCypress 命令行 默认情况下，命令是异步的，请看下面的片段\ncy.visit(url); cy.click(\u0026#39;[data-test=\u0026#34;contact-us-button\u0026#34;]\u0026#39;); cy.contains(\u0026#34;Contact Us\u0026#34;).should(\u0026#34;be.visible\u0026#34;); 你注意到有 await 吗？没有，原因很简单：在 UI 中的所有事物都需要等待，为什么你要管理 await 呢？Cypress 会为你“等待”，这意味着如果一个 DOM 元素在你尝试与之交互时还没有准备好，没问题！Cypress 会重试（默认为 4 秒），直到可以与元素交互（用户的方式，因此仅当元素可见时，不被禁用，没有被覆盖等）。因此，你可以完全避免面对前端固有的异步性！\n上述功能还有一个效果：你还记得那个不太好的测试超时吗？好吧，把它忘掉吧！在 Cypress 中，测试没有超时！你无需猜测（并根据需要不断调整）测试的持续时间，每个命令都有自己的超时时间！如果出了什么问题，测试很快就会失败！而且如果测试顺利进行，就不会面临测试超时的问题！\n最后但并非最不重要的：与 DOM 相关的命令报告与 DOM 相关的错误，你需要的方式。看下面的例子：\nCypress 清晰地从用户/DOM 视角报告问题。\n很明显用户为什么无法在输入框中输入文字。Cypress 不是唯一一个具有像用户一样执行命令的工具，但其清晰的错误报告相当不同寻常。\n测试质量 在测试中，开发人员可能会犯很多常见的错误。有些错误可能微不足道，但有些则相当严重。Cypress 强制你避免一些错误，具体如何呢？\n通过 AAA-质量的文档：快来看一下，它包含了很多最佳实践和反模式。所有人都对文档的质量给予了高度评价。\n重置状态：测试不会共享状态，因为每个测试运行之前都会重置 cookies、localStorage 等。你当然可以创建智能命令，以保持测试的独立性（共享状态的真正问题在于测试的独立性，可以看一下我课程中的一个例子），但你无法跳过重置。这是个优势，相信我 😉\n移除了在断言失败时恢复测试的可能性，如果测试失败，你就无法继续进行。确实需要使测试更加稳定，即使有时可能看起来有些困难。这是一个明智的选择，否则你可能会被允许编写糟糕的测试。\n通过许多等待助手：重试能力 和 自动等待 是救命稻草，它们让你关心你的应用程序和测试，而不是等待元素等。Cypress 允许你等待 DOM 元素、XHR 请求、页面加载，并且它根据需要调整超时（XHR 请求或页面加载可能需要的时间比输入元素出现要长），而无需使用固定时间的等待（再次强调，请阅读等待，不要休眠部分\n生产力 Cypress 在另一个非常重要的方面获胜：提高生产力。请在专门的章节中详细了解：将你的测试工具用作主要的开发工具.\n调试 如上所述，没有一些专门功能的情况下，调试测试可能会成为一场噩梦。调试失败的测试有两种情况：\n在编写测试时\n在 CI/CD 流水线中测试失败时\nCypress 提供了两个令人惊叹的解决方案：\n播放/暂停 功能**：通过编程或通过 UI，你都可以暂停测试然后恢复。是的，它甚至提供逐步导航，就像你习惯于在代码中设置断点并逐步进行一样。使用播放/暂停两次后，你就再也离不开它了 😊 播放/暂停和时光旅行提供了令人惊叹的体验，让你完全忘记常见的费时调试困扰。\n自动截图和视频：如果测试失败，Cypress 会保存测试的最后一步的截图。有时，最后一步可以帮助你理解发生了什么（特别是如果你添加了很多表达明确意图的断言，在这里你可以阅读没有良好的逐步断言，你会面临什么风险），但如果截图不能帮助你太多\u0026hellip; Cypress 还会录制整个测试的视频，包括测试运行器 UI。有时，自动记录帮助我以最简单的方式发现与 CI 相关的问题。\n常见问题 我刚刚将 Cypress 介绍为一个完美的工具，现在我预先回答一些经常问我的常见问题：\nCypress 是否免费？是的，它是免费、开源、采用 MIT 许可。只有当你想要利用其 Dashboard 服务 时，才需要付费。简单来说：你希望 Cypress 托管你测试的视频吗？那就需要付费，否则一切都是免费的。\nCypress 是否支持除 Chrome 之外的其他浏览器？在我写作的时候（2020 年 1 月 21 日），Firefox 和 Edge 的支持正处于 beta 测试阶段。\n我提到了 TestCafé，它们之间的主要区别是什么？\nTestCafé 没有类似于 Test Runner UI 的功能，在我看来是一个很大的缺失。 TestCafé 在 DOM 元素超时到期时等待，而 Cypress 最多等待相同的超时时间。因此，使用 TestCafé 时，你必须手动校准等待时间，以避免测试运行时间过长，而使用 Cypress 则无需关心这个问题。 TestCafé 没有完整的 XHR 请求检查，这是一个有争议的问题，但我认为这是一个重要的功能，可以使测试更加可靠，并提供有用的错误报告。 TestCafé 支持所有现有的浏览器！这是一个独特的特点，而 Cypress 不支持所有浏览器，也不支持移动浏览器。请注意，跨浏览器的需求可能被高估，但如果你确实需要，TestCafé 是完美的工具。 Cypress 有缺点吗？当然有！它存在一个 与 window.fetch 相关的历史问题，这迫使你使用 Axios 或者 添加一个变通方法，而且你可能需要一些额外的步骤来处理 OAuth，因为你的应用运行在 iframe 中。但尽管如此，它仍然是最受欢迎的 UI 测试工具之一。\n更一般地说：请记住，我们正在讨论 UI 测试，Cypress 在这方面表现得特别出色。如果你只是需要自动化浏览器（用于数据抓取或其他用途），请不要使用它！\n结论 总的来说，上述问题和解决方案可以归纳如下：\n前端测试中存在异步问题，Cypress 几乎可以完全透明地处理这些问题。\n逐步调试：Cypress 的时光旅行和播放/暂停功能是你的得力助手。\nCypress 在测试失败时提供清晰的错误信息。\n调试变得非常方便，多亏了并排运行测试和应用程序。\n在测试失败时，自动截图和录像功能为诊断问题提供了帮助。\nCypress 测试本身没有超时限制，但 Cypress 命令有超时设置。\nCypress 允许你在没有后端的情况下轻松进行工作。\nCypress 具备许多提高生产力的功能。\nCypress 设计的唯一目标是使 UI 测试变得简单易行。\n参考资料 掌握 UI 测试 - 会议视频 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-tools-ui-testing-problems-cypress/","summary":"这篇博文聚焦于 UI 测试最佳实践的工具，首篇介绍一些 UI 测试问题及 Cypress 的解决方案。文章探讨了常见 UI 测试难题，详细介绍了 Cypress 框架如何提供强大的解决方案，包括实时查看、可靠性、速度等方面的优势。通过这些解决方案，读者能够更好地应对 UI 测试中的挑战，提高测试效率和可靠性。","title":"UI 测试最佳实践的工具篇（一）：一些 UI 测试问题及 Cypress 的解决方案"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n将测试视为文档工具 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/testing-perks/tests-as-documentation.md\n文档编写通常很困难，需要精确而细致的工作，并要求整个团队理解并重视撰写良好的文档。文档编写是一种无私的行为，对其他开发人员和未来的你都有帮助。\n测试方法不仅是确保我们编写的代码符合项目需求、防止引入回归的绝佳方式，还是对代码和用户流程进行文档编写的利器。\n通过将测试用例作为文档工具的好处包括：\n文档与代码紧密关联：所有 UI 测试都应该从用户的角度出发编写，它们的描述也应如此。观察用户在项目中能够完成的操作是了解项目功能的有效途径。\n每个代码库都由成千上万个小代码片段组成，有时可能很难将所有要点联系在一起。测试有助于对项目有一个总体了解，甚至包括很多技术细节。\n你不依赖于某些员工的历史记忆：很多时候，你最终会向一些了解项目并记得某些特定边缘案例的员工请教。一个良好的测试套件可以大大减少对这种知识的需求，并避免每个新开发人员通过几行代码引入回归问题。\n同时，交接和入职阶段变得相当容易。\n额外的一点是：如果你利用 Gherkin 语法，甚至对一些不太懂技术的人，比如 QA 团队来说，文档的效果都会提高。\n请记住：\n测试描述必须对于不了解项目背景的开发人员来说也必须清晰。\n重复使用的测试函数、固定装置等必须有有意义的名称。一个用于注册和登录测试的 registration-success.json 固定装置可能会误导未来的读者，并使历史知识变得必要。请记住，依赖历史知识总是对必须经受开发人员更替的代码库不利。\n总的来说，UI 测试在前端应用中起着基础作用，它们是唯一记录用户预期能够完成的真实目标的手段。\n测试的代码必须尽可能简单。易于阅读，无条件，抽象级别低，具有良好的日志级别等。永远记住测试必须减轻阅读和理解代码的认知负担，因此它们的复杂性应该比待理解的代码低一个数量级。这提高了开发人员在自动化浏览器中查看测试之后必\n须经历的深入过程。\n\u0026ldquo;连接\u0026quot;代码和测试：如果用户流程相当长，将一些“步骤”（带有一些注释）在源代码和测试代码之间共享可能是有用的。类似于 /** #1 \\*/、/** #2 \\*/ 等。\nUI 测试并不是唯一的测试类型：为代码的某些可能难以理解的部分编写更多的低级测试是描述代码期望行为的好方法。\n在测试中添加注释可以极大地帮助读者，参见\u0026ldquo;匹配测试代码和测试运行命令\u0026quot;章节中的“保持抽象水平以便于调试测试”一章。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-testing-perks-tests-as-documentation/","summary":"这篇博文强调了 UI 测试最佳实践中通用测试的好处，特别是将测试视为文档工具的优势。文章解释了通过编写清晰、可读的测试代码，测试不仅仅是验证功能的手段，还是项目文档的一部分。这种做法有助于项目团队更好地理解系统，提高协作效率，并为后续开发和维护工作提供有价值的参考。通过将测试视为文档工具，项目团队能够更好地利用测试来传递信息，确保系统的可靠性和可维护性。","title":"UI 测试最佳实践的通用测试的好处篇：将测试视为文档工具"},{"content":"写在前面 为什么不用 postman 和 insomnia 关于 Postman：Postman 于 2023 年 5 月宣布将逐步淘汰具有离线功能的 Scratch Pad 模型，大部分功能将转移到云端，这意味着用户必须登录才能使用 Postman。（不登录的情况下可使用的功能有限，登录的话不确认是否会向云端上传我们测试使用的接口信息，安全性不可预估） 关于 Insomnia：Insomnia 在 2023 年 9 月 28 日发布的 8.0 版本中开始加重了对云端的依赖，用户必须登录才能使用全功能的 Insomnia。现有的 Scratch Pad 功能有限（不登录的情况下可使用的功能有限，登录的话不确认是否会向云端上传我们测试使用的接口信息，安全性不可预估） 所以需要一个将 API 工作区数据与第三方服务器隔离的替代方案，Bruno 就是可行的替代方案之一。\n为什么选择 Bruno 官方说明：https://github.com/usebruno/bruno/discussions/269\n与 postman 的对比：https://www.usebruno.com/compare/bruno-vs-postman\n开源，MIT License\n客户端全平台支持 (Mac/linux/Windows)\n离线客户端，无云同步功能计划\n支持 Postman/insomina 脚本导入（只能导入 API 请求脚本，无法导入测试脚本）\n社区相对活跃，产品开发路线图清晰\n从 0 到 1 搭建 Bruno 接口自动化测试项目 这篇文章会更聚焦如何使用 Bruno 提供的功能，从零开始搭建一个接口自动化测试项目。\nBruno 程序的安装和基本使用请参考：postman 替换工具 bruno 使用介绍\n项目结构 Bruno 接口自动化测试项目的基础结构如下：\nBruno-demo ├── README.md // 项目说明文件 ├── package.json ├── package-lock.json ├── Testcase // 测试用例文件夹 │ └── APITestDemo1.bru // 测试用例文件 1 │ └── APITestDemo2.bru // 测试用例文件 2 │ └── bruno.json // bruno COLLECTION 配置文件 │ └── environments // 不同测试环境文件夹 │ └── dev.bru // 测试环境配置文件 │ └── Report // 测试报告文件 │ └── report.json //json 格式报告文件 ├── .gitignore └── node_modules // 项目依赖 项目搭建准备 新建项目文件夹 mkdir Bruno-demo 项目初始化 // 进入项目文件夹下 cd Bruno-demo // nodejs 项目初始化 npm init -y 安装 Bruno CLI 依赖 // 安装 Bruno CLI npm install @usebruno/cli --save-dev Bruno CLI 是 Bruno 官方提供的命令行工具，可以通过简单的命令行命令轻松运行 API 集合。我们可以更轻松地在不同环境中测试 API、自动化测试流程，并将 API 测试与持续集成和部署工作流程集成。\n使用 Bruno 编写接口测试用例 新建测试用例目录 运行 Bruno app 到首页 新建名称为 Testcase 的 COLLECTION，且选择 COLLECTION 的目录为上面创建的项目文件夹 新建 Get 请求测试用例 点击 Testcase 的 COLLECTION 下的 ADD REQUEST 按钮，新建一个 GET 请求 输入请求名称为 GetDemo，输入请求地址为 https://jsonplaceholder.typicode.com/posts/1 给 Get 请求添加测试断言 使用 Bruno 自带的 Assert 编写测试断言 点击 GetDemo 请求下的 Assert 按钮，进入测试断言编辑页面\n输入断言 1：响应状态码等于 200.断言 2：响应体中的 title 包含 provident 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 使用 JavaScript 编写测试断言 点击 GetDemo 请求下的 Tests 按钮，进入测试断言脚本编辑页面 输入脚本代码，断言 1：响应状态码等于 200.断言 2：响应体中的 title 包含 provident test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 新建 Post 请求测试用例 点击 Testcase 的 COLLECTION 下的 ADD REQUEST 按钮，新建一个 POST 请求\n输入请求名称为 PostDemo，输入请求地址为 https://jsonplaceholder.typicode.com/posts 点击新建的 PostDemo 请求下的 Body 按钮，进入请求体编辑页面\n选择 Body 类型为 JSON，输入请求体内容为\n{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 给 Post 请求添加测试断言 使用 Bruno 自带的 Assert 编写 Post 请求测试断言 点击 PostDemo 请求下的 Assert 按钮，进入测试断言编辑页面\n输入断言 1：响应状态码等于 201.断言 2：响应体中的 title 等于 foo 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 使用 JavaScript 编写 Post 请求测试断言 点击 PostDemo 请求下的 Tests 按钮，进入测试断言脚本编辑页面 输入脚本代码，断言 1：响应状态码等于 201.断言 2：响应体中的 title 等于 foo test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(201); }); test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 本地运行两个测试用例 点击 Testcase 的 COLLECTION 下的 Run 按钮，运行所有测试用例 确认运行结果是否符合预期 至此，两个接口的测试用例和断言已经编写完成\n环境变量配置 通过查看上面两个测试用例的运行结果，我们发现两个测试用例的请求地址都是 https://jsonplaceholder.typicode.com，如果我们需要在不同的测试环境中运行这两个测试用例，那么我们需要修改两个测试用例的请求地址，这样的话，如果测试用例很多，那么修改起来就很麻烦。Bruno 提供了环境变量的功能，我们可以将测试用例中的请求地址配置为环境变量，这样的话，我们只需要在不同的测试环境中配置不同的环境变量，就可以实现在不同的测试环境中运行测试用例。\n新建环境变量配置文件 点击 Testcase 的 COLLECTION 下的 Environments 按钮，进入环境变量配置页面 点击右上角的 ADD ENVIRONMENT 按钮，新建一个环境变量配置文件，输入名称为 dev，点击右上角的 SAVE 按钮保存配置文件 点击新建的 dev 环境变量配置文件，进入环境变量配置页面 点击右上角的 ADD VARIABLE 按钮，新建一个环境变量，输入名称为 host，输入值为 https://jsonplaceholder.typicode.com，点击右上角的 SAVE 按钮保存环境变量 在测试用例中使用环境变量 点击 Testcase 的 COLLECTION 下的 GetDemo 请求，进入 GetDemo 请求编辑页面 将 GetDemo 请求的请求地址修改为 {{host}}/posts/1，点击右上角的 SAVE 按钮保存 GetDemo 请求 点击 Testcase 的 COLLECTION 下的 PostDemo 请求，进入 PostDemo 请求编辑页面 将 PostDemo 请求的请求地址修改为 {{host}}/posts，点击右上角的 SAVE 按钮保存 PostDemo 请求 调试环境变量 点击 Testcase 的 COLLECTION 下的 Environments 按钮，选择 dev 环境变量 点击右上角的 RUN 按钮，运行所有测试用例，确认运行结果是否符合预期 至此，环境变量配置和调试已经完成\n命令行运行测试用例 前置检查 刚才我们已经测试用例的存储目录设置为了之前创建的项目文件夹，所以我们需要在项目文件夹下检查用例文件和环境变量配置文件是否已经创建成功。\n目前我们的项目文件夹目录结构如下：\nBruno-demo ├── package.json ├── package-lock.json ├── Testcase // 测试用例文件夹 │ └── APITestDemo1.bru // 测试用例文件 1 │ └── APITestDemo2.bru // 测试用例文件 2 │ └── bruno.json // bruno COLLECTION 配置文件 │ └── environments // 不同测试环境文件夹 │ └── dev.bru // 测试环境配置文件 └── node_modules // 项目依赖 命令行调试运行测试用例 在项目文件下的 Testcase 文件夹，运行命令行命令 bru run --env dev，运行所有测试用例\n确认运行结果是否符合预期\n输出 json 格式报告 在项目文件下的 Testcase 文件夹下新建 Report 文件夹，用于存放测试报告文件\n在项目文件下的 Testcase 文件夹，运行命令行命令 bru run --env dev --output Report/results.json，运行所有测试用例\n确认测试报告文件正常输出 至此，Bruno 接口自动化测试项目的搭建已经完成。\n集成到 CI/CD 流程 Bruno 程序的安装和基本使用请参考：postman 替换工具 bruno 使用介绍#接入 CI\n参考资料 Bruno 官方文档 https://docs.usebruno.com/ postman 替换工具 bruno 使用介绍 https://naodeng.com.cn/zh/posts/api-automation-testing/introduction_of_bruno/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/bruno-tutorial-building-your-own-project-from-0-to-1/","summary":"这篇博文是 Bruno 接口自动化测试教程，从零开始搭建 Bruno 接口自动化测试项目。文章详细指导读者如何建立测试项目的基础结构，配置环境，以及编写第一个接口测试用例。通过这个教程，读者能够逐步了解 Bruno 框架的使用方法，从零到一地构建起完整的接口自动化测试项目，提高测试效率和可维护性。","title":"Bruno 接口自动化测试教程：从 0 到 1 搭建 Bruno 接口自动化测试项目"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n从金字塔顶层入手测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/beginners/top-to-bottom-approach.md\n一段简要说明 当你是一位经验丰富的测试员时，处理测试套件是一件轻松的事情。但学习如何正确地测试，要测试什么、避免什么，选择哪种类型的测试等等，并不那么容易。\n测试在一开始是昂贵的。一切都是新的，你尝试实现的例子不起作用，你不清楚为什么测试失败，它与你的代码有什么关系，等等。\n我们都熟知测试金字塔，通常，我们从底部开始构建。\n标准测试金字塔方法：从下到上。\n从底部开始构建金字塔是有道理的。从单元测试入手更容易，因为它们运行快速，不需要复杂的上下文或工具。一个“单元”（无论你用“单元”表示什么：一个函数、一个组件等）仅包含几行代码，通常几乎没有依赖项（或根本没有依赖项）等等。\n这种方法的最大缺陷是什么？基本上是信心。\n测试关乎信心，以及在高信心但较慢的测试与低信心但较快的测试之间的权衡。\n如果你是测试领域的新手，术语“信心”可能不太清晰，那么你如何确保你正在开发的应用程序在测试通过时是有效的？这就是测试信心。\n为什么单元测试提供的信心如此之少？一些例子：\n如果isValidEmail函数通过了测试，你能确定你的前端应用程序的注册表单有效吗？ 如果Input React 组件通过了测试，你能确定注册表单也有效吗？ 如果整个RegisterForm组件通过了测试，你能确定用户可以注册吗？ 答案是否定的。整个应用程序由许多单元相互集成而成，还不包括一些呈现（CSS）问题，这可能会因为一个 z-index 较高的图像遮挡了提交按钮而阻止用户注册。\n再次谈论测试新手的经验缺失（就像我两年前一样）：每一项新事物都需要大量认知负担，而你不能同时面对太多的新事物。同时处理应用程序的常规开发、新的测试主题、单元测试世界和 UI 测试（后两者需要不同的工具和努力）是很困难的。\n看看这张详尽的图片，它来自 JavaScript 和 Node.js 测试最佳实践 项目：\n由 Yoni Goldberg 提供，请访问 testjavascript.com，并在 JavaScript 和 Node.js 测试最佳实践 资源库。\n对于经验丰富的开发人员来说是如此，而当你第一次接触测试领域时，情况更糟。\n自底向上的方法的结果 你不可避免地将大部分注意力放在金字塔的基础——单元测试上。你即将编写的一堆测试让你熟悉了测试的世界，但缺乏信心。你可能会发现自己在问：\n\u0026ldquo;我写的测试有什么好处呢？\u0026rdquo; \u0026ldquo;我花了一些时间与单元测试战斗，但应用程序仍然像以前一样崩溃，测试是否只是自娱自乐？\u0026rdquo; \u0026ldquo;老实说，我现在比开始测试之前更加疑惑了…\u0026rdquo; 从下到上的方法不可避免地会让你把精力集中在单元测试上。\n问题并不出在你身上，而是在于对于初学者来说，采用了错误的测试方法！\n那么，我的建议是什么呢？从金字塔的顶部开始，首先关注 UI 测试！\n首先，什么是 UI 测试（也称为功能测试、端到端测试等）？本质上，它是一种打开真实浏览器并与 DOM 元素交互的脚本，与真实最终用户的操作方式相同。有时候视频能够更生动地说明问题：看一看对 Conduit - RealWorld 项目运行的端到端测试和Conio 后台的一些 UI 测试。\n在上述视频中，你会看到一个真实的浏览器加载整个前端应用并与其进行交互。这种方法的优点包括：\n你的应用在与最终用户相同的环境（即浏览器）中进行测试，这意味着更高的信心。即使只编写一个 UI 测试，它也比一百个单元测试给你更多的信心。 受测路径（用户执行的步骤，如“注册”、“创建新 帖”等）与最终用户执行的路径相同，这意味着（对你而言）更低的认知负担，以了解你真正在测试什么。\n老实说，与自动化终端相比，自动化浏览器更有趣 😁 UI 测试最适用于你日常工作中大多数项目的小到中等规模。从落地页到小型 CMS：所有这些都至少需要一些 UI 测试，然而基于测试信心和你必须遵守的交付要求，你可能会对基于单元测试的测试信心和交付要求有所超越。只有少数人在 Facebook、Spotify、Netflix 等公司工作，这些公司需要严格的测试策略、代码覆盖要求等。总的来说：如果你为中型到大型产品公司工作，你可能不需要这篇文章，因为测试已经成为公司文化的核心🎉。 当然，这种方法也有一些缺点，但我稍后会列举出来。下面是我建议的方法：\n自上而下的方法\n从上到下的方法是否强制执行测试的不良实践？ 本文不讨论最佳实践或不良实践（请查看文章末尾的一长串资源），而是关注如何让新的前端开发人员在测试领域有益地参与。我的目标是提供一种更实际的方法，一种使开发人员能够享受测试的优势而不至于留下比以前更多的疑问的方法。\n如果 UI 测试如此神奇，为什么还有其他类型的测试存在？ 这正是关键！请注意，我并不反对单元测试！每种测试都很重要，不同的测试提供不同的反馈！从上到下的方法足够让开发人员喜欢整个测试世界。\n然后，你将发现高级别 UI 测试 的局限性：\n它们很慢：我知道上面的视频让你觉得它们运行得很快，但实际上并非如此。当你有五、十、二十个时，它们很快，但是当你有数百个 UI 测试并且它们需要几分钟时，你会开始思考如何改善情况 它们主要提供高层次的反馈：如果表单的提交按钮不起作用，那么问题是什么？有大量可能的原因，但是 UI 测试不能排除其中一些原因 它们呈现整个应用程序，如果你只想测试一些较小的东西，这可能会很麻烦。通过整个应用程序无法复制一些你需要测试的边缘情况 解决上述所有问题的方法是：降低测试金字塔！如果你需要更低级别的测试，那么做得好！这是本文的目标。\n考虑两种方法的结果：\n从下到上：对于你编写的单元测试的效用存在疑虑，并且你不理解这些测试如何帮助你提高测试信心 从上到下：你拥有一些有信心的测试，并最终需要深入测试金字塔。如果你不需要深入，这意味着你的项目很小，不需要更多的测试 然后，请从该项目的根目录开始，探索各种最佳实践，以便从一开始就成功地进行 UI 测试。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-beginners-top-to-botton-approach/","summary":"这篇博文是 UI 测试最佳实践初学者篇，建议从金字塔的顶层入手测试。文章解释了在 UI 测试金字塔的顶部，即端到端测试，开始学习的优势。通过此方法，初学者能够更容易理解应用程序的整体行为，快速验证关键路径，并逐步深入学习更底层的单元测试和集成测试。这种渐进的学习方式有助于建立坚实的 UI 测试基础，提高测试覆盖率和质量。","title":"UI 测试最佳实践的初学者篇：从金字塔顶层入手测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n检验请求和响应负载 原文链接:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/server-communication-testing/test-request-and-response-payload.md\n一段简要说明 前端应用因与后端通信不协调而导致停止工作的频率有多高？\n前端应用和后端应用之间存在一份合同，你始终需要测试合同是否得到遵守。每一次前后端应用之间的通信都由以下几个方面定义：\n请求的 URL 所使用的 HTTP 动词（GET、POST 等） 请求的有效负载和标头：前端应用发送给后端应用的数据 响应的有效负载、标头和状态：后端应用发送回前端应用的数据 你需要对所有这些方面进行测试，更广义地说，你需要等待每个相关的 AJAX 请求，为什么呢？\n相关的 XHR 请求是你正在测试的应用程序流程的一部分 即使 XHR 请求不是你正在测试的流程的一部分，它对达到期望的 UI 状态也可能是相关的 等待 XHR 请求可以使你的测试更为健壮，参见等待，不要休眠章节及其XHR 请求等待部分 在现有的测试工具中，完全等待和检查 XHR 请求并不那么常见，目前 Cypress 提供了最全面的检查支持。\n请注意：以下所有示例均基于 Cypress，它目前提供了最佳的 XHR 测试支持。\n对 XHR 请求进行断言的完整示例 // ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(interception =\u0026gt; { // request headers assertion expect(interception.request.headers).to.have.property(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); // request payload assertions expect(interception.request.body).to.have.property(\u0026#34;username\u0026#34;, \u0026#34;admin\u0026#34;); expect(interception.request.body).to.have.property(\u0026#34;password\u0026#34;, \u0026#34;asupersecretpassword\u0026#34;); // status assertion expect(interception.response.statusCode).to.equal(200); // response headers assertions expect(interception.response.body).to.have.property(\u0026#34;access-control-allow-origin\u0026#34;, \u0026#34;*\u0026#34;); // response payload assertions expect(interception.response.body).to.have.property(\u0026#34;token\u0026#34;); }); 在下面的章节中，我们将详细讨论 XHR 请求的不同特征。\n验证 XHR 请求的 URL 在 Cypress 中，用于请求的 URL 是通过cy.intercept调用定义的。你可能需要检查 URL 的查询字符串。\n// ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;**/authentication**\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(interception =\u0026gt; { // query string assertion expect(interception.request.url).to.contain(\u0026#34;username=admin\u0026#34;); expect(interception.request.url).to.contain(\u0026#34;password=asupersecretpassword\u0026#34;); }); 请注意，当你需要对多个主题进行断言时，Cypress 的then =\u0026gt; expect语法非常有帮助（例如，URL 和状态）。如果你只需要对单个主题进行断言，可以使用更具表现力的should语法。\ncy.wait(\u0026#34;@authentication-xhr\u0026#34;) .its(\u0026#34;url\u0026#34;) .should(\u0026#34;contain\u0026#34;, \u0026#34;username=admin\u0026#34;) .and(\u0026#34;contain\u0026#34;, \u0026#34;password=asupersecretpassword\u0026#34;); XHR 请求的方法 在 Cypress 中，请求使用cy.intercept函数定义。你可以通过指定它来定义要拦截的请求类型。\n// the most compact `cy.intercept` call, the GET method is implied cy.intercept(\u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // method can be explicitly defined cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // the extended `cy.intercept` call is available too cy.intercept({ method: \u0026#34;POST\u0026#34;, url: \u0026#34;**/authentication\u0026#34; }).as(\u0026#34;authentication-xhr\u0026#34;); 验证 XHR 请求的 payload 和 headers 对 XHR 请求的 payload 和 headers 进行断言允许你立即获得有关糟糕的 XHR 请求原因的详细反馈。必须在每个 XHR 请求上进行检查，以确保一切都正确地表示了测试执行的 UI 操作。\n// ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(interception =\u0026gt; { // request headers assertion expect(interception.request.headers).to.have.property(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); // request payload assertions expect(interception.request.body).to.have.property(\u0026#34;username\u0026#34;, \u0026#34;admin\u0026#34;); expect(interception.request.body).to.have.property(\u0026#34;password\u0026#34;, \u0026#34;asupersecretpassword\u0026#34;); }); 验证 XHR 请求响应的 payload, headers 和 status 响应必须百分之百符合前端应用的预期，否则可能向用户展示意料之外的状态。响应断言在完整的端到端测试中很有用，但在 UI 集成测试中则无关紧要（TODO：链接到集成测试页面）。\n// ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(intercept =\u0026gt; { // status assertions expect(intercept.response.statusCode).to.equal(200); // response headers assertions expect(intercept.response.body).to.have.property(\u0026#34;access-control-allow-origin\u0026#34;, \u0026#34;*\u0026#34;); // response payload assertions expect(intercept.response.body).to.have.property(\u0026#34;token\u0026#34;); }); 测试监控 原文链接：:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/server-communication-testing/monitoring-tests.md\n一段简要说明 随着前端期望的提高，服务器和服务的复杂性也在增加。前端应用需要变得越来越快：代码拆分、懒加载、Brotli 压缩等性能优化解决方案已成为标准。还有一些令人惊叹的解决方案，如基于机器学习和分析数据的代码拆分和资源预加载。此外，JAMstack 站点生成器可用于避免手动管理许多性能优化，但它们的配置和构建过程可能会破坏已经测试过的功能。\n有很多我们一旦测试过就认为理所当然的功能，但它们并非无法回归，可能会导致灾难。例如：\nsitemap.xml 和 robots.txt 的爬行配置（通常每个环境都不同） 使用 Brotli/gzip 提供的资产：错误的内容编码可能会破坏站点的所有功能 针对静态或动态资产的不同配置的缓存管理 这些问题可能看起来很明显，但比你想象的更微妙。如果你关心用户体验，就应该保持监控，因为通常在发现问题时已经为时过晚。我知道不能监控所有事物，但是测试应用的次数越多，测试就越能成为首要的质量检查工具。\n监控测试也可以与 E2E 测试集成（毕竟，它们只是简单的 E2E 测试），但将它们保持分开可以帮助你在需要时运行它们。上述大多数事项与 DevOps 相关，有了超快的监控测试，您可以获得即时而专注的反馈。\nCypress 示例 缓存监控测试示例 const urls = { staging: \u0026#34;https://staging.example.com\u0026#34;, production: \u0026#34;https://example.com\u0026#34;, } const shouldNotBeCached = (xhr) =\u0026gt; cy.wrap(xhr).its(\u0026#34;headers.cache-control\u0026#34;).should(\u0026#34;equal\u0026#34;, \u0026#34;public,max-age=0,must-revalidate\u0026#34;) const shouldBeCached = (xhr) =\u0026gt; cy.wrap(xhr).its(\u0026#34;headers.cache-control\u0026#34;).should(\u0026#34;equal\u0026#34;, \u0026#34;public,max-age=31536000,immutable\u0026#34;) // extract the main JS file from the source code of the page const getMainJsUrl = pageSource =\u0026gt; \u0026#34;/app-56a3f6cb9e6156c82be6.js\u0026#34; context(\u0026#39;Site monitoring\u0026#39;, () =\u0026gt; { context(\u0026#39;The HTML should not be cached\u0026#39;, () =\u0026gt; { const test = url =\u0026gt; cy.request(url) .then(shouldNotBeCached) it(\u0026#34;staging\u0026#34;, () =\u0026gt; test(urls.staging)) it(\u0026#34;production\u0026#34;, () =\u0026gt; test(urls.production)) }) context(\u0026#39;The static assets should be cached\u0026#39;, () =\u0026gt; { const test = url =\u0026gt; cy.request(url) .its(\u0026#34;body\u0026#34;) .then(getMainJsUrl) .then(appUrl =\u0026gt; url+appUrl) .then(cy.request) .then(shouldBeCached) it(\u0026#39;staging\u0026#39;, () =\u0026gt; test(urls.staging)) it(\u0026#39;production\u0026#39;, () =\u0026gt; test(urls.production)) }) }) 内容编码监控测试示例 context(\u0026#39;The Brotli-compressed assets should be served with the correct content encoding\u0026#39;, () =\u0026gt; { const test = url =\u0026gt; { cy.request(url) .its(\u0026#34;body\u0026#34;) .then(getMainJsUrl) .then(appUrl =\u0026gt; cy.request({url: url + appUrl, headers: {\u0026#34;Accept-Encoding\u0026#34;: \u0026#34;br\u0026#34;}}) .its(\u0026#34;headers.content-encoding\u0026#34;) .should(\u0026#34;equal\u0026#34;, \u0026#34;br\u0026#34;)) } it(\u0026#39;staging\u0026#39;, () =\u0026gt; test(urls.staging)) it(\u0026#39;production\u0026#39;, () =\u0026gt; test(urls.production)) }) 抓取监测测试示例 context(\u0026#39;The robots.txt file should disallow the crawling of the staging site and allow the production one\u0026#39;, () =\u0026gt; { const test = (url, content) =\u0026gt; cy.request(`${url}/robots.txt`) .its(\u0026#34;body\u0026#34;) .should(\u0026#34;contain\u0026#34;, content) it(\u0026#39;staging\u0026#39;, () =\u0026gt; test(urls.staging, \u0026#34;Disallow: /\u0026#34;)) it(\u0026#39;production\u0026#39;, () =\u0026gt; test(urls.production, \u0026#34;Allow: /\u0026#34;)) }) 由NoriSte 在 dev.to 和 Medium进行联合发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-server-communication-testing-test-the-request-and-response-payloads-and-monitoring-tests/","summary":"这篇博文深入探讨了 UI 测试最佳实践中的服务通信测试，重点关注请求和响应负载的验证以及测试监控。读者将学到如何有效检验 UI 与服务之间的请求和响应负载，以确保系统交互的正确性和可靠性。博文还介绍了在 UI 测试中如何进行监控，以及监测服务通信过程中的性能和可用性。通过这些实践，读者能够更全面地覆盖 UI 测试中的服务通信方面，提高测试的全面性和准确性，确保系统的正常运行。","title":"UI 测试最佳实践的服务通信测试：检验请求和响应负载，测试监控"},{"content":"输出 html 报告 通过之前的 K6 的默认测试报告来看，K6 本身只能输出命令行的报告，没有图形化界面的测试报告。\n如果我们想要生成图形化界面的测试报告，可以使用第三方提供的 K6 HTML Report Exporter v2 插件来生成 html 报告。\n下面是使用 K6 HTML Report Exporter v2 插件来生成 html 报告的步骤：\n在测试脚本中引入 K6 HTML Report Exporter v2 插件 import { htmlReport } from \u0026#34;https://raw.githubusercontent.com/benc-uk/k6-reporter/main/dist/bundle.js\u0026#34;; 在测试脚本中配置 K6 HTML Report Exporter v2 插件 export function handleSummary(data) { return { \u0026#34;summary.html\u0026#34;: htmlReport(data), }; } 完整的测试脚本示例 import { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; import { htmlReport } from \u0026#34;https://raw.githubusercontent.com/benc-uk/k6-reporter/main/dist/bundle.js\u0026#34;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, }); } export function handleSummary(data) { return { \u0026#34;summary.html\u0026#34;: htmlReport(data), }; } 使用 k6 运行测试脚本即可在项目根目录生成名称为 summary.html 的 html 报告 打开 summary.html 报告即可查看 html 报告。 更多关于 K6 HTML Report Exporter v2 插件的用法，请参考官方文档 https://github.com/benc-uk/k6-reporter[https://github.com/benc-uk/k6-reporter]\n持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 k6.yml。\n编辑 k6.yml 文件：将以下内容复制到文件中\nname: K6 Performance Test on: [push] jobs: build: name: Run k6 test runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 - name: Run k6 local test uses: grafana/k6-action@v0.3.1 with: filename: demo.js flags: --vus 50 --duration 10s 提交代码：将 k6.yml 文件添加到仓库中并提交。\n查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 K6 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 我们也通过 github action 输出 html 报告，先调整一下 k6.yml 文件\nname: K6 Performance Test on: [push] jobs: build: name: Run k6 performance test runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 - name: Run k6 local test uses: grafana/k6-action@v0.3.1 with: filename: demo.js flags: --vus 50 --duration 10s - name: Archive K6 performance test report uses: actions/upload-artifact@v3 with: name: K6-performance-test-report path: summary.html - name: Upload K6 performance test report to GitHub uses: actions/upload-artifact@v3 with: name: K6-performance-test-report path: summary.html 提交代码：将 k6.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 K6 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果和测试报告附件。 参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-advanced-usage-output-html-report-and-ci-cd-integration/","summary":"这篇博文深入探讨了 K6 性能测试的进阶用法，集中介绍了输出 HTML 报告和在 CI/CD 中集成 K6 的实践，特别以 GitHub Actions 为例。读者将学到如何生成详细的 HTML 测试报告，以及如何通过 GitHub Actions 集成 K6 到 CI/CD 流程中，实现自动化性能测试。这种高级用法不仅提供了更直观的性能测试结果展示，还确保了性能测试的及时执行，有助于在开发过程中发现和解决潜在的性能问题。","title":"K6 性能测试教程 - 进阶用法：输出 html 报告和 CI/CD 集成"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n将您的测试工具用作主要的开发工具 原文链接:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md\n一段简要说明 一个实例展示出问题的本质。比如说，你正在开发一个身份验证表单，可能的步骤是：\n编写用户名输入字段的代码 在浏览器中手动测试它 编写密码输入字段的代码 在浏览器中手动测试它 编写提交按钮的代码 编写 XHR 请求的处理代码 然后，你遇到了一个问题，因为在不修改源代码的情况下，你需要一个虚拟的或模拟的服务器来响应应用程序的 XHR 请求。于是，你开始编写一个集成测试：\n填写用户名输入字段 填写密码输入字段 点击提交按钮 检查 XHR 请求 模拟 XHR 的响应 检查反馈 对每个错误流程进行相同的测试步骤 编写处理错误流程的代码 重新检查测试结果 看一下第一个测试步骤，它们与我们在编写身份验证表单时手动执行的步骤相同。然后，我们为服务器的响应创建了存根，并检查表单的最终行为（包括成功或失败的响应）。\n这个工作流程可以很容易地得到改进，如果我们在编写表单的同时编写测试（TDD 开发者已经训练成这样）：\n编写用户名输入字段的代码 * 编写填充用户名输入字段的测试* 编写密码输入字段的代码 更新测试以填充密码输入字段 编写提交按钮的代码 更新测试以点击提交按钮 在测试中创建 XHR 的响应存根 编写 XHR 请求的管理代码 检查反馈 编写错误流程的管理代码 更新测试以检查错误流程 对于每个错误流程，重复以上步骤 * 请注意，如果要采用严格的 TDD 方法，可以颠倒第一步和第二步的顺序。\n这样做的最重要的好处是什么？\n你几乎完全避免手动测试应用程序 充分利用测试工具的速度，它以惊人的速度填充表单，让你节省大量时间 无需在编写表单后再编写测试（TDD 开发者已经避免这样做），尽管最初可能看起来有点烦人 完全避免在源代码中引入一些临时状态（例如输入字段的默认值、虚假的 XHR 响应） 直接用真实的网络响应测试你的应用程序（请记住，应用程序不知道网络请求是由测试工具存根的） 每次保存测试文件时都重新启动测试 可以充分利用 Chrome DevTools 和框架特定的开发工具 如何充分利用现有的开发工具？\n嗯，几乎每个测试工具都可以做到这一点，但 Cypress 在这方面脱颖而出。Cypress 拥有一个专门的 Chrome 用户，该用户在所有你的测试和所有你的项目中都是持久存在的。通过这样做，Cypress 允许你拥有一个真正专为测试而设的浏览器，其中包含你喜欢的扩展，即使你使用的是与浏览相同的 Chrome 版本。\n将其与出色的用户界面结合起来，你就可以准备好直接使用 Cypress 开发应用程序。下面你可以看到 Cypress 用户界面的一些截图，展示了将其作为主要开发工具使用的简便性。\n浏览器选择 Cypress 控制的浏览器开发者工具 Cypress Skip 和 Only UI 插件 这个工具让你可以直接在 Cypress UI 中为测试添加.only或.skip。 Cypress 观察和重新加载插件 此功能使您能够在每次源代码编译时重新运行 Cypress 测试。\n如果您想在 Cypress 控制的浏览器中查看 React/Redux 开发工具的实际效果，可以使用 cypress-react-devtools 存储库。\n此文由 NoriSte 在 dev.to 和 Medium上进行联合发表。\n保持低抽象度以便于调试测试 原文链接:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/ui-tests-debugging-best-practices.md\n一段简要说明 UI 测试涉及许多步骤，主要有三个关键目标，但其中两个往往被低估：\n测试一个功能（显而易见） 帮助读者理解代码的作用（通常被低估） 简化调试（被低估，同时需要经验） 下面让我们一起了解编写 UI 测试时要记住的一些简单但有效的技巧。\n可读性 关于测试中抽象的问题是一个有争议的话题（Page-Object Model 的粉丝可能会对此有异议）。\n让我们看一个我不得不修复的真实测试的例子。\n// spec.ts file it(\u0026#39;Create Query Action\u0026#39;, createQueryAction); // test.ts file (simplified version) export const createMutationAction = () =\u0026gt; { // ... clearActionDef(); typeIntoActionDef(statements.createMutationActionText); clearActionTypes(); // ... }; // test.ts file contains the clearActionDef, typeIntoActionDef, etc. const clearActionDef = () =\u0026gt; { cy.get(\u0026#39;textarea\u0026#39;).first().type(\u0026#39;{selectall}\u0026#39;, { force: true }); cy.get(\u0026#39;textarea\u0026#39;).first().trigger(\u0026#39;keydown\u0026#39;, { keyCode: 46, which: 46, force: true, }); }; // test.ts file contains also the statements const statements = { createMutationActionText: `type Mutation { login (username: String!, password: String!): LoginResponse }`, createMutationCustomType: `type LoginResponse { accessToken: String! } `, createMutationHandler: \u0026#39;https://hasura-actions-demo.glitch.me/login\u0026#39;, // ... } 短函数的背后思路是创建小而可重复使用的代码片段，以帮助其他需要在页面上执行类似操作的测试。\n我认为这不太好，因为很难建立对测试的执行过程的心智模型！所有测试部分都被分割成小函数和实用程序，而测试的代码必须尽可能地直截了当。\n你还记得章节开头提到的两个被低估的点吗？这个想法是测试应该实现三个主要目标：\n帮助读者理解代码的作用 以便轻松进行调试 前者要求测试的代码尽可能简单，而在测试的代码中使用抽象并没有好处，因为这会导致花费更多时间调试和维护测试，而不是应用程序。\n后者与测试的错误部分有关：调试/修复它们。调试 UI 测试很困难，因为你需要处理以下元素：\n你的前端应用程序 浏览器 控制浏览器的工具 你提供给控制浏览器的工具的指令 上述每个元素都可能出现问题，即使是经验丰富的开发人员也可能在理解测试失败的原因时感到困扰。\n因此，端到端测试是复杂的。Cypress 提高了开发人员的生活质量（在 一些 UI 测试问题和 Cypress 方法 章节中了解更多），但直截了当的代码会极大地帮助。\n不使用任何抽象 我建议根本不使用抽象（稍后，我将讨论一些例外情况以及哪种抽象是好的）！我将上述例子改写为如下形式：\nit(\u0026#39;Test the feature\u0026#39;, () =\u0026gt; { cy.get(\u0026#39;textarea\u0026#39;).eq(0).as(\u0026#39;actionDefinitionTextarea\u0026#39;); cy.get(\u0026#39;textarea\u0026#39;).eq(1).as(\u0026#39;typeConfigurationTextarea\u0026#39;); cy.get(\u0026#39;@actionDefinitionTextarea\u0026#39;).clearConsoleTextarea().type( `type Mutation { login (username: String!, password: String!): LoginResponse }`, { force: true, delay: 0 } ); cy.get(\u0026#39;@typeConfigurationTextarea\u0026#39;).clearConsoleTextarea().type( `type LoginResponse { accessToken: String! } `, { force: true, delay: 0 } ); // ... }) 重写后的测试与原始测试执行相同的操作，但当你查看测试代码时，无需来回跳转来在脑中建立连接。\n想知道在文本区域中输入了什么吗？毫不费力，就在那里！ 想知道文本使用的是哪个文本区域吗？毫不费力，就在那里！ 在测试中什么时候使用抽象化是好的呢？ 在我看来：\n当我想隐藏一些可能没有价值但可能分散读者注意力的测试怪癖时 当它们是软的，几乎不带参数，只有一层深度 当存在相当数量的重复（确切的数量是主观的） 一个测试怪癖的例子是下面这个\n/** * Clear a Console\u0026#39;s textarea. * Work around cy.clear sometimes not working in the Console\u0026#39;s textareas. */ Cypress.Commands.add(\u0026#39;clearConsoleTextarea\u0026#39;, { prevSubject: \u0026#39;element\u0026#39; }, el =\u0026gt; { cy.wrap(el).type(\u0026#39;{selectall}\u0026#39;, { force: true }).trigger(\u0026#39;keydown\u0026#39;, { keyCode: 46, which: 46, force: true, }); }); 我创建了中心的 cy.clearConsoleTextarea，原因如下：\n这是一种权宜之计 😊 对于新手来说，阅读 trigger('keydown') 而不是使用更符合习惯的 cy.clear 是有点奇怪的，我不想在每个地方都留下解释的注释。 该命令由 5 行代码组成，将使测试代码变得过长而毫无必要。 以下内容是软抽象的一个例子：\nfunction expectSuccessNotification = (title: string) { cy.get(\u0026#39;.notification-success\u0026#39;) .should(\u0026#39;be.visible\u0026#39;) .should(\u0026#39;contain\u0026#39;, title) } 我喜欢它的原因是\n它不依赖其他抽象代码：如果我的测试在 expectSuccessNotification('Table created!') 失败，我不必陷入深奥的代码中，理解 expectSuccessNotification 背后发生了什么。 它只接受一个变量，而不是很多选项；也没有包含那些在理解代码最终执行内容时变得复杂的条件。 它专注于特定用例。它不试图一次性涵盖所有通知类型、内容等。其他专注于特定用例的函数会处理。 如果你重构通知系统，你有一个中心点进行重构，以适应新的通知系统。 相反，这是我不希望拥有的（在谈论通知工具时）。\nexport const expectNotification = ( { type, title, message, }: { type: \u0026#39;success\u0026#39; | \u0026#39;error\u0026#39;; title: string; message?: string; }, timeout = 10000 ) =\u0026gt; { const el = cy.get( type === \u0026#39;success\u0026#39; ? \u0026#39;.notification-success\u0026#39; : \u0026#39;.notification-error\u0026#39;, { timeout } ); el.should(\u0026#39;be.visible\u0026#39;); el.should(\u0026#39;contain\u0026#39;, title); if (message) el.should(\u0026#39;contain\u0026#39;, message); }; 我对上面的例子不太喜欢，原因有两点：\n它试图一次性涵盖太多用例。 如果测试失败，你必须处理让整个体验变成噩梦的各种条件。 在Hasura 控制台 UI 编码模式：测试文章中，你可以找到我们在内部遵循的更多最佳实践。\n匹配测试代码和测试运行器命令 Cypress 测试运行器有助于理解应用程序中发生了什么以及执行了哪些命令，但在调试测试时，很难立即在测试运行器和代码之间建立关联。而且，日志无法帮助理解测试从功能角度正在做什么（例如，日志说“在文本区域中键入”，但没有说明“在类型配置文本区域中键入”）。因此，查找失败的根本原因是困难的。Cypress 会为失败的测试记录视频，但如果阅读者/调试者不能在日志和测试在普通英语中所做的事情之间建立直接关联，则视频就毫无用处。\n请看下面的内容 我添加了一个日志，报告测试正在进行的操作，使测试代码与测试运行程序之间能够直接对应。 (cy.log('**--- Type in the Webhook Handler field**');).\n请注意，你可以向 \u0026lsquo;cy.log\u0026rsquo; 传递更多参数，这些参数将在单击记录的命令时直接显示在开发工具的控制台中。\nStorybook 和 Playwright 已经引入了step实用工具的概念，可以用英语解释测试中的步骤。Cypress 没有相同的选项，因此我认为我提出的cy.log是很有价值的。\n这里需要注意：不要将cy.log链在一起，因为它不是一个查询命令，不会对链进行重试。\n截至 Cypress V12 版本，cy.log在函数级别不进行重试。\n例如：\ncy.log(\u0026#39;foo\u0026#39;).get(\u0026#39;bar\u0026#39;).should(\u0026#39;baz\u0026#39;) // does not retry cy.get(\u0026#39;bar\u0026#39;).should(\u0026#39;baz\u0026#39;) // retries the whole chain until the assertion passes (you have 10 sec timeout set) 值得注意的是，即使 Cypress 没有 step，Filip Hric 的 cypress-plugin-steps 也是一个有效的替代选择。\n使用清晰的选择器 看一下这段代码\ncy.get(\u0026#39;textarea\u0026#39;) .eq(0) .type(`{enter}{uparrow}${statements.createMutationGQLQuery}`, { force: true, }); cy.get('textarea').eq(0) 是什么？在没有更好的选择器的情况下，我建议将它们放在 Cypress 的别名下，比如\n// Assign an alias to the most unclear selectors for future references cy.get(\u0026#39;textarea\u0026#39;).eq(0).as(\u0026#39;actionDefinitionTextarea\u0026#39;); cy.get(\u0026#39;textarea\u0026#39;).eq(1).as(\u0026#39;typeConfigurationTextarea\u0026#39;); 然后通过这种方式来引用它们\ncy.get(\u0026#39;@actionDefinitionTextarea\u0026#39;).clearConsoleTextarea().type(/* ... */); 以提高读者的体验。\n减少 data-testid 属性 我不想讨论测试本身及其对测试结果可信度的价值，只想谈谈 data-testid 属性在调试阶段的影响。\n如果无法从页面中检索带有 data-testid 属性的元素，可能的问题有：\n元素不存在。 元素存在，但它没有该属性。 元素存在，具有该属性，但值不符合预期。 上述所有问题都会导致开发人员重新启动测试、检查元素、查找与测试相关的属性等。相反，如果测试基于文本内容，仅通过截图就足以了解测试搜索的文本是否不存在或错误。\n此外，对于那些必须处理 data-testid 的工程师来说，还有一些不足之处：\n在重构期间必须维护与测试相关的属性，但在有数百个属性时并不容易。 如果测试相关的属性在页面上是唯一的，那么它们会很有帮助。然而，当你有数百个这样的属性时，很难保证它们是唯一的。 我的建议是仅在以下情况使用 data-testid 属性：\n用于节，而不是元素（例如 Header、Footer 等），以减小基于文本搜索的范围。以下是一个示例： cy.get(\u0026#39;[data-test=\u0026#34;Actions list\u0026#34;]\u0026#39;).within(() =\u0026gt; { // \u0026lt;-- reduce the scope cy.contains(\u0026#39;login\u0026#39;) // \u0026lt;-- the \u0026#34;login\u0026#34; text could exist more times in the page }) 非文本元素，如图标、图片等。 最后但同样重要的是：我建议为它们赋予用户友好的值，而不是采用程序员的命名风格（例如，“操作列表”而不是“actionsList”），尤其是当该部分显示相同文本时。这样可以直接关联测试代码、Cypress 的测试运行器和页面的文本内容。\n将相关操作分组 通常来说，阅读一系列平面的交互并不能帮助理解测试运行的页面结构。\n例如：\n获取 1 并点击 获取 2 并点击 获取 3 并点击 获取 4 并点击 获取 5 并点击 获取 6 并点击 获取 7 并点击 获取 8 并点击 然而，将列表展开可以帮助读者构建一个有关所涉及部分位置的心理模型\n在块 1 内 获取 1 并点击 获取 2 并点击 获取 3 并点击 在块 2 内 获取 4 并点击 获取 5 并点击 获取 6 并点击 获取 7 并点击 获取 8 并点击 再强调一下：Storybook 和 Playwright 已经引入了“步骤（step）”实用程序的概念，该实用程序可以将操作进行分组，而上述建议在 Cypress 中非常实用。\n相关章节 🔗 从晦涩难懂的 React 组件测试到简单、易读的版本 由 NoriSte 在 dev.to进行发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-best-practices-3-use-your-testing-tool-as-your-primary-development-tool-and-keep-abstraction-low-to-ease-debugging-the-tests/","summary":"这篇博文深入研究 UI 测试的通用最佳实践之三：将测试工具作为主要开发工具，并保持低抽象度以便于调试。文章强调将测试工具纳入主要开发过程，加强测试与开发的协同，提高代码质量。另外，博文建议保持测试脚本的低抽象度，以便更容易调试和理解。这种做法有助于加速问题排查和测试脚本的维护，从而提高 UI 测试的效率和可靠性。通过采用这些通用最佳实践，读者将能够更好地整合 UI 测试到开发流程中，实现更高效的软件开发。","title":"UI 测试最佳实践的通用最佳实践（三）：将你的测试工具用作主要的开发工具和保持低抽象度以便于调试测试"},{"content":"如何快速编写 K6 性能测试脚本 我们除了可以使用 JavaScript 编写 K6 性能测试脚本外，K6 还提供了多种快捷的方式来编写性能测试脚本。\n1.使用 K6 提供的 Test builder 测试生成器工具来编写脚本 2.使用 K6 Recorder 录制器录制脚本 3.使用 浏览器开发者工具获取 HAR 文件后使用 har-to-k6 工具将 HAR 文件转换为 K6 脚本 下面将分别介绍这三种方式。\n使用 K6 提供的 Test builder 测试生成器工具来编写脚本 k6 的 Test builder 测试生成器提供了一个图形界面，可根据您的输入生成 k6 测试脚本。然后，您可以复制测试脚本并从 CLI 运行测试。\nTest builder 测试生成器目前还是一个实验性的功能，可能会在未来的版本中发生变化。大家可以查看官方文档：https://k6.io/docs/using-k6/test-builder/获取更多信息\n安装 Test builder 测试生成器 Test builder 不需要安装，它是 Grafana Cloud k6 提供的一个功能，可以在浏览器中使用。\n需要注册一个 Grafana Cloud k6 账号，然后登录 Grafana Cloud。\n如何进入 Test builder 测试生成器界面：\n登录进入 Grafana Cloud 首页 依次点击左侧菜单栏上的 Testing \u0026amp; synthetics\u0026mdash;\u0026gt;Performance\u0026mdash;\u0026gt;Projects 然后选择 default project 或者新建一个 project，进入到项目的详情页面 点击页面上的 Start testing 按钮，然后再选择页面下的 Test builder，进入到 Test builder 测试生成器界面 提醒：由于 Test builder 测试生成器是 Grafana Cloud 上登录进行使用，可能 Grafana Cloud 存储一些敏感数据，所以建议大家不要在生产环境中使用 Test builder 测试生成器。\n如何使用 Test builder 测试生成器 1.在 Test builder 测试生成器界面，点击 Scenario_1 下的 Options 按钮进入到配置页面，配置测试场景的基本信息，如下图所示： 可以看到场景配置页面提供了多种配置选项，可以根据自己的需求进行配置场景名称，执行器类型和不同的 UV 配置。\n2.在 Test builder 测试生成器界面，点击 Scenario_1 下的 Requests 按钮进入到 Requests 管理页面，如下图所示： 3.点击页面下的 Request 按钮进入添加请求页面，如下图所示： 4.在添加请求页面，输入请求的 URL 地址，再根据实际情况添加请求的 headers 或请求的 body 或检查点等参数，然后点击页面上的 Create 按钮，完成性能场景的配置，如下图所示： 获取 Test builder 测试生成器生成的脚本 在 Test builder 测试生成器界面，点击页面上的 Script 按钮，页面就会展示出 Test builder 测试生成器生成的脚本，如下图所示：\n可以看到 Test builder 测试生成器生成的脚本，是一个完整的 K6 测试脚本，可以直接复制到本地，然后使用 k6 运行该脚本。\n运行 Test builder 测试生成器生成的脚本 在 Test builder 测试生成器界面，点击页面上的 Run Test 按钮，页面就会展示出 Test builder 测试生成器生成的脚本的运行结果，如下图所示：\n可以看到 Test builder 测试生成器生成的脚本运行的很详细的测试结果信息。\n其他 Test builder 测试生成器的功能 也支持导入 HAR 文件生成测试脚本 也支持多个 scenario 场景的配置和一个 scenario 场景的多个请求的配置 更多关于 Test builder 测试生成器的内容，请参考官方文档：https://grafana.com/docs/grafana-cloud/k6/author-run/test-builder/\n使用 K6 Recorder 录制器录制脚本 K6 Recorder 录制器是 K6 提供的一个浏览器扩展程序，可以在浏览器中录制用户与 Web 应用程序的交互，并将其转换为 k6 测试脚本。\n安装 K6 Recorder 录制器 K6 Recorder 录制器是一个浏览器扩展程序，可以在 Chrome 或 Firefox 中使用。您可以从 Chrome Web Store 或 Firefox Add-ons 页面安装它。\nChrome Web Store 安装地址：https://chrome.google.com/webstore/detail/grafana-k6-browser-record/fbanjfonbcedhifbgikmjelkkckhhidl\nFirefox Add-ons 安装地址：https://addons.mozilla.org/en-US/firefox/addon/grafana-k6-browser-recorder/\n安装完成后，就可以在浏览器中使用 K6 Recorder 录制器了。\n如何使用 K6 Recorder 录制器 在浏览器上点击打开 k6 Recorder 录制器扩展。 选择保存自动生成的脚本的位置。 要将其保存在本地计算机上，请选择\u0026quot;我不想在云中保存测试\u0026quot;(后面的例子我选择的这个选项)。 要将其保存到任何 Grafana Cloud k6 项目中，请选择“登录”。 选择保存脚本位置后，在当前浏览器选项卡输入测试网站地址，点击选择开始录制按钮以开始录制当前浏览器选项卡。 图中我打开了谷歌的首页并点击了搜索框，输入了 123，然后点击了搜索按钮，\n点击了 k6 Recorder 录制器的停止录制按钮停止录制。 将录制的文件取名保存在本地（我这里取名为 record-demo.har）。 使用 har-to-k6 工具将 HAR 文件转换为 K6 脚本。 har-to-k6 工具是一个命令行工具，可以将 HAR 文件转换为 k6 脚本。需要先通过 npm install -g har-to-k6安装 har-to-k6 工具，然后通过 har-to-k6 record-demo.har -O record-demo.js命令将 HAR 文件转换为 K6 脚本。\n转换后的 K6 脚本部分截图如下所示： 大家可以根据自己的需求对转换后的 K6 脚本进行修改，然后使用 k6 运行该脚本。 使用 k6 运行转换后的 K6 脚本，查看运行结果。 更多关于 K6 Recorder 录制器的内容，请参考官方文档：https://grafana.com/docs/k6/latest/using-k6/test-authoring/create-tests-from-recordings/using-the-browser-recorder/\n使用浏览器开发者工具和 har-to-k6 工具生成 K6 脚本 除了我们可以使用 K6 Recorder 录制器来录制脚本外，我们还可以使用浏览器开发者工具获取测试请求的 HAR 文件，然后使用 har-to-k6 工具转换 HAR 文件来生成 K6 脚本。\n可以获取 HAR 文件的浏览器和工具 我们可以根据实际情况选择一个工具来记录 HAR 文件。市面上的很多浏览器和工具可以以 HAR 格式导出 HTTP 流量。大家常用的是：\nChrome 浏览器 Firefox 浏览器 Microsoft Edge 浏览器 Charles 代理抓包工具 (HTTP proxy/recorder) Fiddler 代理抓包工具 (HTTP proxy/recorder) 如何使用浏览器开发者工具获取 HAR 文件 下面是使用 Chrome 浏览器开发者工具获取测试请求 HAR 文件例子：\n在 Chrome 中打开新的隐身窗口。 （可以排除登录 cookies 等干扰信息）。\n打开 Chrome 开发者工具（按 F12）。\n选择网络选项卡 Network。\n检查和确认录音按钮（圆形按钮）是否已激活（红色）。\n如果想要记录多个连续的页面加载，请选中“保留日志”复选框。 输入测试网站的 URL（如 https://www.google.com/），然后开始执行和后续模拟用户执行的操作（如输入 123 进行搜索）。\n完成后，在 Chrome 开发人员工具中，右键单击 URL 并选择“将内容另存为 HAR”。 选择保存 HAR 文件的位置并重命名（如 har-demo），然后点击保存按钮，完成 HAR 文件的保存。\n使用 har-to-k6 进行转换 HAR 文件 安装 har-to-k6 工具 通过 npm install -g har-to-k6命令安装 har-to-k6 工具。 使用 har-to-k6 工具将 HAR 文件转换为 K6 脚本 通过 har-to-k6 har-demo.har -O har-demo.js命令将 HAR 文件转换为 K6 脚本。 转换后的 K6 脚本部分截图如下所示： 大家可以根据自己的需求对转换后的 K6 脚本进行修改，然后使用 k6 运行该脚本。 使用 k6 运行转换后的 K6 脚本，查看运行结果。 更多关于 HAR 文件的内容，请参考官方文档：https://grafana.com/docs/k6/latest/using-k6/test-authoring/create-tests-from-recordings/using-the-har-converter/\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-advanced-usage-how-to-quickly-writing-k6-performance-test-script/","summary":"这篇博文深入介绍了在进行 K6 性能测试时，除了传统的 JavaScript 编写脚本方式外，还介绍了 K6 提供的多种快捷方式。首先，通过 K6 提供的 Test Builder 测试生成器工具，读者能够轻松快捷地生成性能测试脚本，简化了脚本编写过程。其次，博文介绍了使用 K6 Recorder 录制器的方法，通过录制操作生成脚本，省去手动编写的步骤。最后，读者还能了解到使用浏览器开发者工具获取 HAR 文件，并通过 har-to-k6 工具将其转换为 K6 脚本的技巧。通过本文，读者将更全面地了解 K6 性能测试工具的灵活性和多样化的脚本编写方式。","title":"K6 性能测试教程 - 进阶用法：如何快速编写 K6 性能测试脚本"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\nUI 测试调试最佳实践 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/ui-tests-debugging-best-practices.md\n在转向 Cypress 之前，我通常使用 Puppeteer 编写 UI 测试。理解浏览器中发生的事情、了解正在运行的测试以及调试测试都不是简单的任务，因此我开始采取一系列解决方案来帮助我应对整个流程。\n诸如 Cypress 和 TestCafé 的工具几乎使下面列出的最佳实践变得无关紧要，但除非你之前使用过 Selenium 或 Puppeteer 等工具进行测试，否则你不会意识到专为测试而设计的工具对简化生活有多么重要。\n第零步是以非无头模式启动浏览器，然后\u0026hellip;\n在 console.log 中记录/显示测试的描述 由于在浏览器内部无法获得有关正在运行的测试的视觉反馈，请务必在浏览器控制台中记录测试的名称。在测试速度很快的情况下（少于 1 秒），这可能没有太多用处，但在测试时间较长或在使用 test.skip 和 test.only 进行测试时，这是有帮助的，可以对正在运行的测试进行双重检查。\n在 Puppeteer 中，可以通过以下方式实现：\ntest(\u0026#39;Test description\u0026#39;, async () =\u0026gt; { await page.evaluate(() =\u0026gt; console.log(\u0026#39;Test description\u0026#39;)); // ... the test code... }) 如果你需要更为显眼的反馈，甚至可以考虑在页面的左上角添加一个固定的 div，每个测试都会用自己的描述填充\u0026hellip;\n将浏览器的 console.log 转发到 Node.js 使用 Puppeteer 的一个简单例子：\npage.on(\u0026#39;console\u0026#39;, msg =\u0026gt; console.log(\u0026#39;BROWSER LOG:\u0026#39;, msg.text())); 允许你在同一终端窗口中查看测试日志和浏览器日志。简单而有效。\n启动浏览器时已经打开开发者工具 就像在经典的前端开发中一样，在页面加载已经开始后再打开开发者工具可能会导致你错过重要的信息，特别是在网络选项卡中。在调试测试时，启动浏览器时已经打开开发者工具可以节省宝贵的时间和信息。\nconst browser = await puppeteer.launch({ headless: false, devtools: true }); 减缓模拟用户操作速度 浏览器自动化工具速度非常快，这使得我们能在几秒钟内运行大量测试。然而，在调试过程中，这可能是一个劣势，因为你需要用眼睛跟踪页面上发生的情况。减缓每个动作可能会适得其反——因为整个测试变得很慢——但通常这是执行一些快速检查的最简单方法。在 Puppeteer 中，有一个全局设置可以实现这一点。\nconst browser = await puppeteer.launch({ headless: false, slowMo: 250, // slow down every action by 250ms }); 一些动作，比如输入，允许你添加更具体的延迟（这会叠加在全局 slowMo 设置之上）\nawait page.type(\u0026#39;.username\u0026#39;, \u0026#39;admin\u0026#39;, {delay: 10}); 使用调试器语句暂停测试 另一方面，就像在标准的 Web 开发中一样，你可以在运行在页面上的代码中添加一个调试器语句来“暂停”JavaScript 执行。请注意：该语句仅在已打开控制浏览器的开发者工具时有效。\nawait page.evaluate(() =\u0026gt; {debugger;}); 通过点击“继续执行脚本”或按下 F8 键（调试器是一个“飞行”断点），将恢复测试的执行。\n延长测试超时时间 类似 Jest、Jasmine 等的测试运行器都设有测试超时时间。这个超时时间的作用在于，在测试中发生问题导致测试无法正常结束时，及时终止测试。在 UI 测试中，这种行为相对繁琐，因为你需要在测试开始时打开浏览器，在测试结束时关闭浏览器。在正常的测试生命周期中，设定过高的超时时间并不实际，因为一旦测试失败就会导致大量时间的浪费，而过低的超时时间可能在测试完成之前就提前“截断”了测试。\n相反，你需要设定较长的超时时间，因为你不希望测试结束的时候在你检查浏览器时关闭它。这就是为什么在调试受控浏览器时，设定为 10 分钟的超时时间可能会很有帮助。\n当然，也可以\u0026hellip;\n避免在测试结束时关闭浏览器 测试开始时，打开浏览器，而在测试结束时不关闭它。避免关闭浏览器可让你自由地检查前端应用，而无需担心测试超时。这仅在本地运行测试时有效，但在运行测试于 CI 管道之前，必须还原自动关闭以避免由于未关闭的浏览器实例导致内存不足。\n使用截图 在以无头模式运行测试时，这在测试稳定且仅在出现回归时才失败的阶段尤其有帮助。如果测试失败，很多时候截图能让你了解你正在开发的功能是如何影响之前正常工作的功能的。最有效的解决方案是在测试失败时截图，否则，你可以在 UI 测试中确定一些检查点，并在这些步骤中截图。\n频繁使用断言 一个经验法则：如果测试失败，它必须直接带你理解出了什么问题，而不是重新启动测试并手动调试。尝试在你的代码库中手动引入一些错误（改变请求有效载荷，移除元素等），并查看测试报告。错误是否与你引入的错误相关联？阅读失败报告的人是否能够理解需要修复什么？\n你需要在测试中添加很多断言，这是完全可以的！单元测试通常只包含一个步骤和一个或两个断言，但 UI 测试不同，它们有很多步骤，因此你需要很多断言。将它们视为一系列单元测试，其中前一个测试对第二个测试的创建是必要的，以此类推。\n使用 test.skip 和 test.only 这是每个测试运行器的基础之一，但你可能不知道：如果你不习惯使用 skip 和 only，请从现在开始吧！否则，你将浪费很多时间，即使你的测试文件只包含两三个测试。始终仅运行你正在工作或需要调试的最小数量的测试！\n串行运行测试 如果你正在使用 Puppeteer 结合 Jest，请记住 Jest 有一个专门的 runInBand 选项，它防止测试的执行在你的 CPU 核心上分散。将测试并行化可以加快执行速度，但在你需要用眼睛跟踪测试操作时可能会让人感到烦扰。runInBand 选项使测试串行运行。将它与 test.skip、test.only 以及 jest-watch-typeahead 结合使用可以避免很多调试的麻烦。\n保持测试代码简单 宁愿有些重复，也不要过度抽象。努力让测试代码简单易读。你调试 UI 测试越多，就越能体会到其中的困难。当你需要理解底层发生了什么，以及哪一步不按预期工作时，你那超度抽象、完全符合 DRY 原则（不重复自己）的测试代码就会变得令人头痛。\n更一般而言，测试是小型脚本，它们必须比它们测试的代码简单两个数量级，将其视为一个盟友，而不是更复杂的程序。\n选择专门设计的工具 上述提到的解决方案都是有效的，但它们有一个共同点：它们都是变通方法。这是因为我在示例中使用的工具 Puppeteer 并非为 UI 测试而创建的，而是为通用浏览器自动化而设计的，然后，通过一些外部工具的帮助，并在测试中使用 Puppeteer，使其可以用于 UI 测试。测试 Web 应用有不同的需求，需要不同的工具，而不仅仅是自动化操作。\n如果你需要编写 UI 测试，你应该考虑切换到 Cypress 或 TestCafé，因为它们已经被设计成简化你的测试工作。如何实现的呢？通过一系列实用工具和默认行为，以及一系列一流的解决方案，使你能够理解并调试浏览器中发生的情况。请注意，本章中提到的所有 Puppeteer 最佳实践\u0026hellip; 在 Cypress 或 TestCafé 中完全无用 😉\n一些 UI 测试问题及 Cypress 方法 和 前端生产力提升：将 Cypress 作为你的主要开发浏览器 这两章包括了 Cypress 一流工具的概述。\n由NoriSte 在 dev.to 和 Medium上进行联合发表._\n在测试中达到 UI 状态而无需使用 UI 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/reaching-ui-state.md\n一段简要说明 在 UI 场景中覆盖一次是有价值的，而在其他测试中复制其中任何部分提供的价值很小；这些测试可能需要系统的相关状态。假设在一个新测试中，你需要一种状态，而那种状态 - 部分或全部 - 与 UI 测试中的某些部分重复。在这种情况下，可以考虑以下几种技术：\n直接导航 网络存根记录和播放 应用程序动作 数据库种子 免责声明：整个技术包的应用仅在 Cypress 中可能（据我们所知），因此以下代码示例是在 Cypress 上下文中。\n直接导航 这是最简单的技术，适用于任何框架。假设测试的意图与你的应用程序中的某个页面有关。与其进行点击导航，直接访问 URL。一旦到达，你可以等待 UI 元素（任何测试框架）或网络调用（一些测试框架），或两者兼而有之。\n// Test A covers click-navigation to a certain page. // This is Test B, and navigating to that page is the prerequisite step. // assuming baseUrl is set in cypress.json or config file // directly navigate to the page. cy.visit(\u0026#39;/endpoint\u0026#39;); // to ensure stability, wait for network (preferred), ui elements, or both // note: checking the endpoint you are at is entirely optional, only for sanity that you are at the right page cy.url().should(\u0026#39;contain\u0026#39;, \u0026#39;endpoint\u0026#39;); // cy.url().should(\u0026#39;match\u0026#39;, /endpoint/); // there are many, some more complex, ways of doing it // network wait: this is in addition to the sanity url check, and it is more important // because you want the page to \u0026#34;settle\u0026#34; before you start running assertions on it // usually a GET request. Is aliased so we can wait for it. cy.intercept(\u0026#39;some-xhr-call-that-happens-upon-landing\u0026#39;).as(\u0026#39;crutcXHR\u0026#39;); // The default Cypress timeout is 4 seconds. 15 seconds here is arbitrary. // Most pages load faster, but if you need more time then increase the timeout. // The only caveat to increasing timeout is that the tests will take longer to fail, but still run as fast as possible when things work. cy.wait(\u0026#39;@crutchXHR\u0026#39;, {timeout: 15000}); // ui-element wait is straightforward, and may be optional, as well as less stable) cy.get(\u0026#39;element-on-page\u0026#39;).should(\u0026#39;exist\u0026#39;).and(\u0026#39;be.visible\u0026#39;); 直接导航的优缺点 优点：不进行点击导航可以节省测试时间，并减少测试维护的工作量。\n缺点：这种技术忽略了用户通过应用程序的端到端点击方式。确保在其他测试中至少有一个工作流程覆盖与点击导航相同的工作流程，以确保点击导航功能不会出现回归问题。通常，点击导航可以成为一个独立的测试；在设置其他测试的状态时，不要重复已经在其他地方覆盖的 UI 测试。思考模式类似于登录；如果在一个测试中进行 UI 登录，在其他测试中可以实现程序化登录，这既快速又经济。\n应用程序操作 Cypress 为你提供了对应用程序的完全控制权。你可以绕过页面对象的抽象层（与你的应用程序分离），通过 cy.get() 直接访问 UI，还可以访问 API、数据库，甚至可以访问源代码。\n应用程序操作是一种快捷方式，允许你访问内部工具以节省时间。一个简单的例子可以是一个 cy.signup() 自定义命令，该命令进入注册表单并调用注册表单的回调，而不是填写表单并点击注册按钮。\n以下是一个快速示例，演示了在 Angular 应用程序中如何允许 Cypress 访问源代码。\n// Angular Component file example /* setup: 1. Identify the component in the DOM; inspect and find the corresponding \u0026lt;app.. tag, 2. Right in the constructor of your component, insert conditional */ constructor( /* ... */ ) { /* if running inside Cypress tests, set the component may need // @ts-ignore initially */ if (window.Cypress) { window.yourComponent = this; } } // at https://github.com/naodeng/ui-testing-best-practices/blob/master/https://github.com/naodeng/ui-testing-best-practices/blob/master/support/app-actions.ts helper file: /** yields window.yourComponent */ export const yourComponent = () =\u0026gt; cy.window().should(\u0026#39;have.property\u0026#39;, \u0026#39;yourComponent\u0026#39;); /** yields the data property on your component */ export const getSomeListData = () =\u0026gt; yourComponent().should(\u0026#39;have.property\u0026#39;, \u0026#39;data\u0026#39;); 在这之后，在 DevTools 中查看该组件允许的属性，或者在组件代码中查看你可以使用 .invoke() 进行的函数。\n可以查看 演示幻灯片 获取一个使用应用程序操作进行视觉测试的代码示例。\n另一个应用程序操作的示例，利用状态，使用 Siemens 的 Building Operator Siemens 的建筑控制产品 在下面的状态图中有 3 个状态。我们从左右两个窗格都存在的地方开始。如果删除右窗格（删除点/红色流），则只剩下左窗格。如果删除左窗格（删除设备 - 蓝色流），两个窗格都消失，并且 UI 被重定向。\n在测试 UI 时，你可能选择删除右窗格（红色流），然后在另一个测试中，你可能选择删除左窗格（蓝色流）。这遗漏了通过状态图的最后一条路径，其中右窗格和左窗格被逐一删除。\n我们已经在一个 UI 测试中涵盖了删除右窗格（红色路径）。为什么不避免重复进行此测试，利用应用程序操作，获取源代码中的删除函数，并使用 cy.invoke() 调用它呢？\nit(\u0026#39;Component test: delete right pane and then left\u0026#39;, () =\u0026gt; { /* tests a SEQUENCE not covered with UI tests * tests a COMBINATION of components */ appAction.deleteRightPane(); cy.window().should(\u0026#39;not.have.property\u0026#39;, \u0026#39;rightPaneComponent\u0026#39;); cy.window().should(\u0026#39;have.property\u0026#39;, \u0026#39;leftPaneComponent\u0026#39;); appAction.deleteLeftPane(); cy.window().should(\u0026#39;not.have.property\u0026#39;, \u0026#39;leftPaneComponent\u0026#39;); cy.window().should(\u0026#39;not.have.property\u0026#39;, \u0026#39;rightPaneComponent\u0026#39;); cy.url().should(\u0026#39;match\u0026#39;, redirectRoute); }); 应用程序操作的优缺点 使用应用程序操作/拥有组件访问速度很快！测试不太容易受到变化的影响。一般来说，这是在较低级别进行测试的好处。然而，对于工程师而言，这可能会变得让人上瘾，开始忽视对用户界面的测试；优势可能变成劣势。\n有一些反对应用程序的论点。开发人员可能认为 Cypress 对源代码的访问不理想。在 Cypress 具有官方组件测试支持之前，这没有反驳的理由。\n应用程序操作的真正威力在于将应用程序操作与其他技术结合使用时显现出来；不重复 UI 工作流程来设置状态，将组件测试与视觉测试结合使用，将组件测试与网络操作结合使用，这些都是这种方法的亮点所在。\n网络存根记录和回放 这是一种与 UI 集成测试密切相关的高级技术。回顾 UI 集成参考 1, 2。\nCypress 允许你对所有网络流量进行存根。我们可以记录来自一个端点的网络数据，并在 UI 每次调用任意服务器时存根该响应。\n首先，从开发者工具复制网络数据到一个 json 文件中。将其放置在 cypress/fixtures 文件夹中。这个文件夹专为此目的而创建，对它的任何引用都将默认指向文件夹的根目录。\n// prerequisite: the data has been copied to a file `cypress/fixtures/agents.json` // this is a shorthand for cy.fixture(). More at https://docs.cypress.io/api/commands/fixture.html#Accessing-Fixture-Data cy.intercept(\u0026#39;some-xhr-call-that-happens-upon-landing\u0026#39;, { fixture: \u0026#39;agents.json\u0026#39;} ).as(\u0026#39;crutcXHR\u0026#39;); // all calls to the network route will be stubbed by the data in agents.json file 如果有很多网络请求发生怎么办？ 我们从哪里获取所有的模拟数据？我们不想手动复制和保存它们。我们希望在测试运行时记录它们，以便与真实的 API 进行比对。\n至少有两个 Cypress 插件可以用于这个目的 1 和 2。\n如果这些插件不适用于你，你可以轻松使用以下三个函数创建自己的记录和回放工具。\nfunction stubRecorder(pathToJson) { const xhrData = []; // an empty array to hold the data cy.server({ // if recording, save the response data in the array onResponse: (response) =\u0026gt; { const url = response.url; const method = response.method; const data = response.response.body; // We push a new entry into the xhrData array xhrData.push({ url, method, data }); } }); // cy.intercept() specification below is used as a selector for the data you want to record. // In this example, all GET requests from any url will be selected // You can specify the methods and routes that are recorded cy.log(\u0026#39;recording!\u0026#39;); cy.intercept({ method: \u0026#39;GET\u0026#39;, url: \u0026#39;*\u0026#39;, }); // if recording, after the test runs, create a fixture file with the recorded data after(function () { cy.writeFile(`./cypress/fixtures/${pathToJson}.json`, xhrData); cy.log(`Wrote ${xhrData.length} XHR responses to local file ${pathToJson}.json`); }); } /** Plays recorded fixture with all required network data as json*/ function playStubbedFixture(stateFixture) { cy.log(`playing fixture from ${stateFixture}`); cy.fixture(stateFixture, { timeout: 15000 }) // the fixture file may be large and take time in CI .each(({method, url, data}) =\u0026gt; { cy.intercept(method, url, data); }).as(`stateFixture_stub`); } /** Visits the stubbed state */ function visitStubbedState(stubFile, url, wait: boolean = true) { playStubbedFixture(stubFile); cy.visit(url); if (wait) { // sometimes you do not want to wait for network, this gives you the option cy.wait(\u0026#39;@stateFixture_stub\u0026#39;, { timeout: 15000 }); } } ////////// // usage // recording network it(\u0026#39;should run your test\u0026#39;, function () { stubrecorder(\u0026#39;jsonfileNameForNetworkData\u0026#39;); // your original test cy.wait(5000); // one-time wait so that the after() step records all the network without missing anything // the rest of your original test }); // playing the stubbed network it(\u0026#39;should run your test\u0026#39;, function () { // every time we visit this endpoint, all network will be stubbed // double check this by observing (XHR stubbed) network responses in the test runner visitStubbedState(\u0026#39;jsonfileNameForNetworkData\u0026#39;, \u0026#39;/endpoint\u0026#39;); // the rest of your original test }); 网络存根记录和回放的优缺点 UI 集成测试是 UI 测试的核心。它们在真实浏览器中运行整个应用程序，而不连接真实服务器。它们运行速度极快，对网络中的随机故障或错误负面影响较小。\n工程师们必须认识到，这种优势如果被滥用可能成为一种诅咒。UI 应用程序是隔离的，但如果有网络故障，它们会被忽略。这对于功能分支测试非常有用，但在进一步的部署中，应确保后端也正常运行。请参阅 使用集成测试前端，同时使用 E2E 测试后端 了解何时使用哪种技术。\n填充数据库 Cypress cy.task() 功能非常强大。实际上，它允许你在 Cypress 上下文中使用 Node.js。这可以是任何内容，从 Node.js 代码到使用 npm 包来操纵数据库。如果你的应用程序使用 Node.js，你可以重用应用程序代码来帮助设置和操纵测试数据。\n关于这个主题有一个 Cypress 示例，我们将以此作为参考结束。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-best-practices-2-ui-tests-debugging-best-practices-and-reaching-ui-state/","summary":"这篇博文探讨了 UI 测试的通用最佳实践之二：UI 测试调试和无需使用 UI 达到 UI 状态。博文详细介绍了在 UI 测试中的调试技巧，包括使用断点、日志和交互式调试工具等方法，提高测试脚本的调试效率。此外，文章强调了通过直接设置应用程序状态而无需依赖 UI 元素来达到 UI 状态的方法，以提高测试速度和稳定性。通过这些实践，读者能够更好地应对 UI 测试中的调试挑战，同时优化测试脚本的执行效率。","title":"UI 测试最佳实践的通用最佳实践（二）：UI 测试调试最佳实践和在测试中达到 UI 状态而无需使用 UI"},{"content":"K6 常用功能 上一篇博文介绍了K6 性能测试教程：常用功能（1）- HTTP 请求，指标和检查 这一篇文章主要聚焦在阈值设置、测试生命周期和场景设计方面。阐述了如何利用 K6 在性能测试中设定合理的阈值，以便有效监测系统的性能表现。同时，探讨了测试生命周期的重要性，以及如何在不同阶段进行有针对性的性能测试。\nThresholds 阈值 什么是阈值 阈值一般是我们为测试指标定义的通过/失败标准。对于 K6 来说，如果被测系统的性能不满足阈值条件，测试将以失败状态结束。\n前面提到的检查（check）是用来验证测试结果是否符合预期，check 不通过，测试还会继续，而阈值（threshold）是用来验证测试结果是否符合性能要求。如果不符合，测试将以失败状态结束。\n通常情况下，我们进行性能测试时会使用阈值来编写不同服务或接口的 SLOs(服务级别目标 Service Level Objectives)。\n下面为一些阈值的例子：\n不到 1% 的请求返回错误。 95% 的请求响应时间低于 200 毫秒。 99% 的请求响应时间低于 400 毫秒。 特定端点始终在 300 毫秒内响应。 自定义指标（等待时间趋势）的任何条件（大于 300 毫秒）。 如果后续会写性能自动化测试脚本，那么阈值就是必不可少的。\n给你的测试一个阈值。 自动化执行 设置测试失败警报。 HTTP 错误和响应持续时间的阈值示例 以下示例演示如何使用阈值来设置并评估 HTTP 错误率（http_req_failed 指标）和评估 95% 的请求响应是否在特定持续时间内发生（http_req_duration 指标）：\nimport http from \u0026#39;k6/http\u0026#39;; export const options = { thresholds: { http_req_failed: [\u0026#39;rate\u0026lt;0.01\u0026#39;], // HTTP 错误率应该低于 1% http_req_duration: [\u0026#39;p(95)\u0026lt;200\u0026#39;], // 95% 的请求响应应该低于 200ms }, }; export default function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); } 上述的示例中，我们设置了两个阈值：\nHTTP 错误率应该低于 1%。（用到了 http_req_failed 指标） 95% 的请求响应应该低于 200ms。（用到了 http_req_duration 指标） 对于上面代码设置的阈值，如果运行的时候，HTTP 错误率低于 1% 和 95% 的请求响应低于 200ms，那么测试就会以成功状态结束，否则任一阈值不满足，测试就将以失败状态结束。\n运行该脚本，可以看到如下结果：\n结果中显示，http_req_failed 阈值通过了，http_req_duration 阈值没有通过，整体测试以失败状态结束。\n如果任何阈值失败，则阈值名称（http_req_failed、http_req_duration）旁边的绿色小复选标记 ✓ 将是 ✗ 并且 k6 将以非零值退出退出代码。\n阈值语法 阈值语法是一个字符串，由以下部分组成：\n指标名称（例如 http_req_duration）。 一个或多个条件，用逗号分隔。 每个条件都由一个运算符和一个值组成。 运算符可以是以下之一：\u0026gt;、\u0026gt;=、\u0026lt;、\u0026lt;=、==、!=、=~、!~。 值可以是数字或百分比。 百分比值必须在 0 到 100 之间。 想要在测试脚本中使用阈值，步骤如下：\n1.在 options 对象中添加 thresholds 属性，如下所示：\nexport const options = { thresholds: { /* ... */ }, }; 2.在 thresholds 对象中定义阈值表达式（至少一个，可以多个），如下所示：\nexport const options = { thresholds: { //短格式 METRIC_NAME1: [\u0026#39;THRESHOLD_EXPRESSION\u0026#39;, `...`], //长格式 METRIC_NAME2: [ { threshold: \u0026#39;THRESHOLD_EXPRESSION\u0026#39;, abortOnFail: true, // boolean delayAbortEval: \u0026#39;10s\u0026#39;, // string }, ], // full format }, }; 阈值表达式支持短格式和长格式，短格式将所有阈值表达式作为字符串放入数组中。长格式将每个阈值放入一个对象中，并具有在失败时中止的额外属性。 上面示例代码中的 METRIC_NAME1 和 THRESHOLD_EXPRESSION 是占位符。正常情况下必须是指标名称和阈值表达式。 示例代码声明配置指标 metric_name1 和 metric_name2 的两个阈值。通过评估阈值后的\u0026rsquo;threshold_expression\u0026rsquo;来确定阈值是通过还是失败，. 阈值表达式语法 阈值表达式的计算结果为 true 或 false 。阈值表达式必须采用以下格式：\n\u0026lt;aggregation_method\u0026gt; \u0026lt;operator\u0026gt; \u0026lt;value\u0026gt; \u0026lt;aggregation_method\u0026gt;：聚合方法，用于计算指标的值。例如，p(95) 表示 95% 百分位数，而 avg 表示平均值。 \u0026lt;operator\u0026gt;：运算符，用于比较指标的值与阈值表达式中的值。例如，\u0026gt; 表示大于，\u0026lt; 表示小于，== 表示等于。 \u0026lt;value\u0026gt;：阈值表达式中的值。例如，200 表示 200 毫秒，95 表示 95%。 阈值表达式的一些示例如下：\navg \u0026lt; 200 // 平均持续时间必须小于 200 毫秒 count \u0026gt;= 500 // 计数必须大于或等于 500 p(90) \u0026lt; 300 // 90% 的样本必须低于 300 按类型划分的聚合方法 k6 根据类型聚合指标。这些聚合方法构成阈值表达式的一部分。\n以下是按类型划分的聚合方法列表：\n指标类型 聚合方法 ｜Counter count 计数 和 rate 比率 ｜Gauge value 具体的值 ｜Rate rate 比率 ｜Trend avg 平均值、min 最小值、max 最大值、med 和 p(N) 其中 N 指定阈值百分位值，表示为 0.0 到 100 之间的数字。p(99.99) 表示第 99.99 个百分位。这些值以毫秒为单位。｜ 一个复杂的聚合方法示例：\nimport http from \u0026#39;k6/http\u0026#39;; import { Trend, Rate, Counter, Gauge } from \u0026#39;k6/metrics\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const TrendRTT = new Trend(\u0026#39;RTT\u0026#39;); export const RateContentOK = new Rate(\u0026#39;Content OK\u0026#39;); export const GaugeContentSize = new Gauge(\u0026#39;ContentSize\u0026#39;); export const CounterErrors = new Counter(\u0026#39;Errors\u0026#39;); export const options = { thresholds: { // 计数：不允许超过 99 次返回错误的内容。 \u0026#39;Errors\u0026#39;: [\u0026#39;count\u0026lt;100\u0026#39;], // 计量：返回的内容必须控制在 4000 字节以下。 \u0026#39;ContentSize\u0026#39;: [\u0026#39;value\u0026lt;4000\u0026#39;], // 比率：内容必须在 95 次以上达到“OK”。 \u0026#39;Content OK\u0026#39;: [\u0026#39;rate\u0026gt;0.95\u0026#39;], // 趋势：百分位数、平均值、中位数和最小值必须保持在指定的毫秒范围内。 \u0026#39;RTT\u0026#39;: [\u0026#39;p(99)\u0026lt;300\u0026#39;, \u0026#39;p(70)\u0026lt;250\u0026#39;, \u0026#39;avg\u0026lt;200\u0026#39;, \u0026#39;med\u0026lt;150\u0026#39;, \u0026#39;min\u0026lt;100\u0026#39;], }, }; export default function () { const res = http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); const contentOK = res.json(\u0026#39;name\u0026#39;) === \u0026#39;Bert\u0026#39;; TrendRTT.add(res.timings.duration); RateContentOK.add(contentOK); GaugeContentSize.add(res.body.length); CounterErrors.add(!contentOK); sleep(1); } 注意：不要通过重复相同的对象键来为同一指标指定多个阈值。\n由于阈值被定义为 JavaScript 对象的属性，因此您不能指定多个具有相同属性名称的阈值。如果要为一个指标设置多个阈值，请使用同一键的数组指定它们。\n常用的阈值示例 使用阈值的最快方法是先使用内置指标。以下是一些常用的复制示例\n1.在指定持续时间内完成的请求百分比 import http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { // 90% 的请求必须在 400 毫秒内完成。 http_req_duration: [\u0026#39;p(90) \u0026lt; 400\u0026#39;], }, }; export default function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); sleep(1); } 2.错误率低于 1% import http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { // 在整个测试执行过程中，错误率必须低于 1％。 http_req_failed: [\u0026#39;rate\u0026lt;0.01\u0026#39;], }, }; export default function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); sleep(1); } 3.单个指标的多个阈值 我们也可以为一项指标应用多个阈值。该阈值对于不同的请求百分位数有不同的持续时间要求。\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { // 90％的请求必须在 400 毫秒内完成，95％在 800 毫秒内完成，99.9％在 2 秒内完成。 http_req_duration: [\u0026#39;p(90) \u0026lt; 400\u0026#39;, \u0026#39;p(95) \u0026lt; 800\u0026#39;, \u0026#39;p(99.9) \u0026lt; 2000\u0026#39;], }, }; export default function () { const res1 = http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); sleep(1); } 4.持续时间组的阈值 我们也可以为每个组设置阈值。此代码具有针对单独请求和批量请求的组。对于每个组，都有不同的阈值。\nimport http from \u0026#39;k6/http\u0026#39;; import { group, sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { \u0026#39;group_duration{group:::individualRequests}\u0026#39;: [\u0026#39;avg \u0026lt; 400\u0026#39;], \u0026#39;group_duration{group:::batchRequests}\u0026#39;: [\u0026#39;avg \u0026lt; 200\u0026#39;], }, vus: 1, duration: \u0026#39;10s\u0026#39;, }; export default function () { group(\u0026#39;individualRequests\u0026#39;, function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/2/\u0026#39;); http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/3/\u0026#39;); }); group(\u0026#39;batchRequests\u0026#39;, function () { http.batch([ [\u0026#39;GET\u0026#39;, `https://test-api.k6.io/public/crocodiles/1/`], [\u0026#39;GET\u0026#39;, `https://test-api.k6.io/public/crocodiles/2/`], [\u0026#39;GET\u0026#39;, `https://test-api.k6.io/public/crocodiles/3/`], ]); }); sleep(1); } 超过阈值时中止测试 如果在测试过程中，我们想要在阈值不满足时中止测试，那么可以使用 abortOnFail 属性。\n将 abortOnFail 属性设置为 true。当您设置 abortOnFail 时，一旦阈值失败，测试运行就会停止。\n这里也会有一种特殊情况，测试可能会因为这个阈值的设定导致在测试生成重要数据之前中止。为了防止这些情况，我们可以使用 delayAbortEval 延迟 abortOnFail。在此脚本中，abortOnFail 延迟了十秒。十秒后，如果未达到 p(99) \u0026lt; 10 阈值，测试将中止。\nexport const options = { thresholds: { metric_name: [ { threshold: \u0026#39;p(99) \u0026lt; 10\u0026#39;, // string abortOnFail: true, // boolean delayAbortEval: \u0026#39;10s\u0026#39;, // string /*...*/ }, ], }, }; 更多阈值的内容，请参考官方文档：https://k6.io/docs/using-k6/thresholds/\nTest lifecycle 测试生命周期 K6 框架中的测试的生命周期，测试脚本始终都以下面的相同顺序进行执行：\ninit 初始化阶段：上下文中的代码准备脚本、加载文件、导入模块并定义测试生命周期函数。必需的。 setup 前置准备设置阶段：设置测试环境并生成数据。可选的。 VU UV 阶段：代码在 default 或场景函数中运行，运行时间和次数与 options 定义的一样长。必需的。 teardown 后置测试退出阶段：对数据进行后处理并关闭测试环境。可选的。 生命周期函数：除了初始化代码之外，每个阶段都在生命周期函数中发生，这是在 k6 运行时按照特定顺序调用的函数。\n下面是一个完整的测试生命周期示例：\n// 1. 配置 init 阶段（必需的） export function setup() { // 2. 配置 setup 阶段（可选的） } export default function (data) { // 3. 配置 VU 阶段（必需的） } export function teardown(data) { // 4. 配置 teardown 阶段（可选的） } 生命周期阶段概述 测试阶段 目的 示例 请求次数 init 初始化阶段 加载本地文件、导入模块、声明生命周期函数 打开 JSON 文件，导入模块 每个 VU 一次* Setup 前置准备配置阶段 设置要处理的数据，在 VU 之间共享数据 调用 API 启动测试环境 一次 VU code VU 代码阶段 运行测试函数，通常是 default 发出 https 请求，验证响应 每次迭代一次，根据测试选项的需要进行多次 Teardown 测试后置退出阶段 设置代码的处理结果，停止测试环境 验证设置是否有一定的结果，发送 webhook 通知测试已完成 一次 ** * 在云脚本中，init 代码可能会被更频繁地调用。** 如果 Setup 函数异常结束（例如抛出错误），则不会调用 teardown() 函数。考虑向 setup() 函数添加逻辑以处理错误并确保正确清理。\ninit 初始化阶段 K6 测试的必要阶段。这个阶段用来在测试之前准备测试环境和初始化测试条件\ninit 上下文中的代码每个 VU 都会运行一次。\n一般在init 阶段可能会做的事情：\n导入模块 从本地文件系统加载文件 为所有 options 配置测试 为 VU、setup 和 teardown 阶段（以及自定义或 handleSummary() 函数）定义生命周期函数。 init 上下文中的代码始终首先执行\nVU 阶段 VU 阶段是测试的核心。在这个阶段，代码在 default 或场景函数中运行，运行时间和次数与 options 定义的一样长。\n关于 UV 阶段的 Q\u0026amp;A：\n1.为什么有 VU 阶段？\nVU 阶段是测试的核心，脚本必须至少包含一个定义 VU 逻辑的场景函数。该函数内部的代码是 VU 代码。 VU 阶段是真正的测试代码，所以 VU 阶段的代码会被多次执行，执行次数由 options 定义的一样长。 2.为什么把 init 阶段和 VU 阶段分开\n将 init 阶段与 VU 阶段分离，可以消除 VU 代码中不相关的计算，从而提高 k6 性能并使测试结果更加可靠。init 代码的一个限制是它无法发出 HTTP 请求。此限制确保 init 阶段在测试中可重现（协议请求的响应是动态且不可预测的） 将 init 阶段与 VU 阶段分离，可以使 VU 阶段的代码更加简洁，更加专注于测试逻辑。 3.UV 阶段的默认函数生命周期的理解\nVU 从头到尾依次执行 default() 函数。一旦 VU 到达函数末尾，它就会循环回到开头并重新执行代码 作为此“重新启动”过程的一部分，k6 会重置 VU。Cookie 被清除，TCP 连接可能被断开（取决于我们的测试配置选项）。 Setup 测试前置准备配置阶段 和 teardown 测试后置退出阶段 Setup 和 teardown 阶段是可选的。这两个阶段都是在 VU 阶段之前和之后运行的。\n与 default 一样，setup 和 teardown 函数必须是导出函数。但与 default 函数不同，k6 每次测试仅调用 setup 和 teardown 一次。\nsetup 在测试开始时调用，在 init 阶段之后但在 VU 阶段之前。 teardown 在测试结束时、VU 阶段（default 函数）之后调用。 与 init 阶段不同，您可以在设置和拆卸阶段调用完整的 k6 API 更多 K6 测试生命周期的内容，请参考官方文档：https://k6.io/docs/using-k6/test-life-cycle/\nScenarios 测试场景 在 K6 的测试脚本中，可以定义多个测试场景，每个场景都可以有自己的配置项，例如 VU 数量、持续时间等。\n测试场景可以详细配置 VU 和迭代计划的方式。通过测试场景配置，我们可以在性能测试中对不同的工作负载或流量模式进行更好的根据业务进行自定义。\n使用测试场景配置的好处：\n更简便、更灵活的测试组织方式。您可以在同一个脚本中定义多个测试场景，每个场景可以独立执行不同的 JavaScript 函数。 模拟更真实的流量情况。每个测试场景都可以使用不同的虚拟用户（VU）和迭代调度模式，由专门设计的执行器提供支持。 并行或顺序工作负载。各个场景相互独立并行运行，尽管可以通过仔细设置每个场景的 startTime 属性使它们看起来像是按顺序运行的。 细致入微的结果分析。可以为每个场景设置不同的环境变量和指标标签。 测试场景配置 我们可以使用代码中的 options 对象中的 scenarios 键值来配置具体场景方案。也可以为场景指定任意名称，只要脚本中的每个场景名称都是唯一的即可。\n场景配置示例：\nexport const options = { scenarios: { example_scenario: { // 使用的执行器名称 executor: \u0026#39;shared-iterations\u0026#39;, // 常规的场景配置 startTime: \u0026#39;10s\u0026#39;, gracefulStop: \u0026#39;5s\u0026#39;, env: { EXAMPLEVAR: \u0026#39;testing\u0026#39; }, tags: { example_tag: \u0026#39;testing\u0026#39; }, // 与执行器相关的特殊配置 vus: 10, iterations: 200, maxDuration: \u0026#39;10s\u0026#39;, }, another_scenario: { /*...*/ }, }, }; 测试场景执行器 对于每个 k6 场景，VU（虚拟用户）的工作负载由执行器进行调度。执行器配置测试运行的持续时间、流量是否保持恒定或变化，以及工作负载是由 VU 还是到达率（即开放或关闭模型）建模的。\n我们设置的测试场景对象必须定义 executor 属性，并选择其中一个预定义的执行器名称。您选择的执行器将决定 k6 如何对负载进行建模。可选项包括：\n按迭代次数。\nshared-iterations 在 VU 之间共享迭代。 per-vu-iterations 让每个 VU 运行配置的迭代。 按 VU 数量。\nconstant-VUs 以恒定数量发送 VU。 ramping-vus 根据您配置的阶段增加 VU 数量。 按迭代率。\nconstant-arrival-rate 以恒定速率开始迭代。 ramping-arrival-rate 根据您配置的阶段提高迭代率。 除了这些通用场景选项之外，每个执行程序对象还具有特定于其工作负载的其他选项，可以点击执行者获取更多\n测试场景配置选项 选项名称 类型 描述 默认值 executor(必填) string 唯一的执行者名称 - startTime string 自测试开始以来的时间偏移，此时该场景应开始执行。 \u0026ldquo;0s\u0026rdquo; gracefulStop string 在强行停止迭代之前等待迭代完成执行的时间。要了解更多信息，请阅读优雅停止。 \u0026ldquo;30s\u0026rdquo; exec string 要执行的导出 JS 函数的名称。 \u0026ldquo;default\u0026rdquo; env object 此场景特定的环境变量。 {} tags object 特定于此场景的标签。 {} 测试场景示例 测试场景的 demo 脚本 会结合两种场景并按顺序执行：\nshared_iter_scenario 立即启动。10 个 VU 尝试尽快使用 100 次迭代（某些 VU 可能比其他 VU 使用更多迭代）。 per_vu_scenario 在 10 秒后开始。在这种情况下，十个 VU 每个运行十次迭代。 示例代码如下：\nimport http from \u0026#39;k6/http\u0026#39;; export const options = { scenarios: { shared_iter_scenario: { executor: \u0026#39;shared-iterations\u0026#39;, vus: 10, iterations: 100, startTime: \u0026#39;0s\u0026#39;, }, per_vu_scenario: { executor: \u0026#39;per-vu-iterations\u0026#39;, vus: 10, iterations: 10, startTime: \u0026#39;10s\u0026#39;, }, }, }; export default function () { http.get(\u0026#39;https://test.k6.io/\u0026#39;); } 运行场景 demo 脚本，可以看到如下结果：\n观看测试结果，你会发现配置了场景的测试结果中，除了常规的测试结果外，k6 输出将包含有关 demo 场景的 详细结果信息 (shared_iter_scenario 场景和 per_vu_scenario 场景的很详细的指标信息)。\n更多关于测试场景的内容，请参考官方文档：https://k6.io/docs/using-k6/scenarios/\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ K6 性能测试教程：常用功能（1）- HTTP 请求，指标和检查:https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-common-functions-1-http-request-metrics-and-checks/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-common-functions-2-thresholds-test-lifecycle-and-scenarios/","summary":"这篇博文深入介绍了 K6 性能测试工具的常用功能，主要聚焦在阈值设置、测试生命周期和场景设计方面。阐述了如何利用 K6 在性能测试中设定合理的阈值，以便有效监测系统的性能表现。同时，探讨了测试生命周期的重要性，以及如何在不同阶段进行有针对性的性能测试。此外，博文还详细解释了 K6 中场景的概念，以及如何根据实际需求设计和配置场景，确保测试全面覆盖各种使用情景。通过本文，读者能够更深入地了解 K6 性能测试工具在项目中的实际应用，提高性能测试的效果和准确性。","title":"K6 性能测试教程：常用功能（2）- 阈值，测试生命周期和场景"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n等待，不要休眠 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/await-dont-sleep.md\n一段简要说明 在测试 UI 时，您需要定义应用程序必须经过的关键点。到达这些关键点是一个异步过程，因为几乎 100% 的情况下，UI 不会同步更新。\n这些关键点称为确定性事件，即您知道必须发生的事件。\n具体取决于您定义的事件以及 UI 达到这些事件的方式，但通常会存在一些“长时间”等待，例如 XHR 请求，以及一些更快的等待，例如重新渲染更新。\n解决异步更新的方法似乎很简单：休眠/暂停测试一段时间，几毫秒、几分之一秒，甚至几秒钟。这可以使测试正常工作，因为它给应用程序足够的时间来更新自身并移动到下一个要测试的确定性事件。\n请注意，除了特定和已知的等待（例如使用 setInterval 或 setTimeout 时），完全无法预测休眠时间应该是多久，因为它可能取决于：\n网络状态（对于 XHR 请求） 可用机器资源的总量（CPU、RAM 等） 例如，CI 流水线可能会对其进行限制 在本地机器上，其他应用程序也可能会消耗这些资源 其他资源消耗更新的并发情况（canvas 等） 一系列不可预测的因素，如 Service Workers、缓存管理等，可能加快或减缓 UI 更新过程 每个固定的延迟都会使测试变得更加脆弱，并增加其持续时间。您需要在虚假负面和夸张的测试持续时间之间找到平衡。\n等待可分为四个主要类别：\n页面加载等待：测试应用程序时需要处理的第一个等待，等待一个允许您了解页面是否可交互的事件 内容等待：等待匹配选择器的 DOM 元素 XHR 请求等待：等待 XHR 请求开始或相应接收到 以下所有示例都基于 Cypress。\n页面加载等待 // Cypress code cy.visit(\u0026#39;http://localhost:3000\u0026#39;) 内容等待 请看以下示例，了解如何在可用工具中实现等待 DOM 元素。\n内容等待代码示例 等待元素 // Cypress code // it waits up to 4 seconds by default cy.get(\u0026#39;#form-feedback\u0026#39;) // the timeout can be customized cy.get(\u0026#39;#form-feedback\u0026#39;, { timeout: 5000 }) 等待具有特定内容的元素 // Cypress code cy.get(\u0026#39;#form-feedback\u0026#39;).contains(\u0026#39;Success\u0026#39;) XHR-请求等待 XHR-请求等待代码示例 等待 XHR 请求/响应 // Cypress code cy.intercept(\u0026#39;http://dummy.restapiexample.com/api/v1/employees\u0026#39;).as(\u0026#39;employees\u0026#39;) cy.wait(\u0026#39;@employees\u0026#39;) .its(\u0026#39;response.body\u0026#39;) .then((body) =\u0026gt; { /* ... */ }) 由 NoriSte 在 dev.to 和 Medium上进行联合发表.\n明智地为测试文件命名 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/name-test-files-wisely.md\n一段简要说明 编写各种不同的 UI 测试是一种好习惯，而采用一种常见的测试文件命名方式更是有益的。\n这很有用，因为通常情况下，你需要仅运行某一类测试，可能的情况包括：\n在开发过程中，你只需要运行其中一些测试 你正在更改一些相关组件，并需要检查生成的标记是否发生了变化 你正在更改全局 CSS 规则，只需运行视觉测试 你正在更改应用程序流程，需要运行整个应用程序集成测试 你的 DevOps 同事需要确保一切正常运行，最简单的方法就是只运行端对端测试 你的构建流水线需要运行集成测试和端对端测试 你的监控流水线需要一个脚本来运行端对端测试和监控测试 如果你为测试取一个明智的命名，将会非常容易只运行其中的某些类型。\nCypress:\ncypress run --spec \\\u0026#34;cypress/integration/**/*.e2e.*\\\u0026#34; Jest:\njest --testPathPattern=e2e\\\\.*$ 没有一种全局的命名测试文件的方式，一个建议是使用以下方式命名：\n正在测试的主题 测试的类型（integration、e2e、monitoring、component等） 选择的测试后缀（test、spec等） 文件扩展名（.js、.ts、.jsx、.tsx等） 它们之间用句点分隔。\n以下是一些例子：\nauthentication.e2e.test.ts authentication.integration.test.ts site.monitoring.test.js login.component.test.tsx 等等。 参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-best-practices-1-await-dont-sleep-and-name-test-files-wisely/","summary":"这篇博文探讨了 UI 测试的通用最佳实践之一：等待策略。强调了在 UI 测试中避免使用休眠（sleep）方法，而是采用等待机制来确保测试脚本与应用程序的同步。此外，博文提倡为测试文件采用明智的命名规范，以提高代码可维护性和可读性。通过这些最佳实践，读者将更有效地编写稳健的 UI 测试脚本，确保测试的准确性和可靠性，提升整个软件开发过程的质量。","title":"UI 测试最佳实践的通用最佳实践（一）：等待，不要休眠和明智地为测试文件命名"},{"content":"K6 常用功能 HTTP Requests 使用 K6 进行性能测试的第一步就是定义要测试的 HTTP 请求。\nGET 请求例子 使用 k6 new 命令创建的 demo 测试脚本中，已经包含了一个简单的 GET 方法 HTTP 请求：\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export default function() { http.get(\u0026#39;https://test.k6.io\u0026#39;); sleep(1); } POST 请求例子 这个 POST 请求例子展示一些复杂的场景的应用（带有电子邮件/密码身份验证负载的 POST 请求）\nimport http from \u0026#39;k6/http\u0026#39;; export default function () { const url = \u0026#39;http://test.k6.io/login\u0026#39;; const payload = JSON.stringify({ email: \u0026#39;aaa\u0026#39;, password: \u0026#39;bbb\u0026#39;, }); const params = { headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, }; http.post(url, payload, params); } 以上内容参考自 K6 官方文档\n支持的 HTTP 方法 K6 提供的 HTTP 模块能处理各种 HTTP 请求和方法。以下是支持的 HTTP 方法列表：\n方法 作用 batch() 并行发出多个 HTTP 请求（例如浏览器往往会这样做）。 del() 发出 HTTP DELETE 请求。 get() 发出 HTTP GET 请求。 head() 发出 HTTP HEAD 请求。 options() 发出 HTTP OPTIONS 请求。 patch() 发出 HTTP PATCH 请求。 post() 发出 HTTP POST 请求。 put() 发出 HTTP PUT 请求。 request() 发出任何类型的 HTTP 请求。 HTTP 请求标签 K6 允许为每个 HTTP 请求添加标签，结合标签和分组，可以很方便的在测试结果中更好地组织，分组请求和过滤结果组织分析。\n以下为支持的标签列表：\n标签 作用 name 请求名称。默认为请求的 URL method 请求方法（GET、POST、PUT 等） url 默认为请求的 URL。 expected_response 默认情况下，200 到 399 之间的响应状态为 true。使用 setResponseCallback 更改默认行为。 group 当请求在组内运行时，标记值是组名称。默认为空。 scenario 当请求在场景内运行时，标记值是场景名称。默认为 default。 status 响应状态 HTTP 请求使用 tag 和 group 标签的例子会在后续的 demo 中展示。\n大家也可以参考官方的例子：https://grafana.com/docs/k6/latest/using-k6/http-requests/\nMetrics 指标 指标用于衡量系统在测试条件下的性能。默认情况下，k6 会自动收集内置指标。除了内置指标，您还可以创建自定义指标。\n指标一般分为四大类：\n计数器（Counters）：对值求和。 计量器（Gauges）：跟踪最小、最大和最新的值。 比率（Rates）：跟踪非零值发生的频率。 趋势（Trends）：计算多个值的统计信息（如均值、模式或百分位数）。 要使测试断言符合需求标准，可以根据性能测试要求的指标条件编写阈值（表达式的具体内容取决于指标类型）。\n为了后续进行筛选指标，可以使用标签和分组，这样可以更好地组织测试结果。\n测试结果输出文件可以以各种摘要和细粒度格式导出指标，具体信息请参阅结果输出文档。（后面测试结果输出文档会详细介绍这一部分）\nK6 内置指标 每个 k6 测试执行都会发出内置和自定义指标。每个支持的协议也有其特定的指标。\n标准内置指标 无论测试使用什么协议，k6 始终收集以下指标：\n指标名称 指标分类 指标描述 vus Gauge 当前活跃虚拟用户数 vus_max Gauge 最大可能虚拟用户数（VU 资源已预先分配，以避免扩大负载时影响性能） iterations 迭代 Counter VU 执行 JS 脚本（default 函数）的总次数。 iteration_duration Trend 完成一次完整迭代的时间，包括在 setup 和 teardown 中花费的时间。要计算特定场景的迭代函数的持续时间，请尝试此解决方法 dropped_iterations Counter 由于缺少 VU（对于到达率执行程序）或时间不足（基于迭代的执行程序中的 maxDuration 已过期）而未启动的迭代次数。关于删除迭代 data_received Counter 接收到的数据量。此示例介绍如何跟踪单个 URL 的数据。 data_sent Counter 发送的数据量。跟踪单个 URL 的数据以跟踪单个 URL 的数据。 checks Rate 设置的检查成功率。 指标分类分别为：计数器（Counter）、计量器（Gauges）、比率（Rates）、趋势（Trends）\nHTTP 特定的内置指标 HTTP 特定的内置指标是仅在 HTTP 请求期间才会生成和收集的指标。其他类型的请求（例如 WebSocket）不会生成这些指标。\n注意：对于所有 http_req_* 指标，时间戳在请求结束时发出。换句话说，时间戳发生在 k6 收到响应正文末尾或请求超时时。\n下表列出了 HTTP 特定的内置指标：\n指标名称 指标分类 指标描述 http_reqs Counter k6 总共生成了多少个 HTTP 请求。 http_req_blocked Trend 在发起请求之前阻塞（等待空闲 TCP 连接槽）所花费的时间。float类型 http_req_connecting Trend 与远程主机建立 TCP 连接所花费的时间。float类型 http_req_tls_handshaking Trend 与远程主机握手 TLS 会话所花费的时间 http_req_sending Trend 向远程主机发送数据所花费的时间。float类型 http_req_waiting Trend 等待远程主机响应所花费的时间（也称为“第一个字节的时间”或“TTFB”）。float类型 http_req_receiving Trend 从远程主机接收响应数据所花费的时间。float类型 http_req_duration Trend 请求的总时间。它等于 http_req_sending + http_req_waiting + http_req_receiving（即远程服务器处理请求和响应所需的时间，没有初始 DNS 查找/连接时间）。float类型 http_req_failed Rate 根据 setResponseCallback 的失败请求率。 指标分类分别为：计数器（Counter）、计量器（Gauges）、比率（Rates）、趋势（Trends）\n其他内置指标 K6 内置指标除了标准内置指标和 HTTP 特定的内置指标外，还有其他内置指标：\nBrowser metrics 浏览器指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#browser Built-in WebSocket metrics 内置 WebSocket 指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#websockets Built-in gRPC metrics 内置 gRPC 指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#grpc 自定义指标 除了系统内建的指标之外，您还可以创建自定义指标。例如，您可以计算与业务逻辑相关的指标，或者利用 Response.timings 对象为特定的一组端点创建指标。\n每种指标类型都有一个构造函数，用于生成自定义指标。该构造函数会生成一个声明类型的指标对象。每种类型都有一个 add 方法，用于记录指标测量值。\n注意：必须在 init 上下文中创建自定义指标。这会限制内存并确保 K6 可以验证所有阈值是否评估了定义的指标。\n自定义指标 demo 示例 以下示例演示如何创建等待时间的自定义趋势指标：\n项目文件中的 demo_custom_metrics.js 文件已经包含了这个 demo 示例，可以直接运行查看结果。\n1.从导入 k6/metrics 模块引入 Trend 构造函数 import { Trend } from \u0026#39;k6/metrics\u0026#39;; 等待时间趋势指标属于趋势（Trends）指标，所以需要从 k6/metrics 模块引入 Trend 构造函数。\n2.在 init 上下文中构造一个新的自定义度量 Trend 对象 const myTrend = new Trend(\u0026#39;waiting_time\u0026#39;); 在 init 上下文中构造一个新的自定义度量 Trend 对象，脚本中的对象为 myTrend，其指标在结果输出中显示为 waiting_time。\n3.在脚本中使用 add 方法记录指标测量值 export default function() { const res = http.get(\u0026#39;https://test.k6.io\u0026#39;); myTrend.add(res.timings.waiting); } 在脚本中使用 add 方法记录指标测量值，这里使用了 res.timings.waiting，即等待时间。\n4.demo_custom_metrics.js 自定义指标完整代码 import http from \u0026#39;k6/http\u0026#39;; import { Trend } from \u0026#39;k6/metrics\u0026#39;; const myTrend = new Trend(\u0026#39;waiting_time\u0026#39;); export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); myTrend.add(res.timings.waiting); console.log(myTrend.name); // waiting_time } 5.运行 demo_custom_metrics.js 并查看自动化趋势指标 k6 run demo_custom_metrics.js 运行结果如下：\n可以看到，自定义指标 waiting_time 已经在结果输出中显示出来了。\n更多关于自定义指标的内容，请参考官方文档：https://k6.io/docs/using-k6/metrics/#custom-metrics\nChecks 检查 这里也可以理解为断言，即对测试结果进行验证。\n检查用来检验不同测试中的具体测试条件是否正确相应，和我们常规在做其他类型测试时也会对测试结果进行验证，以确保系统是否以期望的内容作出响应。\n例如，一个验证可以确保 POST 请求的响应状态为 201，或者响应体的大小是否符合预期。\n检查类似于许多测试框架中称为断言的概念，但是K6 在验证失败并不会中止测试或以失败状态结束。相反，k6 会在测试继续运行时追踪失败验证的比率。\n每个检查都创建一个速率指标。要使检查中止或导致测试失败，可以将其与阈值结合使用。\n下面会介绍如何使用不同类型的检查，以及如何在测试结果中查看检查结果。\n1.检查 HTTP 响应状态 K6 的检查非常适用于与 HTTP 请求相关的响应断言。\n示例，以下代码片段来检查 HTTP 响应代码为 200：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, }); } 运行该脚本，可以看到如下结果：\n当脚本包含检查时，摘要报告会显示通过了多少测试检查。\n在此示例中，请注意检查“HTTP response code is status 200”在调用时是 100% 成功的。\n2.检查 HTTP 响应体 除了检查 HTTP 响应状态外，还可以检查 HTTP 响应体。\n示例，以下代码片段来检查 HTTP 响应体大小为 9591 bytes：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response body size is 9591 bytes\u0026#39;: (r) =\u0026gt; r.body.length == 9591, }); } 运行该脚本，可以看到如下结果：\n当脚本包含检查时，摘要报告会显示通过了多少测试检查。\n在此示例中，请注意检查“HTTP response body size is 9591 bytes”在调用时是 100% 成功的。\n3.添加多个检查 有时候我们在一个测试脚本中需要添加多个检查，那可以直接在单​​个 check() 语句中添加多个检查，如下面脚本所示：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, \u0026#39;HTTP response body size is 9591 bytes\u0026#39;: (r) =\u0026gt; r.body.length == 9591, }); } 运行该脚本，可以看到如下结果：\n在此示例中，两个检查都是正常通过的（调用是 100% 成功的）。\n注意：当检查失败时，脚本将继续成功执行，并且不会返回“失败”退出状态。如果您需要根据检查结果使整个测试失败，则必须将检查与阈值结合起来。这在特定环境中特别有用，例如将 k6 集成到 CI 管道中或在安排性能测试时接收警报。\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-common-functions-1-http-request-metrics-and-checks/","summary":"这篇文章详细介绍了 K6 中的 HTTP 请求（http request）功能，解析了常用的性能指标和检查功能。学会如何使用 K6 进行强大的性能测试，通过 HTTP 请求模拟用户行为，了解性能指标以评估系统响应。文章还深入讲解了如何配置和执行检查，确保性能符合预期标准。无论您是初学者还是经验丰富的性能测试专业人员，这篇教程将为您提供实用知识，助您充分发挥 K6 的性能测试潜力。点击链接，开启高效性能测试之旅！","title":"K6 性能测试教程：常用功能（1）- HTTP 请求，指标和检查"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n什么样的测试策略才更合理 上一篇文章讲到了不同的测试类型，以及它们的优缺点。在这篇文章中，我们将深入探讨什么样的测试策略才更为合理。 会从在开始阶段，避免追求完美主义，选择一个参考浏览器，发现了 bug？先编写测试，然后再着手修复，和单个长的端到端测试还是多个小的独立测试？等方面阐述了什么样的测试策略才更合理\n在开始阶段，避免追求完美主义 测试真的改变了你的工作方式，但就像所有事情一样，需要一些经验才能真正发挥其威力。在一开始，务必避免完美主义的陷阱。为什么呢？\n测试本质上就是小程序。完美主义可能会导致你在了解如何处理不同的测试上下文之前编写非常复杂的测试。\n复杂的测试是个大敌人，因为调试失败的测试比调试失败的应用程序更加困难。而且复杂的测试让你失去了测试实践本身的优势，浪费了很多时间，最终不可避免地会让你放弃。如果你有这样的经历，不要气馁，对很多测试初学者来说都是一样的（对我来说也是，这就是我开始写这个 repo 的原因 😊），不要害怕向同事或其他开发人员寻求帮助。\n误报：完美主义导致很多误报。误报是指应用程序按预期工作，但测试失败的情况。\n误报在一开始确实让人泄气，因为你开始写测试是为了有一个盟友来检查应用程序状态\u0026hellip; 但最终你却得到了另一个需要维护的应用程序，而测试并没有提供任何帮助。如果你发现自己在与误报作斗争，请停下来，重新学习，并寻求帮助！\n测试的实用性：成功的测试在失败时直接指向问题。正确的断言和确定性事件使你的测试强大而且非常重要的是，它们在失败时是有用的。相反，过多的断言和检查可能会使你的测试因为无用而变得脆弱。\n所谓完美主义是指检查每一个前端细节。在开始时，你的有限的测试经验不允许你有针对性地测试所有的交互。开始时，测试一些简单的事情，比如\n页面是否正确加载？ 菜单按钮是否正常工作？ 用户是否能够填写表单并成功跳转到感谢页面？ 而在开始阶段，不要过于关注测试一些诸如\n条件数据加载 复杂的表单规则 无控制的（第三方）集成 元素选择器 等复杂的交互。 为了避免陷入完美主义的陷阱，初学者的待办事项清单可以是：\n选择最简单的测试对象（对用户有用的东西）。 从用户的角度考虑。记住用户关心内容和功能，而不关心选择器和内部应用程序状态。 编写你的测试。 运行测试多次以确保它的稳定性。 当测试成功时，在前端应用程序中插入一个导致它失败的错误，然后检查测试是否失败。然后移除你故意插入的错误。 以无头和非无头模式运行测试。 根据你的经验（也问问同事），思考从你测试的内容的角度看，可能导致前端应用程序失败的原因是什么。 模拟不同的前端故障（关闭服务器、插入其他错误）并检查测试是否提供足够的反馈，以了解哪里失败了。 仅对两三种故障进行测试，记住你有限的经验可能导致你测试错误的东西。 然后，转移到另一个测试对象并重复所有先前的步骤。 软件测试是一场奇妙的旅程，这个 repo 的目标是帮助你避免最常见的陷阱。\n建议的流程只是可能方法之一。我知道一切都是主观的，请为每个建议提出请求以进行改进！\n选择一个参考浏览器 每个人都关心跨浏览器测试。我们通常习惯在每个浏览器上手动测试所有内容，因为我们知道，不同浏览器之间存在许多差异。当我们开始评估合适的测试工具时，跨浏览器测试是一个重要的话题，也是你在考虑时可能首先想到的。但是不要担心：首先从功能测试和视觉测试分离开始，这是正确评估跨浏览器支持需求（也是选择正确测试工具的第一步）。视觉测试可以集成到每个测试工具中，感谢诸如 Applitools 和 Percy 这样的服务。\n换句话说，不要仅仅基于跨浏览器支持来选择测试工具。以下是一些建议：\nSelenium 和 Puppeteer 是通用的自动化工具。它们可以用作测试工具（有许多插件和模块可帮助你实现），但它们并非专为测试而设计，因此它们缺少一些集成实用工具，这可能使测试编写更加简便。\n只考虑 Cypress、Playwright 和 TestCafé，因为它们是专为简化 UI 测试过程而创建的工具。这些工具自动处理一半的最佳实践，而在测试中的一些方面，它们可能更符合你的需求。在 UI 测试方面，由于其\n困难性，花些时间试验这些工具是值得的。\n仔细思考你需要测试什么。如果你需要测试特定的移动能力，请选择 TestCafé，但如果你只需要测试表单和按钮是否正常工作，你在选择上就更加灵活。\n查看 Cypress Test Runner，这是使 Cypress 异于常人的工具，对于测试开发过程中非常有帮助。\n研究 Playwright 在调试方面的优势。Playwright 非常快速稳定，最近其开发体验有了很大改进。\n跨浏览器测试通常涉及到视觉测试（CSS 浏览器差异），但这与功能测试不同。视觉测试得益于许多专用插件和工具的支持。详细了解 视觉测试对应的章节 Applitools，其中我们讨论了一些专用产品，这些产品可以与几乎所有测试工具集成，通过将被测试页面的快照上传到其服务器并进行呈现来进行工作。\n你还可以在 等待，不是休眠 章节中了解各种测试工具之间的一些差异。\n发现了 bug？先编写测试，然后再着手修复 所以，当你在前端应用程序中发现错误并已经进行了调试时，你可以系统地复现它，准备好修复它。以测试为导向的思维必须经历以下步骤：\n确定预期的行为。 编写一个测试，旨在以正确的方式使用前端应用程序。 测试必须失败，因为错误不允许用户完成任务。 修复错误。 检查测试现在是否通过。 为什么要采用这种方法？为什么要编写测试呢？我知道直接修复错误可能看起来更快，但请考虑以下几点：\n通常情况下，你的测试工具比你更快地达到显示错误的应用程序状态（参见使用测试工具作为主要开发工具 章节）。\n有时你认为你能够系统地复现错误，但这并不总是正确的。编写一个揭示错误的测试可以确保你百分之百确定错误是可重现的，排除了许多偏差变量，如现有的会话、缓存、服务工作者、浏览器扩展、浏览器版本等，这些可能会影响你的信心。有时你可能会发现你并没有完全正确地识别错误。\n与此同时，当测试通过了你的修复时，你确实知道你的解决方\n案按预期工作。可能影响错误识别过程的相同变量可能会影响工作效果的虚假感觉。\n有了测试，错误就可以永远修复了！ 测试将被执行成千上万次，让你对错误修复感到百分之百的信心。\n成功的测试可以作为你所做工作的验证轨迹。\n最后但同样重要的是：确保你编写的测试一开始是失败的！而且它之所以失败是因为有错误！\n测试不仅仅是为了重现错误并在视觉上检查它，而是必须在修复错误后获得积极的反馈。与错误相关的测试如果一开始就没有失败，那真的非常危险，因为你可能认为你做得很好，而实际上你从一开始就没有完全正确地重现错误。\n作为一般规则：破碎的流程必须有一个破碎的测试，一个成功的测试必须与一个正常工作的应用程序相关联。\n单个长的端到端测试还是多个小的独立测试？ 在讨论对 CRUD 应用进行测试时，我们应该如何组织“创建”、“修改”和“删除”端到端（E2E）测试呢？\n完整的选项列表如下：\n有三个小的 E2E 测试，依赖于执行顺序（测试 B 假设测试 A 已运行）- 这是唯一的不良解决方案，我将解释原因。 有三个小的 E2E 测试，独立于执行顺序（测试 B 不受测试 A 是否运行的影响）- 从理论上讲，是最好的解决方案。但仍然需要大量样板代码，而且为了快速执行。 有一个执行所有操作的扩展 E2E 测试 - 对于本文介绍的案例来说，这是一个很好的折中方案。 这取决于情况，我提到的大多数问题与 E2E 测试的隐含问题有关，这是我们应该尽量减少这类测试的强烈信号。作为前端工程师，我更喜欢投资时间编写无需服务器的测试，而不是 E2E 测试。继续阅读，你将了解原因。\n1 - 有三个小的 E2E 测试，依赖于执行顺序（测试 B 假设测试 A 已运行） 测试流程如下：\n开始（应用程序状态为空） 测试 1: 创建实体 测试 2: 修改实体 测试 3: 删除实体 结束（应用程序状态为空） 在这种情况下，这些测试不是独立的，而是依赖于执行顺序。为了测试 CRUD 流程，有三个主要测试：\u0026ldquo;创建实体\u0026rdquo;、\u0026ldquo;修改实体\u0026rdquo;、\u0026ldquo;删除实体\u0026rdquo;。第二个测试（\u0026ldquo;修改实体\u0026rdquo;）假设在其启动时应用程序状态是正确的，因为它在 \u0026ldquo;创建实体\u0026rdquo; 之后运行。\u0026ldquo;删除实体\u0026rdquo; 也必须在 \u0026ldquo;修改实体\u0026rdquo; 之后运行，依此类推。\n将多个测试耦合在一起是一种反模式，原因如下：\n误报：一旦一个测试失败，后续测试会连续失败。 难以调试：由于不确定性较高，理解失败的根本原因更加复杂。测试失败是因为代码本身失败？还是因为先前测试的状态发生了变化？然后，当一个测试失败时，你必须调试两个测试。 难以调试（再次）：开发人员会浪费大量时间，因为他们无法运行单个测试，也无法使用 skip 和 only 仅运行其中一部分测试。 难以重构：测试无法移动到其他位置。如果测试代码变得太长、太复杂等，你无法将其移动到专用文件/目录中，因为它依赖于先前的测试。 难以阅读：读者无法知道一个测试的作用，因为他们还必须了解先前的测试。你必须阅读两个测试，而不是一个，这是不好的。 我不建议以这种方式编写耦合的测试，但我想包含它们以确保您明白原因。\n2 - 设计三个小型端到端（E2E）测试，使其独立于执行顺序 为了确保每个测试的独立性，每个测试在运行前都应该创建所需的应用程序状态，然后在完成后进行清理。相较于原有的顺序（创建-\u0026gt;修改-\u0026gt;删除），前文提到的流程应该调整如下（斜体 表示与原有流程相比的新步骤）：\n开始（应用程序状态为空） 测试 1：创建实体 之前：加载页面（应用程序状态为空） 创建实体 之后：删除实体（应用程序状态为空） 测试 2：修改实体 之前：通过 API 创建实体 之前：加载页面（应用程序状态为空） 修改实体 之后：通过 API 删除实体（应用程序状态为空） 测试 3：删除实体 之前：通过 API 创建实体 之前：加载页面（应用程序状态为空） 删除实体 之后：删除操作（应用程序状态为空） 结束（应用程序状态为空） 通过这种方式，每个测试都是相互独立的。需要注意的是，之前和之后的操作直接通过调用服务器 API 完成，因为通过 UI 完成这些操作将会很慢。然而，这种方法的问题在于测试变得更加耗时，因为每个测试都需要创建实体，并且每个测试都需要访问页面。当应用程序加载需要花费 10 秒钟时（Hasura 的控制台最初的情况），重新加载应用程序将成为一个问题。\n为了确保测试既独立又高效，我们需要进一步改进上述流程：\n充分利用前一个测试的应用状态。 同时，如果尚未运行测试，还需要创建所需的应用状态。 具体来说，流程如下（与前一章节相比，斜体表示新步骤）：\n开始（应用状态为空）\n测试 1： 创建实体\n之前：实体 是否存在？ 否：没问题！ 是：通过 API 删除实体 之前：加载页面（应用状态为空） 创建实体 测试 2： 修改实体\n之前：实体 是否存在？ 是：没问题！ 否：通过 API 创建实体 之前：实体 是否已包含测试即将进行的更改？ 是：没问题！ 否：通过 API 修改实体 之前：我们是否已经在正确的页面上？ 是：没问题！ 否：加载页面 修改实体 测试 3： 删除实体\n之前：实体是否存在？ 是：没问题！ 否：通过 API 创建实体 之前：我们是否已经在正确的页面上？ 是：没问题！ 否：加载页面 删除实体\n结束（应用状态为空）\n现在，如果你一次运行所有测试，每个测试都会利用之前测试的应用状态。如果只运行“修改实体”测试，它会创建所需的一切，然后运行测试本身。\n现在我们既有测试的独立性又有测试的性能！很不错！\n嗯\u0026hellip; 你是否注意到我们需要编写大量代码？cypress-data-session 插件很方便，但存在两个问题：\n有很多与 cypress-data-session 相关的样板代码 在 E2E 测试中，必须维护许多可能与主应用程序中使用的 API 调用不同步的 API 调用。 这是一个与 cypress-data-session 相关的样板代码示例（来自 Hasura Console 代码库）。\nimport { readMetadata } from \u0026#39;../services/readMetadata\u0026#39;; import { deleteHakunaMatataPermission } from \u0026#39;../services/deleteHakunaMatataPermission\u0026#39;; /** * Ensure the Action does not have the Permission. * * ATTENTION: if you get the \u0026#34;setup function changed for session...\u0026#34; error, simply close the * Cypress-controlled browser and re-launch the test file. */ export function hakunaMatataPermissionMustNotExist( settingUpApplicationState = true ) { cy.dataSession({ name: \u0026#39;hakunaMatataPermissionMustNotExist\u0026#39;, // Without it, cy.dataSession run the setup function also the very first time, trying to // delete a Permission that does not exist init: () =\u0026gt; true, // Check if the Permission exists validate: () =\u0026gt; { Cypress.log({ message: \u0026#39;**--- Action check: start**\u0026#39; }); return readMetadata().then(response =\u0026gt; { const loginAction = response.body.actions?.find( action =\u0026gt; action.name === \u0026#39;login\u0026#39; ); if (!loginAction || !loginAction.permissions) return true; const permission = loginAction.permissions.find( permission =\u0026gt; permission.role === \u0026#39;hakuna_matata\u0026#39; ); // Returns true if the permission does not exist return !permission; }); }, preSetup: () =\u0026gt; Cypress.log({ message: \u0026#39;**--- The permission must be deleted**\u0026#39; }), // Delete the Permission setup: () =\u0026gt; { deleteHakunaMatataPermission(); if (settingUpApplicationState) { // Ensure the UI read the latest data if it were previously loaded cy.reload(); } }, }); } 以下是用于创建实体的 API 调用示例（来自 Hasura Console 代码库）。\n/** * Create the Action straight on the server. */ export function createLoginAction() { Cypress.log({ message: \u0026#39;**--- Action creation: start**\u0026#39; }); cy.request(\u0026#39;POST\u0026#39;, \u0026#39;http://localhost:8080/v1/metadata\u0026#39;, { type: \u0026#39;bulk\u0026#39;, source: \u0026#39;default\u0026#39;, args: [ { type: \u0026#39;set_custom_types\u0026#39;, args: { scalars: [], input_objects: [ { name: \u0026#39;SampleInput\u0026#39;, fields: [ { name: \u0026#39;username\u0026#39;, type: \u0026#39;String!\u0026#39; }, { name: \u0026#39;password\u0026#39;, type: \u0026#39;String!\u0026#39; }, ], }, ], objects: [ { name: \u0026#39;SampleOutput\u0026#39;, fields: [{ name: \u0026#39;accessToken\u0026#39;, type: \u0026#39;String!\u0026#39; }], }, { name: \u0026#39;LoginResponse\u0026#39;, description: null, fields: [ { name: \u0026#39;accessToken\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, ], }, { name: \u0026#39;AddResult\u0026#39;, fields: [{ name: \u0026#39;sum\u0026#39;, type: \u0026#39;Int\u0026#39; }], }, ], enums: [], }, }, { type: \u0026#39;create_action\u0026#39;, args: { name: \u0026#39;login\u0026#39;, definition: { arguments: [ { name: \u0026#39;username\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, { name: \u0026#39;password\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, ], kind: \u0026#39;synchronous\u0026#39;, output_type: \u0026#39;LoginResponse\u0026#39;, handler: \u0026#39;https://hasura-actions-demo.glitch.me/login\u0026#39;, type: \u0026#39;mutation\u0026#39;, headers: [], timeout: 25, request_transform: null, }, comment: null, }, }, ], }).then(() =\u0026gt; Cypress.log({ message: \u0026#39;**--- Action creation: end**\u0026#39; })); } 因此，拥有独立的测试是至关重要的，但也伴随着一些成本。\n这就是为什么，针对这个具体问题，我选择了最后一种选择\u0026hellip;\n3 - 进行一次全面的端到端测试 优点：可以减少很多样板文件。\n缺点：与测试一起工作变得更慢了（你不能再仅运行第三个测试了）\n与我们需要编写的样板和需要维护的代码相比，将它们统一起来是值得的。毕竟，我正在处理的特定 CRUD 流程大约需要 20 秒。\n开始 (应用程序状态为空) 测试：CRUD 之前*：如果存在实体，则删除它（应用程序状态为空）* 之前*：加载页面* 创建实体 修改实体 删除实体 之后*：如果存在实体，则删除它（应用程序状态为空）* 结束 (应用程序状态为空) 同时，这也使得 cypress-data-session 变得无用。因此，少了一个需要保持更新的依赖。\n结论 处理端到端测试很困难。处理真实数据、清除真实应用程序状态等都是有成本的。我知道端到端测试是唯一能够提供完整信心的测试，但作为一名前端工程师（请记住，我不是 QA 工程师），我更愿意使用无需服务器的测试。\n相关章节 🔗 从金字塔的顶端着手构建测试！ 🔗 把你的测试工具当作主要的开发工具来使用 由 NoriSte 在 dev.to上进行了跨发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-testing-strategy-2-more-reasonable-testing-strategy-for-ui-testing/","summary":"这篇博文深入探讨 UI 测试最佳实践的测试策略（二），着重介绍了更为合理的测试策略。从避免追求完美主义、选择参考浏览器、发现 Bug 时的处理方式，到在修复之前编写测试、单个长的端到端测试与多个小的独立测试的选择，全面阐述了什么样的测试策略更为合理。无论是初学者还是经验丰富的测试专业人员，这篇博文都将为您提供实用的指导，帮助您制定更明智、高效的 UI 测试策略。点击链接，探索更合理的 UI 测试方法！","title":"UI 测试最佳实践的测试策略（二）：什么样的测试策略才更合理"},{"content":"一段简要说明 在谈论 UI 测试时（请记住我们只谈论 UI，而不是底层 JavaScript 代码），有三种主要的测试类型：\n组件测试：UI 的单元测试，它们在隔离的环境中测试每个单独的组件。\n在隔离中开发组件很重要，因为它允许你将它们与相应的容器/用途隔离开来。组件存在是为了隔离单一的行为/内容（单一职责原则），因此，在隔离中编码是有益的。\n有许多在隔离中开发组件的方法和工具，但由于其效果和生态系统，Storybook 成为了标准选择。\n组件有三种类型的契约：生成的输出（HTML），它们的视觉方面（CSS）和外部 API（props 和回调）。测试每个方面可能很繁琐，这就是 Storyshots 可以派上用场的地方。它允许你自动化：\n快照测试：快照是组件生成的输出，一个包含所有呈现 HTML 的字符串。如果生成的 HTML 更改，无论是意外还是非意外，快照测试都会失败，你可以选择这些更改是有意还是无意。\n视觉回归测试：与先前的组件相比，组件的视觉方面逐像素比较，同样，你被提示选择是否接受更改。\n这些测试由 Storyshots 在每个 Storybook 页面（又名“故事”）上自动启动。\n回调测试：一个小的 React 容器应用呈现组件并传递一些回调。然后，模拟用户交互并传递期望调用的回调。React Testing Library 是这类测试的标准库。\n交互/状态测试：与组件的一些交互期望正确的状态管理。这种类型的测试必须从消费者的角度编写，而不是从内部的角度（例如，用户填写输入字段时的输入字段值，而不是内部组件状态）。交互/状态测试应在触发键盘事件后断言输入字段的值。\n或者，Cypress 推出了自己的解决方案，以便在其中启动组件测试，请查看 使用 Cypress 进行 React 组件单元测试 章节。\nUI 集成测试：它们在真实浏览器中运行整个应用 而不连接真实服务器。这些测试是每个前端开发人员的王牌。它们运行速度快，不容易出现随机失败或假阴性。\n前端应用程序并不知道没有真实服务器：每个 AJAX 调用都会被测试工具在瞬间解决。静态 JSON 响应（称为“fixtures”）用于模拟服务器响应。Fixtures 允许我们测试前端状态，模拟每种可能的后端状态。\n另一个有趣的效果是：Fixtures 允许您在没有工作的后端 应用程序的情况下工作。您可以将 UI 集成测试视为“仅前端”测试。\n在最成功的测试套件的核心，有很多 UI 集成测试，考虑到对前端应用程序的最佳测试类型。\n端到端（E2E）测试：它们与真实服务器进行交互，运行整个应用程序。从用户交互（其中之一是“端”）到业务数据（另一个“端”）：一切都必须按设计工作。E2E 测试通常很慢，因为\n它们需要一个 工作的后端 应用程序，通常在前端应用程序旁边启动。没有服务器，你不能启动它们，所以你依赖于后端开发人员的工作 它们需要 可靠的数据，在每次测试之前进行种植和清理 这就是为什么 E2E 测试不可行作为唯一/主要测试类型的原因。它们非常重要，因为它们测试所有内容（前端 + 后端），但必须小心使用，以避免脆弱且持续时间长的测试套件。\n在具有许多 UI 集成测试的完整套件中，您可以将 E2E 测试视为“后端测试”。通过它们，您应该测试哪些流程？\n快乐路径流程：您需要确保至少用户能够完成基本操作 对您的业务有价值 在具有许多 UI 集成测试的完整套件中，您可以将 E2E 测试视为“后端测试”。通过它们，您应该测试哪些流程？\n快乐路径流程：您需要确保至少用户能够完成基本操作 对您的业务有价值的一切：无论是快乐路径还是其他，都要测试您的业务关心的任何内容（明显是优先考虑它们） 经常中断的一切：系统的薄弱区域也必须受到监视 识别/定义测试类型对于对它们进行分组、合理命名测试文件、限制它们的\n范围以及选择是否在整个应用程序和部署流水线中运行它们很有用。\n由NoriSte在dev.to和Medium上进行了跨发表。\n翻译自：Component vs (UI) Integration vs E2E Tests*\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-testing-strategy-1-component-tests-vs-ui-integration-tests-vs-e2e-tests/","summary":"这篇博文深入研究 UI 测试最佳实践，首篇聚焦于测试策略的选择：组件测试、UI 集成测试和端到端（E2E）测试的区别。了解每种测试类型的优缺点，帮助您在 UI 测试中做出明智的选择。不论您是开发者还是测试专业人员，这篇文章将为您提供深入洞察，助力您设计出更可靠、高效的 UI 测试策略。点击链接，探索 UI 测试的最佳实践，提升您的测试流程质量。","title":"UI 测试最佳实践的测试策略（一）：组件测试 vs（UI）集成测试 vs E2E 测试"},{"content":"什么是 K6 k6 是一款用于性能测试和负载测试的开源工具，主要用于评估和验证应用程序的性能和稳定性。以下是关于 k6 的一些主要特点和信息：\n开源性： k6 是一款完全开源的性能测试工具，代码存储在 GitHub 上。这意味着用户可以自由访问、使用和修改工具的源代码。\nJavaScript 编写脚本： k6 使用 JavaScript 语言编写测试脚本，这使得编写测试用例相对简单，并且对于开发人员而言更加友好。脚本可以包含 HTTP 请求、WebSocket 连接、脚本执行逻辑等。\n支持多种协议： k6 支持多种常见的协议，包括 HTTP、WebSocket、Socket.IO、gRPC 等，使其可以广泛应用于各种类型的应用程序。\n分布式测试： k6 具有分布式测试的能力，允许在多个节点上运行测试，从而模拟更真实的生产环境负载。\n实时结果和报告： k6 提供实时结果，包括请求响应时间、吞吐量等，并能够生成详细的 HTML 报告，帮助用户更好地理解应用程序的性能状况。\n容器化支持： k6 适应容器化环境，可以轻松集成到 CI/CD 流水线中，并与常见的容器编排工具（如 Kubernetes）配合使用。\n插件生态系统： k6 支持插件，用户可以通过插件扩展其功能，满足特定需求。\n活跃的社区： 由于 k6 是一个开源项目，拥有一个积极的社区，提供支持、文档和示例，使用户更容易上手和解决问题。\n总体而言，k6 是一个灵活、强大且易于使用的性能测试工具，适用于各种规模的应用程序和系统。\n官方网站及文档 官方网站 官方文档 安装 Mac 系统安装 Mac 系统可以通过 Homebrew 安装 k6：\nbrew install k6 Windows 系统安装 Windows 系统可以通过 Chocolatey 安装 k6：\nchoco install k6 或者通过 winget 安装 k6：\nwinget install k6 Docker 安装 k6 也可以通过 Docker 安装：\ndocker pull grafana/k6 其他系统安装 K6 除了支持上述系统外，还支持 Linux（Debian/Ubuntu/Fedora/CentOS），也支持下载 K6 二进制文件和 K6 扩展进行安装，具体安装方式请参考官方文档。\n确认 K6 安装成功 安装完成后，可以通过以下命令确认 k6 是否安装成功：\nk6 version 如果安装成功，会显示 k6 的版本信息：\n第一个 K6 测试脚本 编写第一个测试脚本 新建一个 K6 性能测试项目目录并进入 mkdir k6-demo cd k6-demo 创建一个名为 demo.js 的文件，用于编写测试脚本 可以通过 k6 new 命令创建一个测试脚本文件： k6 new demo.js 也可以直接创建一个名为 demo.js 的测试脚本文件 touch demo.js 编辑测试脚本 如果是通过 k6 new 命令创建的测试脚本文件，会自动生成一个简单的测试脚本，如下所示：\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { // A number specifying the number of VUs to run concurrently. vus: 10, // A string specifying the total duration of the test run. duration: \u0026#39;30s\u0026#39;, // The following section contains configuration options for execution of this // test script in Grafana Cloud. // // See https://grafana.com/docs/grafana-cloud/k6/get-started/run-cloud-tests-from-the-cli/ // to learn about authoring and running k6 test scripts in Grafana k6 Cloud. // // ext: { // loadimpact: { // // The ID of the project to which the test is assigned in the k6 Cloud UI. // // By default tests are executed in default project. // projectID: \u0026#34;\u0026#34;, // // The name of the test in the k6 Cloud UI. // // Test runs with the same name will be grouped. // name: \u0026#34;demo.js\u0026#34; // } // }, // Uncomment this section to enable the use of Browser API in your tests. // // See https://grafana.com/docs/k6/latest/using-k6-browser/running-browser-tests/ to learn more // about using Browser API in your test scripts. // // scenarios: { // // The scenario name appears in the result summary, tags, and so on. // // You can give the scenario any name, as long as each name in the script is unique. // ui: { // // Executor is a mandatory parameter for browser-based tests. // // Shared iterations in this case tells k6 to reuse VUs to execute iterations. // // // // See https://grafana.com/docs/k6/latest/using-k6/scenarios/executors/ for other executor types. // executor: \u0026#39;shared-iterations\u0026#39;, // options: { // browser: { // // This is a mandatory parameter that instructs k6 to launch and // // connect to a chromium-based browser, and use it to run UI-based // // tests. // type: \u0026#39;chromium\u0026#39;, // }, // }, // }, // } }; // The function that defines VU logic. // // See https://grafana.com/docs/k6/latest/examples/get-started-with-k6/ to learn more // about authoring k6 scripts. // export default function() { http.get(\u0026#39;https://test.k6.io\u0026#39;); sleep(1); } 如果是直接创建的测试脚本文件，可以将上述内容复制到 demo.js 文件中。\n运行测试脚本 在 demo.js 文件所在目录下，运行以下命令：\nk6 run demo.js 查看测试结果 如果一切正常，会看到类似如下的输出：\n包含以下信息：\nexecution: 执行信息，包括开始时间、结束时间、持续时间、VU 数量、迭代次数等。 scenarios: 场景信息，包括场景名称、VU 数量、迭代次数、持续时间、平均响应时间、吞吐量等。 http_reqs: HTTP 请求信息，包括请求名称、请求数量、失败数量、平均响应时间、吞吐量等。 解析 demo 测试脚本 import http from 'k6/http';：导入 k6 的 HTTP 模块，用于发送 HTTP 请求。\nimport { sleep } from 'k6';：导入 k6 的 sleep 方法，用于执行脚本等待。\nexport const options = { ... }：定义测试脚本的配置项，包括 VU 数量、持续时间等。\nvus: 10,：定义 VU 数量为 10（指定并发运行的 VU 数量）。\nduration: '30s',：定义持续时间为 30 秒（指定测试运行总持续时间）。\nexport default function() { ... }：定义测试脚本的逻辑，包括发送 HTTP 请求、执行等待等。\nhttp.get('https://test.k6.io');：发送一个 GET 请求到 https://test.k6.io。\nsleep(1);：执行等待 1 秒。\n其他注释内容可以忽略，这些内容是关于 k6 的一些高级功能，后续会介绍。\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-getting-started-and-your-first-k6-test-script/","summary":"这篇文章将带您进入 K6 性能测试的世界。博文内容涵盖了 K6 性能测试的入门知识、环境搭建步骤，以及如何编写您的第一个测试脚本。无论您是初学者还是有经验的性能测试专业人员，这篇教程都将为您提供清晰的指导，帮助您快速上手 K6，并开始构建高效的性能测试脚本","title":"K6 性能测试教程：入门介绍，环境搭建和编写第一个 K6 测试脚本"},{"content":"亲爱的读者们，\n最近，在搜索引擎上检查个人博客文章的收录情况时，我不得不向大家通报一件令人痛心的事情。我发现我的博客文章竟然被一位 CSDN 博主原封不动地抄袭复制到他的博客上，而且更令人遗憾的是，他并未注明出处。\n对于这种不道德的行为，我感到愤怒和失望。我一直努力为大家提供原创、有价值的内容，而这样的抄袭行为是对我的辛勤努力和付出的严重不尊重。为了捍卫自己的权益，我认为有必要发布这篇声明，让大家了解事实真相。\n首先，我要明确表示，我坚决反对一切形式的抄袭和侵权行为。我运营的博客是我的个人创作空间，我希望它能成为分享和交流的平台，而不是被他人肆意剽窃的对象。\n在确认了 CSDN 博主的行为后，我深感遗憾，也决定采取一切必要的法律手段来维护自己的合法权益。同时，我呼吁所有博主和创作者共同努力，维护良好的创作环境，杜绝抄袭现象。\n最后，我要感谢一直以来支持我的读者们。你们的支持是我创作的动力，也是我战胜困难的力量。我会继续为大家带来真实、有价值的内容。\n抄袭博客链接：https://blog.csdn.net/2301_76387166?type=blog\n我已经联系 CSDN 下架。\n再次感谢大家的关注和支持。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/article-plagiarism-statement/","summary":"这篇博文是关于我的文章被抄袭的声明。","title":"关于我的文章被抄袭的声明"},{"content":"Java 和 REST Assured 框架实现接口自动化项目 REST Assured 框架教程目录 目录不可点击，仅为展示目录结构\nRestAssured 接口自动化测试快速启动项目 RestAssured 介绍 项目结构 Gradle 构建的版本 Maven 构建的版本 项目依赖 从 0 到 1 搭建 REST Assured 接口测试项目 Gradle 版本 Maven 版本 进阶用法 验证响应数据 文件上传 Logging 日志 Filters 过滤器 持续集成 接入 github action 集成 allure 测试报告 数据驱动 多环境支持 REST Assured 框架教程对应文章 REST Assured 接口自动化测试教程：进阶用法 - 集成 CI/CD 和集成 allure 测试报告:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-integration-ci-cd-and-allure-report/\nREST Assured 接口自动化测试教程：进阶用法 - 验证响应和日志记录，过滤器，文件上传:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-verifying-response-and-logging/\nREST Assured 接口自动化测试教程：从 0 到 1 搭建 REST Assured 接口自动化测试项目:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-building-your-own-project-from-0-to-1/\nREST Assured 接口自动化测试教程：入门介绍和环境搭建准备:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-and-environment-preparation/\nREST Assured 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/RestAssured-API-Test-Starter/ Rest assured 官方文档：https://rest-assured.io/ Rest assured 官方 github：https://github.com/rest-assured/rest-assured Rest assured 官方文档中文翻译：https://github.com/RookieTester/rest-assured-doc Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions JavaScript 和 SuperTest 框架实现接口自动化项目 SuperTest 框架教程目录 目录不可点击，仅为展示目录结构\nSuperTest 接口自动化测试快速启动项目 介绍 项目依赖 项目文件结构 从 0 到 1 搭建 SuperTest 接口自动化测试项目 Mocha 版本 Jest 版本 进阶用法 持续集成 接入 github action 常用断言 SuperTest 的内置断言 CHAI 的常用断言 Jest 的常用断言 数据驱动 多环境支持 SuperTest 框架教程对应文章 SuperTest 接口自动化测试教程：进阶用法 - 多环境支持：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-multiple-environment-support/ SuperTest 接口自动化测试教程：进阶用法 - 数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-data-driven/ SuperTest 接口自动化测试教程：进阶用法 - 常用断言：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-common-assertions/ SuperTest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action:https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-integration-ci-cd-and-github-action/ SuperTest 接口自动化测试教程：从 0 到 1 搭建 Supertest 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-building-your-own-project-from-0-to-1/ SuperTest 接口自动化测试教程：入门介绍和环境搭建准备：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-getting-started-and-own-environment-preparation/ SuperTest 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/SuperTest-API-Test-Starter SuperTest 文档：https://github.com/ladjs/supertest Jest 文档：https://jestjs.io/docs/en/getting-started Mocha 文档：https://mochajs.org/ Chai 文档：https://www.chaijs.com/ Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions Python 和 Pytest 框架实现接口自动化项目 Pytest 框架教程目录 目录不可点击，仅为展示目录结构\nPytest 接口自动化测试快速启动项目 介绍 Pytest 介绍 python 虚拟环境介绍 项目依赖 项目目录结构 从 0 到 1 搭建 Pytest 接口自动化测试项目 进阶用法 持续集成 接入 github action 常用断言 数据驱动 多环境支持 集成 allure 报告 并发测试和分布式测试 筛选用例执行 Pytest 框架教程对应文章 Pytest 接口自动化测试教程：进阶用法 - 筛选测试用例执行，并发测试和分布式测试：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-filter-testcase-and-concurrent-testing-distributed-testing/ Pytest 接口自动化测试教程：进阶用法 - 多环境支持 和 集成 allure 报告：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-multiple-environment-support-and-integration-allure-report/ Pytest 接口自动化测试教程：进阶用法 - 常用断言和数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-common-assertions-and-data-driven/ Pytest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-integration-ci-cd-and-github-action/ Pytest 接口自动化测试教程：从 0 到 1 搭建 Pytest 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-building-your-own-project-from-0-to-1/ Pytest 接口自动化测试教程：入门介绍和环境搭建准备：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-getting-started-and-own-environment-preparation/ Pytest 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Pytest-API-Test-Starter Pytest 文档：https://docs.pytest.org/en/stable/ Pytest-html 文档：https://pypi.org/project/pytest-html/ Pytest-xdist 文档：https://pypi.org/project/pytest-xdist/ Allure-pytest 文档：https://pypi.org/project/allure-pytest/ Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions 测试工具实现接口自动化测试 Postman 接口自动化测试 Postman 框架教程目录 目录不可点击，仅为展示目录结构\nPostman-API-Test-Starter 介绍 接口测试简介 Postman 与 newman 介绍 项目依赖 项目文件结构 从 0 到 1 搭建 Postman 接口自动化测试项目 进阶用法 输出 html 测试报告 CI/CD 持续集成 接入 github action 集成 allure 测试报告 常用测试脚本 响应测试脚本 请求前脚本 测试脚本中可用的第三方库 chai.js 断言库方法 使用 cheerio 操作 HTML 文件 使用 tv4 来验证 JSON Schema 生成 uuid 使用 xml2js 将 XML 转换为 JavaScript 对象 常用工具函数 util stream 流操作 定时器 timers 时间处理 events 数据驱动 使用环境变量 使用数据文件 文件上传 并发测试 Postman 框架教程对应文章 Postman 接口自动化测试教程：进阶用法 - 常用命令行选项，文件上传场景和 SSL 证书场景：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-command-line-options-and-file-upload/ Postman 接口自动化测试教程：进阶用法 - 数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-data-driven-and-environment-data-driven/ Postman 接口自动化测试教程：进阶用法 - 常用的测试脚本和常用的第三方包用法示例：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-test-scripts-and-commonly-used-third-party-packages/ Postman 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action，接入 allure 测试报告：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-integration-html-report-and-allure-report-integration-github-action/ Postman 接口自动化测试教程：入门介绍和从 0 到 1 搭建 Postman 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-getting-started-and-building-your-own-project-from-0-to-1/ Postman 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Postman-API-Test-Starter Postman 官方文档:https://learning.postman.com/docs/getting-started/introduction/ Newman 官方文档:https://github.com/postmanlabs/newman gitHub action 文档：https://docs.github.com/en/actions allure 文档：https://docs.qameta.io/allure/ Bruno 接口自动化测试 Bruno 框架教程目录 目录不可点击，仅为展示目录结构\nbruno-user-guide 为什么选择 bruno 安装 bruno 客户端使用入门 默认主界面 API 请求集 API 请求 编写 API 请求测试脚本 环境变量 测试脚本接口自动化 前置条件 接口自动化项目 demo 接入 CI 接入 github action Postman 脚本迁移 API 请求集迁移 环境变量迁移 测试脚本迁移参考 Bruno 框架教程对应文章 postman 替换工具 bruno 使用介绍:https://naodeng.tech/zh/posts/api-automation-testing/introduction_of_bruno/ Bruno 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Bruno-API-Test-Starter Bruno 文档：https://docs.usebruno.com/ gitHub action 文档：https://docs.github.com/en/actions 推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/a-collection-of-tutorials-on-api-automation-testing-for-different-frameworks-and-different-development-languages/","summary":"这篇博文汇总了关于不同框架和开发语言的接口自动化测试教程，为读者提供全面的学习资源。涵盖了各种流行测试框架和编程语言，让您能够选择适合自己项目的最佳方案。无论您是 Python、Java、JavaScript 还是其他语言的开发者，无论您偏好使用的是 REST Assured、SuperTest 还是其他框架，这个合集都将为您提供深入的学习指南，帮助您在接口自动化测试领域更加游刃有余。不容错过的资源，助您全面掌握接口自动化测试的各种工具和技术。","title":"接口测试新手入门教程：不同框架和不同开发语言"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括常用命令行选项、文件上传场景和 SSL 证书场景。\n文件上传场景 在 postman 和 newman 做接口自动化时，文件上传可以通过 form-data 的方式来实现。\n文件必须存在于当前工作目录中。请求的 \u0026ldquo;src \u0026ldquo;属性中也必须包含文件名。\n在此集合中，当前工作目录中应包含名为 \u0026ldquo;demo.txt\u0026rdquo; 的文件。\n{ \u0026#34;info\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;file-upload\u0026#34; }, \u0026#34;item\u0026#34;: [ { \u0026#34;request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://postman-echo.com/post\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;formdata\u0026#34;, \u0026#34;formdata\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;enabled\u0026#34;: true, \u0026#34;src\u0026#34;: \u0026#34;demo.txt\u0026#34; } ] } } } ] } 注意：调整文件上传的路径，确保文件存在路径在项目根目录下存在或者使用绝对路径\nNewman 常用命令行选项 newman 是一个命令行工具，可以使用它来运行 postman 集合。newman 提供了许多选项，可以在运行集合时使用这些选项。\n以下是一些常用的 newman 命令行选项的介绍和示例：\n基本命令 newman run \u0026lt;collection\u0026gt;： 用于运行 Postman 集合。\nnewman run collection.json -e, --environment \u0026lt;environment\u0026gt;： 指定环境文件。\nnewman run collection.json -e environment.json -g, --globals \u0026lt;globals\u0026gt;： 指定全局变量文件。\nnewman run collection.json -g globals.json -d, --iteration-data \u0026lt;data\u0026gt;： 指定数据文件，用于数据驱动测试。\nnewman run collection.json -d data-file.csv 输出和报告 -r, --reporters \u0026lt;reporters\u0026gt;： 指定报告器，可以生成多个报告，如 cli、json、html 等。\nnewman run collection.json -r cli,json --reporter-json-export \u0026lt;file\u0026gt;： 将测试结果导出为 JSON 文件。\nnewman run collection.json --reporters json --reporter-json-export output.json --reporter-html-export \u0026lt;file\u0026gt;： 将测试结果导出为 HTML 文件。\nnewman run collection.json --reporters html --reporter-html-export output.html --reporter-html-template \u0026lt;file\u0026gt;： 使用自定义 HTML 模板生成 HTML 报告。\nnewman run collection.json --reporters html --reporter-html-template custom-template.hbs 其他选项 -h, --help： 显示帮助信息，列出所有命令行选项。\nnewman run --help -v, --version： 显示 Newman 版本信息。\nnewman --version -x, --suppress-exit-code： 在运行失败时，不返回非零的退出代码。\nnewman run collection.json -x --delay-request \u0026lt;ms\u0026gt;： 设置请求之间的延迟时间，以模拟实际场景。\nnewman run collection.json --delay-request 1000 --timeout \u0026lt;ms\u0026gt;： 设置请求的超时时间。\nnewman run collection.json --timeout 5000 --no-color： 禁用控制台输出的颜色。\nnewman run collection.json --no-color --bail： 在第一个失败的测试时停止运行。\nnewman run collection.json --bail 这只是一些常见的 Newman 命令行选项。你可以通过运行 newman run --help 查看所有可用选项以及它们的描述。根据你的测试需求，你可能需要调整和组合这些选项。\nSSL 证书配置 客户端证书是传统身份验证机制的替代方案。这些允许用户使用公共证书和验证证书所有权的可选私钥向服务器发出经过身份验证的请求。在某些情况下，私钥也可能受到秘密密码的保护，从而提供额外的身份验证安全层。\nNewman 通过以下 CLI 选项支持 SSL 客户端证书：\n使用单个 SSL 客户端证书 直接在 newman 命令后面根据证书的实际情况添加以下选项即可\n--ssl-client-cert 参数后跟着公共客户端证书文件的路径。\n--ssl-client-key 参数后跟着客户端私钥的路径（可选）。\n--ssl-client-passphrase 参数后跟着用于保护私有客户端密钥的秘密密码（可选）。\n使用多个 SSL 客户端证书 适用于每次运行需要支持多个证书的情况\n--ssl-client-cert-list SSL 客户端证书列表配置文件（JSON 格式）的路径。 参考示例/ssl-client-cert-list.json。\n[ { \u0026#34;name\u0026#34;: \u0026#34;domain1\u0026#34;, \u0026#34;matches\u0026#34;: [\u0026#34;https://test.domain1.com/*\u0026#34;, \u0026#34;https://www.domain1/*\u0026#34;], \u0026#34;key\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain1.key\u0026#34;}, \u0026#34;cert\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain1.crt\u0026#34;}, \u0026#34;passphrase\u0026#34;: \u0026#34;changeme\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;domain2\u0026#34;, \u0026#34;matches\u0026#34;: [\u0026#34;https://domain2.com/*\u0026#34;], \u0026#34;key\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain2.key\u0026#34;}, \u0026#34;cert\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain2.crt\u0026#34;}, \u0026#34;passphrase\u0026#34;: \u0026#34;changeme\u0026#34; } ] 另外这种 json 配置也适用于不同证书不同环境的情况，根据 matches 匹配不同的环境和域名。\n备注：此选项允许根据 URL 或主机名设置不同的 SSL 客户端证书。此选项优先于 \u0026ndash;ssl-client-cert、 \u0026ndash;ssl-client-key 和 \u0026ndash;ssl-client-passphrase 选项。如果列表中没有匹配的 URL，这些选项将用作后备选项。\nTrusted CA 证书 适用于需要信任自定义 CA 证书的情况\n如果不想使用 \u0026ndash;insecure 选项，可以像这样提供额外的可信 CA 证书：\n--ssl-extra-ca-certs 参数后跟着保存一个或多个 PEM 格式可信 CA 证书的文件路径的列表。 参考文档 Postman 官方文档:https://learning.postman.com/docs/getting-started/introduction/ Newman 官方文档:https://github.com/postmanlabs/newman?tab=readme-ov-file#command-line-options 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-command-line-options-and-file-upload/","summary":"这篇博文深度挖掘 Postman 接口自动化测试的进阶用法，集中讨论常用命令行选项、文件上传场景和 SSL 证书场景。学会如何运用常用命令行选项优化测试流程，解决文件上传和 SSL 证书等特殊场景的测试挑战","title":"Postman 接口自动化测试教程：进阶用法 - 常用命令行选项，文件上传场景和 SSL 证书场景"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括数据文件驱动和环境变量数据驱动。\n数据驱动 在 API 自动化测试的过程中。使用数据驱动是一种常规测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。\n测试数据可以很容易地修改，而不需要修改测试用例代码。\n数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\n可参考 demo：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n在 Postman 中进行数据驱动测试，特别是使用 JSON 数据作为测试数据，可以通过环境变量和数据文件配合 Postman 提供的测试脚本来实现，以下会分别以简单的示例来介绍环境变量和数据文件的使用。\n使用环境变量 大致的步骤是：将测试数据存储在环境变量中，然后在测试脚本中读取环境变量中的数据，进行测试。\n1. 创建环境变量 在 Postman 中，你可以在 \u0026ldquo;Manage Environments\u0026rdquo; 窗口中创建环境变量。在 \u0026ldquo;Manage Environments\u0026rdquo; 窗口中，你可以创建多个环境，每个环境都有一组环境变量。\n之前在 demo 中创建了一个环境变量，名为 DemoEnv，其中包含了一个环境变量 baseURL，用于存储 API 的基本 URL。 这一次我们在 DemoEnv 环境中添加多个环境变量，用于存储 get-demo 接口和 post-demo 接口的各类测试数据。\n点击编辑DemoEnv环境，添加以下环境变量：\nKey Value getAPI posts/1 getAPIResponseStatus 200 getAPIResponseData {\u0026ldquo;userId\u0026rdquo;:1,\u0026ldquo;id\u0026rdquo;:1,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026rdquo;,\u0026ldquo;body\u0026rdquo;:\u0026ldquo;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026rdquo;} postAPI posts postAPIResponseStatus 201 postAPIResponseData {\u0026ldquo;title\u0026rdquo;:\u0026ldquo;foo\u0026rdquo;,\u0026ldquo;body\u0026rdquo;:\u0026ldquo;bar\u0026rdquo;,\u0026ldquo;userId\u0026rdquo;:1,\u0026ldquo;id\u0026rdquo;:101} 2. 使用环境变量 在 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用环境变量来存储和获取数据。在请求 Body 中，你可以通过 pm.environment.get 获取环境变量的值。\n注意：在 JavaScript 中，环境变量获取的值是字符串\n编辑 get-demo 接口 将 URL 修改为 {{baseURL}}/{{getAPI}}， 编辑 Tests 脚本用来验证响应数据： // 获取环境变量中的数据 const getAPIResponseStatus = parseInt(pm.environment.get(\u0026#34;getAPIResponseStatus\u0026#34;)); const getAPIResponseData = JSON.parse(pm.environment.get(\u0026#39;getAPIResponseData\u0026#39;)); pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(getAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(getAPIResponseData.id); pm.expect(data.userId).to.equal(getAPIResponseData.userId); pm.expect(data.title).to.equal(getAPIResponseData.title); pm.expect(data.body).to.equal(getAPIResponseData.body); }); 点击保存，然后点击发送，可以看到测试通过。 编辑 post-demo 接口 将 URL 修改为 {{baseURL}}/{{postAPI}}， 编辑 Tests 脚本用来验证响应数据： // 获取环境变量中的数据 const postAPIResponseStatus = parseInt(pm.environment.get(\u0026#34;postAPIResponseStatus\u0026#34;)); const postAPIResponseData = JSON.parse(pm.environment.get(\u0026#39;postAPIResponseData\u0026#39;)); pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(postAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(postAPIResponseData.id); pm.expect(data.userId).to.equal(postAPIResponseData.userId); pm.expect(data.title).to.equal(postAPIResponseData.title); pm.expect(data.body).to.equal(postAPIResponseData.body); }); 点击保存，然后点击发送，可以看到测试通过。 3. 调试环境变量数据驱动脚本 选择对应的环境变量和更新后的测试用例，运行整个 demo collection，确认测试通过\n4.自动化运行环境变量数据驱动脚本 将更新后的测试用例导出到自动化测试项目测试用例文件夹下 调整 package.json 在 package.json 文件中，更新测试脚本，用于运行环境变量数据驱动测试用例：\ndemo 项目为了区分不同场景，新增了测试命令为 environment-driven-test\n\u0026#34;environment-driven-test\u0026#34;: \u0026#34;newman run Testcase/Environment-Driven.postman_collection.json -e Env/Environment-Driven-DemoEnv.postman_environment.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34;, 运行测试 npm run environment-driven-test 使用数据文件 大致的步骤是：将测试数据存放在数据文件中，然后在测试脚本中读取数据文件中的数据，进行测试。\npostman 的数据文件支持 json，csv 和 txt 等多种格式，以下示例会以 json 格式 进行\n1.创建数据文件 在 postma 接口自动化测试项目下新建 Data 文件夹 mkdir Data 在 Data 文件夹下新建 json 格式数据文件 testdata.json cd Data touch testdata.json 更新测试数据文件 testdata.json [ { \u0026#34;getAPI\u0026#34;: \u0026#34;posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;: \u0026#34;posts\u0026#34;, \u0026#34;getAPIResponseStatus\u0026#34;: 200, \u0026#34;getAPIResponseData\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPIResponseStatus\u0026#34;: 201, \u0026#34;postAPIResponseData\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } ] 2.更新测试用例 更新 get-demo 接口 编辑 Pre-request Script 脚本来从测试数据文件中获取 请求 url const getAPI = pm.iterationData.get(\u0026#39;getAPI\u0026#39;); 将 URL 修改为 {{baseURL}}/{{getAPI}}，\n编辑 test 脚本来从测试数据文件中获取测试数据\nconst getAPIResponseStatus = pm.iterationData.get(\u0026#39;getAPIResponseStatus\u0026#39;); const getAPIResponseData = pm.iterationData.get(\u0026#39;getAPIResponseData\u0026#39;); pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(getAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(getAPIResponseData.id); pm.expect(data.userId).to.equal(getAPIResponseData.userId); pm.expect(data.title).to.equal(getAPIResponseData.title); pm.expect(data.body).to.equal(getAPIResponseData.body); }); 更新 post-demo 接口 编辑 Pre-request Script 脚本来从测试数据文件中获取 请求 url const postAPI = pm.iterationData.get(\u0026#39;postAPI\u0026#39;); 将 URL 修改为 {{baseURL}}/{{postAPI}}，\n编辑 test 脚本来从测试数据文件中获取测试数据\n// 从数据文件获取测试数据 const postAPIResponseStatus = pm.iterationData.get(\u0026#39;postAPIResponseStatus\u0026#39;); const postAPIResponseData = pm.iterationData.get(\u0026#39;postAPIResponseData\u0026#39;); pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(postAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(postAPIResponseData.id); pm.expect(data.userId).to.equal(postAPIResponseData.userId); pm.expect(data.title).to.equal(postAPIResponseData.title); pm.expect(data.body).to.equal(postAPIResponseData.body); }); 3.调试 在 postman 页面选择 get-demo request 和 post-demo request 所在的 demo Collection，点击右上角的三个点，选择 Run Collection 在 runner 准备页面右侧区域点击 Data 的 Select File 按钮，选择之前的测试数据文件 testdata.json 然后点击 Run demo，确认运行通过即可导出测试用例文件 4.自动化运行数据驱动脚本 将更新后的测试用例导出到自动化测试项目测试用例文件夹下 调整 package.json 在 package.json 文件中，更新测试测试脚本，用于运行数据驱动测试用例：\ndemo 项目为了区分不同场景，新增了测试命令为 data-driven-test，且命令后加了-d 参数 用于指定测试数据文件路径\n\u0026#34;data-driven-test\u0026#34;: \u0026#34;newman run Testcase/Data-Driven.postman_collection.json -e Env/DemoEnv.postman_environment.json -d Data/testdata.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34; 运行测试 npm run data-driven-test 参考文档 Postman 官方文档 newman 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-data-driven-and-environment-data-driven/","summary":"这篇博文深入研究 Postman 接口自动化测试的高级技巧，专注于数据文件驱动和环境变量数据驱动。学习如何通过外部数据文件和灵活的环境变量，优雅地进行测试数据的驱动，提高测试覆盖率。博文将为您展示如何以更智能的方式管理和利用数据，使测试用例更具可扩展性和灵活性。","title":"Postman 接口自动化测试教程：进阶用法 - 数据驱动"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括常用测试响应测试脚本，测试前置脚本和常用的测试脚本可用的第三方包等。\n常用测试脚本 Postman 提供了测试脚本功能，可以使用 JavaScript 编写脚本来验证 API 的响应和行为。这些脚本可以在请求的“Tests”标签下添加，分为请求前脚本（Pre-request Script）和响应后脚本（Tests）两个部分。下面是一些常用的 Postman 和 Newman 测试脚本：\n响应测试脚本 状态码检查：\npm.test(\u0026#34;Status code is 200\u0026#34;, function () { pm.response.to.have.status(200); }); 响应时间检查：\npm.test(\u0026#34;Response time is less than 200ms\u0026#34;, function () { pm.expect(pm.response.responseTime).to.be.below(200); }); 响应体 JSON 格式检查：\npm.test(\u0026#34;Response body is a valid JSON\u0026#34;, function () { pm.response.to.be.json; }); 响应体字段值检查：\npm.test(\u0026#34;Response body contains expected value\u0026#34;, function () { pm.expect(pm.response.json().key).to.eql(\u0026#34;expectedValue\u0026#34;); }); 响应体数组长度检查：\npm.test(\u0026#34;Response body array has correct length\u0026#34;, function () { pm.expect(pm.response.json().arrayKey).to.have.lengthOf(3); }); 响应体属性存在性检查：\npm.test(\u0026#34;Response body has required properties\u0026#34;, function () { pm.expect(pm.response.json()).to.have.property(\u0026#34;key\u0026#34;); }); 请求前脚本 动态设置请求参数：\npm.variables.set(\u0026#34;dynamicVariable\u0026#34;, \u0026#34;dynamicValue\u0026#34;); 使用全局变量设置请求头：\npm.request.headers.add({ key: \u0026#39;Authorization\u0026#39;, value: pm.globals.get(\u0026#39;authToken\u0026#39;) }); 生成随机数并设置为变量：\nconst randomNumber = Math.floor(Math.random() * 1000); pm.variables.set(\u0026#34;randomNumber\u0026#34;, randomNumber); 签名生成或加密等操作：\n// 示例：使用 CryptoJS 进行 HMAC SHA256 签名 const CryptoJS = require(\u0026#39;crypto-js\u0026#39;); const secretKey = \u0026#39;yourSecretKey\u0026#39;; const message = \u0026#39;dataToSign\u0026#39;; const signature = CryptoJS.HmacSHA256(message, secretKey).toString(CryptoJS.enc.Base64); pm.variables.set(\u0026#34;signature\u0026#34;, signature); 测试脚本中可用的第三方库 提供的 require 方法允许您使用沙箱内置库模块。下面列出了个人常用的可用库和示例 更多可用的库可以在这里找到\nchai.js 断言库方法 在 Postman 的测试脚本中，你可以使用 Chai 断言库来编写断言，以验证你的 API 响应是否符合预期。Chai 提供了多种断言风格，包括 BDD（Behavior Driven Development）、TDD（Test Driven Development）等。以下是一些基本的 Chai 使用方法：\n1. 安装 Chai 在 Postman 的脚本环境中，你无需单独安装 Chai，因为 Postman 默认已经内置了 Chai。\n2. 使用 BDD 风格断言 在 Postman 的 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用 Chai 的 BDD 风格断言，例如：\n// 引入 Chai 库 const chai = require(\u0026#39;chai\u0026#39;); // 使用 BDD 风格断言 const expect = chai.expect; // 示例：验证响应状态码为 200 pm.test(\u0026#39;Status code is 200\u0026#39;, function() { expect(pm.response.code).to.equal(200); }); // 示例：验证响应体是 JSON pm.test(\u0026#39;Response body is JSON\u0026#39;, function() { expect(pm.response.headers.get(\u0026#39;Content-Type\u0026#39;)).to.include(\u0026#39;application/json\u0026#39;); }); 3. 使用 TDD 风格断言 // 引入 Chai 库 const chai = require(\u0026#39;chai\u0026#39;); // 使用 TDD 风格断言 const assert = chai.assert; // 示例：使用 assert 断言响应状态码为 200 assert.equal(pm.response.code, 200, \u0026#39;Status code should be 200\u0026#39;); 4. Chai 支持的一些常用断言 相等性：\nexpect(actual).to.equal(expected); 包含：\nexpect(actual).to.include(expected); 类型检查：\nexpect(actual).to.be.a(\u0026#39;string\u0026#39;); 大于/小于：\nexpect(actual).to.be.above(expected); expect(actual).to.be.below(expected); 空/非空：\nexpect(actual).to.be.null; expect(actual).to.not.be.null; 深度相等性：\nexpect(actual).to.deep.equal(expected); 以上只是 Chai 断言库的一些基本用法，你可以根据需要使用更多的断言方法和组合。Chai 提供了丰富的断言功能，可以满足各种测试需求。更多详细信息，请查阅 Chai 的官方文档：Chai Documentation。\n使用 cheerio 操作 HTML 文件 在 Postman 中，Cheerio 是一个基于 jQuery 的库，用于在服务器端操作 HTML 文档。它允许你使用类似于 jQuery 的语法来选择和操作 HTML 元素，非常适用于解析和提取 HTML 页面中的信息。在 Postman 中，你可以使用 Cheerio 库进行 HTML 响应的解析。以下是 Cheerio 在 Postman 中的基本用法：\n安装 Cheerio：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 Cheerio 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，可以使用以下方式安装 Cheerio： // 安装 Cheerio const cheerio = require(\u0026#39;cheerio\u0026#39;); 使用 Cheerio 解析 HTML：\n在请求的 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用 Cheerio 解析 HTML。以下是一个简单的例子： // 从响应中获取 HTML 内容 const htmlContent = pm.response.text(); // 使用 Cheerio 解析 HTML const $ = cheerio.load(htmlContent); // 示例：从 HTML 中提取标题文本 const titleText = $(\u0026#39;title\u0026#39;).text(); console.log(\u0026#39;Title:\u0026#39;, titleText); // 示例：从 HTML 中提取所有链接的 href 属性 const links = []; $(\u0026#39;a\u0026#39;).each(function () { const link = $(this).attr(\u0026#39;href\u0026#39;); links.push(link); }); console.log(\u0026#39;Links:\u0026#39;, links); 在上述例子中，cheerio.load(htmlContent) 用于加载 HTML 内容，并使用类似于 jQuery 的语法来选择和操作元素。\n注意事项：\nCheerio 主要用于解析静态 HTML，对于使用 JavaScript 动态生成的内容，可能无法正常获取。在这种情况下，你可能需要考虑使用 Puppeteer 或其他支持 JavaScript 执行的工具。 这只是 Cheerio 在 Postman 中的基本用法。你可以根据具体的需求使用 Cheerio 提供的各种选择器和方法。请查阅 Cheerio 的官方文档以获取更详细的信息：Cheerio Documentation。\n使用 tv4 来验证 JSON Schema 在 Postman 中，tv4 是一个 JSON Schema 验证库，用于验证 JSON 数据是否符合给定的 JSON Schema。JSON Schema 是一种描述 JSON 数据结构的规范，它定义了 JSON 对象的属性、类型和其他约束。\n以下是在 Postman 中使用 tv4 进行 JSON Schema 验证的基本步骤：\n安装 tv4 库：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 tv4 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 tv4： // 安装 tv4 const tv4 = require(\u0026#39;tv4\u0026#39;); 定义 JSON Schema：\n在 Postman 中，你可以在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分定义 JSON Schema。JSON Schema 可以作为一个 JavaScript 对象进行定义。以下是一个简单的例子： // 定义 JSON Schema const jsonSchema = { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;number\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;] }; 使用 tv4 进行验证：\n在请求的 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用 tv4 对 JSON 数据进行验证。以下是一个简单的例子： // 获取响应的 JSON 数据 const jsonResponse = pm.response.json(); // 使用 tv4 进行 JSON Schema 验证 const isValid = tv4.validate(jsonResponse, jsonSchema); // 检查验证结果 pm.test(\u0026#39;JSON is valid according to the schema\u0026#39;, function() { pm.expect(isValid).to.be.true; }); 在上述例子中，tv4.validate(jsonResponse, jsonSchema) 用于验证 jsonResponse 是否符合 jsonSchema 定义的规范。验证结果存储在 isValid 变量中，然后使用 pm.test 来检查验证结果。\n这只是 tv4 在 Postman 中的基本用法。你可以根据实际需求，定义更复杂的 JSON Schema，并使用 tv4 的其他功能进行更灵活的验证。请查阅 tv4 的官方文档以获取更详细的信息：tv4 Documentation。\n生成 uuid 在 Postman 中，你可以使用 uuid 模块来生成 UUID（Universally Unique Identifier），也被称为 GUID。以下是在 Postman 中使用 uuid 模块的基本用法：\n1. 安装 uuid 模块 在 Postman 的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 uuid 模块：\n// 安装 uuid 模块 const uuid = require(\u0026#39;uuid\u0026#39;); 2. 生成 UUID // 生成 UUID const generatedUUID = uuid.v4(); console.log(\u0026#39;Generated UUID:\u0026#39;, generatedUUID); 在上述例子中，uuid.v4() 用于生成一个基于随机数的 UUID。你可以在 Postman 脚本中使用生成的 UUID，例如将其设置为请求头或参数的值。\n示例 以下是一个在 Postman \u0026ldquo;Pre-request Script\u0026rdquo; 中生成 UUID 并设置为请求头的示例：\n// 安装 uuid 模块 const uuid = require(\u0026#39;uuid\u0026#39;); // 生成 UUID const generatedUUID = uuid.v4(); // 设置请求头 pm.request.headers.add({ key: \u0026#39;X-Request-ID\u0026#39;, value: generatedUUID }); 在上述例子中，X-Request-ID 是一个常见的请求头，用于标识请求的唯一性。生成的 UUID 被设置为这个请求头的值，以确保每个请求都有唯一的标识。\n请注意，Postman 在运行脚本时会自动执行安装依赖项的步骤，无需手动安装 uuid 模块。\n使用 xml2js 将 XML 转换为 JavaScript 对象 在 Postman 中，xml2js 是一个用于将 XML 转换为 JavaScript 对象的库。在 Postman 的脚本中，你可以使用 xml2js 来处理 XML 响应并将其转换为易于处理的 JavaScript 对象。以下是在 Postman 中使用 xml2js 的基本步骤：\n安装 xml2js 库：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 xml2js 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 xml2js： // 安装 xml2js const xml2js = require(\u0026#39;xml2js\u0026#39;); 解析 XML 响应：\n获取 XML 响应后，你可以使用 xml2js 将其解析为 JavaScript 对象。以下是一个简单的例子： // 获取响应的 XML 内容 const xmlContent = pm.response.text(); // 使用 xml2js 解析 XML xml2js.parseString(xmlContent, function (err, result) { if (err) { console.error(\u0026#39;Error parsing XML:\u0026#39;, err); return; } // result 是解析后的 JavaScript 对象 console.log(\u0026#39;Parsed XML:\u0026#39;, result); }); 在上述例子中，xml2js.parseString(xmlContent, function (err, result) {...} 用于异步地解析 XML 内容。解析后的 JavaScript 对象存储在 result 中。\n处理解析后的 JavaScript 对象：\n一旦你获得了解析后的 JavaScript 对象，你就可以按照普通的 JavaScript 对象处理方式访问和操作它的属性。 // 示例：访问解析后的 JavaScript 对象的属性 const value = result.root.element[0].subelement[0]._; console.log(\u0026#39;Value from parsed XML:\u0026#39;, value); 在上述例子中，result.root.element[0].subelement[0]._ 是一个访问解析后对象属性的示例。具体的结构取决于你的 XML 结构。\n这只是 xml2js 在 Postman 中的基本用法。你可以根据实际需求使用 xml2js 的其他功能，例如设置解析选项，处理命名空间等。请查阅 xml2js 的官方文档以获取更详细的信息：xml2js Documentation。\n常用工具函数 util 在 Postman 中，util 是一个全局对象，提供了一些常用的实用工具函数，可以在 Postman 脚本中使用。以下是一些常见的 util 对象的用法：\n1. util.guid() - 生成全局唯一标识符（GUID） // 生成一个全局唯一标识符 const uniqueId = util.guid(); console.log(\u0026#39;Unique ID:\u0026#39;, uniqueId); 2. util.timestamp() - 获取当前时间戳 // 获取当前时间戳（毫秒） const timestamp = util.timestamp(); console.log(\u0026#39;Timestamp:\u0026#39;, timestamp); 3. util.randomInt(min, max) - 生成指定范围内的随机整数 // 生成 1 到 100 之间的随机整数 const randomInt = util.randomInt(1, 100); console.log(\u0026#39;Random Integer:\u0026#39;, randomInt); 4. util.unixTimestamp() - 获取当前时间戳（Unix 时间戳，秒） // 获取当前时间戳（秒） const unixTimestamp = util.unixTimestamp(); console.log(\u0026#39;Unix Timestamp:\u0026#39;, unixTimestamp); 5. util.encodeBase64(str) 和 util.decodeBase64(base64Str) - Base64 编码和解码 // Base64 编码 const encodedString = util.encodeBase64(\u0026#39;Hello, World!\u0026#39;); console.log(\u0026#39;Encoded String:\u0026#39;, encodedString); // Base64 解码 const decodedString = util.decodeBase64(encodedString); console.log(\u0026#39;Decoded String:\u0026#39;, decodedString); 6. util.each(obj, callback) - 遍历对象或数组 // 遍历数组 const array = [1, 2, 3, 4]; util.each(array, function (value, index) { console.log(`Index ${index}: ${value}`); }); // 遍历对象 const obj = { a: 1, b: 2, c: 3 }; util.each(obj, function (value, key) { console.log(`Key ${key}: ${value}`); }); 注意事项 在 Postman 脚本中，可以通过 util 对象直接调用这些实用工具函数。 util 对象提供的这些方法能够简化在 Postman 脚本中的一些常见任务，如生成随机数、处理时间戳等。 请注意查阅 Postman 的官方文档，因为 Postman 会不断更新和改进其脚本环境，可能会引入新的实用工具函数。 stream 流操作 在 Node.js 中使用流（Streams）通常用于处理大量的数据，可以有效地降低内存占用并提高性能。以下是一些在 Node.js 中使用流的基本用法，可以参考这些方法来处理数据或文件。\n1. 读取流（Readable Streams）： const fs = require(\u0026#39;fs\u0026#39;); // 创建可读流 const readableStream = fs.createReadStream(\u0026#39;input.txt\u0026#39;); // 设置编码（如果是文本文件） readableStream.setEncoding(\u0026#39;utf-8\u0026#39;); // 处理数据 readableStream.on(\u0026#39;data\u0026#39;, function(chunk) { console.log(\u0026#39;Received chunk:\u0026#39;, chunk); }); // 处理结束 readableStream.on(\u0026#39;end\u0026#39;, function() { console.log(\u0026#39;Stream ended.\u0026#39;); }); // 处理错误 readableStream.on(\u0026#39;error\u0026#39;, function(err) { console.error(\u0026#39;Error:\u0026#39;, err); }); 2. 写入流（Writable Streams）： const fs = require(\u0026#39;fs\u0026#39;); // 创建可写流 const writableStream = fs.createWriteStream(\u0026#39;output.txt\u0026#39;); // 写入数据 writableStream.write(\u0026#39;Hello, World!\\n\u0026#39;); writableStream.write(\u0026#39;Another line.\u0026#39;); // 结束写入 writableStream.end(); // 处理结束 writableStream.on(\u0026#39;finish\u0026#39;, function() { console.log(\u0026#39;Write completed.\u0026#39;); }); // 处理错误 writableStream.on(\u0026#39;error\u0026#39;, function(err) { console.error(\u0026#39;Error:\u0026#39;, err); }); 3. 转换流（Transform Streams）： const { Transform } = require(\u0026#39;stream\u0026#39;); // 创建转换流 const myTransform = new Transform({ transform(chunk, encoding, callback) { // 转换数据 const transformedData = chunk.toString().toUpperCase(); this.push(transformedData); callback(); } }); // 管道连接读取流、转换流和写入流 readableStream.pipe(myTransform).pipe(writableStream); 这只是 Node.js 中使用流的一些基本用法。在 Postman 中，你可以在请求的脚本中使用这些方法，例如 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，通过 Node.js 运行环境来执行这些脚本。请注意，Node.js 中的流 API 可以更复杂，例如通过使用 pipeline 函数来处理多个流的连接。\n定时器 timers 在 Postman 中，你可以使用 Node.js 的定时器功能来处理定时任务或延时执行的操作。以下是一些基本的 Node.js 定时器的用法，这些用法可以在 Postman 的脚本中使用。\n1. setTimeout - 延时执行 // 延时执行操作 setTimeout(function() { console.log(\u0026#39;Delayed operation.\u0026#39;); }, 2000); // 2000 毫秒（2 秒） 2. setInterval - 定时执行重复操作 // 定时执行重复操作 const intervalId = setInterval(function() { console.log(\u0026#39;Repeated operation.\u0026#39;); }, 3000); // 3000 毫秒（3 秒） // 取消定时执行 // clearInterval(intervalId); 3. 在 Postman 中使用 在 Postman 中，你可以在 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分中使用这些定时器。例如，在 \u0026ldquo;Tests\u0026rdquo; 部分中延时执行操作：\n// 在 \u0026#34;Tests\u0026#34; 部分延时执行操作 setTimeout(function() { console.log(\u0026#39;Delayed operation in Tests.\u0026#39;); }, 2000); // 2000 毫秒（2 秒） 请注意，在 Postman 的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分执行的代码是在 Node.js 环境中运行的，因此你可以使用 Node.js 支持的大多数功能，包括定时器。\n在以上例子中，setTimeout 会在指定的延时后执行一次操作，而 setInterval 会在每隔指定的时间间隔后执行一次操作。在 Postman 中，你可以根据实际需求使用这些定时器功能。\n时间处理 events 在 Postman 的脚本环境中，你可以使用 Node.js 的 events 模块来处理事件。events 模块提供了 EventEmitter 类，该类可以用于定义和触发事件。以下是在 Postman 中使用 Node.js 的 events 模块的一些基本用法：\n1. 创建事件发射器 const EventEmitter = require(\u0026#39;events\u0026#39;); const myEmitter = new EventEmitter(); 2. 定义事件处理函数 // 定义事件处理函数 function myEventHandler() { console.log(\u0026#39;Event handled.\u0026#39;); } 3. 注册事件处理函数 // 注册事件处理函数 myEmitter.on(\u0026#39;myEvent\u0026#39;, myEventHandler); 4. 触发事件 // 触发事件 myEmitter.emit(\u0026#39;myEvent\u0026#39;); 示例 在 Postman 的脚本环境中，你可以使用事件来实现异步操作的回调或处理。以下是一个简单的例子，演示如何在异步操作完成后触发事件：\nconst EventEmitter = require(\u0026#39;events\u0026#39;); const myEmitter = new EventEmitter(); // 模拟异步操作 function performAsyncOperation() { setTimeout(function() { console.log(\u0026#39;Async operation completed.\u0026#39;); // 触发事件 myEmitter.emit(\u0026#39;asyncOperationComplete\u0026#39;); }, 2000); } // 注册事件处理函数 myEmitter.on(\u0026#39;asyncOperationComplete\u0026#39;, function() { console.log(\u0026#39;Handling async operation completion.\u0026#39;); // 这里可以执行异步操作完成后的处理逻辑 }); // 执行异步操作 performAsyncOperation(); 在上述例子中，performAsyncOperation 函数模拟了一个异步操作，当该操作完成时，通过 myEmitter.emit 触发了 asyncOperationComplete 事件。在事件处理函数中，你可以编写处理异步操作完成后的逻辑。\n请注意，在 Postman 的脚本中，异步操作的执行方式可能受到限制，因此在实际使用中需要谨慎考虑。\n参考文档 Postman 官方文档 newman 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-test-scripts-and-commonly-used-third-party-packages/","summary":"深入研究 Postman 接口自动化测试的高级用法，专注于常用的测试脚本和第三方包示例。探讨如何编写强大的测试脚本，涵盖各种测试场景，并介绍一些常用的第三方包，优化测试流程。","title":"Postman 接口自动化测试教程：进阶用法 - 常用的测试脚本和常用的第三方包用法示例"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括测试数据、测试脚本、测试报告和测试报告集成等。 也会介绍如何将 Postman 和 Newman 集成到 CI/CD 流程中，以实现自动化测试。\n输出 html 测试报告 demo 会以集成newman-reporter-htmlextra为例，介绍如何输出 html 测试报告。\n安装 newman-reporter-htmlextra 依赖包 npm install newman-reporter-htmlextra --save-dev 注意：目前 newman 最新 V6 版本在 html 测试报告的一些包兼容性上有问题，所以这里使用 5.1.2 版本\n调整 package.json 在 package.json 文件中，更新测试测试脚本，用于运行测试用例并输出 html 测试报告：\n\u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r htmlextra --reporter-htmlextra-export ./Report/Postman-newman-demo-api-testing-report.html\u0026#34; 指定输出 html 测试报告的路径为 Report/Postman-newman-demo-api-testing-report.html\n运行测试用例输出 html 报告 运行测试用例 npm run test 检查报告文件 浏览器打开报告文件 输出多种格式的测试报告 前面的配置是输出 html 格式的测试报告，如果想要输出多种格式的测试报告，如命令行 cli 的报告，可以在 package.json 文件中添加以下脚本：\n\u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r cli,htmlextra --reporter-htmlextra-export ./Report/Postman-newman-demo-api-testing-report.html\u0026#34; 再次运行测试用例，可以看到在 Report 文件夹下，除了 html 格式的测试报告，还有 cli 格式的测试报告。\nCI/CD 持续集成 将接口自动化测试的代码集成到 CI/CD 流程中，可以实现自动化测试，提高测试效率。\n接入 github action 以 github action 为例，其他 CI 工具类似\n可参考 demo：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 postman.yml。\n编辑 postman.yml 文件：将以下内容复制到文件中\nname: RUN Postman API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-Postman-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive Postman test report uses: actions/upload-artifact@v3 with: name: Postman-test-report path: Report - name: Upload Postman report to GitHub uses: actions/upload-artifact@v3 with: name: Postman-test-report path: Report 提交代码：将 postman.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN-Postman-API-Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 集成 allure 测试报告 allure 是一个轻量级的、灵活的、多语言支持的测试报告工具，可以生成各种各样的测试报告，包括饼图、柱状图、曲线图等，可以方便地查看测试结果。\n安装 allure 测试报告依赖 npm install newman-reporter-allure --save-dev 调整 package.json 中输出 allure 测试报告的脚本 \u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34; 调整 Postman 测试用例 调整 get-demo 的 Tests 脚本，添加以下脚本，用于生成 allure 测试报告： // @allure.label.suite=postman-new-api-testing-demo // @allure.label.story=\u0026#34;Verify-the-get-api-return-correct-data\u0026#34; // @allure.label.owner=\u0026#34;naodeng\u0026#34; // @allure.label.tag=\u0026#34;GETAPI\u0026#34; pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调整 post-demo 的 Tests 脚本，添加以下脚本，用于生成 allure 测试报告： // @allure.label.suite=postman-new-api-testing-demo // @allure.label.story=\u0026#34;Verify-the-post-api-return-correct-data\u0026#34; // @allure.label.owner=\u0026#34;naodeng\u0026#34; // @allure.label.tag=\u0026#34;POSTAPI\u0026#34; pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(201); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(101); pm.expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 保存更改后的 postman 测试用例，重新导出测试用例文件并替换原来的测试用例文件。 运行测试用例输出 allure 报告 运行测试用例 npm run test 会在项目文件夹下生成 allure-results 文件夹，里面包含了测试用例的执行结果。\n预览 allure 测试报告 allure serve 参考文档 Postman 官方文档 newman 官方文档 newman-reporter-htmlextra newman-reporter-allure github action 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-integration-html-report-and-allure-report-integration-github-action/","summary":"Postman 接口自动化测试的进阶应用，专注于 CI/CD 和 GitHub Actions 的集成，以及 Allure 测试报告的接入。学习如何将 Postman 测试无缝整合到 CI/CD 流程中，通过 GitHub Actions 实现自动化测试。此外，了解如何集成 Allure 测试报告框架，生成详尽的测试结果报告","title":"Postman 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action，接入 allure 测试报告"},{"content":"介绍 接口测试简介 什么是 API? API:应用程序接口（全称：application programming interface），缩写为 API，是一种计算接口，它定义多个软件中介之间的交互，以及可以进行的调用（call）或请求（request）的种类，如何进行调用或发出请求，应使用的数据格式，应遵循的惯例等。它还可以提供扩展机制，以便用户可以通过各种方式对现有功能进行不同程度的扩展。一个 API 可以是完全定制的，针对某个组件的，也可以是基于行业标准设计的以确保互操作性。通过信息隐藏，API 实现了模块化编程，从而允许用户实现独立地使用接口。\n什么是 API 测试？ 接口测试是软件测试的一种，它包括两种测试类型：狭义上指的是直接针对应用程序接口（下面使用缩写 API 指代，其中文简称为接口）的功能进行的测试；广义上指集成测试中，通过调用 API 测试整体的功能完成度、可靠性、安全性与性能等指标。\nAPI Best Practice:\nAPI 定义遵循 RESTFUL API 风格，语意化的 URI 定义，准确的 HTTP 状态码，通过 API 的定义就可以知道资源间的关系 配有详细且准确的 API 文档（如 Swagger 文档） 对外的 API 可以包含版本号以快速迭代（如 https://thoughtworks.com/v1/users/） 测试四象限中不同象限的测试，其测试目的跟测试策略也不同，API 测试主要位于第二、第四象限\nAPI 测试在测试金子塔中处于一个相对靠上的位置，主要站在系统、服务边界来测试功能和业务逻辑，执行时机是在服务完成构建、部署到测试环境之后再执行、验证。\nAPI 测试类型 功能测试\n正确性测试 异常处理 内部逻辑 …… 非功能测试\n性能 安全 …… API 测试步骤 发送请求 得到响应 验证响应结果 Postman 与 newman 介绍 Postman 是一个流行的 API 开发工具，它提供了一个易于使用的图形界面，可用于创建，测试和调试 API。Postman 还提供了一个可以轻松编写和共享测试脚本的功能。它支持多种 HTTP 请求方法，包括 GET，POST，PUT，DELETE 等，并且可以使用各种身份验证和授权方式来测试 API。\nNewman 是 Postman 的命令行工具，可用于在不使用 Postman GUI 的情况下运行测试集。使用 Newman，用户可以轻松地将 Postman 集合导出为一个可执行文件，并在任何环境中运行它。此外，Newman 还支持生成 HTML 或 Junit 格式的测试报告，以及集成到 CI/CD 管道中以实现自动化测试。\n总的来说，Postman 是一个强大的 API 开发和测试工具，而 Newman 则是一个方便的命令行工具，用于在不使用 Postman GUI 的情况下运行测试集。它们的结合使用可以提高 API 测试和开发的效率和准确性。\n除了基本功能，Postman 还具有以下特性：\n环境和变量管理：Postman 支持在不同环境之间切换，例如在开发、测试和生产环境之间切换。同时，它还支持变量管理，可以轻松地为不同的测试用例和请求设置变量。 自动化测试：用户可以使用 Postman 创建和运行自动化测试，以便在持续集成或部署流程中集成。这使得测试变得更加准确和高效。 协作和共享：Postman 支持将集合和环境与团队共享，方便团队成员之间的协作。 监控：Postman 还提供 API 监控功能，可以实时监控 API 的可用性和性能。 而 Newman 则主要有以下特点：\n命令行接口：Newman 可以在命令行中运行，因此可以方便地自动化测试和集成到 CI/CD 流程中。 支持多种输出格式：Newman 支持多种输出格式，包括 HTML、JSON 和 JUnit 格式，方便用户在不同场景下使用。 并发执行：Newman 支持并发执行测试，从而提高了测试的效率。 轻量级：与 Postman GUI 相比，Newman 是一个轻量级的工具，因此在运行测试时需要更少的资源。 总之，Postman 和 Newman 是现代 API 测试的重要工具，它们提供了强大的功能，可以使 API 测试变得更加高效、准确和自动化。\n除了上述提到的功能和特点，Postman 和 Newman 还有其他一些重要的功能和优势：\n集成：Postman 和 Newman 可以与许多其他工具和服务进行集成，例如 GitHub、Jenkins、Slack 等。这使得它们可以轻松地集成到开发和部署流程中，以实现更高效的 API 开发和测试。 文档生成：Postman 可以使用 API 的请求和响应来生成 API 文档。这可以使 API 文档更加准确和及时。 测试脚本：Postman 可以使用 JavaScript 编写测试脚本，这可以使测试变得更加灵活和自定义。用户可以轻松地编写自定义测试脚本，以确保 API 的行为符合预期。 历史记录：Postman 可以存储 API 请求的历史记录，这可以方便用户查看和管理以前的请求和响应。这对于调试和问题排查非常有用。 多平台支持：Postman 和 Newman 可以在多种平台上运行，包括 Windows、MacOS 和 Linux 等。 总之，Postman 和 Newman 是现代 API 测试和开发的强大工具。它们提供了丰富的功能和灵活的测试脚本，可以帮助开发人员和测试人员更快、更准确地构建和测试 API。\n项目依赖 需提前安装好以下环境\nnodejs, demo 版本为 v21.1.0 Postman 安装完成，可通过官方网站下载安装包进行安装 项目文件结构 以下是一个 Postman 和 Newman 的接口自动化测试项目的文件结构，其中包含了测试配置文件、测试用例文件、测试工具文件和测试报告文件。可进行参考。\nPostman-Newman-demo ├── README.md ├── package.json ├── package-lock.json ├── Data // 测试配置文件 │ └── testdata.csv // 测试数据 ├── Testcase // 测试用例文件夹 │ └── APITestDemo.postman_collection.json // 测试用例文件 ├── Env // 不同测试环境文件夹 │ └── DemoEnv.postman_environment.json // 测试环境配置文件 ├── Report // 测试报告文件 │ └── report.html ├── .gitignore └── node_modules // 项目依赖 从 0 到 1 搭建 Postman 接口自动化测试项目 下面会介绍从 0 到 1 搭建一个 Postman 和 Newman 的接口自动化测试项目，包括测试配置、测试用例、测试环境、测试工具和测试报告等。\n可参考 demo 项目：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n新建项目文件夹 mkdir Postman-Newman-demo 项目初始化 // 进入项目文件夹下 cd Postman-Newman-demo // nodejs 项目初始化 npm init -y 安装依赖 目前 newman 最新版本在 html 测试报告的一些包兼容性上有问题，所以这里使用 4.2.3 版本\n// 安装 newman npm install newman@4.2.3 --save-dev Postman 编写接口测试用例 新建 Collection 和 Request 打开 Postman，点击左上角的 New 按钮，选择 Collection，输入 Collection 的名称，点击 Create Collection 按钮，创建一个名称为 demo 的 Collection。 在 Collection 中，点击右上角的三个点，选择 Add Request，输入 Request 的名称，点击 Save 按钮，创建一个 Request 命名为 get-demo。再添加一个 Request 命名为 post-demo。 编辑 Request 和编写测试用例 可根据项目文件下的 demoAPI.md 文件中的接口文档，获取 demo 使用的 Request 的 URL、请求方法、请求头、请求体等信息。\nget-demo 在 get-demo 的 Request 中，选择 GET 请求方法，输入 URL 为https://jsonplaceholder.typicode.com/posts/1 在 Headers 中，添加一个 Key 为 Content-Type，Value 为 application/json; 的请求头。 在 Tests 下，添加以下脚本，用于验证响应结果： pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 点击 Send 按钮，发送请求，验证响应结果。 确认响应结果正确后，点击 Save 按钮，保存 Request。\npost-demo 在 post-demo 的 Request 中，选择 POST 请求方法，输入 URL 为https://jsonplaceholder.typicode.com/posts 在 Headers 中，添加一个 Key 为 Content-Type，Value 为 application/json; 的请求头。 在 Body 中，选择 raw，选择 JSON 格式，输入以下请求体： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 在 Tests 下，添加以下脚本，用于验证响应结果： pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(201); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(101); pm.expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 确认响应结果正确后，点击 Save 按钮，保存 Request。\nPostman 编写测试环境配置文件 下面会取接口请求的 host 为环境变量来进行 demo\n添加环境变量 在 Postman 的右上角，点击齿轮图标，选择 Manage Environments，点击 Add 按钮，输入环境名称为 DemoEnv，点击 Add 按钮，创建一个名称为 DemoEnv 的环境。 编辑环境变量，添加一个 Key 为 host，Value 为https://jsonplaceholder.typicode.com的环境变量。 点击 Add 按钮，保存环境变量。 更新 Request 在 get-demo 的 Request 中，更新 URL 为{{host}}/posts/1 在 post-demo 的 Request 中，更新 URL 为{{host}}/posts 验证环境变量 在 Postman 的右上角，点击齿轮图标，选择 DemoEnv，切换环境变量为 DemoEnv。 选择 get-demo 的 Request，点击 Send 按钮，发送请求，验证响应结果。确认响应结果正确后，点击 Save 按钮，保存 Request。 选择 post-demo 的 Request，点击 Send 按钮，发送请求，验证响应结果。确认响应结果正确后，点击 Save 按钮，保存 Request。 导出环境变量和测试用例文件 在 Postman 的右上角，点击齿轮图标，选择 Export，选择 DemoEnv，点击 Export 按钮，导出环境变量。 选择 get-demo request 和 post-demo request 所在的 demo Collection，点击右上角的三个点，选择 Export，选择 Collection v2.1，点击 Export 按钮，导出测试用例文件。 调整项目文件结构 新建 Env 和 Testcase 文件夹 在项目文件夹下，新建一个名为 Env 的文件夹，用于存放环境变量文件。 // 新建 Env 文件夹 mkdir Env 在项目文件夹下，新建一个名为 Testcase 的文件夹，用于存放测试用例文件。 // 新建 Testcase 文件夹 mkdir Testcase 调整用例文件和环境变量文件 将导出的环境变量文件和测试用例文件放到项目文件夹下的 Env 和 Testcase 文件夹下。\n调整 package.json 文件 在 package.json 文件中，添加以下脚本，用于运行测试用例： \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json\u0026#34; } 运行测试用例 npm run test 参考文档 Postman 官方文档 newman 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-getting-started-and-building-your-own-project-from-0-to-1/","summary":"关于 Postman 接口自动化测试的导引，全面介绍入门基础和从零开始搭建项目的步骤。学习如何有效地使用 Postman 进行 API 测试，了解项目搭建的基础结构、环境设置和测试用例的编写","title":"Postman 接口自动化测试教程：入门介绍和从 0 到 1 搭建 Postman 接口自动化测试项目"},{"content":"进阶用法 并发测试和分布式测试 在日常的接口自动化测试过程中，需要并发执行测试用例，以提高测试效率。\n有时候也需要引入分布式测试，以便在多台机器上同时运行测试用例，也能更好的提升测试效率。\npytest-xdist 是 Pytest 的一个插件，能提供了一些对应的功能，主要用于支持并发测试和分布式测试。\npytest-xdist 功能介绍 并发执行测试：\n使用 -n 选项：pytest -n NUM 允许并发运行测试，其中 NUM 是并发 worker 的数量。这可以加速测试执行，特别是在拥有多个 CPU 内核的计算机上。 pytest -n 3 # 启动 3 个并发 worker 执行测试 分布式测试：\n使用 pytest --dist=loadscope：允许在多个节点上执行测试，通过分布式测试可以更快地完成测试运行。 pytest --dist=loadscope 使用 pytest --dist=each：每个节点运行一组测试，适用于分布式测试。 pytest --dist=each 参数化测试和并发：\n使用 pytest.mark.run：结合 pytest.mark.run 标记，可以选择在不同的进程或节点上运行具有不同标记的测试。 @pytest.mark.run(processes=2) def test_example(): pass 分布式环境设置：\n使用 pytest_configure_node：可以在节点上运行测试之前进行配置。 def pytest_configure_node(node): node.slaveinput[\u0026#39;my_option\u0026#39;] = \u0026#39;some value\u0026#39; 使用 pytest_configure_node：可以在节点上运行测试之前进行配置。 def pytest_configure_node(node): node.slaveinput[\u0026#39;my_option\u0026#39;] = \u0026#39;some value\u0026#39; 分布式测试环境销毁：\n使用 pytest_configure_node：可以在节点上运行测试之后进行清理。 def pytest_configure_node(node): # 配置节点 yield # 在节点上运行测试后执行清理 print(\u0026#34;Cleaning up after test run on node %s\u0026#34; % node.gateway.id) 这些是 pytest-xdist 提供的一些功能，可以帮助您更有效地执行并发测试和分布式测试，以加速测试执行并提高效率。确保在使用前查阅 pytest-xdist 的文档以获取更详细的信息和用法示例。\n安装 pytest-xdist 依赖 pip install pytest-xdist 并发运行测试用例示例 并发 3 个 worker 执行测试用例 分别运行以下命令，查看测试用例的执行时长\n并发执行 pytest -n 3 默认串行执行 pytest 串行执行耗时 9.81s，而并发执行耗时 1.63s，可以看到并发执行测试用例可以大大提高测试效率。\n并发 3 个 worker 执行测试用例，并且每个 worker 都会打印测试用例的进度 pytest -n 3 -v 测试结果中会打印测试进度，可以更好的了解测试用例的执行情况。\n分布式测试示例 分布式测试，每个节点运行一组测试 pytest --dist=each 分布式测试可以更快地完成测试运行。\n分布式测试，每个节点运行一组测试，并且每个 worker 都会打印测试用例的进度 pytest --dist=each -v 测试结果中会打印测试进度，可以更好的了解测试用例的执行情况。\n分布式测试，每个节点运行一组测试，并且每个 worker 都会打印测试用例的进度，同时打印测试日志的输出 pytest --dist=each -v --capture=no 测试结果中会打印测试日志的输出，可以更好的了解测试用例的执行情况。\n筛选用例执行 在日常的接口测试过程中，我们需要根据实际情况来选择性地执行测试用例，以提高测试效率。\n一般我们使用 allure 测试报告的时候，可以使用 Allure 标签特性来进行筛选对应标签的的用例来执行测试，但 Pytest 框架不直接支持运行基于 Allure 标签的测试。所以可以使用 Pytest 标记来实现这一点。\nPytest 提供 marks标记功能可以用来标记不同类型的测试用例，然后进行筛选对应类型的测试用例进行执行。\n大致流程为你可以用自定义标记（如 Regression/Smoke）来标记测试，然后使用 pytest 的 -m 选项只运行这些测试。\n定义 Pytest 标记 编辑 pytest.ini 文件，添加以下内容：自定义标记的类型\nRegression:标记为回归测试的用例 Smoke:标记为冒烟测试的用例 markers = Regression: marks tests as Regression Smoke: marks tests as Smoke 标记用例 操作步骤为：\n引入 pytest 使用 @pytest.mark 标记测试用例 为做区分，这里新建测试用例文件，文件名为 test_demo_filter.py\nimport pytest import requests import json class TestPytestMultiEnvDemo: @pytest.mark.Regression # mark the test case as regression def test_get_demo_filter(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send request response = requests.get(host+get_api) # assert assert response.status_code == 200 assert response.json() == get_api_response_data @pytest.mark.Smoke # mark the test case as smoke def test_post_demo_filter(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] print(\u0026#34;make the request\u0026#34;) post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # Your test code here response = requests.post(host + post_api, json=post_api_request_data) print(\u0026#34;verify the response status code\u0026#34;) assert response.status_code == 201 print(\u0026#34;verify the response data\u0026#34;) assert response.json() == post_api_response_data 筛选测试用例执行 运行 Regression 标记的测试用例 pytest -m Regression 这条命令告诉 pytest 只运行标有 Regression 的测试。\n运行 Smoke 标记的测试用例 pytest -m Smoke 这条命令告诉 pytest 只运行标有 Smoke 的测试。\n参考资料 pytest-xdist 文档:https://pytest-xdist.readthedocs.io/en/stable/ pytest makers 文档:https://docs.pytest.org/en/6.2.x/example/markers.html pytest 文档:https://docs.pytest.org/en/6.2.x/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-filter-testcase-and-concurrent-testing-distributed-testing/","summary":"聚焦于测试用例筛选、并发测试和分布式测试。学会如何有针对性地执行测试用例，提高测试效率。探索 Pytest 的并发测试特性，了解如何同时执行多个测试用例，缩短测试时间。","title":"Pytest 接口自动化测试教程：进阶用法 - 筛选测试用例执行，并发测试和分布式测试"},{"content":"进阶用法 多环境支持 在实际的 API 自动化测试过程中，我们需要在不同的环境中运行测试用例，以确保 API 在各个环境中都能正常运行。\n通过使用 Pytest 的 fixture 功能，我们可以轻松地实现多环境支持。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n新建不同环境测试配置文件 配置文件会以 json 格式存储为例，其他格式如 YAML、CSV 等类似，均可参考\n// 新建测试配置文件夹 mkdir config // 进入测试配置文件夹 cd config // 新建开发环境测试配置文件 touch dev_config.json // 新建生产环境测试配置文件 touch prod_config.json 编写不同环境测试配置文件 编写开发环境测试配置文件 根据实际情况配置开发环境测试配置文件\n{ \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 编写生产环境测试配置文件 根据实际情况配置生产环境测试配置文件\n{ \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 新建不同环境测试数据文件 不同环境请求数据文件和响应数据文件分别存储测试用例的不同环境请求数据和不同环境预期响应数据。\n// 新建测试数据文件夹 mkdir data // 进入测试数据文件夹 cd data // 新建开发环境请求数据文件 touch dev_request_data.json // 新建开发环境响应数据文件 touch dev_response_data.json // 新建生产环境请求数据文件 touch prod_request_data.json // 新建生产环境响应数据文件 touch prod_response_data.json 编写不同环境测试数据文件 编写开发环境请求数据文件 开发环境请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写开发环境响应数据文件 开发环境响应数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 编写生产环境请求数据文件 生产环境请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写生产环境响应数据文件 生产环境响应数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 配置支持多环境的 fixture fixture 会以 conftest.py 文件存储为例，其他格式如 YAML、CSV 等类似，均可参考\n项目根目录新建 conftest.py 文件 mkdrir conftest.py 编写 conftest.py 文件 import pytest import json import json import os @pytest.fixture(scope=\u0026#34;session\u0026#34;) def env_config(request): # get config file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;config/{env}_config.json\u0026#39;, \u0026#39;r\u0026#39;) as config_file: config = json.load(config_file) return config @pytest.fixture(scope=\u0026#34;session\u0026#34;) def env_request_data(request): # get request data file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;data/{env}_request_data.json\u0026#39;, \u0026#39;r\u0026#39;) as request_data_file: request_data = json.load(request_data_file) return request_data @pytest.fixture (scope=\u0026#34;session\u0026#34;) def env_response_data(request): # get response data file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;data/{env}_response_data.json\u0026#39;, \u0026#39;r\u0026#39;) as response_data_file: response_data = json.load(response_data_file) return response_data 更新测试用例来支持多环境 为做区分，这里新建测试用例文件，文件名为 test_demo_multi_environment.py\nimport requests import json class TestPytestMultiEnvDemo: def test_get_demo_multi_env(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send request response = requests.get(host+get_api) # assert assert response.status_code == 200 assert response.json() == get_api_response_data def test_post_demo_multi_env(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # send request response = requests.post(host + post_api, post_api_request_data) # assert assert response.status_code == 201 assert response.json() == post_api_response_data 运行该测试用例确认多环境支持是否生效 运行开发环境测试用例 ENV=dev pytest test_case/test_demo_multi_environment.py 运行生产环境测试用例 ENV=prod pytest test_case/test_demo_multi_environment.py 集成 allure 报告 allure 是一个轻量级的、灵活的、易于扩展的测试报告工具，它提供了丰富的报告类型和功能，可以帮助您更好地可视化测试结果。\nallure 报告可以与 Pytest 集成，以生成详细的测试报告。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n安装 allure-pytest 依赖 pip install allure-pytest 避免之前安装的 pytest-html-reporter 与 allure-pytest 冲突，建议先卸载 pytest-html-reporter\npip uninstall pytest-html-reporter 配置 allure-pytest 更新 pytest.ini 文件来指定 allure 报告的存储位置\n[pytest] # allure addopts = --alluredir ./allure-results 调整测试用例来支持 allure 报告 为做区分，这里新建测试用例文件，文件名为 test_demo_allure.py\nimport allure import requests @allure.feature(\u0026#34;Test example API\u0026#34;) class TestPytestAllureDemo: @allure.story(\u0026#34;Test example get endpoint\u0026#34;) @allure.title(\u0026#34;Verify the get API\u0026#34;) @allure.description(\u0026#34;verify the get API response status code and data\u0026#34;) @allure.severity(\u0026#34;blocker\u0026#34;) def test_get_example_endpoint_allure(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_request_data = env_request_data[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send get request response = requests.get(host + get_api) # assert print(\u0026#34;response status code is\u0026#34; + str(response.status_code)) assert response.status_code == 200 print(\u0026#34;response data is\u0026#34; + str(response.json())) assert response.json() == get_api_response_data @allure.story(\u0026#34;Test example POST API\u0026#34;) @allure.title(\u0026#34;Verify the POST API\u0026#34;) @allure.description(\u0026#34;verify the POST API response status code and data\u0026#34;) @allure.severity(\u0026#34;Critical\u0026#34;) def test_post_example_endpoint_allure(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # send request response = requests.post(host + post_api, json=post_api_request_data) # assert print(\u0026#34;response status code is\u0026#34; + str(response.status_code)) assert response.status_code == 201 print(\u0026#34;response data is\u0026#34; + str(response.json())) assert response.json() == post_api_response_data 运行测试用例生成 allure 报告 ENV=dev pytest test_case/test_demo_allure.py 查看 allure 报告 输入以下命令来启动 allure 服务并浏览器中查看 allure 报告\nallure serve allure-results 调整 CI/CD 流程来支持 allure 报告 以 github action 为例，其他 CI 工具类似\n更新.github/workflows/pytest.yml 文件内容来上传 allure 报告到 GitHub\nname: Pytest API Testing on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] permissions: contents: read jobs: Pytes-API-Testing: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python 3.10 uses: actions/setup-python@v3 with: python-version: \u0026#34;3.10\u0026#34; - name: Install dependencies run: | python -m pip install --upgrade pip pip install -r requirements.txt - name: Test with pytest run: | ENV=dev pytest - name: Archive Pytest allure test report uses: actions/upload-artifact@v3 with: name: Pytest-allure-report path: allure-results - name: Upload Pytest allure report to GitHub uses: actions/upload-artifact@v3 with: name: Pytest-allure-report path: allure-results 查看 github action allure 报告 在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Pytest API Testing 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。\n参考 Pytest 文档 Allure 文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-multiple-environment-support-and-integration-allure-report/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 如何支持不同环境测试用例执行，以及如何集成 allure 报告来实现测试报告多样化。","title":"Pytest 接口自动化测试教程：进阶用法 - 多环境支持 和 集成 allure 报告"},{"content":"进阶用法 常用断言 使用 Pytest 在接口自动化测试用例编写过程中，我们需要使用各种断言来验证测试的预期结果。\nPytest 提供了更多的断言和灵活的断言库，以满足各种测试需求。\n以下是一些常用的 Pytest 接口自动化测试断言：\n相等性断言：检查两个值是否相等。\nassert actual_value == expected_value 不相等性断言：检查两个值是否不相等。\nassert actual_value != expected_value 包含断言：检查一个值是否包含在另一个值中，通常用于检查字符串是否包含子字符串。\nassert substring in full_string 成员资格断言：检查一个值是否在集合、列表或其他可迭代对象中。\nassert item in iterable 真值断言：检查一个表达式或变量是否为真。\nassert expression 或\nassert variable 假值断言：检查一个表达式或变量是否为假。\nassert not expression 或\nassert not variable 大于、小于、大于等于、小于等于断言：检查一个值是否大于、小于、大于等于或小于等于另一个值。\nassert value \u0026gt; other_value assert value \u0026lt; other_value assert value \u0026gt;= other_value assert value \u0026lt;= other_value 类型断言：检查一个值的类型是否符合预期。\nassert isinstance(value, expected_type) 例如，检查一个值是否是字符串：\nassert isinstance(my_string, str) 异常断言：检查在代码块中是否引发了特定类型的异常。\nwith pytest.raises(ExpectedException): # 代码块，期望引发 ExpectedException 异常 近似相等断言：检查两个浮点数是否在某个误差范围内相等。\nassert math.isclose(actual_value, expected_value, rel_tol=1e-9) 列表相等断言：检查两个列表是否相等。\nassert actual_list == expected_list 字典相等断言：检查两个字典是否相等。\nassert actual_dict == expected_dict 正则表达式匹配断言：检查一个字符串是否匹配给定的正则表达式。\nimport re assert re.match(pattern, string) 空值断言：检查一个值是否为 None。\nassert value is None 非空值断言：检查一个值是否不为 None。\nassert value is not None 布尔值断言：检查一个值是否为 True 或 False。\nassert boolean_expression 空容器断言：检查一个列表、集合或字典是否为空。\nassert not container # 检查容器是否为空 包含子集断言：检查一个集合是否包含另一个集合作为子集。\nassert subset \u0026lt;= full_set 字符串开头或结尾断言：检查一个字符串是否以指定的前缀或后缀开头或结尾。\nassert string.startswith(prefix) assert string.endswith(suffix) 数量断言：检查一个列表、集合或其他可迭代对象的元素数量。\nassert len(iterable) == expected_length 范围断言：检查一个值是否在指定的范围内。\nassert lower_bound \u0026lt;= value \u0026lt;= upper_bound 文件存在断言：检查文件是否存在。\nimport os assert os.path.exists(file_path) 以上是一些 Pytest 常用的断言，但根据具体的测试需求，您可能会使用其他断言或结合多个断言来更全面地验证测试结果。 详细的断言文档可以在 Pytest 官方网站找到：Pytest - Built-in fixtures, marks, and nodes\n数据驱动 在 API 自动化测试的过程中。使用数据驱动是一种常规测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。\n测试数据可以很容易地修改，而不需要修改测试用例代码。\n数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n新建测试配置文件 配置文件会以 json 格式存储为例，其他格式如 YAML、CSV 等类似，均可参考\n// 新建测试配置文件夹 mkdir config // 新建测试配置文件 cd config touch config.json 编写测试配置文件 配置文件存储测试环境的配置信息，如测试环境的 URL、数据库连接信息等。\ndemo 中的测试配置文件内容如下：\n配置 host 信息 配置 getAPI 接口信息 配置 postAPI 接口信息 { \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 新建测试数据文件 请求数据文件和响应数据文件分别存储测试用例的请求数据和预期响应数据。\n// 新建测试数据文件夹 mkdir data // 进入测试数据文件夹 cd data // 新建请求数据文件 touch request_data.json // 新建响应数据文件 touch response_data.json 编写测试数据文件 编写请求数据文件 请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写响应数据文件 请求数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 更新测试用例来支持数据驱动 为做区分，这里新建测试用例文件，文件名为 test_demo_data_driving.py\nimport requests import json # 从配置文件夹获取测试配置 with open(\u0026#34;config/config.json\u0026#34;, \u0026#34;r\u0026#34;) as json_file: config = json.load(json_file) # 从测试数据文件夹获取接口请求数据 with open(\u0026#39;data/request_data.json\u0026#39;, \u0026#39;r\u0026#39;) as json_file: request_data = json.load(json_file) # 从测试数据文件夹获取接口响应数据 with open(\u0026#39;data/response_data.json\u0026#39;, \u0026#39;r\u0026#39;) as json_file: response_data = json.load(json_file) class TestPytestDemo: def test_get_demo(self): host = config.get(\u0026#34;host\u0026#34;) get_api = config.get(\u0026#34;getAPI\u0026#34;) get_api_response_data = response_data.get(\u0026#34;getAPI\u0026#34;) # 发起请求 response = requests.get(host+get_api) # 断言 assert response.status_code == 200 assert response.json() == get_api_response_data def test_post_demo(self): host = config.get(\u0026#34;host\u0026#34;) post_api = config.get(\u0026#34;postAPI\u0026#34;) post_api_request_data = request_data.get(\u0026#34;postAPI\u0026#34;) post_api_response_data = response_data.get(\u0026#34;postAPI\u0026#34;) # 发起请求 response = requests.post(host + post_api, post_api_request_data) # 断言 assert response.status_code == 201 assert response.json() == post_api_response_data 运行该测试用例确认数据驱动是否生效 若用 demo 项目运行数据驱动支持测试用例：test_demo_data_driving.py，建议先屏蔽掉其他测试用例，否则可能会报错\n参考 pytest 文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-common-assertions-and-data-driven/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 常用断言和数据驱动。","title":"Pytest 接口自动化测试教程：进阶用法 - 常用断言和数据驱动"},{"content":"进阶用法 持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 pytest.yml。\n编辑 pytest.yml 文件：将以下内容复制到文件中\n# This workflow will install Python dependencies, run tests and lint with a single version of Python # For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python name: Pytest API Testing on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] permissions: contents: read jobs: Pytes-API-Testing: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python 3.10 uses: actions/setup-python@v3 with: python-version: \u0026#34;3.10\u0026#34; - name: Install dependencies run: | python -m pip install --upgrade pip pip install -r requirements.txt - name: Test with pytest run: | pytest - name: Archive Pytest test report uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: report - name: Upload Pytest report to GitHub uses: actions/upload-artifact@v3 with: name: Pytest-test-report path: report 提交代码：将 pytest.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Pytest API Testing 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 参考 pytest 文档 gitHub action 文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-integration-ci-cd-and-github-action/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 集成到 CI/CD 流程中，以及如何使用 GitHub Actions 实现自动化测试。","title":"Pytest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action"},{"content":"从 0 到 1 搭建 Pytest 接口自动化测试项目 1.创建项目目录 mkdir Pytest-API-Testing-Demo 2.项目初始化 // 进入项目文件夹下 cd Pytest-API-Testing-Demo // 创建项目 python 项目虚拟环境 python -m venv .env // 启用项目 python 项目虚拟环境 source .env/bin/activate 3.安装项目依赖 // 安装 requests 包 pip install requests // 安装pytest 包 pip install pytest // 将项目依赖项保存到 requirements.txt 文件中 pip freeze \u0026gt; requirements.txt 4.新建测试文件及测试用例 // 新建测试文件夹 mkdir tests // 新建测试用例文件 cd tests touch test_demo.py 5.编写测试用例 测试接口可参考项目中 demoAPI.md 文件\nimport requests class TestPytestDemo: def test_get_demo(self): base_url = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34; # 发起请求 response = requests.get(f\u0026#34;{base_url}/posts/1\u0026#34;) # 断言 assert response.status_code == 200 assert response.json()[\u0026#39;userId\u0026#39;] == 1 assert response.json()[\u0026#39;id\u0026#39;] == 1 def test_post_demo(self): base_url = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34; requests_data = { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } # 发起请求 response = requests.post(f\u0026#34;{base_url}/posts\u0026#34;, requests_data) # 断言 assert response.status_code == 201 print(response.json()) assert response.json()[\u0026#39;userId\u0026#39;] == \u0026#39;1\u0026#39; assert response.json()[\u0026#39;id\u0026#39;] == 101 6.运行测试用例 pytest 7.查看测试报告 8.接入 pytest-html-reporter 测试报告 https://github.com/prashanth-sams/pytest-html-reporter\n安装 pytest-html-reporter 依赖 pip install pytest-html-reporter 配置测试报告参数 项目根目录下新建 pytest.ini 文件 添加以下内容 [pytest] addopts = -vs -rf --html-report=./report --title=\u0026#39;PYTEST REPORT\u0026#39; --self-contained-html 运行测试用例 pytest 查看测试报告 报告在项目根目录下的 report 目录下，使用浏览器打开 pytest_html_report.html 文件即可查看\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-building-your-own-project-from-0-to-1/","summary":"将从零开始教您如何建立 Pytest 接口自动化测试项目。您将学习如何创建项目的基础结构，设置环境，编写测试用例，以及执行自动化测试。","title":"Pytest 接口自动化测试教程：从 0 到 1 搭建 Pytest 接口自动化测试项目"},{"content":"介绍 Pytest 介绍 Pytest 是一个流行的 Python 测试框架，用于编写、组织和运行各种类型的自动化测试。它提供了丰富的功能，使您能够轻松编写和管理测试用例，以及生成详细的测试报告。以下是 Pytest 的一些主要特点和优势：\n简单和易用：Pytest 的设计使得编写测试用例变得简单且易于理解。您可以使用 Python 的标准 assert 语句来编写测试断言，而不需要学习新的断言语法。\n自动发现测试用例：Pytest 可以自动发现和运行项目中的测试用例，而不需要显式配置测试套件。测试用例文件可以命名为 test_*.py 或 *_test.py，或使用特定的测试函数命名规范。\n丰富的插件生态系统：Pytest 可以通过插件扩展其功能。有许多第三方插件可用，以满足不同测试需求，如 Allure 报告、参数化、覆盖率分析等。\n参数化测试：Pytest 支持参数化测试，允许您运行相同的测试用例多次，但使用不同的参数。这可以减少代码重复，提高测试覆盖率。\n异常和故障定位：Pytest 提供详细的错误和异常信息，有助于您更容易地定位和解决问题。它还提供详细的回溯（traceback）信息。\n并行测试执行：Pytest 支持并行执行测试用例，提高了测试执行的速度，特别是在大型项目中。\n多种报告格式：Pytest 支持多种测试报告格式，包括终端输出、JUnit XML、HTML 报告和 Allure 报告等。这些报告可以帮助您可视化测试结果。\n命令行选项：Pytest 提供了丰富的命令行选项，以定制测试运行的行为，包括过滤、重试、覆盖率分析等。\n集成性：Pytest 可以与其他测试框架和工具（如 Selenium、Django、Flask 等）以及持续集成系统（如 Jenkins、Travis CI 等）轻松集成。\n活跃的社区：Pytest 拥有一个活跃的社区，有广泛的文档和教程可供学习和参考。您还可以在社区中获得支持和解决问题。\n总之，Pytest 是一个强大且灵活的测试框架，适用于各种规模和类型的项目。它的易用性、自动化能力以及丰富的插件使它成为 Python 测试领域的首选工具之一。\n官方网站：https://docs.pytest.org/en/latest/\npython 虚拟环境介绍 Python 虚拟环境（Virtual Environment）是一种机制，用于在单个 Python 安装中创建和管理多个隔离的开发环境。虚拟环境有助于解决不同项目之间的依赖冲突问题，确保每个项目都能够使用其独立的 Python 包和库，而不会相互干扰。以下是如何创建和使用 Python 虚拟环境的步骤：\n安装虚拟环境工具: 在开始之前，确保您已安装 Python 的虚拟环境工具。在 Python 3.3 及更高版本中，venv 模块已经内置，可以使用它来创建虚拟环境。如果您使用较旧版本的 Python，您可以安装 virtualenv 工具。\n对于 Python 3.3+，venv 工具已内置，无需额外安装。\n对于 Python 2.x，可以使用以下命令安装 virtualenv 工具：\npip install virtualenv 创建虚拟环境: 打开终端，移动到您希望创建虚拟环境的目录，并运行以下命令以创建虚拟环境：\n使用 venv（适用于 Python 3.3+）：\npython -m venv myenv 使用 virtualenv（适用于 Python 2.x）：\nvirtualenv myenv 在上述命令中，myenv 是虚拟环境的名称，您可以自定义名称。\n激活虚拟环境: 要开始使用虚拟环境，需要激活它。在不同的操作系统中，激活命令略有不同：\n在 macOS 和 Linux 上：\nsource myenv/bin/activate 在 Windows 上（使用 Command Prompt）：\nmyenv\\Scripts\\activate 在 Windows 上（使用 PowerShell）：\n.\\myenv\\Scripts\\Activate.ps1 一旦虚拟环境激活，您会在终端提示符前看到虚拟环境的名称，表示您已进入虚拟环境。\n在虚拟环境中安装依赖: 在虚拟环境中，您可以使用 pip 安装项目所需的任何 Python 包和库，这些依赖将与该虚拟环境关联。例如：\npip install requests 使用虚拟环境: 在虚拟环境中工作时，您可以运行 Python 脚本和使用安装在虚拟环境中的包。这确保了您的项目在独立的环境中运行，不会与全局 Python 安装产生冲突。\n退出虚拟环境: 要退出虚拟环境，只需在终端中运行以下命令：\ndeactivate 这将使您返回到全局 Python 环境。\n通过使用虚拟环境，您可以在不同项目之间维护干净的依赖关系，并确保项目的稳定性和隔离性。这是 Python 开发中的一个良好实践。\n项目依赖 需提前安装好以下环境\npython, demo 版本为 v3.11.6 大家安装 python3.x 以上的版本即可\n项目目录结构 以下为一个 Pytest 接口自动化测试项目的目录结构示例：\n后续 demo 项目会引入 allure 报告，所以会多出一个 allure-report 目录\nPytest-allure-demo/ ├── tests/ # 存放测试用例文件 │ ├── test_login.py # 示例测试用例文件 │ ├── test_order.py # 示例测试用例文件 │ └── ... ├── data/ # 存放测试数据文件（如 JSON、CSV 等） │ ├── dev_test_data.json # 开发环境测试数据文件 │ ├── prod_test_data.json # 生产环境测试数据文件 │ ├── ... ├── config/ │ ├── dev_config.json # 开发环境配置文件 │ ├── prod_config.json # 生产环境配置文件 │ ├── ... ├── conftest.py # Pytest 的全局配置文件 ├── pytest.ini # Pytest 配置文件 ├── requirements.txt # 项目依赖项文件 └── allure-report/ # 存放 Allure 报告 参考 Pytest: https://docs.pytest.org/en/latest/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-getting-started-and-own-environment-preparation/","summary":"包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 Pytest 以及如何开始使用它来进行 API 测试。","title":"Pytest 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"多环境支持 在使用 Jest 或 Mocha 进行 API 测试时，你可能需要支持测试不同的环境，例如开发环境、测试环境和生产环境。这可以通过配置不同的测试脚本和环境变量来实现。\n下面会简单描述一下如何在 Jest 和 Mocha 中配置多环境支持，会以支持两个环境来进行 demo 演示。\nMocha 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\nJest 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\nmocha 版本和 Jest 版本类似，这里以 Mocha 版本为例\n新建多环境测试配置文件 // 新建测试配置文件夹 若已有则不用新建 mkdir Config // 新建测试环境测试配置文件 cd Config touch testConfig-test.js // 新建开发环境测试配置文件 touch testConfig-dev.js 编写多环境测试配置文件 编写测试环境测试配置文件 根据实际情况编写测试环境测试配置文件\n// Test config file for test environment module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 编写开发环境测试配置文件 根据实际情况编写开发环境测试配置文件\n// Test config file for dev environment module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 新建多环境测试数据文件 // 新建测试数据文件夹 若已有则不用新建 mkdir testData // 进入测试数据文件夹 cd testData // 新建测试环境请求数据文件 touch requestData-test.js // 新建测试环境响应数据文件 touch responseData-test.js // 新建开发环境请求数据文件 touch requestData-dev.js // 新建开发环境响应数据文件 touch responseData-dev.js 编写多环境测试数据文件 编写测试环境请求数据文件 根据实际情况编写测试环境请求数据文件\n// Test request data file for test environment module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写测试环境响应数据文件 根据实际情况编写测试环境响应数据文件\n// Test response data file for test environment module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 编写开发环境请求数据文件 根据实际情况编写开发环境请求数据文件\n// Test request data file for dev environment module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写开发环境响应数据文件 根据实际情况编写开发环境响应数据文件\n// Test response data file for dev environment module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 更新测试用例来支持多环境 为做区分，这里新建测试用例文件，文件名为 multiEnvTest.spec.js\n// Test: multiEnvTest.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect const config = process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../Config/testConfig-test\u0026#39;) : require(\u0026#39;../Config/testConfig-dev\u0026#39;); // import test config const requestData = process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../TestData/requestData-test\u0026#39;) : require(\u0026#39;../TestData/requestData-dev\u0026#39;); // import request data const responseData= process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../TestData/responseData-test\u0026#39;) : require(\u0026#39;../TestData/responseData-dev\u0026#39;); // import response data // Test Suite describe(\u0026#39;multiEnv-Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;multiEnv-Verify that the GET API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .get(config.getAPI) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.getAPI.id) expect(res.body.userId).to.equal(responseData.getAPI.userId) expect(res.body.title).to.equal(responseData.getAPI.title) expect(res.body.body).to.equal(responseData.getAPI.body) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;multiEnv-Verify that the POST API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .post(config.postAPI) // API endpoint .send(requestData.postAPI) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.postAPI.id ) expect(res.body.userId).to.equal(responseData.postAPI.userId ) expect(res.body.title).to.equal(responseData.postAPI.title ) expect(res.body.body).to.equal(responseData.postAPI.body ) }) // expected response body .end(done) // end the test case }); }); 更新测试脚本来支持多环境 \u0026lsquo;\u0026lsquo;\u0026lsquo;json // package.json \u0026ldquo;scripts\u0026rdquo;: { \u0026ldquo;test\u0026rdquo;: \u0026ldquo;NODE_ENV=test mocha\u0026rdquo; // 运行测试环境测试脚本 \u0026ldquo;dev\u0026rdquo;: \u0026ldquo;NODE_ENV=dev mocha\u0026rdquo; // 运行 dev 环境测试脚本 }, \u0026rsquo;\u0026rsquo;\u0026rsquo;\n运行该测试用例确认多环境支持是否生效 若用 demo 项目运行多环境支持测试用例：multiEnvTest.spec.js，建议先屏蔽掉 dataDrivingTest.spec.js 和 test.spec.js 测试用例，否则会报错\n运行测试环境测试脚本 npm run test 运行开发环境测试脚本 npm run dev 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-multiple-environment-support/","summary":"专注于 SuperTest 的高级用法，着重介绍多环境支持。您将学习如何配置和管理多个测试环境，以适应不同开发和部署阶段。","title":"SuperTest 接口自动化测试教程：进阶用法 - 多环境支持"},{"content":"数据驱动 API 测试的数据驱动是一种测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\nMocha 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\nJest 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\nmocha 版本和 Jest 版本类似，这里以 Mocha 版本为例\n新建测试配置文件 // 新建测试配置文件夹 mkdir Config // 新建测试配置文件 cd Config touch config.js 编写测试配置文件 // Test config file module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 新建测试数据文件 // 新建测试数据文件夹 mkdir testData // 进入测试数据文件夹 cd testData // 新建请求数据文件 touch requestData.js // 新建响应数据文件 touch responseData.js 编写测试数据文件 编写请求数据文件 // Test request data file module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写响应数据文件 // Test response data file module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 更新测试用例来支持数据驱动 为做区分，这里新建测试用例文件，文件名为 dataDrivingTest.spec.js\n// Test: dataDrivingTest.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect const config = require(\u0026#39;../Config/testConfig\u0026#39;); // import test config const requestData = require(\u0026#39;../TestData/requestData\u0026#39;); // import request data const responseData = require(\u0026#39;../TestData/responseData\u0026#39;); // import response data // Test Suite describe(\u0026#39;Data Driving-Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;Data Driving-Verify that the GET API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .get(config.getAPI) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.getAPI.id) expect(res.body.userId).to.equal(responseData.getAPI.userId) expect(res.body.title).to.equal(responseData.getAPI.title) expect(res.body.body).to.equal(responseData.getAPI.body) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;Data Driving-Verify that the POST API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .post(config.postAPI) // API endpoint .send(requestData.postAPI) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.postAPI.id ) expect(res.body.userId).to.equal(responseData.postAPI.userId ) expect(res.body.title).to.equal(responseData.postAPI.title ) expect(res.body.body).to.equal(responseData.postAPI.body ) }) // expected response body .end(done) // end the test case }); }); 运行该测试用例确认数据驱动是否生效 若用 demo 项目运行数据驱动支持测试用例：dataDrivingTest.spec.js，建议先屏蔽掉 test.spec.js 测试用例，否则会报错\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-data-driven/","summary":"专注于 SuperTest 的高级用法，侧重于数据驱动测试。您将学习如何通过数据参数化来扩展和优化您的 SuperTest 测试套件，提高测试覆盖率。","title":"SuperTest 接口自动化测试教程：进阶用法 - 数据驱动"},{"content":"常用断言 下面会一次介绍一下 SuperTest,CHAI 和 Jest 常用的断言。\nSuperTest 的内置断言 Supertest 是基于SuperAgent 构建的一个更高级的库，所以 Supertest 可以很轻松的使用 SuperAgent 的 HTTP 断言。\n示例如下：\n.expect(status[, fn]) //断言响应状态代码。 .expect(status, body[, fn]) // 断言响应状态代码和正文。 .expect(body[, fn]) // 用字符串、正则表达式或解析后的正文对象断言响应正文文本。 .expect(field, value[, fn]) // 用字符串或正则表达式断言标题字段值。 .expect(function(res) {}) // 传递一个自定义断言函数。它将得到要检查的响应对象。如果检查失败，则抛出错误。 CHAI 的常用断言 相等性断言（Equality Assertions） expect(actual).to.equal(expected) // 验证实际值是否等于期望值。 expect(actual).to.deep.equal(expected) // 验证实际值和期望值是否深度相等，适用于对象和数组比较。 expect(actual).to.eql(expected) // 与 deep.equal 一样，用于深度相等的比较。 包含性断言（Inclusion Assertions） expect(array).to.include(value) // 验证数组是否包含指定的值。 expect(string).to.include(substring) // 验证字符串是否包含指定的子字符串。 expect(object).to.include(key) // 验证对象是否包含指定的键。 类型断言（Type Assertions） expect(actual).to.be.a(type) // 验证实际值的类型是否等于指定类型。 expect(actual).to.be.an(type) // 与 to.be.a 一样，用于类型断言。 expect(actual).to.be.an.instanceof(constructor) // 验证实际值是否是指定构造函数的实例。 真假性断言（Truthiness Assertions） expect(value).to.be.true // 验证值是否为真。 expect(value).to.be.false // 验证值是否为假。 expect(value).to.exist // 验证值是否存在，非 null 和非 undefined。 长度断言（Length Assertions） expect(array).to.have.length(length) // 验证数组的长度是否等于指定长度。 expect(string).to.have.lengthOf(length) // 验证字符串的长度是否等于指定长度。 空值断言（Empty Assertions） expect(array).to.be.empty // 验证数组是否为空。 expect(string).to.be.empty // 验证字符串是否为空。 范围断言（Range Assertions） expect(value).to.be.within(min, max) // 验证值是否在指定的范围内。 expect(value).to.be.above(min) // 验证值是否大于指定值。 expect(value).to.be.below(max) // 验证值是否小于指定值。 异常断言（Exception Assertions） expect(fn).to.throw(error) // 验证函数是否抛出指定类型的异常。 expect(fn).to.throw(message) // 验证函数是否抛出包含指定消息的异常。 存在性断言（Existence Assertions） expect(object).to.have.property(key) // 验证对象是否包含指定属性。 expect(array).to.have.members(subset) // 验证数组是否包含指定的成员。 更多 chai 的断言，请查看https://www.chaijs.com/api/assert/\nJest 的常用断言 相等性断言（Equality Assertions） expect(actual).toBe(expected) // 验证实际值是否严格等于期望值。 expect(actual).toEqual(expected) // 验证实际值和期望值是否深度相等，适用于对象和数组比较。 不相等性断言 expect(actual).not.toBe(expected) // 验证实际值与期望值不相等。 包含性断言（Inclusion Assertions） expect(array).toContain(value) // 验证数组是否包含指定的值。 类型断言（Type Assertions） expect(actual).toBeTypeOf(expected) // 验证实际值的类型是否等于指定类型。 真假性断言（Truthiness Assertions） expect(value).toBeTruthy() // 验证值是否为真。 expect(value).toBeFalsy() // 验证值是否为假。 异步断言 await expect(promise).resolves.toBe(expected) // 验证异步操作是否成功完成并返回与期望值匹配的结果。 异常断言 expect(fn).toThrow(error) // 验证函数是否抛出指定类型的异常。 expect(fn).toThrow(message) // 验证函数是否抛出包含指定消息的异常。 范围断言 expect(value).toBeGreaterThanOrEqual(min) // 验证值是否大于或等于指定的最小值。 expect(value).toBeLessThanOrEqual(max) // 验证值是否小于或等于指定的最大值。 对象属性断言 expect(object).toHaveProperty(key, value) // 验证对象是否包含指定属性，并且该属性的值等于指定值。 更多 Jest 的断言，请查看https://jestjs.io/docs/expect\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-common-assertions/","summary":"聚焦于 Supertest 的高级用法，特别关注常用断言。您将学习如何使用这些断言来验证 API 响应，包括状态码、响应内容、和响应头部等。","title":"SuperTest 接口自动化测试教程：进阶用法 - 常用断言"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nMocha 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 mocha.yml。\n编辑 mocha.yml 文件：将以下内容复制到文件中\nname: RUN SuperTest API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-SuperTest-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive SuperTest mochawesome test report uses: actions/upload-artifact@v3 with: name: SuperTest-mochawesome-test-report path: Report - name: Upload SuperTest mochawesome report to GitHub uses: actions/upload-artifact@v3 with: name: SuperTest-mochawesome-test-report path: Report 提交代码：将 mocha.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN SuperTest API Test CI 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Jest 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 jest.yml。\n编辑 jest.yml 文件：将以下内容复制到文件中\nname: RUN SuperTest API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-SuperTest-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive SuperTest test report uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: Report - name: Upload SuperTest report to GitHub uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: Report 提交代码：将 jest.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN-SuperTest-API-Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-integration-ci-cd-and-github-action/","summary":"深入探讨 Supertest 的高级用法，着重介绍如何将 Supertest 集成到 CI/CD 流程中，以及如何使用 GitHub Actions 实现自动化测试。","title":"SuperTest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action"},{"content":"从 0 到 1 搭建 SuperTest 接口自动化测试项目 下面会从 0 到 1 搭建一个 SuperTest 接口自动化测试项目，会使用 Jest 或 Mocha 作为测试框架进行 demo 演示。\nMocha 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n新建项目文件夹 mkdir SuperTest-Mocha-demo 项目初始化 // 进入项目文件夹下 cd SuperTest-Mocha-demo // nodejs 项目初始化 npm init -y 安装依赖 // 安装 supertest npm install supertest --save-dev // 安装 mocha测试框架 npm install mocha --save-dev // 安装 chai断言库 npm install chai --save-dev 新建测试文件及测试用例 // 新建测试文件夹 mkdir Specs // 新建测试用例文件 cd Specs touch test.spec.js 编写测试用例 测试接口可参考项目中 demoAPI.md 文件\n// Test: test.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest const chai = require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect // Test Suite describe(\u0026#39;Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;Verify that the GET API returns correctly\u0026#39;, function(done){ request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .get(\u0026#39;/posts/1\u0026#39;) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(1 ) expect(res.body.userId).to.equal(1) expect(res.body.title).to.equal(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;) expect(res.body.body). to.equal(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;Verify that the POST API returns correctly\u0026#39;, function(done){ request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .post(\u0026#39;/posts\u0026#39;) // API endpoint .send({ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(101 ) expect(res.body.userId).to.equal(1) expect(res.body.title).to.equal(\u0026#34;foo\u0026#34;) expect(res.body.body).to.equal(\u0026#34;bar\u0026#34;) }) // expected response body .end(done) // end the test case }); }); 配置 mocha 配置文件 新建配置文件 // 项目根目录下新建配置文件 touch .mocharc.js 更新配置文件 // mocha config module.exports = { timeout: 5000, // 设置测试用例的默认超时时间（毫秒） spec: [\u0026#39;Specs/**/*.js\u0026#39;], // 指定测试文件的位置 }; 调整测试脚本 在 package.json 文件中添加测试脚本\n\u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;mocha\u0026#34; }, 运行测试用例 // 运行测试用例 npm run test 测试报告 命令行测试报告 集成 mochawesome 测试报告 安装 mochawesome npm install --save-dev mochawesome 更新 mocha 配置文件 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n// mocha config module.exports = { timeout: 5000, // 设置测试用例的默认超时时间（毫秒） reporter: \u0026#39;mochawesome\u0026#39;, // 使用 mochawesome 报告生成器 \u0026#39;reporter-option\u0026#39;: [ \u0026#39;reportDir=Report\u0026#39;, // 报告生成路径 \u0026#39;reportFilename=[status]_[datetime]-[name]-report\u0026#39;, //报告名称 \u0026#39;html=true\u0026#39;, // 生成 html 格式报告 \u0026#39;json=false\u0026#39;, // 不生成 json 格式报告 \u0026#39;overwrite=false\u0026#39;, // 不覆盖已经存在的报告 \u0026#39;timestamp=longDate\u0026#39;, // 给报告添加时间戳 ], // 传递给报告生成器的参数 spec: [\u0026#39;Specs/**/*.js\u0026#39;], // 指定测试文件的位置 }; 运行测试用例 // 运行测试用例 npm run test 查看测试报告 测试报告文件夹：Report，点击使用浏览器打开最新 html 报告文件\nJest 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n新建 Jest demo 项目文件夹 mkdir SuperTest-Jest-demo Jest demo 项目初始化 // 进入项目文件夹下 cd SuperTest-Mocha-demo // nodejs 项目初始化 npm init -y Jest demo 安装依赖 // 安装 supertest npm install supertest --save-dev // 安装 Jest测试框架 npm install jest --save-dev 新建 Jest demo 项目的测试文件及测试用例 // 新建测试文件夹 mkdir Specs // 新建测试用例文件 cd Specs touch test.spec.js 编写 Jest demo 测试用例 测试接口可参考项目中 demoAPI.md 文件\nconst request = require(\u0026#39;supertest\u0026#39;); // Test Suite describe(\u0026#39;Verify that the Get and POST API returns correctly\u0026#39;, () =\u0026gt; { // Test case 1 it(\u0026#39;Verify that the GET API returns correctly\u0026#39;, async () =\u0026gt; { const res = await request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .get(\u0026#39;/posts/1\u0026#39;) // API endpoint .send() // request body .expect(200); // use supertest\u0026#39;s expect to verify that the status code is 200 // user jest\u0026#39;s expect to verify the response body expect(res.status).toBe(200); // Verify that the status code is 200 expect(res.body.id).toEqual(1); // Verify that the id is 1 expect(res.body.userId).toEqual(1); // Verify that the userId is 1 expect(res.body.title) .toEqual(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;); expect(res.body.body) .toEqual(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;); }); // Test case 2 it(\u0026#39;Verify that the POST API returns correctly\u0026#39;, async() =\u0026gt;{ const res = await request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .post(\u0026#39;/posts\u0026#39;) // API endpoint .send({ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }) // request body .expect(201); // use supertest\u0026#39;s expect to verify that the status code is 201 // user jest\u0026#39;s expect to verify the response body expect(res.statusCode).toBe(201); expect(res.body.id).toEqual(101); expect(res.body.userId).toEqual(1); expect(res.body.title).toEqual(\u0026#34;foo\u0026#34;); expect(res.body.body).toEqual(\u0026#34;bar\u0026#34;); }); }); 配置 Jest 配置文件 新建配置文件 // 项目根目录下新建配置文件 touch jest.config.js 更新配置文件 // Desc: Jest configuration file module.exports = { // 测试文件的匹配规则 testMatch: [\u0026#39;**/Specs/*.spec.js\u0026#39;], }; 调整 Jest 测试脚本 在 package.json 文件中添加测试脚本\n\u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;jest\u0026#34; }, 运行 Jest 测试用例 // 运行测试用例 npm run test Jest 测试报告 Jest 命令行测试报告 集成 jest-html-reporters 测试报告 安装 jest-html-reporters npm install --save-dev jest-html-reporters 更新 Jest 配置文件 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n// Desc: Jest configuration file module.exports = { // 测试文件的匹配规则 testMatch: [\u0026#39;**/Specs/*.spec.js\u0026#39;], // 测试报告生成器 reporters: [ \u0026#39;default\u0026#39;, [ \u0026#39;jest-html-reporters\u0026#39;, { publicPath: \u0026#39;./Report\u0026#39;, // 报告生成路径 filename: \u0026#39;report.html\u0026#39;, // 报告名称 pageTitle: \u0026#39;SuperTest and Jest API Test Report\u0026#39;, // 报告标题 overwrite: true, // 报告文件是否覆盖 expand: true, // 展开所有测试套件 }, ], ], }; 运行 Jest 测试用例 // 运行测试用例 npm run test 查看测试报告 测试报告文件夹：Report，点击使用浏览器打开最新 html 报告文件\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-building-your-own-project-from-0-to-1/","summary":"从零开始教您如何建立 SuperTest 接口自动化测试项目。您将学习如何创建项目的基础结构，设置环境，编写测试用例，以及执行自动化测试。","title":"SuperTest 接口自动化测试教程：从 0 到 1 搭建 Supertest 接口自动化测试项目"},{"content":"介绍 本项目是一个使用 SuperTest 进行 API 自动化测试的快速启动项目教程，会使用 Jest 或 Mocha 作为测试框架进行 demo 演示。\n下面会依次介绍 SuperTest、Jest 和 Mocha，让大家提前了解这些工具的基本使用。\nSuperTest 介绍 \u0026ldquo;Supertest\u0026rdquo; 是一个用于测试 Node.js 应用程序的流行 JavaScript 库。它主要用于进行端到端（End-to-End）测试，也称为集成测试，以确保你的应用程序在不同组件之间正常运行。Supertest 通常与 Mocha、Jasmine 或 Jest 等测试框架一起使用，以编写和运行测试用例。\n以下是 Supertest 的一些关键特点和用途：\n发起 HTTP 请求：Supertest 允许你轻松地模拟 HTTP 请求，例如 GET、POST、PUT、DELETE 等，以测试你的应用程序的路由和端点。 链式语法：Supertest 提供了一种链式语法，使你能够在单个测试用例中构建和执行多个请求，这有助于模拟用户在应用程序中的不同操作。 断言和期望：你可以使用 Supertest 结合断言库（如 Chai）来检查响应的内容、状态码、头信息等，以确保应用程序的期望行为。 身份验证测试：Supertest 可以用于测试需要身份验证的端点，以确保用户登录和授权功能正常。 异步支持：Supertest 可以处理异步操作，例如等待响应返回后执行进一步的测试代码。 方便的集成：Supertest 可以轻松与不同的 Node.js 框架（如 Express、Koa、Hapi 等）一起使用，因此你可以测试各种类型的应用程序。 使用 Supertest 可以帮助你验证你的应用程序是否按预期工作，以及在应用程序发生更改时快速捕获潜在的问题。通常，你需要在项目中安装 Supertest 和测试框架，然后编写测试用例来模拟不同的请求和检查响应。这有助于提高代码质量和可维护性，确保你的应用程序在不断演化的过程中保持稳定性。\n官方文档：https://github.com/ladjs/supertest\n备注：Supertest 不止可以用来做 API 测试，也可以用来做单元测试和集成测试\n代码示例：\n// 导入 supertest const request = require(\u0026#39;supertest\u0026#39;); request({URL}) // 请求 (url) 或 请求 (app) .get() or .put() or.post() // http method .set() // http 选项 .send() // 请求的 body .expect() // 断言 .end() // 结束请求 Jest 介绍 Jest 是一个流行的 JavaScript 测试框架，用于编写和运行 JavaScript 应用程序的单元测试、集成测试和端到端测试。它的目标是提供简单、快速和易于使用的测试工具，适用于各种 JavaScript 应用程序，包括前端和后端应用程序。\n以下是 Jest 的一些关键特点和用途：\n内置断言库：Jest 包括一个强大的断言库，使你能够轻松地编写断言，以验证代码的行为是否符合预期。 自动模拟：Jest 自动创建模拟（mocks），帮助你模拟函数、模块和外部依赖，从而让测试更加简单和可控。 快速和并行：Jest 通过智能地选择要运行的测试以及并行执行测试，可以快速地运行大量测试用例，从而节省时间。 全面的测试套件：Jest 支持单元测试、集成测试和端到端测试，并可以测试 JavaScript、TypeScript、React、Vue、Node.js 等各种应用程序类型。 快照测试：Jest 具有快照测试功能，可用于检查 UI 组件的渲染是否与之前的快照匹配，从而捕获 UI 变化。 自动监视模式：Jest 具有一个监视模式，可在代码更改时自动重新运行相关测试，从而支持开发人员进行持续测试。 丰富的生态系统：Jest 有丰富的插件和扩展，可用于扩展其功能，如覆盖率报告、测试报告和其他工具的集成。 社区支持：Jest 是一个流行的测试框架，拥有庞大的社区，提供了大量的文档、教程和支持资源。 Jest 通常与其他工具如 Babel（用于转译 JavaScript）、Enzyme（用于 React 组件测试）、Supertest（用于 API 测试）等一起使用，以实现全面的测试覆盖和确保代码质量。无论你是在编写前端代码还是后端代码，Jest 都是一个强大的测试工具，可以帮助你捕获潜在的问题，提高代码质量和可维护性。\n官方文档：https://jestjs.io/docs/zh-Hans/getting-started\n代码示例：\n// 导入 jest const jest = require(\u0026#39;jest\u0026#39;); describe(): // 测试场景 it(): // 测试用例，it() 在 describe() 里面 before(): // 这个动作在所有测试用例之前执行 after(): // 这个动作在所有测试用例之后执行 Mocha 介绍 Mocha 是一个流行的 JavaScript 测试框架，用于编写和运行 JavaScript 应用程序的各种测试，包括单元测试、集成测试和端到端测试。Mocha 提供了灵活性和可扩展性，使开发人员能够轻松地定制测试套件以满足其项目的需求。\n以下是 Mocha 的一些关键特点和用途：\n多种测试风格：Mocha 支持多种测试风格，包括 BDD（行为驱动开发）和 TDD（测试驱动开发）。这使开发人员可以根据自己的偏好编写测试用例。 丰富的断言库：Mocha 本身并不包括断言库，但它可以与多种断言库（如 Chai、Should.js、Expect.js 等）结合使用，使你能够使用喜欢的断言风格来编写测试。 异步测试：Mocha 内置支持异步测试，允许你测试异步代码、Promise、回调函数等，确保代码在异步场景下的正确性。 并行测试：Mocha 可以并行运行测试套件中的测试用例，提高测试执行效率。 丰富的插件和扩展：Mocha 有丰富的插件生态系统，可以用于扩展其功能，如测试覆盖率报告、测试报告生成等。 易于集成：Mocha 可以与各种断言库、测试运行器（如 Karma 和 Jest）、浏览器（使用浏览器测试运行器）等一起使用，以适应不同的项目和测试需求。 命令行界面：Mocha 提供了一个易于使用的命令行界面，用于运行测试套件，生成报告以及其他测试相关操作。 持续集成支持：Mocha 可以轻松集成到持续集成（CI）工具中，如 Jenkins、Travis CI、CircleCI 等，以确保代码在每次提交后都能得到测试。 Mocha 的灵活性和可扩展性使其成为一个受欢迎的测试框架，适用于各种 JavaScript 项目，包括前端和后端应用程序。开发人员可以根据自己的需求和喜好选择测试工具、断言库和其他扩展，以满足项目的要求。无论你是在编写浏览器端代码还是服务器端代码，Mocha 都是一个强大的测试工具，可帮助你确保代码质量和可靠性。\n官方文档：https://mochajs.org/\n代码示例：\n// 导入 mocha const mocha = require(\u0026#39;mocha\u0026#39;); describe(): // 测试场景 it(): // 测试用例，it() 在 describe() 里面 before(): // 这个动作在所有测试用例之前执行 after(): // 这个动作在所有测试用例之后执行 CHAI 简介 Chai 是一个 JavaScript 断言库，用于编写和运行测试用例时进行断言和期望值的验证。它是一个流行的测试工具，通常与测试框架（如 Mocha、Jest 等）一起使用，以帮助开发者编写和执行各种类型的测试，包括单元测试和集成测试。\n以下是一些 Chai 的主要特点和用途：\n可读性强的断言语法：Chai 提供了一个易于阅读和编写的断言语法，使测试用例更易于理解。它支持自然语言的断言风格，例如 expect(foo).to.be.a(\u0026lsquo;string\u0026rsquo;) 或 expect(bar).to.equal(42)。 多种断言风格：Chai 提供了多种不同的断言风格，以适应不同开发者的偏好。主要的风格包括 BDD（Behavior-Driven Development）风格、TDD（Test-Driven Development）风格和 assert 风格。 插件扩展：Chai 可以通过插件进行扩展，以支持更多的断言类型和功能。这使得 Chai 可以满足各种测试需求，包括异步测试、HTTP 请求测试等。 易于集成：Chai 可以轻松集成到各种测试框架中，例如 Mocha、Jest、Jasmine 等。这使得它成为编写测试用例的强大工具。 支持链式断言：Chai 允许你对多个断言进行链式调用，以便更容易进行复杂的测试和验证。 官方文档：https://www.chaijs.com/\n代码示例：\n// 导入 chai const chai = require(\u0026#39;chai\u0026#39;); const expect = chai.expect; // demo 断言 .expect(\u0026lt;actual result\u0026gt;).to.{assert}(\u0026lt;expected result\u0026gt;) // 断言目标严格等于值 .expect(‘hello\u0026#39;).to.equal(\u0026#39;hello\u0026#39;); // 断言目标严格等于值 .expect({ foo: \u0026#39;bar\u0026#39; }).to.not.equal({ foo: \u0026#39;bar\u0026#39; }); // 断言目标值不严格等于值。 .expect(\u0026#39;foobar\u0026#39;).to.contain(\u0026#39;foo\u0026#39;); // 断言目标字符串包含给定的子字符串。 .expect(foo).to.exist; // 断言目标既不是 null 也不是未定义。 .expect(5).to.be.at.most(5); // 断言目标值小于或等于值。 项目依赖 需提前安装好以下环境\nnodejs, demo 版本为 v21.1.0 项目文件结构 以下是一个 SuperTest 接口自动化测试项目的文件结构，其中包含了测试配置文件、测试用例文件、测试工具文件和测试报告文件。可进行参考。\nSuperTest-Jest-demo ├── README.md ├── package.json ├── package-lock.json ├── Config // 测试配置文件 │ └── config.js ├── Specs // 测试用例文件 │ └── test.spec.js ├── Utils // 测试工具文件 │ └── utils.js ├── Report // 测试报告文件 │ └── report.html ├── .gitignore └── node_modules // 项目依赖 Next 下一篇文章将会介绍如何使用 Supertest 从 0 到 1 搭建 SuperTest 接口自动化测试项目，敬请期待。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-getting-started-and-own-environment-preparation/","summary":"关于 Supertest 的教程，主要包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 Supertest 以及如何开始使用它来进行 API 测试。","title":"SuperTest 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nGradle 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gradle.yml。\n编辑 gradle.yml 文件：将以下内容复制到文件中\nname: Gradle and REST Assured Tests on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v3 - name: Setup Java uses: actions/setup-java@v3 with: java-version: \u0026#39;11\u0026#39; distribution: \u0026#39;adopt\u0026#39; - name: Build and Run REST Assured Tests with Gradle uses: gradle/gradle-build-action@bd5760595778326ba7f1441bcf7e88b49de61a25 # v2.6.0 with: arguments: build - name: Archive REST-Assured results uses: actions/upload-artifact@v2 with: name: REST-Assured-results path: build/reports/tests/test - name: Upload REST-Assured results to GitHub uses: actions/upload-artifact@v2 with: name: REST-Assured-results path: build/reports/tests/test 提交代码：将 gradle.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Gradle and REST Assured Tests 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Maven 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 maven.yml。\n编辑 maven.yml 文件：将以下内容复制到文件中\nname: Maven and REST Assured Tests on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: Run-Rest-Assured-Tests: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up JDK 17 uses: actions/setup-java@v3 with: java-version: \u0026#39;17\u0026#39; distribution: \u0026#39;temurin\u0026#39; cache: maven - name: Build and Run REST Assured Tests with Maven run: mvn test - name: Archive REST-Assured results uses: actions/upload-artifact@v3 with: name: REST-Assured-results path: target/surefire-reports - name: Upload REST-Assured results to GitHub uses: actions/upload-artifact@v3 with: name: REST-Assured-results path: target/surefire-reports 提交代码：将 maven.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Maven and REST Assured Tests 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 集成 allure 测试报告 allure 简介 Allure是一个用于生成漂亮、交互式测试报告的开源测试框架。它可以与多种测试框架（如JUnit、TestNG、Cucumber等）和多种编程语言（如Java、Python、C#等）一起使用。\nAllure 测试报告具有以下特点：\n美观和交互式：Allure 测试报告以美观和交互式的方式呈现测试结果，包括图形、图表和动画。这使得测试报告更容易阅读和理解。 多语言支持：Allure 支持多种编程语言，因此您可以在不同的语言中编写测试，并生成统一的测试报告。 测试用例级别的详细信息：Allure 允许您为每个测试用例添加详细信息，包括描述、类别、标签、附件、历史数据等。这些信息有助于更全面地了解测试结果。 历史趋势分析：Allure 支持测试历史趋势分析，您可以查看测试用例的历史表现，识别问题和改进测试质量。 类别和标签：您可以为测试用例添加类别和标签，以更好地组织和分类测试用例。这使得报告更具可读性。 附件和截图：Allure 允许您附加文件、截图和其他附件，以便更好地记录测试过程中的信息。 集成性：Allure 可以与各种测试框架和构建工具（如 Maven、Gradle）无缝集成，使得生成报告变得简单。 开源社区支持：Allure 是一个开源项目，拥有一个活跃的社区，提供了广泛的文档和支持。这使得它成为许多自动化测试团队的首选工具。 Allure 测试报告的主要目标是提供一个清晰、易于阅读的方式来展示测试结果，以帮助开发团队更好地理解测试的状态和质量，快速识别问题，并采取必要的行动。无论您是开发人员、测试人员还是项目经理，Allure 测试报告都能为您提供有用的信息，以改进软件质量和可靠性。\n官方网站：https://docs.qameta.io/allure/\n集成步骤 Maven 版本集成 allure 在 POM.xml 中添加 allure 依赖 可 copy 本项目中的 pom.xml 文件内容\n\u0026lt;!-- https://mvnrepository.com/artifact/io.qameta.allure/allure-testng --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-testng\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.24.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/io.qameta.allure/allure-rest-assured --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.24.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在 POM.xml 中添加 allure 插件 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-maven\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;resultsDirectory\u0026gt;../allure-results\u0026lt;/resultsDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 在 src/test/java 下创建用于测试 REST API 的测试代码 以下为 demo 示例，详细部分可参考 项目：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\npackage com.example; import io.qameta.allure.*; import io.qameta.allure.restassured.AllureRestAssured; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; @Epic(\u0026#34;REST API Regression Testing using TestNG\u0026#34;) @Feature(\u0026#34;Verify that the Get and POST API returns correctly\u0026#34;) public class TestDemo { @Test(description = \u0026#34;To get the details of post with id 1\u0026#34;, priority = 1) @Story(\u0026#34;GET Request with Valid post id\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the GET API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;To create a new post\u0026#34;, priority = 2) @Story(\u0026#34;POST Request\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 运行测试并生成 Allure 报告 mvn clean test 生成的 Allure 报告在项目根目录的 allure-results 文件下\n预览 Allure 报告 mvn allure:serve 运行命令会自动打开浏览器，预览 Allure 报告\nGradle 版本集成 allure 在 build.gradle 中添加 allure 插件 可 copy 本项目中的 build.gradle 文件内容\nid(\u0026#34;io.qameta.allure\u0026#34;) version \u0026#34;2.11.2\u0026#34; 在 build.gradle 中添加 allure 依赖 可 copy 本项目中的 build.gradle 文件内容\nimplementation \u0026#39;io.qameta.allure:allure-testng:2.24.0\u0026#39; // Add allure report dependency implementation \u0026#39;io.qameta.allure:allure-rest-assured:2.24.0\u0026#39; // Add allure report dependency 在 src/test/java 下创建用于测试 REST API 的测试代码 以下为 demo 示例，详细部分可参考 项目：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\npackage com.example; import io.qameta.allure.*; import io.qameta.allure.restassured.AllureRestAssured; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; @Epic(\u0026#34;REST API Regression Testing using TestNG\u0026#34;) @Feature(\u0026#34;Verify that the Get and POST API returns correctly\u0026#34;) public class TestDemo { @Test(description = \u0026#34;To get the details of post with id 1\u0026#34;, priority = 1) @Story(\u0026#34;GET Request with Valid post id\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the GET API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;To create a new post\u0026#34;, priority = 2) @Story(\u0026#34;POST Request\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 运行测试并生成 Allure 报告 gradle clean test 生成的 Allure 报告在项目根目录的 build/allure-results 文件下\n预览 Allure 报告 gradle allureServe 运行命令会自动打开浏览器，预览 Allure 报告\n参考资料 Rest assured 官方文档：https://rest-assured.io/\nRest assured 官方 github：https://github.com/rest-assured/rest-assured\nRest assured 官方文档中文翻译：https://github.com/RookieTester/rest-assured-doc\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-integration-ci-cd-and-allure-report/","summary":"深入研究 REST Assured 的高级应用，侧重于如何集成 CI/CD（持续集成/持续交付）工具和整合 Allure 测试报告。","title":"REST Assured 接口自动化测试教程：进阶用法 - 集成 CI/CD 和集成 allure 测试报告"},{"content":"进阶用法 验证响应数据 您还可以验证状态码，状态行，Cookie，headers，内容类型和正文。\n响应体断言 json 格式断言 假设某个 get 请求 (http://localhost:8080/lotto) 返回 JSON 如下：\n{ \u0026#34;lotto\u0026#34;:{ \u0026#34;lottoId\u0026#34;:5, \u0026#34;winning-numbers\u0026#34;:[2,45,34,23,7,5,3], \u0026#34;winners\u0026#34;:[{ \u0026#34;winnerId\u0026#34;:23, \u0026#34;numbers\u0026#34;:[2,45,34,23,3,5] },{ \u0026#34;winnerId\u0026#34;:54, \u0026#34;numbers\u0026#34;:[52,3,12,11,18,22] }] } } REST assured 可以帮您轻松地进行 get 请求并对响应信息进行处理。\n断言 lottoId 的值是否等于 5，示例： get(\u0026#34;/lotto\u0026#34;).then().body(\u0026#34;lotto.lottoId\u0026#34;, equalTo(5)); 断言 winnerId 的取值包括 23 和 54，示例： get(\u0026#34;/lotto\u0026#34;).then().body(\u0026#34;lotto.winners.winnerId\u0026#34;, hasItems(23, 54)); 提醒一下：equalTo 和 hasItems是 Hamcrest matchers 提供的方法，所以需要静态导入入 org.hamcrest.Matchers。\nxml 格式断言 XML 可以一种通过简单的方式解析。假设一个 POST 请求http://localhost:8080/greetXML返回：\n\u0026lt;greeting\u0026gt; \u0026lt;firstName\u0026gt;{params(\u0026#34;firstName\u0026#34;)}\u0026lt;/firstName\u0026gt; \u0026lt;lastName\u0026gt;{params(\u0026#34;lastName\u0026#34;)}\u0026lt;/lastName\u0026gt; \u0026lt;/greeting\u0026gt; 断言 firstName 是否返回正确，示例： given(). parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;). when(). post(\u0026#34;/greetXML\u0026#34;). then(). body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;)). 同时断言 firstname 和 lastname 是否返回正确，示例： given(). parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;). when(). post(\u0026#34;/greetXML\u0026#34;). then(). body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;)). body(\u0026#34;greeting.lastName\u0026#34;, equalTo(\u0026#34;Doe\u0026#34;)); with().parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;) .when().post(\u0026#34;/greetXML\u0026#34;) .then().body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;), \u0026#34;greeting.lastName\u0026#34;, equalTo(\u0026#34;Doe\u0026#34;)); Cookie 断言 断言 cookie 的值是否等于 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().cookie(\u0026#34;cookieName\u0026#34;, \u0026#34;cookieValue\u0026#34;) 同时断言 多个 cookie 的值是否等于 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().cookies(\u0026#34;cookieName1\u0026#34;, \u0026#34;cookieValue1\u0026#34;, \u0026#34;cookieName2\u0026#34;, \u0026#34;cookieValue2\u0026#34;) 断言 cookie 的值是否包含 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().cookies(\u0026#34;cookieName1\u0026#34;, \u0026#34;cookieValue1\u0026#34;, \u0026#34;cookieName2\u0026#34;, containsString(\u0026#34;Value2\u0026#34;)) 状态码 Status Code 断言 断言 状态码是否等于 200，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusCode(200) 断言 状态行是否为 something，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusLine(\u0026#34;something\u0026#34;) 断言 状态行是否包含 some，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusLine(containsString(\u0026#34;some\u0026#34;)) Header 断言 断言 Header 的值是否等于 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().header(\u0026#34;headerName\u0026#34;, \u0026#34;headerValue\u0026#34;) 同时断言 多个 Header 的值是否等于 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().headers(\u0026#34;headerName1\u0026#34;, \u0026#34;headerValue1\u0026#34;, \u0026#34;headerName2\u0026#34;, \u0026#34;headerValue2\u0026#34;) 断言 Header 的值是否包含 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().headers(\u0026#34;headerName1\u0026#34;, \u0026#34;headerValue1\u0026#34;, \u0026#34;headerName2\u0026#34;, containsString(\u0026#34;Value2\u0026#34;)) 断言 Header 的“Content-Length”小于 1000，示例： 可以先使用映射函数首先将头值转换为 int，然后在使用 Hamcrest 验证前使用“整数”匹配器进行断言：\nget(\u0026#34;/something\u0026#34;).then() .assertThat().header(\u0026#34;Content-Length\u0026#34;, Integer::parseInt, lessThan(1000)); Content-Type 断言 断言 Content-Type 的值是否等于 application/json，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().contentType(ContentType.JSON) 内容全匹配断言 断言 响应体是否完全等于 something，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().body(equalTo(\u0026#34;something\u0026#34;)) 响应时间断言 REST Assured 2.8.0 开始支持测量响应时间，例如：\nlong timeInMs = get(\u0026#34;/lotto\u0026#34;).time() 或使用特定时间单位：\nlong timeInSeconds = get(\u0026#34;/lotto\u0026#34;).timeIn(SECONDS); 其中 SECONDS 只是一个标准的 TimeUnit。您还可以使用 DSL 验证：\nwhen(). get(\u0026#34;/lotto\u0026#34;). then(). time(lessThan(2000L)); // Milliseconds 或\nwhen(). get(\u0026#34;/lotto\u0026#34;). then(). time(lessThan(2L), SECONDS); 需要注意的是，您只能参考性地将这些测量数据与服务器请求处理时间相关联（因为响应时间将包括 HTTP 往返和 REST Assured 处理时间等，不能做到十分准确）。\n文件上传 通常我们在向服务器传输大容量的数据时，比如文件时会使用 multipart 表单数据技术。 rest-assured 提供了一种multiPart方法来辨别这究竟是文件、二进制序列、输入流还是上传的文本。\n表单中上只传一个文件，示例： given(). multiPart(new File(\u0026#34;/path/to/file\u0026#34;)). when(). post(\u0026#34;/upload\u0026#34;); 存在 control 名的情况下上传文件，示例： given(). multiPart(\u0026#34;controlName\u0026#34;, new File(\u0026#34;/path/to/file\u0026#34;)). when(). post(\u0026#34;/upload\u0026#34;); 同一个请求中存在多个\u0026quot;multi-parts\u0026quot;事务，示例： byte[] someData = .. given(). multiPart(\u0026#34;controlName1\u0026#34;, new File(\u0026#34;/path/to/file\u0026#34;)). multiPart(\u0026#34;controlName2\u0026#34;, \u0026#34;my_file_name.txt\u0026#34;, someData). multiPart(\u0026#34;controlName3\u0026#34;, someJavaObject, \u0026#34;application/json\u0026#34;). when(). post(\u0026#34;/upload\u0026#34;); MultiPartSpecBuilder 用法，示例： 更多使用方法可以使用MultiPartSpecBuilder：\nGreeting greeting = new Greeting(); greeting.setFirstName(\u0026#34;John\u0026#34;); greeting.setLastName(\u0026#34;Doe\u0026#34;); given(). multiPart(new MultiPartSpecBuilder(greeting, ObjectMapperType.JACKSON_2) .fileName(\u0026#34;greeting.json\u0026#34;) .controlName(\u0026#34;text\u0026#34;) .mimeType(\u0026#34;application/vnd.custom+json\u0026#34;).build()). when(). post(\u0026#34;/multipart/json\u0026#34;). then(). statusCode(200); MultiPartConfig 用法，示例： MultiPartConfig可用来指定默认的 control 名和文件名\ngiven().config(config().multiPartConfig(multiPartConfig() .defaultControlName(\u0026#34;something-else\u0026#34;))) 默认把 control 名配置为\u0026quot;something-else\u0026quot;而不是\u0026quot;file\u0026quot;。 更多用法查看 博客介绍\nLogging 日志 当我们在编写接口测试脚本的时候，我们可能需要在测试过程中打印一些日志，以便于我们在测试过程中查看接口的请求和响应信息，以及一些其他的信息。RestAssured 提供了一些方法来打印日志，我们可以根据需要选择合适的方法来打印日志。\nRestAssured 提供了一个全局的日志配置方法，可以在测试开始前配置日志，然后在测试过程中打印日志。这种方法适用于所有的测试用例，但是它只能打印请求和响应的信息，不能打印其他的信息。\nRestAssured 还提供了一个局部的日志配置方法，可以在测试过程中打印日志。这种方法可以打印请求和响应的信息，也可以打印其他的信息。\n全局日志配置 添加全局日志步骤 引入日志相关的依赖类 import io.restassured.config.LogConfig; import io.restassured.filter.log.LogDetail; import io.restassured.filter.log.RequestLoggingFilter; import io.restassured.filter.log.ResponseLoggingFilter; 在 setup() 方法中添加日志配置 使用 LogConfig 配置，启用了请求和响应的日志记录，以及启用了漂亮的输出格式。启用了请求和响应的日志记录过滤器，这将记录请求和响应的详细信息。\n// 启用全局请求和响应日志记录 RestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); 在 setup() 方法中启用了全局日志记录过滤器 // 启用全局请求和响应日志记录过滤器 RestAssured.filters(new RequestLoggingFilter(), new ResponseLoggingFilter()); 全局日志代码示例 package com.example; import io.restassured.RestAssured; // 引入日志相关的类 import io.restassured.config.LogConfig; import io.restassured.filter.log.LogDetail; import io.restassured.filter.log.RequestLoggingFilter; import io.restassured.filter.log.ResponseLoggingFilter; import org.testng.annotations.BeforeClass; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @BeforeClass public void setup() { // 启用全局请求和响应日志记录 RestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); // 启用全局请求和响应日志记录过滤器 RestAssured.filters(new RequestLoggingFilter(), new ResponseLoggingFilter()); } @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // 测试用例已省略，可参考 demo } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // 测试用例已省略，可参考 demo } } 查看全局日志输出 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 查看日志输出 局部日志配置 在 RestAssured 中，你可以进行局部日志配置，以便在特定的测试方法或请求中启用或禁用日志记录，而不影响全局配置。\n添加日志步骤 在想要打印日志的测试方法中启用了添加日志配置，示例： @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .log().everything(true) // 输出 request 相关日志 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .log().everything(true) // 输出 response 相关日志 .statusCode(200) } 查看局部日志输出 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 查看日志输出 LogConfig 配置说明 在 RestAssured 中，你可以使用 LogConfig 类来配置请求和响应的日志记录。LogConfig 允许你定义日志详细程度、输出格式、输出位置等。以下是一些常见的 LogConfig 配置示例：\n启用请求和响应的日志记录：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL)); 这将启用请求和响应的日志记录，只有当验证失败时才记录。\n配置输出级别：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.HEADERS)); 这将只记录请求和响应的头部信息。\n配置输出位置：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true) .defaultStream(FileOutputStream(\u0026#34;log.txt\u0026#34;))); 这将日志记录输出到名为 \u0026ldquo;log.txt\u0026rdquo; 的文件。\n配置漂亮的输出格式：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); 这将启用漂亮的输出格式，使日志更易于阅读。\n你可以根据你的具体需求组合这些配置选项，并将其设置为 RestAssured.config 以配置全局的请求和响应日志记录。这将有助于在 RestAssured 中记录和审查请求和响应，以便调试和分析问题。\nRequest Logging 请求日志记录 从版本 1.5 开始，REST Assured 支持在使用 RequestLoggingFilter 将请求规范发送到服务器之前记录请求规范。请注意，HTTP Builder 和 HTTP Client 可能会添加日志中打印的内容之外的其他标头。筛选器将仅记录请求规范中指定的详细信息。也就是说，您不能将 RequestLoggingFilter 记录的详细信息视为实际发送到服务器的详细信息。此外，后续筛选器可能会在日志记录发生后更改请求。如果您需要记录网络上实际发送的内容，请参阅 HTTP 客户端日志记录文档或使用外部工具，例如 Wireshark。\n示例：\ngiven().log().all() // 记录所有请求规范细节，包括参数、标头和正文 given().log().params() // 只记录请求的参数 given().log().body() // 只记录请求正文 given().log().headers() // 只记录请求头 given().log().cookies() // 只记录请求 cookies given().log().method() // 只记录请求方法 given().log().path() // 只记录请求路径 Response Logging 响应日志记录 只想要打印响应正文，而不考虑状态代码，可以执行以下操作， 示例： get(\u0026#34;/x\u0026#34;).then().log().body() 不管是否发生错误，都将打印响应正文。如果只对在发生错误时打印响应正文感兴趣，示例： get(\u0026#34;/x\u0026#34;).then().log().ifError() 在响应中记录所有详细信息，包括状态行、标头和 Cookie，示例： get(\u0026#34;/x\u0026#34;).then().log().all() 在响应中记录只记录状态行、标题或 Cookie，示例： get(\u0026#34;/x\u0026#34;).then().log().statusLine() // 只记录状态行 get(\u0026#34;/x\u0026#34;).then().log().headers() // 只记录响应头 get(\u0026#34;/x\u0026#34;).then().log().cookies() // 只记录响应 cookies 配置为仅当状态代码与某个值匹配时才记录响应，示例： get(\u0026#34;/x\u0026#34;).then().log().ifStatusCodeIsEqualTo(302) // 仅在状态代码等于 302 时记录日志 get(\u0026#34;/x\u0026#34;).then().log().ifStatusCodeMatches(matcher) // 仅在状态代码与提供的配置匹配时才记录日志 只在验证失败时记录日志 从 REST Assured 2.3.1 开始，只有在验证失败时才能记录请求或响应。要记录请求日志，示例： given().log().ifValidationFails() 要记录响应日志，示例： then().log().ifValidationFails() 可以使用 LogConfig 同时为请求和响应启用此功能，示例： given().config(RestAssured.config().logConfig(logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(HEADERS))) 如果验证失败，日志仅记录请求头。\n另外一个快捷方式，用于在验证失败时为所有请求启用请求和响应的日志记录，示例： RestAssured.enableLoggingOfRequestAndResponseIfValidationFails(); 从版本 4.5.0 开始，您还可以使用 指定 onFailMessage 测试失败时将显示的消息，示例： when(). get(). then(). onFailMessage(\u0026#34;Some specific message\u0026#34;). statusCode(200); Header 黑名单配置 从 REST Assured 4.2.0 开始，可以将标头列入黑名单，以便它们不会显示在请求或响应日志中。相反，标头值将替换为 [ BLACKLISTED ] .您可以使用 LogConfig 启用此基于每个标头的功能，示例：\ngiven().config(config().logConfig(logConfig().blacklistHeader(\u0026#34;Accept\u0026#34;))) Filters 过滤器 在 RestAssured 中，你可以使用过滤器来修改请求和响应。过滤器允许你在请求和响应的不同阶段修改请求和响应。例如，你可以在请求之前修改请求，或者在响应之后修改响应。你可以使用过滤器来添加请求头、请求参数、请求体、响应头、响应体等。\n过滤器可用于实现自定义身份验证方案、会话管理、日志记录等。若要创建筛选器，需要实现 io.restassured.filter.Filter 接口。要使用过滤器，您可以执行以下操作：\ngiven().filter(new MyFilter()) REST Assured 提供了几个可供使用的过滤器：\nio.restassured.filter.log.RequestLoggingFilter ：将打印请求规范详细信息的筛选器。 io.restassured.filter.log.ResponseLoggingFilter ：如果响应与给定状态代码匹配，则将打印响应详细信息的筛选器。 io.restassured.filter.log.ErrorLoggingFilter ：在发生错误时打印响应正文的筛选器（状态代码介于 400 和 500 之间）。 Ordered Filters 有序过滤器 从 REST Assured 3.0.2 开始，如果需要控制筛选器排序，可以实现 io.restassured.filter.OrderedFilter 接口。在这里，您将实现返回一个整数的方法，getOrder 该整数表示筛选器的优先级。值越低，优先级越高。您可以定义的最高优先级是 Integer.MIN_VALUE，最低优先级是 Integer.MAX_VALUE。未实现 io.restassured.filter.OrderedFilter 的过滤器的默认优先级为 1000。\n示例\nResponse Builder 响应生成器 如果需要更改筛选器中的响应内容，可以使用 ResponseBuilder 基于原始响应创建新的响应。例如，如果要将原始响应的正文更改为其他内容，可以执行以下操作：\nResponse newResponse = new ResponseBuilder() .clone(originalResponse).setBody(\u0026#34;Something\u0026#34;).build(); 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-verifying-response-and-logging/","summary":"深入介绍 REST Assured 的进阶用法，重点放在验证 API 响应、日志记录和过滤器的应用上。","title":"REST Assured 接口自动化测试教程：进阶用法 - 验证响应和日志记录，过滤器，文件上传"},{"content":"从 0 到 1 搭建 REST Assured 接口测试项目 REST Assured 支持 Gradle 和 Maven 两种构建工具，你可以根据自己的喜好选择其中一种。下面分别介绍 Gradle 和 Maven 两种构建工具的项目初始化过程。\n本项目使用 Gradle 8.44 和 Maven 3.9.5 进行构建，如果你使用的是其他版本，可能会有不同。\nGradle 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\n创建一个空的 Gradle 工程 mkdir RestAssured-gradle-demo cd RestAssured-gradle-demo gradle init 配置项目 build.gradle demo 项目引入了 testNG 测试框架，仅供参考\n在项目根目录下创建一个 build.gradle 文件，用于配置项目 示例配置如下，可供参考 // 插件配置 plugins { id \u0026#39;java\u0026#39; // 使用 java 插件 } // 仓库资源配置 repositories { mavenCentral() // 使用 maven中央版本库源 } // 项目依赖配置 dependencies { testImplementation \u0026#39;io.rest-assured:rest-assured:5.3.1\u0026#39; // 添加rest-assured依赖 testImplementation \u0026#39;org.testng:testng:7.8.0\u0026#39; // 添加TestNG测试框架依赖 implementation \u0026#39;org.uncommons:reportng:1.1.4\u0026#39; // 添加testng 测试报告依赖 implementation \u0026#39;org.slf4j:slf4j-api:2.0.9\u0026#39; // 添加测试日志依赖 implementation \u0026#39;org.slf4j:slf4j-simple:2.0.9\u0026#39; // 添加测试日志依赖 implementation group: \u0026#39;com.google.inject\u0026#39;, name: \u0026#39;guice\u0026#39;, version: \u0026#39;7.0.0\u0026#39; } // 项目测试配置 test { reports.html.required = false // 禁用 gradle 原生HTML 报告生成 reports.junitXml.required = false // 禁用 gradle 原生 JUnit XML 报告生成 // 告诉 Gradle 使用 TestNG 作为测试框架 useTestNG() { useDefaultListeners = true suites \u0026#39;src/test/resources/testng.xml\u0026#39; // 声明 testng 的 xml 配置文件路径 } testLogging.showStandardStreams = true // 将测试日志输出到控制台 testLogging.events \u0026#34;passed\u0026#34;, \u0026#34;skipped\u0026#34;, \u0026#34;failed\u0026#34; // 定义测试日志事件类型 } 可 copy 本项目中的 build.gradle 文件内容，更多配置可参考官方文档\ntestng.xml 配置 在 src/test目录下创建一个 resources 目录，用于存放测试配置文件\n在 resources 目录下创建一个 testng.xml 文件，用于配置 TestNG 测试框架\n示例配置如下，可供参考\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE suite SYSTEM \u0026#34;http://testng.org/testng-1.0.dtd\u0026#34;\u0026gt; \u0026lt;suite name=\u0026#34;restAssured-gradleTestSuite\u0026#34;\u0026gt; \u0026lt;test thread-count=\u0026#34;1\u0026#34; name=\u0026#34;Demo\u0026#34;\u0026gt; \u0026lt;classes\u0026gt; \u0026lt;class name=\u0026#34;com.example.TestDemo\u0026#34;/\u0026gt; \u0026lt;!-- 测试脚本 class--\u0026gt; \u0026lt;/classes\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- Test --\u0026gt; \u0026lt;/suite\u0026gt; \u0026lt;!-- Suite --\u0026gt; gradle build 项目并初始化 用编辑器打开本项目 Terminal 窗口，执行以下命令确认项目 build 成功 gradle build 初始化完成：完成向导后，Gradle 将在项目目录中生成一个基本的 Gradle 项目结构 初始化目录 目录结构可参考 \u0026raquo; 项目结构\n在项目的测试源目录下创建一个新的测试类。默认情况下，Gradle 通常将测试源代码放在 src/test/java 目录中。你可以在该目录下创建测试类的包，并在包中创建新的测试类\n创建一个 TestDemo 的测试类，可以按以下结构创建文件\nsrc └── test └── java └── com └── example └── TestDemo.java demo 测试接口 Get 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts/1 请求方式：GET 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：无 返回状态码：200 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; } Post 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts 请求方式：POST 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：raw json 格式 body 内容如下： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 返回状态码：201 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } 编写脚本 打开 TestDemo.java 文件，开始编写测试脚本\n示例脚本如下，可供参考\npackage com.example; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 调试脚本 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 gradle test 查看测试报告 命令行报告 testng html 报告 打开项目 build/reports/tests/test 目录 点击 index.html 文件，查看测试报告 Maven 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\n创建一个空的 Maven 工程 mvn archetype:generate -DgroupId=com.example -DartifactId=RestAssured-maven-demo -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 初始化完成：完成向导后，Maven 将在新建项目目录并生成一个基本的 Maven 项目结构\n配置项目 pom.xml 在 项目中 pom.xml 文件中添加以下内容\n可 copy 本项目中的 pom.xml 文件内容，更多配置可参考官方文档\n\u0026lt;!-- 依赖配置 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/io.rest-assured/rest-assured --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.rest-assured\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.testng/testng --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.testng\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;testng\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.8.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 插件配置 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;suiteXmlFiles\u0026gt; \u0026lt;suiteXmlFile\u0026gt;src/test/resources/testng.xml\u0026lt;/suiteXmlFile\u0026gt; \u0026lt;/suiteXmlFiles\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; testng.xml 配置 在 src/test目录下创建一个 resources 目录，用于存放测试配置文件\n在 resources 目录下创建一个 testng.xml 文件，用于配置 TestNG 测试框架\n示例配置如下，可供参考\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE suite SYSTEM \u0026#34;http://testng.org/testng-1.0.dtd\u0026#34;\u0026gt; \u0026lt;suite name=\u0026#34;restAssured-gradleTestSuite\u0026#34;\u0026gt; \u0026lt;test thread-count=\u0026#34;1\u0026#34; name=\u0026#34;Demo\u0026#34;\u0026gt; \u0026lt;classes\u0026gt; \u0026lt;class name=\u0026#34;com.example.TestDemo\u0026#34;/\u0026gt; \u0026lt;!-- 测试脚本 class--\u0026gt; \u0026lt;/classes\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- Test --\u0026gt; \u0026lt;/suite\u0026gt; \u0026lt;!-- Suite --\u0026gt; 初始化目录 目录结构可参考 \u0026raquo; 项目结构\n在项目的测试源目录下创建一个新的测试类。默认情况下，Gradle 通常将测试源代码放在 src/test/java 目录中。你可以在该目录下创建测试类的包，并在包中创建新的测试类\n创建一个 TestDemo 的测试类，可以按以下结构创建文件\nsrc └── test └── java └── com └── example └── TestDemo.java demo 测试接口 Get 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts/1 请求方式：GET 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：无 返回状态码：200 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; } Post 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts 请求方式：POST 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：raw json 格式 body 内容如下： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 返回状态码：201 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } 编写脚本 打开 TestDemo.java 文件，开始编写测试脚本\n示例脚本如下，可供参考\npackage com.example; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 调试脚本 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 mvn test 查看测试报告 命令行报告 testng html 报告 打开项目 target/surefire-reports 目录 点击 index.html 文件，查看测试报告 更多信息 访问我的个人博客：https://naodeng.tech/ 我的 QA 自动化快速启动项目页面：https://github.com/Automation-Test-Starter 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-building-your-own-project-from-0-to-1/","summary":"深入探讨如何从零开始构建一个 REST Assured 接口自动化测试项目。","title":"REST Assured 接口自动化测试教程：从 0 到 1 搭建 REST Assured 接口自动化测试项目"},{"content":"RestAssured 介绍 REST Assured 是一种用于测试 RESTful API 的 Java 测试框架，它使开发人员/测试人员能够轻松地编写和执行 API 测试。它的设计旨在使 API 测试变得简单和直观，同时提供了丰富的功能和灵活性。以下是 REST Assured 的一些重要特点和用法：\n发起 HTTP 请求：REST Assured 允许你轻松地构建和发起 HTTP GET、POST、PUT、DELETE 等类型的请求。你可以指定请求的 URL、头部、参数、体等信息。\n链式语法：REST Assured 使用链式语法，使测试代码更加可读和易于编写。你可以按照一种自然的方式描述你的测试用例，而不需要编写大量的代码。\n断言和校验：REST Assured 提供了丰富的校验方法，可以用于验证 API 响应的状态码、响应体、响应头等。你可以根据你的测试需求添加多个断言。\n支持多种数据格式：REST Assured 支持多种数据格式，包括 JSON、XML、HTML、Text 等。你可以使用适当的方法来处理不同格式的响应数据。\n集成 BDD（行为驱动开发）：REST Assured 可以与 BDD 框架（如 Cucumber）结合使用，使你可以更好地描述和管理测试用例。\n模拟 HTTP 服务器：REST Assured 还包括一个模拟 HTTP 服务器的功能，允许你模拟 API 的行为以进行端到端测试。\n可扩展性：REST Assured 可以通过插件和扩展进行定制，以满足特定的测试需求。\n总的来说，REST Assured 是一个功能强大且易于使用的 API 测试框架，它可以帮助你轻松地进行 RESTful API 测试，并提供了许多工具来验证 API 的正确性和性能。无论是初学者还是有经验的开发人员/测试人员，REST Assured 都是一个非常有价值的工具，可用于快速的上手 API 自动化 测试。\n项目结构 Gradle 构建的版本 - src - main - java - (应用的主要源代码) - test - java - api - (REST Assured 测试代码) - UsersAPITest.java - ProductsAPITest.java - util - TestConfig.java - resources - (配置文件、测试数据等) - (其他项目文件和资源) - build.gradle (Gradle 项目配置文件) 在这个示例目录结构中：\nsrc/test/java/api 目录用于存放 REST Assured 的测试类，每个测试类通常涉及到一个或多个相关的 API 端点的测试。例如，UsersAPITest.java 和 ProductsAPITest.java 可以包含用户管理和产品管理的测试。 src/test/java/util 目录可用于存放测试中共享的工具类，例如用于配置 REST Assured 的 TestConfig.java。 src/test/resources 目录可以包含测试数据文件、配置文件等资源，这些资源可以在测试中使用。 build.gradle 是 gradle 项目的配置文件，它用于定义项目的依赖项、构建配置以及其他项目设置。 Maven 构建的版本 - src - main - java - (应用的主要源代码) - test - java - api - (REST Assured 测试代码) - UsersAPITest.java - ProductsAPITest.java - util - TestConfig.java - resources - (配置文件、测试数据等) - (其他项目文件和资源) - pom.xml (Maven 项目配置文件) 在这个示例目录结构中：\nsrc/test/java/api 目录用于存放 REST Assured 的测试类，每个测试类通常涉及到一个或多个相关的 API 端点的测试。例如，UsersAPITest.java 和 ProductsAPITest.java 可以包含用户管理和产品管理的测试。 src/test/java/util 目录可用于存放测试中共享的工具类，例如用于配置 REST Assured 的 TestConfig.java。 src/test/resources 目录可以包含测试数据文件、配置文件等资源，这些资源可以在测试中使用。 pom.xml 是 Maven 项目的配置文件，它用于定义项目的依赖项、构建配置以及其他项目设置。 项目依赖 JDK 1.8+ ，我使用的 JDK 19 Gradle 6.0+ 或 Maven 3.0+，我使用的 Gradle 8.44 和 Maven 3.9.5 RestAssured 4.3.3+，我使用的是最新的 5.3.1 版本 语法示例 以下是一个简单的 RestAssured 语法示例，演示如何执行一个 GET 请求并验证响应：\n首先，确保你的 Gradle 或 Maven 项目中已添加了 RestAssured 依赖。\nGradle 依赖：\ndependencies { implementation \u0026#39;io.rest-assured:rest-assured:5.3.1\u0026#39; } Maven 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.rest-assured\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接下来，创建一个测试类，编写以下代码：\nimport io.restassured.RestAssured; import io.restassured.response.Response; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class RestAssuredDemo { @Test public void testGetRequest() { // 设置基本 URI，这里以 JSONPlaceholder 为例 RestAssured.baseURI = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;; // 发送 GET 请求，并保存响应 Response response = given() .when() .get(\u0026#34;/posts/1\u0026#34;) .then() .extract() .response(); // 打印响应的 JSON 内容 System.out.println(\u0026#34;Response JSON: \u0026#34; + response.asString()); // 验证状态码为 200 response.then().statusCode(200); // 验证响应中的特定字段值 response.then().body(\u0026#34;userId\u0026#34;, equalTo(1)); response.then().body(\u0026#34;id\u0026#34;, equalTo(1)); response.then().body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)); response.then().body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } } 上述代码执行了一个 GET 请求到 JSONPlaceholder 的 /posts/1 端点，并验证了响应的状态码和特定字段的值。你可以根据你的需求修改基本 URI 和验证条件。\n在这个示例中，我们使用了 TestNG 测试框架，但你也可以使用其他测试框架，例如 JUnit。确保你的测试类中包含了合适的导入语句，并根据需要进行适当的配置。\n这是一个简单的 RestAssured 语法示例，用于执行 GET 请求和验证响应。你可以根据项目的需求和接口的复杂性来构建更复杂的测试用例。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-and-environment-preparation/","summary":"包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 REST Assured 以及如何开始使用它来进行 API 测试。教程将涵盖 REST Assured 的基本概念，包括如何设置测试环境，准备所需的工具和资源，以便读者可以开始编写和执行他们自己的 API 测试。","title":"REST Assured 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nGradle + Scala 版本 可参考 demo：https://github.com/Automation-Test-Starter/gatling-gradle-scala-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gatling.yml。\n编辑 gatling.yml 文件：将以下内容复制到文件中。\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | ./gradlew gatlingRun env: GATLING_SIMULATIONS_FOLDER: src/gatling/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling 提交代码：将 gatling.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Maven + Scala 版本 可参考 demo：https://github.com/Automation-Test-Starter/gatling-maven-scala-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gatling.yml。\n编辑 gatling.yml 文件：将以下内容复制到文件中。\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | mvn gatling:test env: GATLING_SIMULATIONS_FOLDER: src/test/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling 提交代码：将 gatling.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 参考 galting 官网：https://gatling.io/ galting 官方文档：https://gatling.io/docs/gatling/ galting 官方 github: https://github.com/gatling/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro-ci-cd-integration/","summary":"文章介绍性能测试工具 gatling 的进阶用法：CI/CD 集成，以 github action 为例来介绍如何集成 gatling 到 CI/CD 流程中","title":"gatling 性能测试教程 - 进阶用法：CI/CD 集成"},{"content":"测试报告解析 总览 总览图 性能测试执行结束后打开详细的 html 报告，可以看到详细的性能测试报告； 可通过指标、活跃用户和随时间变化的请求/响应以及分布来分析您的报告\n页面中间标题处显示 Simulation 的名字 左侧的列表展示不同类型的报告菜单，可点击切换 页面中部展示性能测试报告的总览信息，包括：请求总数、成功请求总数、失败请求总数、最短响应时间、最长响应时间、平均响应时间、吞吐量、标准差、百分比分布等。也会展示 gatling 的版本及本次报告运行的时间和时长 全局菜单指向综合统计数据。 详细信息菜单指向每个请求类型的统计信息。 请求数\u0026amp;响应时间分布图 此图表展示了响应时间在标准范围内的分布情况 左侧的列表显示所有的请求以及请求响应的时间分布，红色代表失败的请求 右边 Number of request 代表用户并发数量，以及各个请求的请求数量及其成功失败状态\n这些范围可以在 gatling.conf 文件中配置\n请求标准统计分析图 此图表显示了一些标准统计数据，例如全局和每个请求的最小值、最大值、平均值、标准差和百分位数。 stats 显示了所有请求具体的成功失败情况 OK 代表成功，KO 代表失败，百分比 99th pct 代表对于这一个 API 总的请求中有百分之 99 的请求 response time 是这个数值\n这些百分位数可以在 gatling.conf 文件中配置。\n活跃用户数统计图 此图表展示了活跃用户数指的是在测试时间段内，正在进行请求的用户数。在测试开始时，活跃用户数为 0。当用户开始发送请求时，活跃用户数开始增加。当用户完成请求时，活跃用户数开始减少。活跃用户数的最大值是在测试期间同时发送请求的用户数。\n响应时间分布图 此图表显示了响应时间的分布，包括请求成功的响应时间和请求失败的响应时间。\n响应时间百分位对比图 此图表显示一段时间内的各种响应时间百分位数，但仅适用于成功的请求。由于失败的请求可能会提前结束或由超时引起，因此它们会对百分位数的计算产生巨大影响。\n每秒请求数图 此图表展示了每秒的请求数，包括成功的请求数和失败的请求数。\n每秒响应数图 此图表展示了每秒的响应数，包括成功的响应数和失败的响应数。\n单个请求分析报告 可点击报告页面上的 details 菜单切换到 details tab 页面，查看单个请求的详细报告\nDetails 页面主要展示了每个请求的统计数据，与全局报告相似地包括了响应时间分布图，响应时间百分位图，每秒请求数图，每秒响应数图。不同的是最底下有一张图是描述单个请求相对于全局所有请求的响应时间。该图横坐标是每秒全局所有请求数，纵坐标是单个请求的响应时间。\n性能场景设置 Injection 注入 什么是 Injection 在 Gatling 性能测试中，\u0026ldquo;Injection\u0026quot;是指将虚拟用户（或负载）引入系统的一种方式。它定义了模拟用户如何被引入测试场景，包括用户的数量、速率和方式。Injection 是 Gatling 中用于控制负载和并发度的关键概念，允许你模拟不同的用户行为和负载模型。\n用户注入配置文件的定义是通过 injectOpen 和 injectClosed 方法（Scala 中的 inject）完成的。此方法将按顺序处理的注入步骤序列作为参数。每个步骤都定义了一组用户，以及如何将这些用户注入到场景中。\n官网更多介绍：https://gatling.io/docs/gatling/reference/current/core/injection/\n常用 Injection 场景 Open Model 开放模型场景 setUp( scn.inject( nothingFor(4), // 1 atOnceUsers(10), // 2 rampUsers(10).during(5), // 3 constantUsersPerSec(20).during(15), // 4 constantUsersPerSec(20).during(15).randomized, // 5 rampUsersPerSec(10).to(20).during(10.minutes), // 6 rampUsersPerSec(10).to(20).during(10.minutes).randomized, // 7 stressPeakUsers(1000).during(20) // 8 ).protocols(httpProtocol) ) nothingFor(duration)：设置一段停止的时间，这段时间什么都不做 atOnceUsers(nbUsers)：立即注入一定数量的虚拟用户 rampUsers(nbUsers) during(duration)：在指定时间内，设置一定数量逐步注入的虚拟用户 constantUsersPerSec(rate) during(duration)：定义一个在每秒钟恒定的并发用户数，持续指定的时间 constantUsersPerSec(rate) during(duration) randomized：定义一个在每秒钟围绕指定并发数随机增减的并发，持续指定时间 rampUsersPerSec(rate1) to (rate2) during(duration)：定义一个并发数区间，运行指定时间，并发增长的周期是一个规律的值 rampUsersPerSec(rate1) to(rate2) during(duration) randomized：定义一个并发数区间，运行指定时间，并发增长的周期是一个随机的值 stressPeakUsers(nbUsers).during(duration) ：按照拉伸到给定持续时间的阶跃函数的平滑近似注入给定数量的用户。 Closed Model 闭合模型场景 setUp( scn.inject( constantConcurrentUsers(10).during(10), // 1 rampConcurrentUsers(10).to(20).during(10) // 2 ) ) constantConcurrentUsers(nbUsers).during(duration) ：注入以使系统中的并发用户数恒定 rampConcurrentUsers(fromNbUsers).to(toNbUsers).during(duration) ：注入，使系统中的并发用户数从一个数字线性增加到另一个数字 Meta DSL 场景 \u0026ldquo;Meta DSL\u0026quot;是一种特殊的领域特定语言（DSL），用于描述性能测试场景的元数据（metadata）和全局配置。Meta DSL 允许你定义性能测试中的一些全局设置和参数，以影响整个测试过程，而不是特定于某个场景。\n可以使用 Meta DSL 的元素以更简单的方式编写测试。如果您想要链接级别和斜坡以达到应用程序的极限（有时称为容量负载测试的测试），您可以使用常规 DSL 手动完成，并使用 map 和 flatMap 进行循环。\nincrementUsersPerSec setUp( // 生成一个开放的工作量注入配置文件 // 每秒分别有 10、15、20、25 和 30 个用户到达 // 每个级别持续 10 秒 // 每级持续 10 秒 scn.inject( incrementUsersPerSec(5.0) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Double ) incrementConcurrentUsers setUp( // 生成一个封闭的工作负载注入配置文件 // 并发用户分别为 10、15、20、25 和 30 级 // 每个级别持续 10 秒 // 每级持续 10 秒 scn.inject( incrementConcurrentUsers(5) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Int ) ) incrementUsersPerSec 用于开放式工作负载，incrementConcurrentUsers 用于封闭式工作负载（用户数/秒与并发用户数）。\nseparatedByRampsLasting 和 startingFrom 都是可选的。如果您不指定斜坡，测试完成后就会立即从一个级别跳到另一个级别。如果您不指定启动用户数，测试将从 0 个并发用户或每秒 0 个用户开始，并立即进入下一步。\nConcurrent Scenarios 并发场景 setUp( scenario1.inject(injectionProfile1), scenario2.inject(injectionProfile2) ) 您可以在同一个 setUp 块中配置多个场景同时启动并并发执行。\n其他场景 查看官网介绍：https://gatling.io/docs/gatling/reference/current/core/injection/\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro-advanced-usage/","summary":"文章介绍性能测试工具 gatling 的进阶用法：性能测试报告的解析，不同类型的测试报告报表介绍，不同业务类型下的性能测试场景配置","title":"gatling 性能测试教程 - 进阶用法：报告解析和场景设置"},{"content":"从 0 到 1 搭建自己的 Gatling 工程 Gradle + Scala 版本 创建一个空的 Gradle 工程 mkdir gatling-gradle-demo cd gatling-gradle-demo gradle init 配置项目 build.gradle 在 项目中 build.gradle 文件中添加以下内容\n可 copy 本项目中的 build.gradle 文件内容，更多配置可参考官方文档\n// 插件配置 plugins { id \u0026#39;scala\u0026#39; // scala插件声明（基于开发工具插件） id \u0026#39;io.gatling.gradle\u0026#39; version \u0026#39;3.9.5.6\u0026#39; // 基于gradle的gatling框架插件版本声明 } //仓库源配置 repositories { // 使用 maven 中心仓库源 mavenCentral() } // gatling 配置 gatling { // logback root level，如果配置文件夹中不存在 logback.xml，则默认 Gatling 控制台日志级别 logLevel = \u0026#39;WARN\u0026#39; // 执行记录 HTTP 请求的详细程度 // set to \u0026#39;ALL\u0026#39; for all HTTP traffic in TRACE, \u0026#39;FAILURES\u0026#39; for failed HTTP traffic in DEBUG logHttp = \u0026#39;FAILURES\u0026#39; // Simulations 过滤器 simulations = { include \u0026#34;**/simulation/*.scala\u0026#34; } } // 依赖配置 dependencies { // 图表库，用于生成报告图表 gatling \u0026#39;io.gatling.highcharts:gatling-charts-highcharts:3.8.3\u0026#39; } gradle build 项目并初始化 用编辑器打开本项目 Terminal 窗口，执行以下命令确认项目 build 成功 gradle build 初始化完成：完成向导后，Gradle 将在项目目录中生成一个基本的 Gradle 项目结构 初始化目录 在 src/gatling/scala 目录下创建一个 simulation 目录，用于存放测试脚本\nGatling 测试通常位于 src/gatling 目录中。你需要在项目根目录下手动创建 src 目录，然后在 src 目录下创建 gatling 目录。在 gatling 目录下，你可以创建你的测试模拟文件夹 simulation，以及其他文件夹，如 data、bodies、resources 等。\n编写脚本 在 simulation 目录下创建一个 demo.scala 文件，用于编写测试脚本\n示例脚本如下，可供参考\n脚本包含了两个场景，一个是 get 请求，一个是 post 请求 get 接口验证接口返回状态码为 200，post 接口验证接口返回状态码为 201 get 接口使用了 rampUsers，post 接口使用了 constantConcurrentUsers rampUsers：在指定时间内逐渐增加并发用户数，constantConcurrentUsers：在指定时间内保持并发用户数不变 两个接口的并发用户数都是 10 个，持续时间都是 10 秒 两个接口的请求间隔都是 2 秒\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } 调试脚本 执行以下命令，运行测试脚本并查看报告\ngradle gatlingRun Maven + Scala 版本 创建一个空的 Maven 工程 mvn archetype:generate -DgroupId=demo.gatlin.maven -DartifactId=gatling-maven-demo 初始化完成：完成向导后，Maven 将在新建项目目录并生成一个基本的 Maven 项目结构\n配置项目 pom.xml 在 项目中 pom.xml 文件中添加以下内容\n可 copy 本项目中的 pom.xml 文件内容，更多配置可参考官方文档\n\u0026lt;!-- 依赖配置 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.gatling.highcharts\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-charts-highcharts\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.9.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 插件配置 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.gatling\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.6.0\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;net.alchim31.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;scalaVersion\u0026gt;2.13.12\u0026lt;/scalaVersion\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;testCompile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;jvmArgs\u0026gt; \u0026lt;jvmArg\u0026gt;-Xss100M\u0026lt;/jvmArg\u0026gt; \u0026lt;/jvmArgs\u0026gt; \u0026lt;args\u0026gt; \u0026lt;arg\u0026gt;-deprecation\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-feature\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-unchecked\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:implicitConversions\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:postfixOps\u0026lt;/arg\u0026gt; \u0026lt;/args\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 初始化目录 在 src/test/scala 目录下创建一个 simulation 目录，用于存放测试脚本\nscala 测试通常位于 src/test 目录中。你需要在项目 test 目录下创建 scala 目录。在 scala 目录下，你可以创建你的测试模拟文件夹 simulation，以及其他文件夹，如 data、bodies、resources 等。\n编写脚本 在 simulation 目录下创建一个 demo.scala 文件，用于编写测试脚本\n示例脚本如下，可供参考\n脚本包含了两个场景，一个是 get 请求，一个是 post 请求 get 接口验证接口返回状态码为 200，post 接口验证接口返回状态码为 201 get 接口使用了 rampUsers，post 接口使用了 constantConcurrentUsers rampUsers：在指定时间内逐渐增加并发用户数，constantConcurrentUsers：在指定时间内保持并发用户数不变 两个接口的并发用户数都是 10 个，持续时间都是 10 秒 两个接口的请求间隔都是 2 秒\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } 调试脚本 执行以下命令，运行测试脚本并查看报告\nmvn gatling:test 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro2/","summary":"文章介绍性能测试工具 gatling 的进阶介绍：从 0 到 1 搭建自己的 Gatling 工程，介绍了 Gatling 的基本使用方法，以及如何搭建自己的 Gatling 工程，编写性能测试脚本，查看测试报告等","title":"gatling 性能测试教程：从 0 到 1 搭建自己的 Gatling 工程"},{"content":"Gatling 介绍 Gatling 是一个用于性能测试和负载测试的开源工具，特别适用于测试 Web 应用程序。它是一个基于 Scala 编程语言的高性能工具，用于模拟并测量应用程序在不同负载下的性能。\n以下是 Gatling 的一些重要特点和优势：\n基于 Scala 编程语言：Gatling 的测试脚本使用 Scala 编写，这使得它具有强大的编程能力，允许用户编写复杂的测试场景和逻辑。 高性能：Gatling 被设计为高性能的负载测试工具。它使用了非阻塞的 I/O 和异步编程模型，能够模拟大量并发用户，从而更好地模拟真实世界中的负载情况。 易于学习和使用：尽管 Gatling 的测试脚本是使用 Scala 编写的，但它的 DSL（领域特定语言）非常简单，容易上手。即使你不熟悉 Scala，也可以快速学会如何创建测试脚本。 丰富的功能：Gatling 提供了丰富的功能，包括请求和响应处理、数据提取、条件断言、性能报告生成等。这些功能使你能够创建复杂的测试场景，并对应用程序的性能进行全面的评估。 多协议支持：除了 HTTP 和 HTTPS，Gatling 还支持其他协议，如 WebSocket，JMS，和 SMTP。这使得它适用于测试各种不同类型的应用程序。 实时结果分析：Gatling 可以在测试运行期间提供实时的性能数据和图形化报告，帮助你快速发现性能问题。 开源和活跃的社区：Gatling 是一个开源项目，拥有一个活跃的社区，不断更新和改进工具。 支持 CI/CD 集成：Gatling 可以与 CI/CD 工具（如 Jenkins）集成，以便在持续集成和持续交付流程中执行性能测试。 总的来说，Gatling 是一个功能强大的性能测试工具，适用于测试各种类型的应用程序，帮助开发团队识别和解决性能问题，以确保应用程序在生产环境中具有稳定的性能和可伸缩性。\n环境搭建 由于我是 macbook，后面的介绍几本会以 macbook demo 为例，windows 的同学可以自行参考\nVSCode + Gradle + Scala 版本 准备工作 开发工具：VSCode 安装 Gradle 版本\u0026gt;=6.0，我使用的 Gradle 8.44 安装 JDK 版本\u0026gt;=8，我使用的 JDK 19 安装插件 VSCode 搜索 Scala (Metals) 插件进行安装 VSCode 搜索 Gradle for Java 插件进行安装 官方 demo 初始化\u0026amp;调试 前面先会用官方 demo 工程来做初始化和调试，后面再介绍如何自己创建工程\n克隆官方 demo 工程 git clone git@github.com:gatling/gatling-gradle-plugin-demo-scala.git 使用 VSCode 打开克隆下来的官方 demo 工程\n用 VSCode 打开本项目 Terminal 窗口，执行以下命令\ngradle build 运行工程中的 demo gradle gatlingRun 查看命令行运行结果 点击命令行报告中的 html 报告链接，并使用浏览器打开，即可查看详细的报告信息 VSCode + Maven + Scala 版本 准备工作 开发工具：VSCode 安装 Maven，我使用的 Maven 3.9.5 JDK 版本\u0026gt;=8，我使用的 JDK 19 安装插件 VSCode 搜索 Scala (Metals) 插件进行安装 VSCode 搜索 Maven for Java 插件进行安装 官方 demo 初始化\u0026amp;调试 前面先会用官方 demo 工程来做初始化和调试，后面再介绍如何自己创建工程\n克隆官方 demo 工程 git clone git@github.com:gatling/gatling-maven-plugin-demo-scala.git 使用 VSCode 打开克隆下来的官方 demo 工程\n用 VSCode 打开本项目 Terminal 窗口，执行以下命令运行工程中的 demo\nmvn gatling:test 查看命令行运行结果 点击命令行报告中的 html 报告链接，并使用浏览器打开，即可查看详细的报告信息 IDEA + Gradle + Scala 版本 与 VSCode 下基本类似，这里就不再赘述了\n差异点如下：\nIDEA 搜索 Scala 插件进行安装 新的运行方式：右键选择项目目录下的 Engine.scala 文件，选择 Run \u0026lsquo;Engine\u0026rsquo;也可以运行 demo（运行过程中需要按回车键确认哦） IDEA + Maven + Scala 版本 与 VSCode 下基本类似，这里就不再赘述了\n差异点如下：\nIDEA 搜索 Scala 插件进行安装 新的运行方式：右键选择项目目录下的 Engine.scala 文件，选择 Run \u0026lsquo;Engine\u0026rsquo;也可以运行 demo（运行过程中需要按回车键确认哦） 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro1/","summary":"文章介绍性能测试工具 gatling 的新手入门介绍，环境搭建，如何将官方 demo 跑起来","title":"gatling 性能测试教程：入门介绍"},{"content":"为什么选择 bruno 官方说明：https://github.com/usebruno/bruno/discussions/269\n与 postman 的对比：https://www.usebruno.com/compare/bruno-vs-postman\n开源，MIT License\n客户端全平台支持 (Mac/linux/Windows)\n离线客户端，无云同步功能计划\n支持 Postman/insomina 脚本导入（只能导入 API 请求脚本，无法导入测试脚本）\n社区相对活跃，产品开发路线图清晰\n安装 bruno Download link: https://www.usebruno.com/downloads\nMac 电脑推荐 brew 命令下载\n​ brew install Bruno\n客户端使用入门 默认主界面 API 请求集 创建 API 请求集 首页点击‘Create Collection’链接，打开创建 API 请求集的弹窗\n弹窗上依次输入\nName: 输入 API 请求集的名字\nLocation：输入想要保存 API 请求集文件的文件夹路径 (建议选择此项目所在路径)\nFolder Name：可输入 API 请求集名字（会在刚才选择的路径下创建一个对应名字的文件夹）\n点击 Create 按钮即可完成 API 请求集的创建，并展示在界面上 (左侧 请求集列表会展示新建的 API 请求集的信息)\n打开 API 请求集 首页点击‘Open Collection’链接，打开选择已有的 bruno 格式的 API 请求集文件夹 点击 open 即可完成选择，并展示在界面上 (左侧 collection 列表会展示选择的 API 请求集信息) 导入 API collection 首页点击‘Import Collection’链接，打开导入 API collection 的弹窗 (支持 Bruno/Postman/Insomnia 的导入) 弹窗上选择对应格式的的链接，再选在已存在的对应格式的文件路径 点击 open 即可完成选择，并展示在界面上 (左侧 collection 列表会展示选择的 API collection 信息) 本地运行 API collection 在主界面左侧 collection 列表选择想要运行的 API 请求集 在菜单上选择 Run，右侧界面会打开 Runner tab，会展示所选择 API 请求集里面 requests 的一些信息 点击 Run Collection 按钮即可本地运行 (运行完界面上会展示允许结果) 导出 API 请求集 在主界面左侧 collection 列表选择想要运行的 API 请求集，右键打开菜单 在菜单上选择 Export，再选择想要导出文件的路径即可完成导出 (导出文件也是为 json 格式) API 请求 新建 API 请求 前置条件：已经创建了 API 请求集 (参考上面的创建 API 请求集) 在主界面左侧 collection 列表选择想要新建 API 请求的 API 请求集 在菜单上选择 New Request，右侧界面会打开 Request tab，会展示所选择 API 请求集里面 requests 的一些信息 在 new Request 窗口上先选择请求类型：HTTP/GraphQL 依次输入 Name: 输入 API 请求的名字 URL：输入 API 请求的 URL Method：选择 API 请求的 Method 点击 Create 按钮即可完成 API 请求的创建，并展示在界面上 (左侧 请求集列表会展示新建的 API 请求的信息) 编辑 API 请求 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)\n在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求\n然后可以根据 API 请求类型再来编辑请求的不同字段 Body：输入 API 请求的 Body\nHeaders：输入 API 请求的 Headers\nParams：输入 API 请求的 Params\nAuth：输入 API 请求的 Auth\nVars：输入 API 请求的 Vars\nScript：输入 API 请求的 Script\nAssert：输入 API 请求的 Assert\nTests：输入 API 请求的 Tests\n点击 Save 按钮即可完成 API 请求的编辑，并展示在界面上 (左侧 请求集列表会展示编辑的 API 请求的信息)\n运行 API 请求 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) API 请求生成代码 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 菜单右键选择 Generate Code，再选择想要生成代码的语言 Generate Code 窗口即可展示不同语言的请求代码 编写 API 请求测试脚本 API 请求 Assert Assert 介绍 打开任意的 API 请求，切换到 Assert tab\nAssert tab 会展示 API 请求的 Assert 信息\nAssert 用来判断 API 请求的返回结果是否符合预期\nExpr：输入预期结果的表达式，可以是 API 请求的返回结果的某个字段的值，可输入两种类型：Status Code 和 Response Body Status Code：判断 API 请求的返回状态码是否符合预期 (默认为 200) Response Body：判断 API 请求的返回结果是否符合预期 (默认为 true)\nOperator：输入预期结果的验证方式。支持多种判断方式：Equal 和 Not Equal 等 Equal：判断 API 请求的返回结果是否等于预期结果 Not Equal：判断 API 请求的返回结果是否不等于预期结果\nValue：输入预期结果的值，支持两种预期结果的输入方式：Static 和 Dynamic Static：输入预期结果的静态值 Dynamic：输入预期结果的动态值，可以是 API 请求的返回结果的某个字段的值\nAssert 示例 Assert status code 为 200 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 status 是否为 200， 打开该 API 请求，切换到 Assert tab 依次输入如下信息 Expr: res.status Operator：Equal Value：200 Assert repsponse body 符合预期 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 repsponse body 是否符合预期 打开该 API 请求，切换到 Assert tab Assert1 依次输入如下信息 Expr: res.body.id Operator：Equal Value：1 Assert2 依次输入如下信息 Expr: res.body.title Operator：contains Value：provident 调试 Assert 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也按照 demo 编写了对应的 Assert 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) 切换到 Tests tab，会展示 API 请求的 Tests 信息，里面也会包括请求的 Assert 信息 API 请求 Tests Tests 介绍 打开任意的 API 请求，切换到 Tests tab Tests tab 会展示 API 请求的 Tests 信息 Tests 用来编写 API 请求的测试脚本，目前较好支持 javascript 语言 Tests 里面可以编写多个测试脚本，每个测试脚本都可以单独运行 Tests 示例 验证 status code 为 200 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 status 是否为 200， 打开该 API 请求，切换到 Tests tab 输入如下脚本 test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); Assert repsponse body 符合预期 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 repsponse body 是否符合预期 打开该 API 请求，切换到 Tests tab 输入如下脚本 test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.id).to.equal(1); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调试 Tests 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也按照 demo 编写了对应的 Tests 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) 切换到 Tests tab，会展示 API 请求的 Tests 信息，里面也会包括请求的 Tests 信息 环境变量 创建环境变量 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 选择想要创建环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗（支持创建新的环境变量和导入已有的环境变量） 弹窗上点击 Create Environment 按钮，输入环境变量的名字，点击 create 按钮即可创建环境变量 然后在弹窗上点击 Add Variable 按钮，输入环境变量的 key 和 value，点击 Save 按钮即可添加环境变量 环境变量 demo 需求：创建一个 demo 环境变量，里面包含一个 key 为 host，value 为 https://jsonplaceholder.typicode.com 的环境变量\n选择想要创建环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗 弹窗上点击 Create Environment 按钮，输入环境变量的名字 demo，点击 create 按钮即可创建环境变量 demo 选择 demo 环境变量，然后在页面上点击 Add Variable 按钮，输入环境变量的 key 为 host，value 为 https://jsonplaceholder.typicode.com ，点击 Save 按钮即可添加环境变量 如下图所示 使用环境变量 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也创建了 demo 环境变量 选择想要使用环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 demo 按钮即可使用 demo 环境变量 然后在 API 请求的 URL 变更为输入 {{host}}/posts/1 即可使用环境变量 测试脚本接口自动化 前置条件 已创建了 API 请求集（示例名为:api-collects） 已创建了 API 请求（示例名为:api request1） 已创建了环境变量（示例名为:demo） 也为 API 请求编写了 assert 或者 tests 脚本 接口自动化项目 demo 安装 node.js 安装 npm 新建项目文件夹（示例名为:bruno-test） 项目文件夹下执行 npm init 将项目初始化为 npm 项目 安装 @usebruno/cli 依赖 (脚本为：npm install @usebruno/cli) 打开保存 API 请求集的文件夹目录，将 api-collects 目录下的所有文件都复制到 bruno-test 项目目录下下 项目目录如下所示 bruno-test //项目主文件夹 api request1.bru //api 请求 enviroments //环境变量 demo.bru bruno.json node_modules //node 包依赖 package-lock.json package.json //npm 项目配置文件 运行接口自动化脚本 bruno run --env demo 运行结果如下 接入 CI 接入 github action 以 github action 为例，其他 CI 工具类似\n前置准备：在项目 package.json 文件中添加如下脚本 \u0026#34;test\u0026#34;: \u0026#34;bru run --env demo\u0026#34; 在项目根目录下创建 .github/workflows 文件夹 在 .github/workflows 文件夹下创建 main.yml 文件 main.yml 文件内容如下 name: bruno cli CI on: push: branches: [ main ] pull_request: branches: [ main ] jobs: run_bruno_api_test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - run: npm install - name: run tests run: npm run test 提交代码到 github，会自动触发 github action 查看 github action 运行结果，如图示例： 可拉取本项目代码进行参考：https://github.com/dengnao-tw/Bruno-API-Test-Starter\n测试报告\u0026mdash;TODO bruno 更多用法\u0026mdash;TODO Postman 脚本迁移 API 请求集迁移 在首页点击‘Import Collection’链接，打开导入 API collection 的弹窗 点击选择 Postman Collection 的链接，再选在已存在的 Postman 请求集文件路径 即可导入 Postman 的请求集 但是目前只支持导入 API 请求，无法导入测试脚本，如图所示（但不影响请求调用） 环境变量迁移 在首页选择刚才导入的 Postman 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗 点击‘Import Environment’链接，打开导入 Environment 的弹窗 点击选择 Postman Environment 的链接，再选在已存在的 Postman 环境变量文件路径 即可导入 Postman 的环境变量 测试脚本迁移参考 两个工具测试脚本的语法存在一部分差异，需要手动修改\nPostman 测试脚本语法参考：https://learning.postman.com/docs/writing-scripts/test-scripts/ Postman 测试脚本示例 pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); Bruno 测试脚本语法参考：https://docs.usebruno.com/testing/introduction.html Bruno 测试脚本示例 test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.id).to.equal(1); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/introduction_of_bruno/","summary":"文章介绍 postman 替换工具 Bruno 的新手入门介绍，如何迁移 postman 脚本到 Bruno","title":"postman 替换工具 bruno 使用介绍"},{"content":"什么是二八法则 二八法则，也被称为帕累托法则（Pareto principle），是一种经济学原理和管理学理论，描述了一种观察结果：80% 的结果往往来自于 20% 的原因。这个法则最初由意大利经济学家维尔弗雷多·帕累托（Vilfredo Pareto）提出。\n二八法则可以应用于各个领域，包括经济、生产、销售、时间管理等。具体来说，它意味着一个系统或者群体中，少数重要的因素往往对于大部分结果产生了主要的影响，而其余的因素只起到了次要的作用。换句话说，大部分的产出、收益或者结果来自于少数关键的因素或者部分。\n举个例子，二八法则可以应用于销售领域。80% 的销售额往往来自于 20% 的顾客，或者说 80% 的问题往往来自于 20% 的产品。这意味着经营者可以通过专注于那些最重要的 20% 顾客或产品，获得最大的收益。\n二八法则的应用还可以帮助人们更有效地管理时间。根据这个原理，80% 的成果往往来自于 20% 的时间和精力投入。因此，人们可以通过识别那些最重要的任务和活动，并优先处理它们，来提高工作效率和成果。\n需要注意的是，二八法则的具体数字并不一定是严格的 80-20 比例，这只是一个常见的例子。在实际应用中，比例可能会有所不同，但基本思想保持一致：少数重要的因素或者部分对于整体结果起到了关键作用。\n软件研发过程中的二八法则 在软件研发中，二八法则可以应用于多个方面，包括功能开发、缺陷修复、需求管理和团队效率等。以下是一些常见的应用场景：\n功能开发：根据二八法则，80% 的用户使用率通常来自于 20% 的核心功能。在软件开发过程中，团队可以优先开发和完善这些核心功能，以满足大部分用户的需求。这有助于提高产品的可用性和用户体验。 缺陷修复：类似地，80% 的软件缺陷往往由 20% 的核心功能引起。因此，在缺陷修复过程中，团队应该重点关注那些最常见、最严重或者影响最广泛的缺陷。这有助于快速改善软件的质量和稳定性。 需求管理：根据二八法则，80% 的用户需求通常来自于 20% 的关键需求。在需求管理过程中，团队应该专注于梳理和管理那些最重要、最紧急的需求，确保其优先级得到合理的安排。这有助于提高项目的交付价值和满足用户期望。 团队效率：二八法则也可以应用于团队效率的管理。根据这个原则，80% 的工作成果往往来自于 20% 的高效工作时间。团队可以通过优化工作流程、减少低价值的任务和降低工作负荷，来提高团队的整体效率和生产力。 需要注意的是，二八法则在软件研发中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，以达到最佳的开发效果和资源利用。同时，综合考虑其他因素，如用户反馈、市场需求和团队能力等，以实现整体的项目成功。\n软件研发质量中的二八法则 在软件质量管理中，二八法则可以应用于缺陷管理、测试策略和持续改进等方面。以下是一些常见的应用场景：\n缺陷管理：根据二八法则，80% 的缺陷通常来自于 20% 的功能模块或者代码区域。在软件质量管理过程中，团队应该重点关注那些最容易引发缺陷的核心功能或者代码部分。这有助于提高缺陷发现和修复的效率，确保关键功能的质量和稳定性。 测试策略：根据二八法则，80% 的软件缺陷往往由 20% 的核心功能或者测试用例引起。在测试策略制定过程中，团队可以优先选择那些最关键、最具代表性的功能进行测试。同时，重点关注那些最有可能引发缺陷的测试用例，以提高测试覆盖和效果。 持续改进：二八法则也可以应用于持续改进的过程中。根据这个原则，80% 的改进效果通常来自于 20% 的关键改进措施。团队应该重点关注那些最重要、最有影响力的改进项目，以最大程度地提升软件质量和用户体验。 用户反馈和需求：根据二八法则，80% 的用户满意度通常来自于 20% 的关键功能或者需求。在软件质量管理中，团队应该重点关注那些对用户最重要、最有价值的功能和需求。通过积极收集用户反馈和需求，团队可以针对性地改进和优化这些关键领域，提升软件的质量和用户满意度。 需要注意的是，二八法则在软件质量管理中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，并结合其他质量管理方法和工具，以实现最佳的软件质量和用户体验。\n软件测试中的二八法则 在软件测试中，二八法则可以被应用于缺陷定位和优先级管理。根据这个原则，大约 80% 的缺陷通常来自于 20% 的功能模块或测试用例。这意味着测试团队可以通过重点关注那些最有可能引发缺陷的关键功能，以及那些覆盖最广泛、最重要的测试用例，来获得最佳的测试覆盖和缺陷发现效果。\n具体应用二八法则的方法包括：\n重点测试关键功能：根据系统的复杂性和业务重要性，确定关键的功能模块或者业务流程。将更多的测试资源和时间分配给这些关键功能，以确保其质量和稳定性。 优先处理高风险区域：通过分析过往的缺陷数据、用户反馈和业务需求，确定系统中最容易出现问题的区域。将更多的测试活动放在这些高风险区域，以提前发现和修复潜在的问题。 选择关键测试用例：在测试用例设计和执行过程中，根据业务价值、功能复杂度和影响范围等因素，选择那些最具代表性和最重要的测试用例进行执行。确保这些关键测试用例的覆盖率和测试深度，以有效检测潜在的缺陷。 精细化缺陷管理：将测试团队的精力集中在那些最关键、最严重的缺陷上，确保这些缺陷得到及时的处理和修复。同时，对于一些次要的或影响较小的缺陷，可以在资源允许的情况下进行适当的延后处理，以保证测试团队的效率和优先级的合理分配。 需要注意的是，二八法则在软件测试中的应用并非严格的数值比例，具体的比例可能会因项目的特点、复杂性和风险等因素而有所不同。测试团队应根据具体情况灵活运用这个原则，以实现最佳的测试效果和资源利用。\n如何优化软件研发质量中的二八法则 要优化软件质量管理中的二八法则应用，可以考虑以下几点：\n数据驱动决策：收集和分析准确、全面的数据是优化的基础。通过使用测试管理工具、缺陷跟踪系统和用户反馈渠道等，获取有关缺陷、功能使用率、用户需求等方面的数据。这样可以更准确地确定哪些功能模块或代码区域是关键的，从而更有针对性地进行测试和改进。 重点关注核心功能：根据数据分析的结果，重点关注那些最关键、最常用的功能模块或代码区域。在测试过程中，为这些核心功能分配更多的资源和测试覆盖，以确保其质量和稳定性。 细化测试策略：根据数据分析和风险评估，制定细化的测试策略。考虑到功能的重要性、复杂性和用户影响，确定关键测试用例，并确保其充分覆盖核心功能。同时，可以利用自动化测试工具和技术，提高测试效率和覆盖率。 高效缺陷管理：建立有效的缺陷管理流程，确保缺陷能够及时被跟踪、分析和修复。优先处理那些最严重、最影响用户体验的缺陷，并跟踪缺陷修复的进度和效果。同时，进行缺陷分析，找出常见的缺陷模式和根本原因，以便改进开发过程和减少类似缺陷的再次发生。 用户参与和反馈：积极与用户进行互动，了解他们的需求、问题和意见。通过用户调研、用户体验测试和用户反馈渠道，获取用户的反馈和建议。将用户需求和反馈作为优化软件质量管理的重要依据，并将其纳入开发和改进的决策过程中。 持续改进和学习：软件质量管理是一个持续改进的过程。团队应该定期评估和反思当前的质量管理实践，寻找改进的机会。借鉴行业的最佳实践，关注新技术和工具的发展，不断学习和提升团队的能力和水平。 综合运用以上策略，可以优化软件质量管理中的二八法则应用，提高软件的质量和用户满意度。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/80-20-rule/","summary":"什么是二八法则 二八法则，也被称为帕累托法则（Pareto principle），是一种经济学原理和管理学理论，描述了一种观察结果：80% 的结果往往来自于 20% 的原因。这个法则最初由意大利经济学家维尔弗雷多·帕累托（Vilfredo Pareto）提出。\n二八法则可以应用于各个领域，包括经济、生产、销售、时间管理等。具体来说，它意味着一个系统或者群体中，少数重要的因素往往对于大部分结果产生了主要的影响，而其余的因素只起到了次要的作用。换句话说，大部分的产出、收益或者结果来自于少数关键的因素或者部分。\n举个例子，二八法则可以应用于销售领域。80% 的销售额往往来自于 20% 的顾客，或者说 80% 的问题往往来自于 20% 的产品。这意味着经营者可以通过专注于那些最重要的 20% 顾客或产品，获得最大的收益。\n二八法则的应用还可以帮助人们更有效地管理时间。根据这个原理，80% 的成果往往来自于 20% 的时间和精力投入。因此，人们可以通过识别那些最重要的任务和活动，并优先处理它们，来提高工作效率和成果。\n需要注意的是，二八法则的具体数字并不一定是严格的 80-20 比例，这只是一个常见的例子。在实际应用中，比例可能会有所不同，但基本思想保持一致：少数重要的因素或者部分对于整体结果起到了关键作用。\n软件研发过程中的二八法则 在软件研发中，二八法则可以应用于多个方面，包括功能开发、缺陷修复、需求管理和团队效率等。以下是一些常见的应用场景：\n功能开发：根据二八法则，80% 的用户使用率通常来自于 20% 的核心功能。在软件开发过程中，团队可以优先开发和完善这些核心功能，以满足大部分用户的需求。这有助于提高产品的可用性和用户体验。 缺陷修复：类似地，80% 的软件缺陷往往由 20% 的核心功能引起。因此，在缺陷修复过程中，团队应该重点关注那些最常见、最严重或者影响最广泛的缺陷。这有助于快速改善软件的质量和稳定性。 需求管理：根据二八法则，80% 的用户需求通常来自于 20% 的关键需求。在需求管理过程中，团队应该专注于梳理和管理那些最重要、最紧急的需求，确保其优先级得到合理的安排。这有助于提高项目的交付价值和满足用户期望。 团队效率：二八法则也可以应用于团队效率的管理。根据这个原则，80% 的工作成果往往来自于 20% 的高效工作时间。团队可以通过优化工作流程、减少低价值的任务和降低工作负荷，来提高团队的整体效率和生产力。 需要注意的是，二八法则在软件研发中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，以达到最佳的开发效果和资源利用。同时，综合考虑其他因素，如用户反馈、市场需求和团队能力等，以实现整体的项目成功。\n软件研发质量中的二八法则 在软件质量管理中，二八法则可以应用于缺陷管理、测试策略和持续改进等方面。以下是一些常见的应用场景：\n缺陷管理：根据二八法则，80% 的缺陷通常来自于 20% 的功能模块或者代码区域。在软件质量管理过程中，团队应该重点关注那些最容易引发缺陷的核心功能或者代码部分。这有助于提高缺陷发现和修复的效率，确保关键功能的质量和稳定性。 测试策略：根据二八法则，80% 的软件缺陷往往由 20% 的核心功能或者测试用例引起。在测试策略制定过程中，团队可以优先选择那些最关键、最具代表性的功能进行测试。同时，重点关注那些最有可能引发缺陷的测试用例，以提高测试覆盖和效果。 持续改进：二八法则也可以应用于持续改进的过程中。根据这个原则，80% 的改进效果通常来自于 20% 的关键改进措施。团队应该重点关注那些最重要、最有影响力的改进项目，以最大程度地提升软件质量和用户体验。 用户反馈和需求：根据二八法则，80% 的用户满意度通常来自于 20% 的关键功能或者需求。在软件质量管理中，团队应该重点关注那些对用户最重要、最有价值的功能和需求。通过积极收集用户反馈和需求，团队可以针对性地改进和优化这些关键领域，提升软件的质量和用户满意度。 需要注意的是，二八法则在软件质量管理中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，并结合其他质量管理方法和工具，以实现最佳的软件质量和用户体验。\n软件测试中的二八法则 在软件测试中，二八法则可以被应用于缺陷定位和优先级管理。根据这个原则，大约 80% 的缺陷通常来自于 20% 的功能模块或测试用例。这意味着测试团队可以通过重点关注那些最有可能引发缺陷的关键功能，以及那些覆盖最广泛、最重要的测试用例，来获得最佳的测试覆盖和缺陷发现效果。\n具体应用二八法则的方法包括：","title":"软件研发质量中的二八法则"},{"content":"什么是 API? API:应用程序接口（全称：application programming interface），缩写为 API，是一种计算接口，它定义多个软件中介之间的交互，以及可以进行的调用（call）或请求（request）的种类，如何进行调用或发出请求，应使用的数据格式，应遵循的惯例等。它还可以提供扩展机制，以便用户可以通过各种方式对现有功能进行不同程度的扩展。一个 API 可以是完全定制的，针对某个组件的，也可以是基于行业标准设计的以确保互操作性。通过信息隐藏，API 实现了模块化编程，从而允许用户实现独立地使用接口。\n什么是 API 测试？ 接口测试是软件测试的一种，它包括两种测试类型：狭义上指的是直接针对应用程序接口（下面使用缩写 API 指代，其中文简称为接口）的功能进行的测试；广义上指集成测试中，通过调用 API 测试整体的功能完成度、可靠性、安全性与性能等指标。\nAPI Best Practice:\nAPI 定义遵循 RESTFUL API 风格，语意化的 URI 定义，准确的 HTTP 状态码，通过 API 的定义就可以知道资源间的关系 配有详细且准确的 API 文档（如 Swagger 文档） 对外的 API 可以包含版本号以快速迭代（如 https://thoughtworks.com/v1/users/） API 测试与测试四象限 测试四象限中不同象限的测试，其测试目的跟测试策略也不同，API 测试主要位于第二、第四象限\nAPI 测试与测试金字塔 API 测试在测试金子塔中处于一个相对靠上的位置，主要站在系统、服务边界来测试功能和业务逻辑，执行时机是在服务完成构建、部署到测试环境之后再执行、验证。\nAPI 测试类型 功能测试\n正确性测试 异常处理 内部逻辑 …… 非功能测试\n性能 安全 …… API 测试步骤 发送请求 得到响应 验证响应结果 API 功能测试设计 设计理论\n正面 负面 异常处理 内部逻辑 …… 测试方法\n等价类划分 边界值 错误推断 …… API 非功能测试设计 安全测试\n随机测试 SQL 注入 XSS …… 性能测试\n性能瓶颈 稳定性测试 …… API 测试工具 API 请求工具\nCURL Soap UI Postman Swagger UI …… Http proxy 工具\nFiddler Charles …… API 性能测试工具\nab(apache bench) Jmeter …… 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/introduction_of_api_test/","summary":"文章介绍接口测试的简介，类型和工具","title":"接口测试简介"},{"content":"Google Bard Google Bard 进入公开测试版。测试申请中~~~\n申请链接：https://bard.google.com/\n谷歌发布 Bard，这是其在创建人工智能竞赛中的竞争对手推出 ChatGPT 之后的放的大招。\n经过多年的谨慎开发，这家互联网巨头将授予用户访问聊天机器人的权限，以追逐竞争对手 OpenAI 和微软的引人注目的首次亮相之后的惊艳表现。\n百度文心一言 百度于 3 月 16 日正式公布大语言模型“文心一言”，这是一款基于人工智能技术的智能对话系统，可进行语义理解、智能问答和情感交流等多种形式的对话。\n3 月 16 日起，首批用户即可通过邀请测试码在文心一言官网体验产品，后续将陆续开放给更多用户。 此外，百度智能云即将面向企业客户开放文心一言 API 接口调用服务。\n3 月 16 日起正式开放预约，搜索“百度智能云”进入官网，可申请加入文心一言云服务测试。\n申请链接：https://yiyan.baidu.com/welcome\n合作申请链接：https://cloud.baidu.com/survey_summit/wenxin.html?track=C856571\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/different-types-of-ai-join-waiting-list/","summary":"Google Bard Google Bard 进入公开测试版。测试申请中~~~\n申请链接：https://bard.google.com/\n谷歌发布 Bard，这是其在创建人工智能竞赛中的竞争对手推出 ChatGPT 之后的放的大招。\n经过多年的谨慎开发，这家互联网巨头将授予用户访问聊天机器人的权限，以追逐竞争对手 OpenAI 和微软的引人注目的首次亮相之后的惊艳表现。\n百度文心一言 百度于 3 月 16 日正式公布大语言模型“文心一言”，这是一款基于人工智能技术的智能对话系统，可进行语义理解、智能问答和情感交流等多种形式的对话。\n3 月 16 日起，首批用户即可通过邀请测试码在文心一言官网体验产品，后续将陆续开放给更多用户。 此外，百度智能云即将面向企业客户开放文心一言 API 接口调用服务。\n3 月 16 日起正式开放预约，搜索“百度智能云”进入官网，可申请加入文心一言云服务测试。\n申请链接：https://yiyan.baidu.com/welcome\n合作申请链接：https://cloud.baidu.com/survey_summit/wenxin.html?track=C856571\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。","title":"不同类型 AI 申请加入等待列表入口"},{"content":" 打开 edge 浏览器 在地址栏输入命令 edge://flags/ 在 flags 的页面输入 11 进行搜索 在搜索结果下选择“Show Windows 11 visual effects in title bar and toolbar”将状态变更为启用 重启浏览器，即可看到新的 edge 浏览器 UI 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/edge-enablenew-ui/","summary":"打开 edge 浏览器 在地址栏输入命令 edge://flags/ 在 flags 的页面输入 11 进行搜索 在搜索结果下选择“Show Windows 11 visual effects in title bar and toolbar”将状态变更为启用 重启浏览器，即可看到新的 edge 浏览器 UI 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。","title":"新技术分享：Mac OS 下 edge 浏览器开启新 UI"},{"content":"如果你的项目是采用敏捷测试，那么欢迎加入很棒的 30 天敏捷测试挑战。\n以下是 30 个挑战的列表，每月每天一个，打印下面的列表，把它保存在某个地方。打印出来。把它贴在墙上。让我们这样做吧！\n规则是什么？ 目标是尽可能多地的完成挑战。您可以在自己的时间范围和能力范围内做到这一点。\n您可能有图像可以分享，博客文章，视频，状态更新，无论它是什么！来参加吧！\n以下是分享进度的方法：\n在微博和朋友圈上 - 使用**#30DaysOfTesting**标签 30 天敏捷测试列表 Day 1 Buy an agile testing related book and share something you\u0026rsquo;ve learnt by day 30 买一本敏捷测试相关的书，并在第 30 天结束时分享你的所学 Day 2 Create a mindmap, document, diagram or sketchnote about what you think agile testing is\n用图表或文档的方式列出你理解的敏捷测试 Day 3 Find a video on YouTuBe about agile testing, then watch it!\n看一个敏捷测试的视频 Day 4 Read the agile manifesto and reflect on the implications for your role\n读敏捷宣言，并反思对你角色的影响 Day 5 Pair with a developer on a feature\n跟 Dev pair Day 6 Map out what your exploratory testing looks like, compare it to what other testers do\n列出你理解的探索式测试，并与其他人员的进行比较 Day 7 Find a visual way of representing your tests - e.g. A mind map, diagram, model, etc\n找一个可视化的方式展示你的测试 Day 8 Speak to a developer about a bug you found instead of loging it in the tracking system\n跟 dev 直接说你发现的 bug，而不是在 bug 管理系统里记录 Day 9 Pair whth a developer on a code review. Can you identify any risks?\n参加 dev 的 code review。你能定位任何的风险吗？ Day 10 Learn where the application logs are and how to read them.\n了解应用程序的 log 记录在哪里，并学习看 log。 Day 11 Find out what customers are saying about your product. What did you learn?\n了解客户对你的产品的评价。从中学到了什么？ Day 12 What test documentation does your team have? How can you improve it?\n你的团队有什么样的测试文档？你觉得可以怎么改进一下？ Day 13 Learn to use a tool that your developers use - e.g. an IDE\n学习使用 Dev 在用的工具 Day 14 How can you deliver greater value to your customer?\n如何能够交付更多的价值给客户？ Day 15 How can you make your testing processes (more) lean?\n如何能让你的测试流程更加精益？ Day 16 What barriers do you feel exist in testing in agile?\n你感觉敏捷测试中存在什么障碍？ Day 17 Map out your current team structure. How does it compare to other teams?\n绘制出您当前的团队结构。它与其他团队相比如何？ Day 18 How can you make testing jobs easier?\n如何让测试工作变得更轻松？ Day 19 How can you make jobs for your team easier?\n如何让你的团队工作更轻松？ Day 20 Investigate what is in your and your team\u0026rsquo;s tool kit\n调查你和你团队使用的工具有哪些 Day 21 How are you managing your testing, is it really agile?\n你如何管理你的测试，真的敏捷吗？ Day 22 Find out what testing is being done by other team members.\n了解其他团队成员正在进行的测试 Day 23 What agile strategies are there for managing tests?\n有哪些管理测试的敏捷策略？ Day 24 Look for a task that can be automated.\n找一个可以自动化的 task. Day 25 What can\u0026rsquo;t you automate? Communicate that to your team\n什么是你不能自动化的？跟团队沟通一下 Day 26 What does your Test Plan look like, what format do you use?\n你的测试计划什么样的，使用的什么格式？ Day 27 Look into zero bug tolerance, is this something your team could do?\n了解 bug 零容忍，这是你的团队可以做的吗？ Day 28 What learning culture exist in your company? How can you contribute to it?\n公司的学习文化是什么样的？你如何为此贡献？ Day 29 What columns do you have on your work tracker or kanban board?\n你们的看板上有哪些 column？ Day 30 What action does your team take on a red build?\nbuild 红了团队会采取什么 action？ Day 31 BONUS: Debrief your whole team on your last session of testing\n跟整个团队汇报你的测试 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n| ","permalink":"https://naodeng.com.cn/zh/posts/others/30-days-of-agile-testing/","summary":"如果你的项目是采用敏捷测试，那么欢迎加入很棒的 30 天敏捷测试挑战。\n以下是 30 个挑战的列表，每月每天一个，打印下面的列表，把它保存在某个地方。打印出来。把它贴在墙上。让我们这样做吧！\n规则是什么？ 目标是尽可能多地的完成挑战。您可以在自己的时间范围和能力范围内做到这一点。\n您可能有图像可以分享，博客文章，视频，状态更新，无论它是什么！来参加吧！\n以下是分享进度的方法：\n在微博和朋友圈上 - 使用**#30DaysOfTesting**标签 30 天敏捷测试列表 Day 1 Buy an agile testing related book and share something you\u0026rsquo;ve learnt by day 30 买一本敏捷测试相关的书，并在第 30 天结束时分享你的所学 Day 2 Create a mindmap, document, diagram or sketchnote about what you think agile testing is\n用图表或文档的方式列出你理解的敏捷测试 Day 3 Find a video on YouTuBe about agile testing, then watch it!\n看一个敏捷测试的视频 Day 4 Read the agile manifesto and reflect on the implications for your role","title":"敏捷测试的 30 天挑战"},{"content":"下面的信息是对 playwright 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\n安装 Install 非 VS Code 编辑器安装 新建项目文件 使用命令行工具进入新建的项目文件夹 输入命令进行项目初始化 npm init playwright@latest 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo VS Code 编辑器安装 新建项目文件 使用 VS Code 编辑器打开新建的项目文件夹 在 VS Code 编辑器安装 Playwright Test for VSCode 插件 然后在 VS Code 编辑器的命令面板上输入 Install Playwright 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo 运行测试 Run test VS Code 运行 通过 Playwright Test for VSCode 插件运行 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击绿色三角形就可以运行 demo 测试用例了 可以点击是否选中'show browser'来控制是否无头浏览器运行用例和打开浏览器运行用例 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 点击测试块旁边的绿色三角形 就可以运行测试来运行单个测试 命令行运行 运行所有测试\nnpx playwright test 运行单个测试文件\nnpx playwright test landing-page.spec.ts 运行一组测试文件\nnpx playwright test tests/todo-page/ tests/landing-page/ 运行文件名中有landing或login的文件\nnpx playwright test landing login 运行带有标题的测试\nnpx playwright test -g \u0026#34;add a todo item\u0026#34; 在引导模式 (打开浏览器) 下运行测试\nnpx playwright test landing-page.spec.ts --headed 在特定项目上运行测试\nnpx playwright test landing-page.ts --project=chromium 调试 Debug 由于 Playwright 在 Node.js 中运行，您可以使用您选择的调试器对其进行调试，例如使用console.log或在您的 IDE 内部或直接在 VS 代码中使用[VS 代码扩展](https://playwright.dev/docs/getting-started-vscode)。Playwright 带有[Playwright Inspector](https://playwright.dev/docs/debug#playwright-inspector)，它允许您单步执行 Playwright API 调用，查看他们的调试日志并探索[选择器](https://playwright.dev/docs/selectors)。\n命令行调试 调试所有测试：\nnpx playwright test --debug 调试一个测试文件：\nnpx playwright test example.spec.ts --debug 从test(..定义的行号调试测试：\nnpx playwright test example.spec.ts:42 --debug VS code 调试 通过 Playwright Test for VSCode 插件调试 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击第二个运行按钮就可以调试 demo 测试用例了 可以之前在想要调试的测试脚本文件中提前打一些断点 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 选中测试代码块，然后右键选择 debug test 就可以调试测试用例了 测试报告 Test report 命令行输入如下命令，就可以打开 html 版本的测试报告 npx playwright show-report 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/playwright-get-started/","summary":"下面的信息是对 playwright 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\n安装 Install 非 VS Code 编辑器安装 新建项目文件 使用命令行工具进入新建的项目文件夹 输入命令进行项目初始化 npm init playwright@latest 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo VS Code 编辑器安装 新建项目文件 使用 VS Code 编辑器打开新建的项目文件夹 在 VS Code 编辑器安装 Playwright Test for VSCode 插件 然后在 VS Code 编辑器的命令面板上输入 Install Playwright 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo 运行测试 Run test VS Code 运行 通过 Playwright Test for VSCode 插件运行 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击绿色三角形就可以运行 demo 测试用例了 可以点击是否选中'show browser'来控制是否无头浏览器运行用例和打开浏览器运行用例 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 点击测试块旁边的绿色三角形 就可以运行测试来运行单个测试 命令行运行 运行所有测试","title":"Playwright 自动化框架入门"},{"content":"Cypress Studio 提供了一种在测试运行程序中生成测试的可视化方法，通过记录与被测应用程序的交互。支持.click（）、.type（）、.check（）、.uncheck（）和.select（）Cypress 命令，这些命令将在与 Cypress Studio 内部的 DOM 交互时生成测试代码\n通过阅读文章你会学到什么：\n如何使用 Cypress Studio 以交互方式扩展测试\n如何使用 Cypress Studio 以交互方式添加新测试\n概述 Cypress Studio 通过记录与 被测应用程序的交互，提供了一种在 Test Runner 中生成测试的可视化方式。\n支持、.click()、.type()、和 Cypress 命令 .check() ，并在与 Cypress Studio 内部的 DOM 交互时生成测试代码。您还可以通过右键单击要断言的元素来生成断言。 .uncheck() .select()\n使用 Cypress Studio Cypress Studio 是一项实验性功能，可以通过将 experimentalStudio 属性添加到您的配置文件来启用（ cypress.json 默认情况下）。\n{ \u0026#34;experimentalStudio\u0026#34;: true} Cypress Real World App (RWA) 是一个开源项目，它实现了一个支付应用程序，以展示 Cypress 测试方法、模式和工作流程的实际使用情况。下面将使用它来演示 Cypress Studio 的功能。\n扩展测试 您可以扩展任何预先存在的测试，或者通过使用以下测试脚手架在您的 integrationFolder（默认情况下）中创建一个新测试来开始。\n第 1 步 - 运行用例 我们将使用 Cypress Studio 执行“新交易”用户流程。首先，启动 Test Runner 并运行在上一步中创建的用例。\n[image:F5CF37A4-27C0-4A6A-82DA-52C19191EB41-665-000000B8AF4F75E1/640.jpeg]\n第 2 步 - 启动 Cypress Studio 测试完成运行后，将鼠标悬停在命令日志中的测试上以显示“Add commands to Test”按钮。\n单击“Add Commands to Test”将启动 Cypress Studio。\nCypress Studio 直接与 命令日志集成。\n[image:7C04963F-638B-492C-B6D1-0C2C6FD31021-665-000000B8AF4F2B69/_640.jpeg]\nCypress 将自动执行所有挂钩和当前存在的测试代码，然后可以从该点开始扩展测试（例如，我们登录到 beforeEach 块内的应用程序）。\n接下来，Test Runner 将单独执行测试，并在测试中的最后一条命令后暂停。\n[image:E57D4269-75B6-49C2-9EC7-CB2BA527070D-665-000000B8AF4ECFAF/__640.jpeg]\n现在，我们可以开始更新测试以在用户之间创建新事务。\n第 3 步 - 与应用程序交互 要记录操作，请开始与应用程序交互。在这里，我们将单击标题右侧的“新建”按钮，结果我们将看到我们的单击记录在命令日志中。\n[image:B55CC01A-E8EF-4B70-9687-CC8A6423AD9A-665-000000B8AF4E893E/___640.jpeg]\n接下来，我们可以开始输入我们想要支付的用户名。\n[image:F647E6CB-2456-4602-84CB-B37B2B313DCF-665-000000B8AF4E4B07/____640.jpeg]\n一旦我们看到名字出现在结果中，我们想要添加一个断言来确保我们的搜索功能正常工作。右键单击用户名将弹出一个菜单，我们可以从中添加断言以检查元素是否包含正确的文本（用户名）。\n[image:F347B11C-142A-4EFC-821F-9B3F36B68119-665-000000B8AF4E15D4/_____640.jpeg] 然后，我们可以单击该用户以进入下一个屏幕。我们将通过单击并输入金额和描述输入来完成交易表格。\n[image:1A5CFBED-CD31-4912-90A1-960E05992DC7-665-000000B8AF4DE240/______640.jpeg]\n注意命令日志中生成的命令。\n现在是时候完成交易了。您可能已经注意到，在我们输入输入之前，“支付”按钮已被禁用。为了确保我们的表单验证正常工作，让我们添加一个断言以确保启用“支付”按钮。\n[image:F3E5EBF7-FB37-4A50-AF65-607939F664F0-665-000000B8AF4DAF00/_______640.jpeg]\n最后，我们将单击“支付”按钮，并显示我们新交易的确认页面。\n[image:AFF8F1D8-4FDC-42DF-BEEA-EDB769B0588A-665-000000B8AF4D783F/________640.jpeg]\n要放弃交互，请单击“取消”按钮退出 Cypress Studio。如果对与应用程序的交互感到满意，请单击“保存命令”，测试代码将保存到您的规范文件中。或者，您可以选择“复制”按钮以将生成的命令复制到剪贴板。\n生成的测试代码 查看我们的测试代码，我们可以看到在点击“Save Commands”后测试更新了我们在 Cypress Studio 中记录的操作。\n添加新测试 您可以通过单击我们定义的块上的“Add New Test”来向任何现有 describe 或块添加新测试。 context describe\n[image:0A8CA77E-9AEF-45B9-9B70-F15C01983DFF-665-000000B8AF4D4166/_________640.jpeg]\n我们被启动到 Cypress Studio 并可以开始与我们的应用程序交互以生成测试。\n对于此测试，我们将添加一个新的银行帐户。我们的互动如下：\n点击左侧导航中的“银行账户” [image:02219635-D587-4A52-BD45-738DA52F08E2-665-000000B8AF4D0E28/__________640.jpeg]\n点击银行账户页面上的“创建”按钮 [image:42C66725-A8B3-4ED6-9472-C0A0FF5AB64A-665-000000B8AF4CD946/___________640.jpeg]\n填写银行账户信息 [image:2E4443DE-C9A6-4D7A-84BB-6E6A5AA3F476-665-000000B8AF4CA262/____________640.jpeg]\n点击“保存”按钮 [image:655AAC92-065E-438E-B62C-145A771AD889-665-000000B8AF4C6D6F/_____________640.jpeg]\n要放弃交互，请单击“取消”按钮退出 Cypress Studio。\n如果对与应用程序的交互感到满意，请单击“保存命令”，提示将询问测试名称。单击“保存测试”，测试将保存到文件中。\n[image:A9CFD28A-A32C-42B5-97D7-7BD34A46D85F-665-000000B8AF4C390B/______________640.jpeg]\n保存后，该文件将在 Cypress 中再次运行。\n[image:560BE965-9C4C-4E9A-A17F-4992200B053B-665-000000B8AF4BF3D8/_______________640.jpeg]\n最后，查看我们的测试代码，我们可以看到点击“Save Commands”后测试更新了我们在 Cypress Studio 中记录的操作。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo6/","summary":"Cypress Studio 提供了一种在测试运行程序中生成测试的可视化方法，通过记录与被测应用程序的交互。支持.click（）、.type（）、.check（）、.uncheck（）和.select（）Cypress 命令，这些命令将在与 Cypress Studio 内部的 DOM 交互时生成测试代码\n通过阅读文章你会学到什么：\n如何使用 Cypress Studio 以交互方式扩展测试\n如何使用 Cypress Studio 以交互方式添加新测试\n概述 Cypress Studio 通过记录与 被测应用程序的交互，提供了一种在 Test Runner 中生成测试的可视化方式。\n支持、.click()、.type()、和 Cypress 命令 .check() ，并在与 Cypress Studio 内部的 DOM 交互时生成测试代码。您还可以通过右键单击要断言的元素来生成断言。 .uncheck() .select()\n使用 Cypress Studio Cypress Studio 是一项实验性功能，可以通过将 experimentalStudio 属性添加到您的配置文件来启用（ cypress.json 默认情况下）。\n{ \u0026#34;experimentalStudio\u0026#34;: true} Cypress Real World App (RWA) 是一个开源项目，它实现了一个支付应用程序，以展示 Cypress 测试方法、模式和工作流程的实际使用情况。下面将使用它来演示 Cypress Studio 的功能。\n扩展测试 您可以扩展任何预先存在的测试，或者通过使用以下测试脚手架在您的 integrationFolder（默认情况下）中创建一个新测试来开始。\n第 1 步 - 运行用例 我们将使用 Cypress Studio 执行“新交易”用户流程。首先，启动 Test Runner 并运行在上一步中创建的用例。","title":"Cypress UI 自动化测试框架学习（6）- 用例编辑和脚本录制工具 Cypress Studio 介绍"},{"content":"Cypress UI 自动化测试框架学习（5）- 命令大全 命令大全 and：创建断言 as：创建别名 blur：失去焦点 check：选中 check 或者 radio children：获取一组 DOM 元素中每个元素的子元素 clear：清除 input 或者 textarea 的值 clearCookie：清除特定的浏览器 cookie clearCookies：清除浏览器的所有 cookie clearLocalStorage：清除 localstorage 的数据 click：点击 DOM 元素 clock：覆盖全局与时间相关的函数 closest：获取与选择器匹配的第一个 DOM 元素 contains：获取包含文本的 DOM 元素 dblclick：双击 DOM 元素 debug：设置调试器并记录上一个命令产生的内容 document：获取 window.document 对象 each：迭代数组结构 end：结束一系列命令 eq：在元素数组中获取特定索引的 DOM 元素 exec：执行系统命令 filter：获取特定选择器匹配的元素 find：查找特定选择器的特定后代元素 first：获取一组 DOM 元素中的第一个 DOM 元素 fixture：加载文件中的数据集 focus：使一个 DOM 元素获取焦点 focused：获取当前获取焦点的 DOM 元素 get：通过选择器或者别名获取一个或者多个 DOM 元素 getCookie：获取浏览器的特定 cookie getCookies：获取浏览器的所有 cookie go：前进或者后退 hash：获取当前页面地址的哈希值 hover：不存在这个命令 invoke：在前边生成的主题上调用函数 its：获取前边生成的主题的属性值 last：获取一组 DOM 元素的最后一个 DOM 元素 location：获取活动页面的 window.location 对象 log：打印 cypress 日志信息 next：获取紧接的下一个兄弟 DOM 元素 nextAll：获取所有兄弟 DOM 元素 nextUntil：获取一组匹配的 DOM 元素中的每个后续兄弟元素，不包括提供的元素 not：过滤 DOM 元素 parent：获取父元素 parents：获取所有的父元素 parentsUntil：获取所有的父元素，不包括提供的元素 pause：暂停执行 cypress 命令 prev：获取前一个兄弟节点 prevAll：获取前边的所有兄弟节点 prevUntil：获取前边所有的兄弟节点，不包括提供的元素 readFile：读取文件内容 reload：重新加载页面 request：发送 HTTP 请求 root：获取页面根节点 route：管理网络请求的行为 screenshot：生成截图 scrollIntoView：将元素滚动到视图中 scrollTo：滚动到特定位置 select：选择 select 中的 option server：启动服务器开始讲响应路由到 cy.route() 和 cy.request() setCookie：设置浏览器 cookie should：创建断言，同 and() siblings：获取兄弟 DOM 元素 spread：将数组扩展为多个参数 spy：包装方法，记录函数的调用和参数 stub：替换函数，记录其用法并控制其行为 submit：提交一个表单 task：通过 task 插件，在 Node.js 中执行代码 then：使用上一个命令产生的结果 tick：移动时间 title：获取活动页面的 document.title trigger：触发 DOM 元素上的事件 type：给 DOM 元素输入内容 uncheck：取消选中复选框 url：获取当前活动页面的 URL viewport：控制应用程序的屏幕大小和方向 visit：访问远程 URL wait：等待方法 window：获取当前活动窗口的 window 对象 within：将后续命令限制在此元素内 wrap：产生传递给 .wrap() 的对象 writeFile：写入指定内容到文件 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo5/","summary":"Cypress UI 自动化测试框架学习（5）- 命令大全 命令大全 and：创建断言 as：创建别名 blur：失去焦点 check：选中 check 或者 radio children：获取一组 DOM 元素中每个元素的子元素 clear：清除 input 或者 textarea 的值 clearCookie：清除特定的浏览器 cookie clearCookies：清除浏览器的所有 cookie clearLocalStorage：清除 localstorage 的数据 click：点击 DOM 元素 clock：覆盖全局与时间相关的函数 closest：获取与选择器匹配的第一个 DOM 元素 contains：获取包含文本的 DOM 元素 dblclick：双击 DOM 元素 debug：设置调试器并记录上一个命令产生的内容 document：获取 window.document 对象 each：迭代数组结构 end：结束一系列命令 eq：在元素数组中获取特定索引的 DOM 元素 exec：执行系统命令 filter：获取特定选择器匹配的元素 find：查找特定选择器的特定后代元素 first：获取一组 DOM 元素中的第一个 DOM 元素 fixture：加载文件中的数据集 focus：使一个 DOM 元素获取焦点 focused：获取当前获取焦点的 DOM 元素 get：通过选择器或者别名获取一个或者多个 DOM 元素 getCookie：获取浏览器的特定 cookie getCookies：获取浏览器的所有 cookie go：前进或者后退 hash：获取当前页面地址的哈希值 hover：不存在这个命令 invoke：在前边生成的主题上调用函数 its：获取前边生成的主题的属性值 last：获取一组 DOM 元素的最后一个 DOM 元素 location：获取活动页面的 window.","title":"Cypress UI 自动化测试框架学习（5）- 命令大全"},{"content":"下面的信息是自动化测试框架学习第四篇数据驱动方法封装参数化和测试框架的介绍。 在自动化测试框架学习中，有很多方法可以用来驱动测试框架。例如，数据驱动方法封装参数化和测试框架。这两个方法都可以将测试框架的数据处理和预设环境等现有模型结合起来。这样就可以方便地开发、测试和运行新的测试框架。\n测试数据驱动 js 格式测试数据驱动 简介 数据以 js 格式存储，使用 js 的 import 方法导入使用\n使用方法 新建测试数据 js 文件 示例：在项目的 cypress/integration 文件夹下新建 testData 目录，然后在该目录下创建一个 js 文件，示例文件名为：testLogin.data.js\ntestLogin.data.js 示例代码如下：\nexport const testLoginUserEmail = [ { summary: \u0026#34;正确邮箱账号登录验证\u0026#34;, username:\u0026#34;dengnao.123@163.com\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserId = [ { summary: \u0026#34;正确id账号登录验证\u0026#34;, username:\u0026#34;waitnoww\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserMobilephone = [ { summary: \u0026#34;正确手机号账号登录验证\u0026#34;, username:\u0026#34;18888139031\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_js.js\n示例代码如下：\nimport { testLoginUserEmail, testLoginUserId, testLoginUserMobilephone } from \u0026#34;./testData/testLogin.data\u0026#34;; // 测试用例 describe(\u0026#34;光谷社区登录验证\u0026#34;, function () { // 执行用例执行用例之前先进入首页 beforeEach(function () { // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) //正确邮箱账号登录 it(testLoginUserEmail[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserEmail[0].username) //输入邮箱用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserEmail[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确ID账号登录 it(testLoginUserId[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserId[0].username) //输入ID用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserId[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确手机账号登录 it(testLoginUserMobilephone[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserMobilephone[0].username) //输入手机号用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserMobilephone[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }) // 执行用例执行用例之后清除登录信息 afterEach(function () { // 清除cookies cy.clearCookies() }) }) 运行测试用例 运行脚本：npm run cypress:open 点击运行 testLogin_guanggoo_data_by_js.js 用例 查看运行结果 (测试数据能正常获取到) fixture 测试数据驱动介绍 fixture 数据驱动方式是 cypress 框架推荐的方法，支持的格式也很多，如.json/txt/html/jpg/gif/mp3/zip 等，具体可参考：https://docs.cypress.io/api/commands/fixture\n简介 Cypress 使用 cypress/fixture 目录存放 json 文件数据，cy.fixture() 加载测试数据，如果不指定文件路径，默认从 cypress/fixtures 文件下去查找，也可以自己设置文件路径\n使用方法 以 json 格式读取举例介绍\n新建测试数据 json 文件 示例：在项目的 cypress/fixtures 文件夹下新建一个 json 文件，示例文件名为：testLoginData.json\ntestLoginData.json 示例代码如下（账号密码记得换成自己的）：\n\u0026#34;testLoginUserEmail\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确邮箱账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;dengnao.123@163.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; }, \u0026#34;testLoginUserId\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确 id 账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;waitnoww\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; }, \u0026#34;testLoginUserMobilephone\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确手机号账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;18888889031\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; } } 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_fixture.js\n示例代码如下：\ndescribe(\u0026#34;光谷社区登录验证\u0026#34;, function () { // 执行用例执行用例之前先进入首页 beforeEach(function () { // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 // 获取测试数据 cy.fixture(\u0026#39;testLoginData.json\u0026#39;).as(\u0026#39;loginData\u0026#39;) }) //正确邮箱账号登录 it(\u0026#34;正确邮箱账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserEmail.username) //输入邮箱用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserEmail.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确ID账号登录 it(\u0026#34;正确id账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserId.username) //输入ID用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserId.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确手机账号登录 it(\u0026#34;正确手机号账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserMobilephone.username) //输入手机号用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserMobilephone.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }) // 执行用例执行用例之后清除登录信息 afterEach(function () { // 清除cookies cy.clearCookies() }) }) 运行测试用例 运行脚本：npm run cypress:open 点击运行 testLogin_guanggoo_data_by_fixture.js 用例 查看运行结果 (测试数据能正常获取到) 方法封装参数化 简介 cypress 框架提供了一个 commands.js 可以自定义各种命令，用来封装各种通用方法，参数化方法，常用脚本等；\n将常用的通用方法如登录方法在 cypress/support/commands.js 中编写完成之后，与 cy.get()/cy.visit() 一样，可以直接用 cy.xxx() 形式调用，非常方便，减少维护成本\n使用介绍 示例会介绍常用的参数化登录命令和进入首页命令\n登录参数化登录封装 代码编写 打开 cypress/support/commands.js 文件 输入如下代码： Cypress.Commands.add(\u0026#34;login\u0026#34;,(username,password) =\u0026gt; { cy.clearCookies() //清除 cookies,保证页面为未登录状态 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问 url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标 url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(username) //输入参数化的用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(password) //输入参数化的密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;:nth-child(2) \u0026gt; .nav-collapse\u0026#39;).should(\u0026#39;contain\u0026#39;, \u0026#39;设置\u0026#39;) //验证登录成功回到首页，设置按钮展示正确 }) 代码使用 在测试用例中可直接进行方法调用 cy.login(username,password) 换成自己的账号密码进行登录操作了 cy.login(\u0026#34;dengnao.123@163.com\u0026#34;,\u0026#34;xxxx\u0026#34;) 进入首页方法封装 代码编写 打开 cypress/support/commands.js 文件 输入如下代码： Cypress.Commands.add(\u0026#34;initHomePage\u0026#34;,() =\u0026gt; { cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问 url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标 url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) 代码使用 在测试用例中可直接进行方法调用 cy.initHomePage() 即可进入首页 cy.initHomePage() 测试框架介绍 简介 Cypress 框架采用了 Mocha 框架的语法，故 Mocha 框架的测试语法可在 cypress 上直接使用\n语法介绍 describe() 定义测试套件，里面还可以定义多个 context 或 it\ncontext() 定义测试套件，是 describe() 的别名，可以替代 describe\nit() 定义测试用例\nbefore() 在一个测试套件中的所有测试用例之前执行，设置一些运行 testcase 的前置条件\n// runs once before the first test in this block }); beforeEach() 在每个测试用例之前执行\n// 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) afterEach() 在每个测试用例之后执行，可以执行清除数据等操作\n// 清除 cookies cy.clearCookies() }) after() 在一个测试套件中的所有测试用例之后执行\n// runs once after the last test in this block }); .only() 设置只执行某个 testcase/testsuite\ndescribe.only(\u0026#39;#indexOf()\u0026#39;, function() { // ... }); }); .skip() 设置跳过执行某个 testcase/testsuite\ndescribe(\u0026#39;#indexOf()\u0026#39;, function() { it.skip(\u0026#39;should return -1 unless present\u0026#39;, function() { // this test will not be run }); it(\u0026#39;should return the index when present\u0026#39;, function() { // this test will be run }); }); }); 参考网址 https://docs.cypress.io/guides/references/bundled-tools#Mocha 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo4/","summary":"下面的信息是自动化测试框架学习第四篇数据驱动方法封装参数化和测试框架的介绍。 在自动化测试框架学习中，有很多方法可以用来驱动测试框架。例如，数据驱动方法封装参数化和测试框架。这两个方法都可以将测试框架的数据处理和预设环境等现有模型结合起来。这样就可以方便地开发、测试和运行新的测试框架。\n测试数据驱动 js 格式测试数据驱动 简介 数据以 js 格式存储，使用 js 的 import 方法导入使用\n使用方法 新建测试数据 js 文件 示例：在项目的 cypress/integration 文件夹下新建 testData 目录，然后在该目录下创建一个 js 文件，示例文件名为：testLogin.data.js\ntestLogin.data.js 示例代码如下：\nexport const testLoginUserEmail = [ { summary: \u0026#34;正确邮箱账号登录验证\u0026#34;, username:\u0026#34;dengnao.123@163.com\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserId = [ { summary: \u0026#34;正确id账号登录验证\u0026#34;, username:\u0026#34;waitnoww\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserMobilephone = [ { summary: \u0026#34;正确手机号账号登录验证\u0026#34;, username:\u0026#34;18888139031\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_js.js\n示例代码如下：\nimport { testLoginUserEmail, testLoginUserId, testLoginUserMobilephone } from \u0026#34;.","title":"Cypress UI 自动化测试框架学习（4）- 数据驱动，方法封装参数化和测试框架"},{"content":"下面的信息是对于框架学习第 3 篇的介绍。在该篇文章中，我们学习了如何使用元素定位、操作和断言。该框架可以帮助用户定位相关的元素，并且可以帮助用户进行操作。这些操作可以帮助用户断言事件。\n元素定位 谈到 UI 自动化测试，不管是 web 端还是移动端，页面元素的各种操作在编写测试脚本时都会涉及，如果想写出高通过率和高健壮性的自动化测试用例，必须要确保正确高效的页面元素识别和使用。\ncypress 框架除了支持常用的元素定位，还提供了好用的 JQuery css 选择器。\n下面会介绍常用的元素定位方法，常用的定位方式，以及框架自带可视化自助元素定位方法\n常用元素定位 #id 定位 描述：通过元素的 id 属性来定位\n前提：定位的元素 css 样式须存在 id 属性且唯一\n//元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码 cy.get('#email') .class 定位 描述：通过元素的 class 属性来定位\n前提：定位的元素 css 样式存在 class 属性且唯一\n//元素前端代码示例 \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;img width=\u0026quot;150\u0026quot; height=\u0026quot;28\u0026quot; border=\u0026quot;0\u0026quot; align=\u0026quot;default\u0026quot; alt=\u0026quot;光谷社区\u0026quot; src=\u0026quot;http://cdn.guanggoo.com//static/images/guanggoonew.png\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\n示例代码 cy.get('.navbar-brand')\nname 定位 描述：通过元素 name 定位\n前提：定位的元素 css 样式存在 name 属性且唯一 //元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码\ncy.get('input[name=\u0026quot;email\u0026quot;]')\n常用定位方式 .get() 描述：使用 get() 定位元素，定位元素用 CSS selectors，跟 jQuery 一样 示例代码 cy.get('#email')\n.contains() 描述：可以使用 cy.contains（）根据元素的内容找到元素\n示例代码\ncy.contains(‘value’) cy.get(‘div[name=“div_name”]’).contains(‘value’)\n.within() 描述：可以在特定的 DOM 元素中找到元素\n示例代码\ncy.get('.query-form').within(() =\u0026gt; { cy.get('input:first').should('have.attr', 'placeholder', 'Email') cy.get('input:last').should('have.attr', 'placeholder', 'Password') })\nCypress.$ 描述：Cypress 也提供了 JQuery 选择器，调用 Cypress.$(\u0026lsquo;button\u0026rsquo;）会自动在您的窗口中查询元素。换句话说，Cypress 会自动将文档设置为您当前通过 cy.visit() 导航到的任何内容，这是从开发人员工具调试时同步查询元素的好方法。\n示例代码\nCypress.$(selector) // other proxied jQuery methods Cypress.$.Event Cypress.$.Deferred Cypress.$.ajax Cypress.$.get Cypress.$.getJSON Cypress.$.getScript Cypress.$.post\n框架自带可视化自助元素定位 1.前提：demo 代码已经跑起来 (运行脚本：npm run cypress:open) 2.点击运行调试用例，进入定位元素对应的页面 3.在页面上选择瞄准镜标识（open selector playground）\n4.选择页面上的元素区域，元素的定位信息就会展示在定位信息展示区域，点击复制就可使用\n元素常用操作 .click() 描述：单击\n示例代码\ncy.get('.btn-success').click()\n.type(value) 描述：输入内容\n示例代码 cy.get(‘input[name=“username”]’).type(\u0026lsquo;dengnao.123@163.com\u0026rsquo;)``\n.clear() 描述：清空输入内容\n示例代码\ncy.get(‘[type=“text”]’).clear()\n.submit() 描述：提交表单\n示例代码\ncy.get(‘.ant-input’).submit()\n.dbclick()/.rightclick() 描述：鼠标双击操作/鼠标右击操作\n示例代码\ncy.get('.menu').rightclick() // 鼠标右击 .menu 菜单元素\n.select() 描述：针对元素选择一个选项\n示例代码\ncy.get('color').select('red') // 颜色选项中选择红色\n.check()/.uncheck() 描述：单选或多选进行勾选/取消选中 (反选)\n示例代码\ncy.get('[type=\u0026quot;checkbox\u0026quot;]').check() // 对 checkbox 进行选中操作 cy.get('[type=\u0026quot;checkbox\u0026quot;]').uncheck() // 对 checkbox 进行取消选中操作\n.focus()/.blur() 描述：对选项进行聚焦/失焦操作\n示例代码\ncy.get(‘input[name=“username”]’).focus() //对于用户名输入框进行聚焦操作\n断言 BDD 断言 断言类型 .should()： 描述：创建断言，断言会自动重试，直到它们通过或超时。\n示例代码\ncy.get(‘.ant-checkbox).should(‘be.checked’)\n.expect()： 描述：预期结果\n示例代码\nexpect(name).to.not.equal(‘dengnao.123@163.com’)\n常用断言 可参考官网文档:https://docs.cypress.io/guides/references/assertions#BDD-Assertions\nTDD 断言 断言类型 .assert()： 描述：断言\n示例代码\nassert.equal(3,3,’vals equal’)\n常用断言 可参考官网文档:https://docs.cypress.io/guides/references/assertions#TDD-Assertions\n常用断言 针对长度（length）的断言 `//重试，直到找到 3 个匹配的\u0026lt;li.selected\u0026gt; cy.get('li.selected').should('have.length',3)` 针对类（Class）的断言 `//重试，直到 input 元素没有类被 disabled 为止（或者超时为止） cy.get('from').fijd('input').should('not.have.class','disabled')` 针对值（Value）断言 `//重试，直到 textarea 的值为‘iTesting’ cy.get('textarea').should('have.value','iTesting')` 针对文本内容（Text Content）的断言 //重试，直到这个 span 不包含“click me”字样 cy.get('a').parent('span.help').should('not.contain','click me') //重试，直到这个 span 包含“click me”字样 cy.get('a').parent('span.help').should('contain','click me')\n针对元素可见与否（Visibility）的断言 //重试，直到这个 button 是可为止 cy.get('button').should('be.visible')\n针对元素存在与否（Existence）的断言 //重试，直到 id 为 loading 的 spinner 不在存在 cy.get('#loading').should('not.exist')\n针对元素状态的（status）的断言 `//重试，直到这个 radio button 是选中状态 cy.get('：radio').should('be.checked')` 针对 CSS 的断言 `//重试，直到 completed 这个类有匹配的 css 为止 cy.get('.completed').should('have.css','text-decoration','line-through')` 运行出错问题记录 运行 npm run cypress:open 报错，提示 No version of Cypress is installed 报错截图如下： 修复方式 //项目根目录下运行如下命令即可解决 ./node_modules/.bin/cypress install\n原因 电脑使用过清理软件，安装的 cypress 缓存信息被删除了，重新安装就好\n运行 npm run cypress:open 报错，提示 Cypress verification timed out 报错截图如下： 修复方式 重新运行 npm run cypress:open 尝试即可\n原因 电脑 cypress 验证超时了，一般重新操作即可恢复\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo3/","summary":"下面的信息是对于框架学习第 3 篇的介绍。在该篇文章中，我们学习了如何使用元素定位、操作和断言。该框架可以帮助用户定位相关的元素，并且可以帮助用户进行操作。这些操作可以帮助用户断言事件。\n元素定位 谈到 UI 自动化测试，不管是 web 端还是移动端，页面元素的各种操作在编写测试脚本时都会涉及，如果想写出高通过率和高健壮性的自动化测试用例，必须要确保正确高效的页面元素识别和使用。\ncypress 框架除了支持常用的元素定位，还提供了好用的 JQuery css 选择器。\n下面会介绍常用的元素定位方法，常用的定位方式，以及框架自带可视化自助元素定位方法\n常用元素定位 #id 定位 描述：通过元素的 id 属性来定位\n前提：定位的元素 css 样式须存在 id 属性且唯一\n//元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码 cy.get('#email') .class 定位 描述：通过元素的 class 属性来定位\n前提：定位的元素 css 样式存在 class 属性且唯一\n//元素前端代码示例 \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;img width=\u0026quot;150\u0026quot; height=\u0026quot;28\u0026quot; border=\u0026quot;0\u0026quot; align=\u0026quot;default\u0026quot; alt=\u0026quot;光谷社区\u0026quot; src=\u0026quot;http://cdn.guanggoo.com//static/images/guanggoonew.png\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\n示例代码 cy.get('.navbar-brand')\nname 定位 描述：通过元素 name 定位\n前提：定位的元素 css 样式存在 name 属性且唯一 //元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;","title":"Cypress UI 自动化测试框架学习（3）- 元素定位，操作和断言"},{"content":"下面的信息是介绍 cypress 自动化测试框架学习第 3 篇的测试报告的内容 主要介绍一下如何去使用不同格式的 cypress 自动化测试报告模版\n写在前面 由于 Cypress 测试报告是建立在 Mocha 测试报告之上的，这意味着任何为 Mocha 构建的报告程序都可以与 Cypress 一起使用。\n以下是内置的 Mocha 测试类型列表（Cypress 也同样支持）：https://mochajs.org/#reporters\n前置准备工作 在 package.json 文件的 scripts 模块加入了如下脚本：\u0026ldquo;cypress:run\u0026rdquo;:\u0026ldquo;cypress run\u0026rdquo;，便于后面生成报告\n不同运行脚本的区别：\ncypress run：是以无头浏览器模式跑测试用例文件夹下的所有测试用例 cypress open：会打开测试用例集的界面，需要手动运行 常用报告类型 spec 格式报告 运行命令 $ npm run cypress:run --reporter=spec 报告截图 Dot 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026quot;: \u0026ldquo;dot\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 json 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;json\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 List 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;list\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 NYAN 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;nyan\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 高大上报告类型 Mochawesome 格式报告 前置：安装 Mocha、Mochawesome 至项目中 npm install --save-dev mocha npm install --save-dev mochawesome 在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;mochawesome\u0026quot;信息\n运行命令\n$ npm run cypress:run 报告截图 allure 格式报告 前置：安装 allure（推荐使用 brew 安装） $ brew install allure 在 cypress.json 文件新增如下信息 \u0026#34;reporter\u0026#34;: \u0026#34;junit\u0026#34;, \u0026#34;reporterOptions\u0026#34;: { \u0026#34;mochaFile\u0026#34;: \u0026#34;results/test_report_[hash].xml\u0026#34;, \u0026#34;toConsole\u0026#34;: true } 运行命令 $ npm run cypress:run 生成报告 $ allure serve results 报告截图 Dashboard 格式报告 待完善，参考资料：https://docs.cypress.io/guides/dashboard/introduction#Features\n运行命令 npx cypress run --record --key 7aaee33b-f67b-4993-8d6c-2c392a1bd1c8 报告截图 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo2/","summary":"下面的信息是介绍 cypress 自动化测试框架学习第 3 篇的测试报告的内容 主要介绍一下如何去使用不同格式的 cypress 自动化测试报告模版\n写在前面 由于 Cypress 测试报告是建立在 Mocha 测试报告之上的，这意味着任何为 Mocha 构建的报告程序都可以与 Cypress 一起使用。\n以下是内置的 Mocha 测试类型列表（Cypress 也同样支持）：https://mochajs.org/#reporters\n前置准备工作 在 package.json 文件的 scripts 模块加入了如下脚本：\u0026ldquo;cypress:run\u0026rdquo;:\u0026ldquo;cypress run\u0026rdquo;，便于后面生成报告\n不同运行脚本的区别：\ncypress run：是以无头浏览器模式跑测试用例文件夹下的所有测试用例 cypress open：会打开测试用例集的界面，需要手动运行 常用报告类型 spec 格式报告 运行命令 $ npm run cypress:run --reporter=spec 报告截图 Dot 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026quot;: \u0026ldquo;dot\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 json 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;json\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 List 格式报告 前置：在 cypress.","title":"Cypress UI 自动化测试框架学习（2）- 测试报告"},{"content":"下面的信息是对 Cypress 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\nIntroduction 基于 JavaScript 的前端自动化测试工具，可以对浏览器中运行的任何内容进行快速、简单、可靠的测试\nCypress 是自集成的，提供了一套完整的端到端测试，无须借助其他外部工具，安装后即可快速地创建、编写、运行测试用例，且对每一步操作都支持回看\n不同于其他只能测试 UI 层的前端测试工具，Cypress 允许编写所有类型的测试，覆盖了测试金字塔模型的所有测试类型【界面测试，集成测试，单元测试】\nCypress 官网：https://www.cypress.io/\nGetting Started 下面以 MacOS 来进行介绍，其他系统可参考官网信息\nOperating System macOS 10.9 and above (64-bit only) Node.js 12 or 14 and above Before Started 已安装好 node.js 和 npm 已安装好 vs code 或者其他代码编辑器 Started and Run Step1：通过 npm 新建项目 # 新建项目文件夹 $ mkdir cypress-demo # 进入项目文件夹 $ cd cypress-demo # npm项目环境准备 $ npm init Step2：安装 cypress # 项目安装cypress包 $ npm install cypress --save-dev Step3：运行 cypress 程序 若提示：npm ERR! missing script: cypress:open，可在项目根目录 package.json 文件的 scripts 下新增\u0026quot;cypress:open\u0026quot;: \u0026ldquo;cypress open\u0026rdquo;，保存后再次运行命令即可\n# 启动demo $ npm run cypress:open Started Screenshot 运行截图 demo 用例执行截图 Try First Testscript Testcase 1.访问光谷社区主页http://www.guanggoo.com/ 2.验证是否正确跳转到光谷社区页面 3.验证网页标题是否正确 4.点击登录按钮，验证正确跳转到登录页面 5.在登录页面输入用户名和输入密码 6.点击登录按钮，验证登录成功 Testscript 在项目 cypress/integration 下新建 demo 文件夹\n在 demo 文件夹下新建 demo-guanggoo.js\ndemo-guanggoo.js 编写测试脚本\n脚本中账号密码需换成自己的账号密码\ndescribe(\u0026#39;first testcase for cypress\u0026#39;,function(){ it(\u0026#39;visit guanggoo homepage and login for guanggoo:\u0026#39;,function(){ // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;,\u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;,\u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;,\u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(\u0026#39;dengnao.123@163.com\u0026#39;) //输入用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(\u0026#39;xxxxxxx\u0026#39;) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 }) }) Run Screenshot 运行 cypress 程序 # 启动 $ npm run cypress:open 页面上选择点击运行 demo-guanggoo.js 即可 运行通过无报错，代表用例编写成功 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo1/","summary":"下面的信息是对 Cypress 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\nIntroduction 基于 JavaScript 的前端自动化测试工具，可以对浏览器中运行的任何内容进行快速、简单、可靠的测试\nCypress 是自集成的，提供了一套完整的端到端测试，无须借助其他外部工具，安装后即可快速地创建、编写、运行测试用例，且对每一步操作都支持回看\n不同于其他只能测试 UI 层的前端测试工具，Cypress 允许编写所有类型的测试，覆盖了测试金字塔模型的所有测试类型【界面测试，集成测试，单元测试】\nCypress 官网：https://www.cypress.io/\nGetting Started 下面以 MacOS 来进行介绍，其他系统可参考官网信息\nOperating System macOS 10.9 and above (64-bit only) Node.js 12 or 14 and above Before Started 已安装好 node.js 和 npm 已安装好 vs code 或者其他代码编辑器 Started and Run Step1：通过 npm 新建项目 # 新建项目文件夹 $ mkdir cypress-demo # 进入项目文件夹 $ cd cypress-demo # npm项目环境准备 $ npm init Step2：安装 cypress # 项目安装cypress包 $ npm install cypress --save-dev Step3：运行 cypress 程序 若提示：npm ERR!","title":"Cypress UI 自动化测试框架学习（1）- 上手"}]