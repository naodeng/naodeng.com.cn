[{"content":"第 7 天：研究并分享提示词工程技术 哇哦！我们已经来到“30 天 AI 测试挑战活动”的第 7 天！ :then: 在这一周里，我们已经涵盖了许多关于理解人工智能概念、工具和实际影响的内容。\n现在，让我们专注于利用人工智能的一个关键技能：提示词工程。提示词工程是设计提示词以从人工智能获取更好输出的实践。你今天的挑战是发现并分享有效的提示词工程技术。\n任务步骤 研究提示词工程： 对有效的提示词工程技术进行一些研究。\n分享你的发现： 在这个主题的回复中分享你发现的 2-3 种提示词工程技术，这些技术对你来说可能是相关的、有用的或新颖的。可以链接到你发现的任何有帮助的资源。\n以下是一个示例，可以指导你的回复：\n提示词技术 1：[名称] 工作原理：[简要描述] 潜在影响：[它如何改善人工智能输出] 有用资源：https://www.promptingguide.ai/ 参与原因 增强与人工智能的交互： 学习并应用提示工程技术可以改善你使用人工智能工具的方式，实现更准确和相关的输出。\n分享与学习： 通过分享你的发现并讨论提示工程策略，你为整个社区的知识库做出了贡献，帮助其他人完善他们与人工智能的交互。\n任务链接 https://club.ministryoftesting.com/t/day-7-research-and-share-prompt-engineering-techniques/74862\n我的第七天任务 入门 Prompt：我最开始是通过这个 Github 项目awesome-chatgpt-prompts来模仿和练习编写自己想要的 Prompt\nPrompt 技巧学习：一本免费的电子书，名称为\u0026quot;The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts\u0026ldquo;来帮助我提升编写提示词的能力和效率。\n关于 Prompt 很有意思的话：没想到答案，就不要寻找题目。以这个原则去编写 Prompt，对我很有效\n关于 Prompt 的要求：会提问，提问的艺术：尝试明确描述问题，一次把问题和想要的解决方案说清楚。\n我常用的 Prompt 技巧：我现在常用的 Prompt 一般包含这三个内容：背景 + 约束条件 + 目标 + 期望回答\n描述清楚背景： 常用 给出的 Prompt 背景中，一般会包含以下信息： - 角色 (WHO)——指定 Prompt 的角色以及相关的角色。 - 地点 (WHERE)——指定 Prompt 的地域，如果你希望得到针对性的解决方案，给出具体的地域可能得到的结果会合适，避免文化差异。 - 事件 (WHAT)——指定 Prompt 具体发生的事情。 - 时间 (WHEN)——指定 Prompt 事件发生的时间。 再来明确目标：你想从 AI 的回答中获得什么结果\n添加约束条件：对 Prompt 所描述场景中的人力/时间/物质等约束\n最后设定期望回答：例如要求结果的具体格式（markdown，english，chinese 等），或者要求输出多种方案让我来选择更好的\n社区中回复结果的资源 Prompt 工程指南 https://www.promptingguide.ai/ 思维链 Prompt https://www.promptingguide.ai/techniques/cot 计算机视觉中的零样本学习是什么？ https://blog.roboflow.com/zero-shot-learning-computer-vision/#:~:text=Zero%2DShot%20Learning%20(ZSL),new%20objects%20on%20their%20own 解锁 React Prompt 的力量 https://blog.nimblebox.ai/react-prompting-revolutionizing-language-models Few-Shot Prompt https://www.promptingguide.ai/techniques/fewshot Prompt 工程教程：全面指南及示例和最佳实践 https://www.lambdatest.com/learning-hub/prompt-engineering Prompt 的要素 https://www.promptingguide.ai/introduction/elements 精通 Prompt 技术：自一致性提示 https://www.promptingguide.ai/introduction/elements Prompt 工程是过去的工作 https://www.wearedevelopers.com/magazine/prompt-engineering-is-a-job-of-the-past 关于活动 30 天 AI 测试挑战活动是 Ministry 测试社区发起的活动，上一次我了解这个社区是关于他们发起的 30 天敏捷测试的活动。\n社区官网：https://www.ministryoftesting.com\n活动链接：https://www.ministryoftesting.com/events/30-days-of-ai-in-testing\n推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/event/30-days-of-ai-in-testing-day-7-research-and-share-prompt-engineering-techniques/","summary":"这篇博文是 30 天 AI 测试挑战活动的第七天，要求参与者研究并分享即时工程技术。博文可能包括对即时工程技术的定义、其在测试领域的应用、相关工具和技术的介绍，以及作者对即时工程技术的看法。通过分享关于即时工程技术的研究，读者将能够了解其在测试中的潜在价值，以及如何有效地应用这一技术。这个系列活动有望为测试专业人士提供一个深入了解和讨论新兴技术的平台。","title":"30 天 AI 测试挑战活动：第七天：研究并分享提示词工程技术"},{"content":"第 6 天任务：探索并分享对 AI 测试工具的见解 我们已经进入“30 天 AI 测试挑战”的第 6 天！昨天，我们探讨了 AI 在实际中的例子。今天，让我们专注于特定的 AI 辅助测试工具，这些工具满足您在测试过程中特定的需求。\n任务步骤 1. 选择测试需求 选择一个在测试中满足您感兴趣的测试需求的 AI 应用（例如，测试用例生成，测试数据管理等）。\n提示：查看第 3 天挑战的回复，获取关于 AI 用途的想法，或者专注于您昨天发现的 AI 应用。\n2. 研究和分析 AI 测试工具 接下来，研究三个或更多使用 AI 解决您确定的测试需求的 AI 测试工具。列出几个工具，做相关注解，并比较它们在您看重的要求和功能上的区别。\n提示：@shwetaneelsharma的有关比较工具方法的讲座可能有助于您的分析。\n3. 分享您的发现 最后，通过回复此主题分享您对这些工具的发现。考虑分享：\n每个工具的简要概述 主要功能 您对它们对效率或测试流程潜在影响的看法 您最感兴趣的工具及其原因 为什么参与 增强工具包: 通过探索 AI 辅助工具，您正在寻找潜在的资源，以帮助使您的测试更加智能和高效。\n社区智慧: 与社区分享和讨论这些工具，使我们能够从彼此的研究和经验中学习，拓宽我们对 AI 在测试中作用的共同理解。\n任务链接 https://club.ministryoftesting.com/t/day-6-explore-and-share-insights-on-ai-testing-tools/74482\n我的第 6 天任务 为什么选择 Katalon Studio 由于它的官方介绍和其他社区成员的介绍让我想尝试：\nAI 集成的用例编写 快速生成测试脚本。1 次点击立即生成代码。\n测试脚本的自愈能力 无代码或全代码，为初学者而设计，对专业人士而言功能强大。 灵活性测试任何应用。 下载链接 https://katalon.com/download-next-steps\n简单尝试 我通过一个简单的业务场景进行了测试用例的录制和调试，并在调试测试用例后尝试了测试脚本自我修复功能，目前看起来效果不错。\n测试脚本的自愈功能可以节省一些本应用于调试和修复脚本的时间。\n我尚未使用 AI 集成的编写测试脚本功能，稍后尝试后将提供结论。\n回答问题 工具概述 Katalon Studio 帮助团队以简单、灵活和 AI 集成的解决方案更快地编写更好的测试。\n使用简单，适合初学者，专业人士功能强大。无代码或全代码选项。 🪄 测试灵活性 测试任何应用，与 web、移动、API、桌面等集成。 ⚡️❤️ AI 集成 通过 AI 强化和集成提高生产力。 测试脚本的自愈能力 主要功能 AI 集成 易用性较好 测试脚本的自我修复 支持 web、移动、API、桌面 我对它们对效率或测试流程潜在影响的看法 我个人认为以下几点可能对效率或测试流程产生影响：\n通过 AI 提示词生成自动化测试脚本可以提高测试脚本编写的效率，同时减少对高编码技能 QA 的依赖。 AI 的自愈能力可以快速修复遇到错误的脚本，从而提高测试用例创建和回归测试的效率。 关于活动 30 天 AI 测试挑战活动是 Ministry 测试社区发起的活动，上一次我了解这个社区是关于他们发起的 30 天敏捷测试的活动。\n社区官网：https://www.ministryoftesting.com\n活动链接：https://www.ministryoftesting.com/events/30-days-of-ai-in-testing\n推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/event/30-days-of-ai-in-testing-day-6-explore-and-share-insights-on-ai-testing-tools/","summary":"这篇博文是 30 天 AI 测试挑战活动的第六天，鼓励参与者探索并分享有关人工智能测试工具的见解。博文可能包括对不同人工智能测试工具的介绍，评估其特点和适用场景，并分享作者对这些工具的体验和看法。通过这样的分享，读者能够更好地了解当前市场上的人工智能测试工具，以及它们在测试流程中的作用。这个系列活动有望为测试专业人士提供对人工智能测试工具的全面了解，并促使他们更灵活地选择适用于其项目的工具。","title":"30 天 AI 测试挑战活动：第六天：探索并分享对 AI 测试工具的见解"},{"content":"第五天任务：确定一个测试中的人工智能案例研究，并分享您的发现 我们现在已经进入了 30 天 AI 测试挑战的第 5 天！在过去的几天里，我们已经建立了有关 AI 在测试中的基础知识。今天，我们将通过探索案例研究或分享个人经验，看看我们的发现在现实世界中是如何应用的。\n任务步骤 选项 1：案例研究分析 搜索一个真实世界的例子，说明 AI 是如何用来解决测试挑战的。这可以是一份已发表的案例研究，也可以是在文章或博客中分享的例子。\n选择并分析一个对你来说相关或有趣的案例研究。记录公司和背景，AI 是如何应用在他们的测试过程中的，具体使用了哪些 AI 工具或技术，以及对测试结果/效率的影响。\n选项 2：个人经验分享 如果你在测试活动中使用 AI 工具或技术有个人经验，你可以分享你的旅程和收获。\n描述背景，你使用了哪些 AI 工具或技术，你是如何应用它们的，以及你面临的结果或挑战。\n分享你的发现 无论你选择选项 1 还是选项 2，通过回复此帖分享你的发现。以下是一些提示，指导你的帖子： 案例研究或个人经验的简要背景 AI 是如何在他们/你的测试中使用的？ 他们/你使用了哪些工具或技术？ 他们/你取得了什么结果？ 这个例子中有什么令人印象深刻或让你感到惊讶的地方？ 它与你自己的背景或对 AI 的期望有何关联？ 为什么参加 看到 AI 在测试中的应用：通过探索实际例子，我们能够了解到可能发生的事情，并开始想象 AI 如何能够改变我们自己的测试。\n加深对 AI 的理解：通过探索案例研究或个人经验，你将更深刻地了解将 AI 整合到测试工作流程中的复杂性和细微差别。\n分享知识：分享你的案例研究发现或个人经验，并与其他人讨论，提供了一个学习彼此研究的机会，拓展了我们对 AI 在测试中角色的集体知识和看法。\n任务链接 https://club.ministryoftesting.com/t/day-5-identify-a-case-study-on-ai-in-testing-and-share-your-findings/74458/1\n我的第五天任务 我最近阅读了这篇文章基于 UI 交互意图理解的异常检测方法，它是一项基于 UI 交互意图理解的异常检测方法的研究成果和具体演示示例。\n结合第五天的任务我来回答以下问题：\n案例研究或个人经验的简要背景：\n美团的商店平台技术部和质量工程部与复旦大学周阳帆教授的团队合作，共同开发了一种多模态 UI 交互意图识别模型和相应的 UI 交互框架。随着美团各个业务线的扩张和迭代，UI 测试任务变得越来越繁重，促使了这一模型的开发。 在测试中如何应用人工智能：\n人工智能的应用非常巧妙。团队利用 AI 技术将用户可以看到的文本、视觉图像内容以及 UI 组件树中的属性结合起来，从而准确无误地识别出 UI 交互的意图。这种技术的运用，有效解决了 UI 测试中人力成本高昂和过度依赖脚本测试的问题。 使用的工具或技术：\n研究团队采用了结合机器学习、图像、文本和渲染树信息的多模态模型。这种方法不仅能理解测试人员通常执行的“认知 - 操作 - 检查”过程，而且能够在不同的应用程序和平台之间进行泛化，无需为每个新环境编写特定的测试脚本。 取得的成果：\n案例研究表明，基于 UI 交互意图编写的测试用例展现了在不需要特定适应的情况下能够在不同平台、应用和技术上实现泛化的能力。该研究已被 ESEC/FSE 2023（软件领域的顶级会议）接受，并将在其行业专题中进行演讲。 这个例子中让你印象深刻或感到惊讶的是什么：\n这项研究已经被软件领域的顶级会议 ESEC/FSE 2023 接受，并在会议上进行展示。这标志着该研究不仅在学术上得到认可，而且其实用价值和创新性也得到了业界的高度评价。对于我这样一个 QA 来说，这种跨学科的合作和创新技术的应用是非常令人兴奋的，它不仅为我们打开了 AI 在 UI 测试领域应用的新篇章，更为软件质量保障的未来指明了方向。 关于活动 30 天 AI 测试挑战活动是 Ministry 测试社区发起的活动，上一次我了解这个社区是关于他们发起的 30 天敏捷测试的活动。\n社区官网：https://www.ministryoftesting.com\n活动链接：https://www.ministryoftesting.com/events/30-days-of-ai-in-testing\n推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/event/30-days-of-ai-in-testing-day-5-identify-a-case-study-on-ai-in-testing-and-share-your-findings/","summary":"这篇博文是 30 天 AI 测试挑战活动的第五天，要求参与者确定一个测试中的人工智能案例研究，并分享他们的发现。博文可能包括案例研究的背景、目的和方法，以及在研究过程中所发现的重要见解。通过分享案例研究，作者能够向读者展示 AI 在实际测试场景中的应用，促进知识的交流和学习。这个系列活动有望为测试专业人士提供深入了解 AI 测试的机会，并鼓励他们积极参与实际案例的研究。","title":"30 天 AI 测试挑战活动：第五天：确定一个测试中的人工智能案例研究，并分享您的发现"},{"content":"第四天任务：观看有关测试中人工智能的任何问题视频并分享主要收获 在 30 天人工智能测试挑战赛的第 4 天，我们希望你观看由知识渊博的 Carlos Kidman（一位经验丰富的人工智能和测试专家）主持的有关测试中人工智能的任何问题。\n在本次 AMA 中，Carlos 分享了他在应用机器学习解决复杂测试挑战方面的经验和见解、他向领先的测试 AI 计划的转变、AI 在测试中的未来等等！\n任务步骤 与 Carlos 一起观看“关于测试中人工智能的任何问题”。你可以选择观看整个内容（强烈推荐！），也可以使用播放器上的章节图标或单击播放栏中用小点指示的章节来选择感兴趣的问题。边走边记笔记。\n观看后，反思会议并通过单击“参加”按钮并回复俱乐部主题来分享对你影响最大的要点。例如，这可能是对人工智能在测试中的潜力的新理解，或者是对你来说突出的任何道德考虑。\n为什么参加 加深你的人工智能知识：Carlos 的经验和 AMA 中涵盖的许多主题提供了丰富的信息来源，可帮助你快速了解人工智能在测试中可以发挥的巨大作用。 与同行互动：发布你在 AMA 中的重要见解，看看其他人的想法。这是获得不同观点的好方法。 免费观看：这是额外的观看奖励！AMA 录音以前是专业人士专属内容，现于 3 月 24 日向所有会员免费开放。抓住这个机会，免费观看这些宝贵的内容。 任务链接 https://club.ministryoftesting.com/t/day-4-watch-the-ama-on-artificial-intelligence-in-testing-and-share-your-key-takeaway/74456?cf_id=9wao9R1uOnP\n我的第四天 视频链接：https://www.ministryoftesting.com/testbash-sessions/ask-me-anything-artificial-intelligence-in-testing\n大致看完了全部的内容，会上讨论了如何测试 AI 的偏见、如何确保用户对 AI 驱动软件的信心、如何使用 AI 帮助日常测试、如何使用机器学习进行测试、如何确保数据的安全性和机密性、AI 在可用性和 UX 测试中的作用、以及未来十年软件测试员的角色等话题。\nCarlos 还分享了他对 AI 在未来软件开发和测试中的作用的看法，认为 AI 将在自动化测试方面发挥重要作用，而软件测试人员的角色将更多地侧重于分析和评估 AI 生成的测试结果。他还提到了使用 AI 时的道德和合规性问题，并强调了监控 AI 性能和数据漂移的重要性。\n最后，Carlos 提到了 AI 在帮助初级测试人员提高测试能力方面的潜力。整个访谈涉及到了 AI 和机器学习在软件测试中的应用，测试 AI 的偏见和限制，以及 AI 如何帮助提高测试效率和质量。\n以下的话题我比较感兴趣 能否测试人工智能中的偏差？\n如何评估用户对人工智能软件的信心？\n你使用什么工具进行人工智能测试？\n如何使用人工智能进行日常测试？\n如何进入人工智能测试领域？\n如何确保人工智能的质量？\n关于测试 AI 的偏见，Carlos Kidman 提到可以使用不变性测试技术来测试 AI 的偏见。这种技术涉及到替换词汇来观察 AI 的反应。例如，他提到了将句子中的\u0026quot;Chicago\u0026quot;替换为\u0026quot;Dallas\u0026quot;，并观察 AI 对情感分析的改变。通过这种方式，可以识别并修正 AI 模型中的偏见。\n关于评估用户对 AI 软件的信心，Carlos 提到使用可观测性技术。他举例说明了如何通过用户的反馈（例如点赞或点踩）来收集数据，并分析这些数据来评估用户对 AI 输出的信心和满意度。\n在 AI 测试工具方面，Carlos 提到他们使用名为\u0026quot;Ling Smith\u0026quot;的工具，它是\u0026quot;Ling Chain\u0026quot;的一部分，用于观测 AI 系统的表现。他还提到使用\u0026quot;Pytest\u0026quot;来自动化一些测试案例。\n关于日常测试中如何使用 AI，Carlos 建议尝试使用像 ChatGPT 和 Bard 这样的工具来激发创意和解决测试问题。他强调了工具必须具备足够的上下文才能有效地应用于测试。\n对于如何进入 AI 测试领域，Carlos 建议初学者使用 ChatGPT 和 Bard 等工具来开始探索，这有助于他们发现 AI 在测试中的潜在用途。\n最后，关于如何保障 AI 在生产环境中的表现随数据变化而变化的质量，Carlos 强调了监控 AI 性能的重要性，他提到了\u0026quot;数据漂移\u0026quot;的概念，并分享了一个关于房地产公司因未能监控 AI 性能而造成损失的故事。他提醒说，随着环境的变化，AI 也需要更新和调整，以保持其性能和效果。\n对我来说，影响最大的点就是：如何更好的利用好 AI 的能力，而不是简单的使用 AI 使用 AI 和我们测试工作一样，都需要提升效率和质量。\n如何通过提示词和上下文的提供，来更大程度上的利用 AI 的能力来帮助我们更高效率和高质量的完成工作，可能是我们后续需要思考的方向。\n关于活动 30 天 AI 测试挑战活动是 Ministry 测试社区发起的活动，上一次我了解这个社区是关于他们发起的 30 天敏捷测试的活动。\n社区官网：https://www.ministryoftesting.com\n活动链接：https://www.ministryoftesting.com/events/30-days-of-ai-in-testing\n推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/event/30-days-of-ai-in-testing-day-4-watch-the-ama-on-artificial-intelligence-in-testing-and-share-your-key-takeaway/","summary":"这篇博文是 30 天 AI 测试挑战活动的第四天，要求参与者观看关于测试中人工智能的视频或演讲，并分享他们的主要收获。博文可能包括作者对所观看内容的总结，提到对于人工智能在测试中的理解和应用的新见解。通过这个系列活动，读者可以通过观看视频等形式不断扩展对 AI 测试领域的了解，同时分享这些知识，促进参与者之间的互动。","title":"30 天 AI 测试挑战活动：第四天：观看有关测试中人工智能的任何问题视频并分享主要收获"},{"content":"第三天任务：AI 在测试中的多种应用方式 挖掘今天 AI 在测试中实际应用的更深层次\n欢迎来到 30 天 AI 测试的第三天！今天，我们将更深入地了解 AI 在测试中的实际应用。你的任务是发现并列举 AI 如何改变我们的测试实践。\n任务步骤 进行研究，发现有关 AI 在测试中应用的信息。 列举你发现的三种或更多不同的 AI 使用方式，并注意你发现的任何有用的工具，以及它们如何增强测试，例如： 测试自动化： 自愈测试 - AI 工具评估代码库中的更改，并自动更新为新属性，以确保测试稳定 - Katalon、Functionize、Testim、Virtuoso 等。 总结并写下在你的情境中哪些 AI 使用方式/特性最有用，以及为什么。 点击下方的‘参与’并在回复“俱乐部话题”时发布你的 AI 使用列表和思考。 阅读其他人的贡献。随时提问，分享你的想法，或者用❤️表示对有用发现和总结的欣赏。 为什么要参与 发现 AI 的新用法：了解 AI 在测试中的使用方式向我们展示了新的技巧和工具，我们可能之前并不了解。这有助于我们发现支持日常测试任务的有用方式。 使其适用于你：看看哪些 AI 解决方案适用于你正在处理的问题，有助于选择最合适的工具和解决方案。这就像为你的食谱选择合适的配料一样。 分享智慧：当我们分享学到的知识时，我们一起变得更聪明。把这看作一个拼图，每个人都贡献了谜题的一部分。 任务链接 https://club.ministryoftesting.com/t/day-3-list-ways-in-which-ai-is-used-in-testing/74454?cf_id=OZBDM2eTAXX\n我的第三天 我目前看到的\n测试数据生成：通过给 AI 工具提供对应的数据规则，让其帮忙生成包含各种场景的测试数据，对应的一个文章是：[独立思考的测试数据：人工智能驱动的测试数据生成]https://hackernoon.com/test-data-that-thinks-for-itself-ai-powered-test-data-generation\n缺陷预测：AI 可以分析我们给出历史数据，预测代码库中更容易出现缺陷的区域或者项目的风险，从而集中精力进行测试。对应的文章是：[人工智能和机器学习如何预测软件缺陷？]https://www.linkedin.com/advice/3/how-can-ai-machine-learning-predict-software-defects-xb9sc\n视觉测试：AI 驱动的视觉测试工具（如 Applitools、Percy）可以识别不同浏览器和设备的视觉差异。AI 驱动的测试自动化平台\nQA 知识库：通过喂给 AI 我们已有的 QA 知识库信息，训练出我们自己的 AI 知识库机器人，来帮助提升知识传递效率和质量\nQA 测试工具开发：由 AI 帮助我们完成测试工具开发\n关于活动 30 天 AI 测试挑战活动是 Ministry 测试社区发起的活动，上一次我了解这个社区是关于他们发起的 30 天敏捷测试的活动。\n社区官网：https://www.ministryoftesting.com\n活动链接：https://www.ministryoftesting.com/events/30-days-of-ai-in-testing\n推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/event/30-days-of-ai-in-testing-day-3-list-ways-in-which-ai-is-used-in-testing/","summary":"这篇博文是 30 天 AI 测试挑战活动的第三天，聚焦于 AI 在测试中的多种应用方式。博文可能包括对 AI 在测试领域的各种用途的介绍，如自动化测试、缺陷分析、性能测试优化等。读者将了解到 AI 如何改善测试流程，提高测试效率，以及在测试中应用 AI 的潜在优势。这个系列活动有望为测试专业人士提供一个全面了解和讨论 AI 在测试中应用的平台。","title":"30 天 AI 测试挑战活动：第三天：AI 在测试中的多种应用方式"},{"content":"Automated Testing 自动化测试 自动化测试使用脚本来执行重复性任务，提高软件性能和测试效率。它提高了测试覆盖率和执行速度，使软件测试过程更加有效。\n相关术语：\n手工测试 测试自动化 也可以看看：\n维基百科 关于自动化测试的问题 基础知识和重要性 什么是自动化测试？ 自动化测试是使用软件工具执行预先编写的测试脚本来验证软件应用功能、性能和可靠性的过程。与手动测试不同，自动化测试一旦设置完成，就可以在最小的人工监督下重复执行。\n这些测试通常使用与应用代码相同或不同的语言编写，旨在具有可重用性和可维护性。测试的范围可以从验证各个组件的简单单元测试到验证应用程序内整个工作流程的复杂端到端测试。\n自动化测试是持续集成/持续部署（CI/CD）流水线的一部分，确保新的代码更改不会引入回归问题。这在快节奏的开发环境中保持软件质量至关重要。\n// Example of a simple automated test script in TypeScript import { expect } from \u0026#39;chai\u0026#39;; import { Calculator } from \u0026#39;./Calculator\u0026#39;; describe(\u0026#39;Calculator\u0026#39;, () =\u0026gt; { it(\u0026#39;should add two numbers correctly\u0026#39;, () =\u0026gt; { const calculator = new Calculator(); expect(calculator.add(2, 3)).to.equal(5); }); }); 有效的自动化测试取决于选择适当的工具和框架、开发健壮的测试用例并随着应用程序演变进行维护。同时，必须确保全面的测试覆盖，以在部署之前捕获尽可能多的问题。随着人工智能和机器学习的进步，自动化测试变得更加智能，能够以更少的手动输入预测和适应软件的变化。\n为什么自动化测试很重要？ 自动化测试对于以无法匹敌的速度和规模确保软件质量至关重要。它使团队能够在较短的时间内执行更多的测试，对代码变更提供快速反馈。这在现代开发实践中至关重要，例如敏捷和 DevOps，其中持续集成和交付是关键。自动化通过允许频繁而一致的测试来支持这些方法，从而早期发现缺陷，降低了修复缺陷的成本和工作量。\n此外，自动化测试可以重复运行，几乎没有额外成本，确保在新变更后之前开发的功能仍然可用（回归测试）。它们还允许在各种环境和设备上进行并行执行，提高了测试覆盖和效率。自动化测试以较少的人为错误生成可靠的结果，并提供详细的日志，有助于调试。\n实质上，自动化测试是**质量保证战略**的基石，旨在及时交付健壮的软件。它通过处理重复且耗时的任务来补充手动测试工作，使人工测试人员能够专注于更复杂和探索性测试场景。\n自动化测试的优点和缺点是什么？ 自动化测试的优势：\n速度和效率：相比手动测试，自动化测试可以更快地执行更多的测试，提供对代码变更的快速反馈。 可重用性：测试脚本可以在应用程序的不同版本之间重复使用，节省了测试准备的时间。 一致性：确保每次执行测试时都是相同的，消除了人为错误。 覆盖范围：能够执行手动情况下难以实现的全面测试，包括复杂的场景和大型数据集。 持续集成：通过允许在进行更改时自动运行测试，有助于 CI/CD，是现代开发实践的关键。 早期缺陷检测：能够在开发过程中迅速识别问题，降低修复成本。 非功能性测试：非常适合性能、负载和压力测试，这些测试在手动情况下难以执行。 自动化测试的劣势：\n初期投资：在工具和测试环境的设置方面有较高的初始成本。 维护：测试脚本需要定期更新以适应应用程序的变化。 学习曲线：团队需要时间学习工具并开发有效的测试。 有限范围：无法像人类一样处理视觉参考或 UX 评估。 误报/漏报：自动化测试可能报告不是缺陷的失败（误报）或错过缺陷（漏报）。 复杂的设置：有些测试场景很难自动化，可能不值得付出努力。 工具限制：工具可能不支持每种技术或应用程序类型，限制了它们的使用。 自动化测试如何融入软件开发生命周期？ 自动化测试被无缝地融入到软件开发生命周期（SDLC）的各个阶段，以提高效率和可靠性。在需求阶段，我们计划了自动化测试，以确保其与验收标准一致。在设计和开发阶段，我们实施了自动化单元测试，通常遵循测试驱动开发（TDD）的实践。随着特性的完成，自动化集成测试用于验证组件之间的交互。\n在测试阶段，自动化回归测试确保新的更改不会破坏现有功能，而自动化系统测试则验证整个软件系统。自动化端到端测试模拟用户行为，覆盖整个应用程序的工作流程。对于部署而言，在 CI/CD 流水线中，自动化测试对构建的健康状态提供了即时反馈。\n在部署后，自动化测试继续支持维护阶段，快速发现由于补丁或更新引入的问题。在整个 SDLC 期间，我们会对自动化测试进行维护和完善，以适应应用程序要求的不断发展和覆盖新场景的需要。\n自动化测试的角色是迭代的和持续的，与敏捷开发和 DevOps 方法论相一致，支持快速的开发周期和频繁的发布。这确保了质量从一开始就被内嵌到产品中，并在整个生命周期中得以保持。\n// Example of a simple automated unit test in TypeScript import { add } from \u0026#39;./math\u0026#39;; describe(\u0026#39;add function\u0026#39;, () =\u0026gt; { it(\u0026#39;should add two numbers correctly\u0026#39;, () =\u0026gt; { expect(add(2, 3)).toBe(5); }); }); 手动测试和自动化测试有什么区别？ 手动测试涉及到测试人员在没有工具或脚本的帮助下执行测试用例。相反，自动化测试使用软件工具自动运行测试，同时管理测试的执行和实际结果与预期结果的比较。\n主要区别包括：\n执行：手动测试需要人类在每个步骤进行干预，而自动化测试则由软件执行。 速度：一旦测试被开发，自动化测试的速度明显更快。 一致性：自动化测试可以在相同条件下重复运行，确保一致性。而手动测试可能会受到人为错误的影响。 初始成本：设置自动化测试需要比手动测试更多的时间和资源。 维护：随着应用程序的变化，自动化测试需要进行维护以保持其有效性，而手动测试则更易于适应变化而无需额外设置。 可扩展性：自动化测试能够处理大量测试并具有可扩展性，而手动测试在这方面具有挑战性。 复杂性：一些复杂的用户交互可能难以自动化，手动评估可能更为合适。 反馈：手动测试能够提供即时的定性反馈，而自动化测试则无法做到这一点。 用例：手动测试通常更适用于探索性、可用性和临时测试。而自动化测试则非常适用于回归、负载和性能测试等场景。 在实践中，通常采用平衡的方法，充分发挥两种方法的优势，是最有效的策略。\n工具和技术 自动化测试常用的工具有哪些？ 一些常见的自动化测试工具包括：\nSelenium：一个用于在不同浏览器和平台上进行网页应用测试的开源框架。它支持多种编程语言，如Java、C#和Python。 WebDriver driver = new ChromeDriver(); driver.get(\u0026#34;http://www.example.com\u0026#34;); Appium：一个用于在 iOS 和 Android 平台上自动化移动应用的开源工具。它使用 WebDriver 协议。 DesiredCapabilities caps = new DesiredCapabilities(); caps.setCapability(\u0026#34;platformName\u0026#34;, \u0026#34;iOS\u0026#34;); caps.setCapability(\u0026#34;deviceName\u0026#34;, \u0026#34;iPhone Simulator\u0026#34;); JUnit和TestNG：Java 单元测试的框架，提供注解和断言以帮助组织和运行测试。 @Test public void testMethod() { assertEquals(1, 1); } Cypress：一个基于 JavaScript 的端到端测试框架，可在浏览器中运行，实现对在浏览器中运行的任何内容的快速、简便和可靠的测试。 describe(\u0026#39;My First Test\u0026#39;, () =\u0026gt; { it(\u0026#39;Visits the Kitchen Sink\u0026#39;, () =\u0026gt; { cy.visit(\u0026#39;https://example.cypress.io\u0026#39;) }) }) Robot Framework：一个关键字驱动的测试自动化框架，用于验收测试和验收测试驱动开发（ATDD）。 *** Test Cases *** Valid Login Open Browser To Login Page Input Username demo Input Password mode Submit Credentials Postman：一个用于 API 测试的工具，允许用户发送 HTTP 请求和分析响应，创建自动化测试，并与 CI/CD 流水线集成。 { \u0026#34;id\u0026#34;: \u0026#34;f2955b9f-da77-4f80-8f1c-9f8b0d8f2b7d\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;API Test\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.example.com/v1/users\u0026#34; } } Cucumber：支持行为驱动开发（BDD），允许使用普通语言规定应用程序行为。 Feature: Login functionality Scenario: Successful login with valid credentials Given the user is on the login page When the user enters valid credentials Then the user is redirected to the homepage 这些工具提供了各种不同测试需求的能力，从单元测试和集成测试到端到端和API 测试。\n这些工具之间有什么区别？ 不同的自动化测试工具具有独特的特性、功能和用例。以下是简要的比较：\nSelenium：用于在不同浏览器和平台上测试 Web 应用程序的开源工具。支持多种编程语言，并与各种框架集成。 WebDriver driver = new ChromeDriver(); driver.get(\u0026#34;http://www.example.com\u0026#34;); QTP/UFT (统一的 功能测试)：Micro Focus 提供的商业工具，用于功能和回归测试，主要针对桌面和 Web 应用程序。它使用 VBScript，并以其录制和回放功能而闻名。 Browser(\u0026#34;Example\u0026#34;).Page(\u0026#34;Home\u0026#34;).Link(\u0026#34;Login\u0026#34;).Click TestComplete：另一款商业工具，支持桌面、移动和 Web 应用程序。它提供基于脚本和关键字驱动的测试，并支持各种脚本语言。 Sys.Browser(\u0026#34;*\u0026#34;).Page(\u0026#34;http://www.example.com\u0026#34;).Link(\u0026#34;Login\u0026#34;).Click(); Cypress：专为现代 Web 应用程序设计的基于 JavaScript 的端到端测试框架。它在相同的运行循环中运行测试，提供实时反馈和更快的测试执行。 cy.visit(\u0026#39;http://www.example.com\u0026#39;); cy.contains(\u0026#39;Login\u0026#39;).click(); Jest：一个专注于简单性的 JavaScript 测试框架，支持单元和集成测试。它与 React 和其他现代 JavaScript 库兼容。 test(\u0026#39;adds 1 + 2 to equal 3\u0026#39;, () =\u0026gt; { expect(sum(1, 2)).toBe(3); }); Appium：一个用于自动化测试移动应用程序的开源工具。支持原生、混合和移动 Web 应用程序，并与任何测试框架一起使用。 driver.findElement(By.id(\u0026#34;com.example:id/login\u0026#34;)).click(); Robot Framework：一个使用表格测试数据语法的关键字驱动测试自动化框架。对于不熟悉编程的人来说，学习起来很容易，并与 Selenium 进行 Web 测试集成。 *** Test Cases *** Login Test Open Browser http://www.example.com Chrome Click Link Login 每个工具都有其优势，选择通常取决于被测试应用程序、首选的编程语言以及测试过程的具体要求。\n如何为特定的测试任务选择正确的工具？ 在选择适用于特定测试任务的正确工具时，需要考虑多个因素：\n兼容性：确保工具支持您应用的技术栈，如 Web、移动或桌面。 可用性：选择符合团队技能的工具。如果学习曲线陡峭，可能会妨碍生产力。 集成性：工具应能够与已有工具和工作流（如版本控制、CI/CD 流水线和问题跟踪系统）无缝集成。 可扩展性：考虑工具是否能够应对应用规模和复杂性的增长。 灵活性：具备编写自定义功能或与其他工具集成的能力，这对于处理复杂的测试场景至关重要。 报告功能：详细的报告和分析有助于迅速发现趋势并准确定位问题。 支持与社区：强大的社区和良好的供应商支持对于解决问题和保持工具更新至关重要。 成本：评估工具的总体成本，包括许可、维护和培训成本，以确保符合预算。 性能：工具应能够快速高效地执行测试，以适应迅速的开发周期。 可靠性：选择具有稳定记录的工具，以避免测试失败或结果不一致。 通过在这些因素和测试任务的具体需求之间进行权衡，您可以选择一个提高测试效率和效果的工具。请记得定期重新评估您的选择，因为需求和工具本身都在不断发展。\n自动化测试中常用的技术有哪些？ 自动化测试 中的一些常见技术包括：\n页面对象模型 (POM)：在类中封装页面元素和交互，以促进代码重用和可维护性。\n模块化测试：将测试分解成较小、可管理的模块，具有独立的测试脚本，增强可维护性和可扩展性。\n混合测试框架：结合各种测试方法，如关键字驱动和数据驱动，以发挥它们的优势。\n行为驱动开发 (BDD)：使用自然语言描述定义应用程序的行为，促进各方之间的沟通。\n测试驱动开发 (TDD)：在实际编码之前编写测试用例，确保软件在测试方面构建。\n数据驱动测试：使用外部数据源将多个数据集输入到测试用例中，提高覆盖范围和效率。\n关键字驱动测试：使用代表操作和数据的关键字定义测试，使测试更易于理解和维护。\n持续测试：将测试集成到持续集成和交付流水线中，实时提供有关构建健康状况的反馈。\n并行测试：在不同环境中同时执行多个测试，减少测试执行所需的时间。\nAPI 测试：专注于直接测试API的功能、可靠性、性能和安全性，通常比 UI 测试更低级别。\n模拟和插桩：使用模拟对象和插桩来模拟真实组件的行为，允许对系统的部分进行隔离测试。\n视觉回归测试：通过将当前屏幕截图与基准图像进行比较，检测意外的视觉变化。\n负载和性能测试：模拟用户对软件的负载，检查在不同条件下的性能和可扩展性。\n安全测试：用于探测应用程序漏洞的自动化脚本，确保软件受到潜在攻击的保护。\n这些技术可以结合和定制以满足特定项目要求，确保自动化测试过程的稳健和高效。\n如何将自动化测试工具集成到 CI/CD 流水线中？ 将自动化测试工具集成到 CI/CD 流水线中涉及以下几个步骤：\n选择适当的工具，确保能够与您的 CI/CD 服务器（例如 Jenkins、GitLab CI、CircleCI）无缝集成。 配置 CI/CD 服务器以触发自动化测试。通常通过在流水线配置文件中定义作业或阶段来完成。 设置测试环境，用于运行自动化测试。这可以是专用的测试服务器、容器化环境或基于云的服务。 编写测试脚本，确保与 CI/CD 环境兼容，可以在无需手动干预的情况下执行。 将测试脚本**存储在版本控制系统中，与应用程序代码一起，以保持版本控制和更改跟踪。 为自动化测试定义触发器，例如在每次提交时、每夜构建时或按需触发。 作为流水线的一部分执行测试，并确保将测试结果报告回 CI/CD 服务器。 通过设置通知、仪表板或与其他工具集成进行结果分析来处理测试结果。 管理测试数据**和依赖项，以确保在测试运行之间保持一致性。 在运行测试之前自动化应用程序的部署到测试环境。 Jenkinsfile 的示例流水线配置片段：\npipeline { agent any stages { stage(\u0026#39;Test\u0026#39;) { steps { // Checkout code checkout scm // Run tests script { // Execute test command sh \u0026#39;npm test\u0026#39; } } post { always { // Publish test results junit \u0026#39;**/target/surefire-reports/TEST-*.xml\u0026#39; } } } } } 确保流水线设计为在测试失败时停止部署，以保持发布的质量。定期审查和更新测试用例和脚本，以适应应用程序的变化。\n测试用例和脚本 如何开发自动化测试的测试用例？ 为自动化测试制定测试用例涉及以下几个步骤：\n确定测试需求：分析待测试的应用程序（AUT），确定测试需求。集中关注高风险或频繁更改的功能、功能和区域。\n明确测试目标：清晰地说明每个测试用例应验证的内容。目标应具体、可测量，并与用户故事或需求对齐。\n设计测试用例：创建详细的测试用例，包括前提条件、测试数据、执行的操作和预期结果。确保它们具有可重用性和可维护性。\n使用参数进行测试：使用参数使测试用例支持数据驱动，以便使用相同脚本测试多个数据集。\n制定断言：实施断言来检查 AUT 的响应是否符合预期结果。断言对于确定测试的通过/失败状态至关重要。\n编写测试脚本：使用自动化工具或框架编写脚本。遵循编码的最佳实践，例如使用页面对象模型分离 UI 测试的测试逻辑和页面特定代码。\n设置测试环境：配置测试运行的必要环境，包括浏览器、数据库和其他任何依赖项。\n实施测试执行逻辑：定义测试的执行方式，包括顺序、依赖关系以及前/后测试步骤的处理。\n审查和改进：同行审查或演练可帮助及早发现问题。根据需要进行重构，以提高清晰度、效率和可维护性。\n版本控制：将测试用例和脚本存储在版本控制系统中，以跟踪更改并与团队成员合作。\n与 CI/CD 集成：将测试用例的自动化执行作为 CI/CD 流水线的一部分，以确保在每次构建或发布时对 AUT 进行持续验证。\n通过遵循这些步骤，测试自动化工程师可以创建健壮、可靠且有效的自动化测试用例，从而提高软件产品的整体质量。\n自动化测试中的测试脚本是什么？ 在自动化测试中，**测试脚本**是由自动化工具执行的一组指令，用于验证软件应用程序的功能。它本质上是一个自动执行手动测试用例步骤的程序。\n测试脚本与被测试的应用程序（AUT）进行交互，输入数据，并将预期结果与实际结果进行比较。它们是用自动化工具支持的编程或脚本语言编写的，如 JavaScript、Python 或 Ruby。\n以下是使用假设的测试框架，用 JavaScript 编写的测试脚本的简化示例：\ndescribe(\u0026#39;Login Page Tests\u0026#39;, function() { it(\u0026#39;should allow a user to log in\u0026#39;, function() { goToLoginPage(); enterUsername(\u0026#39;testUser\u0026#39;); enterPassword(\u0026#39;password123\u0026#39;); submitLoginForm(); expect(isLoggedIn()).toBe(true); }); }); 该脚本描述了一个登录页面的测试用例，其中导航到登录页面，输入凭据，提交表单，并检查登录是否成功。\n有效的测试脚本应具备以下特点：\n可重用性：像 goToLoginPage() 这样的函数可以在多个测试用例中使用。 可维护性：在 AUT 更改时应易于更新。 可读性：清晰而简洁，以便其他工程师能够理解和修改。 可靠性：它们产生一致的结果，并能够优雅地处理异常情况。 脚本通常组织成测试套件以便更好地进行管理，并可以作为独立运行或作为更大测试运行的一部分。它们对于持续集成和交付流水线至关重要，允许对软件构建进行频繁和自动化的验证。\n如何确保您的测试用例涵盖所有可能的场景？ 为确保测试用例涵盖所有可能的情景，请采取以下策略：\n等价分区：将输入划分为逻辑组，其中相同行为的测试仅针对每个分区中的一个值进行。 边界值分析：专注于输入范围边界的极端情况。 决策表测试：创建表格以探讨不同输入组合及其对应操作。 状态转换测试：将场景建模为系统的各种状态，识别变换和全面覆盖的条件。 用例测试：从真实用例中衍生测试用例，以确保覆盖用户的各种路径。 组合测试：应用成对测试等工具，检查参数之间的相互作用。 基于风险的测试：根据潜在故障的风险及其影响对测试进行优先排序。 探索性测试：通过手动的探索性会话补充自动化测试，以揭示未预料到的行为。 基于模型的测试：从表示期望行为的系统模型生成测试用例。 代码覆盖分析：使用工具衡量测试执行的代码覆盖范围，力求获得高覆盖率指标，包括语句、分支和路径覆盖。 将这些策略融入测试设计过程中，打造一个全面的测试套件。定期审查和更新测试用例，以适应应用程序及其使用模式的变化。\n编写测试脚本的最佳实践有哪些？ 编写测试脚本的最佳实践包括：\n可维护性：使用注释解释复杂逻辑，编写清晰易懂的代码。使用页面对象或类似的模式将测试逻辑与 UI 结构分离，使脚本更易更新。\n可重用性：为常见操作创建可重用的函数或方法。这减少了重复，简化了更新。\n模块化：将测试拆分为较小的独立模块，可以组合成更大的测试。这提高了可读性和可调试性。\n数据分离：将测试数据与脚本分开。使用外部数据源，如 JSON、XML 或 CSV 文件作为输入数据，这有助于轻松更新和进行数据驱动测试。\n版本控制：将测试脚本存储在版本控制系统中，以跟踪更改，与他人协作，并在必要时恢复到先前的版本。\n命名约定：对测试用例和函数使用描述性名称，以便一目了然地传达其目的。\n错误处理：实施健壮的错误处理来处理意外事件。测试应该以清晰的错误消息优雅地失败。\n断言：使用清晰具体的断言来确保测试准确验证预期结果。\n并行执行：设计测试在可能的情况下并行运行，以加快执行时间。\n清理：始终清理测试数据并将系统恢复到其原始状态，以避免影响后续测试。\n报告：生成详细的日志和报告，以深入了解测试结果并便于故障排除。\n持续集成：将测试脚本集成到 CI/CD 流水线中，以确保它们定期执行并提供有关代码更改的即时反馈。\n// Example of a reusable function in TypeScript function login(username: string, password: string) { // Code to perform login action } 遵循这些实践将带来健壮、可靠且高效的测试自动化脚本。\n随着时间的推移，您如何管理和维护测试用例和脚本？ 如何随着时间的推移管理和维护测试用例和脚本需要结合良好实践、组织和工具。以下是一些策略：\n版本控制：使用像 Git 这样的版本控制系统跟踪更改，与团队成员合作，并在必要时回滚。 模块化设计：以可重用的组件方式编写测试，以最小化维护工作并促进更新。 文档：清晰地记录测试用例和脚本，包括目的、输入、预期结果和更改历史。 重构：定期对测试进行重构，以提高清晰度、效率和可维护性，减少冗余并改善结构。 代码审查：对测试脚本进行同行审查，确保质量并符合标准。 自动化检查：实施自动化的清理和代码分析工具，以执行编码标准并及早检测问题。 测试数据管理：使用数据工厂或固定装置等策略有效地管理测试数据，确保其保持相关性和准确性。 持续集成：将测试脚本集成到 CI/CD 管道中，以确保它们定期执行并与代码库兼容。 监控：监控测试执行结果，迅速识别和解决不稳定性或失败。 优先级：根据测试的关键性，优先处理维护任务，重点关注应用程序的高影响区域。 淘汰策略：明确制定淘汰和删除过时测试的策略，以避免混乱和困扰。 通过采用这些策略，测试自动化工程师可以确保他们的测试套件随着时间的推移保持强大\n、相关和可靠，为软件开发生命周期提供持续的价值。\n自动化测试的类型 什么是单元测试？ 单元测试是一种实践，用于测试应用程序中最小可测试的部分，通常是函数或方法，而这些部分与系统的其余部分隔离开来。这确保每个组件都按照预期的方式运行。通常，开发人员在编写代码时编写并运行单元测试，以便及时获得对其更改的反馈。\n在自动化测试的背景下，单元测试通常会自动执行，通常作为构建过程的一部分或通过持续集成（CI）系统执行。它们对于在开发周期的早期识别问题非常重要，这有助于减少修复缺陷的成本和时间。\n单元测试的特点是其范围（狭窄，专注于代码的单一“单元”）和速度（执行速度快）。它们使用单元测试框架编写，例如 Java 的 JUnit，.NET 的NUnit，或 JavaScript 的Jest。这些框架提供了编写测试的结构，并包含断言以验证代码的行为是否符合预期。\n以下是使用Jest在 TypeScript 中编写的简单单元测试示例：\nimport { add } from \u0026#39;./math\u0026#39;; test(\u0026#39;adds 1 + 2 to equal 3\u0026#39;, () =\u0026gt; { expect(add(1, 2)).toBe(3); }); 单元测试应该是可维护和可靠的，不依赖于外部系统或状态。它们是健壮的自动化测试策略的基本组成部分，有助于提高软件的整体健康和质量。\n什么是集成测试？ 集成测试是软件测试流程中的一环，它将软件应用程序的个体单元或组件组合在一起，作为一个组进行测试。其主要目标是验证集成的模块之间的功能、性能和可靠性。\n在自动化测试中，集成测试是经过脚本编写的，通常并入构建过程，以确保新的更改不会破坏组件之间的交互。这些测试可能比单元测试更复杂，因为它们需要配置环境，让多个组件进行交互。\n通常使用与单元测试相同或类似的工具编写自动化集成测试，但它们侧重于组件之间的交互点，以确保在组合时数据流、API合同和用户界面能够按预期工作。它们可以在持续集成环境中执行，以在每次提交后或定期提供关于应用程序集成状态的反馈。\n在 TypeScript 中的自动化集成测试示例：\nimport { expect } from \u0026#39;chai\u0026#39;; import { fetchData, processInput } from \u0026#39;./integrationComponents\u0026#39;; describe(\u0026#39;Integration Test\u0026#39;, () =\u0026gt; { it(\u0026#39;should process input and return expected data\u0026#39;, async () =\u0026gt; { const input = \u0026#39;test input\u0026#39;; const processedData = await processInput(input); const fetchedData = await fetchData(processedData); expect(fetchedData).to.be.an(\u0026#39;object\u0026#39;); expect(fetchedData).to.have.property(\u0026#39;key\u0026#39;, \u0026#39;expected value\u0026#39;); }); }); 该示例演示了一个简单的集成测试，其中processInput和fetchData是两个需要正确协同工作的单独组件。该测试确保一个组件处理的数据适用于另一个组件获取期望的结果。\n什么是系统测试？ 系统测试是一个高层次的测试阶段，对完整的、集成的软件系统进行评估，以验证其是否符合指定的要求。它在**集成测试之后和验收测试**之前进行，主要关注各种条件下的系统行为和输出。\n在系统测试期间，应用程序在一个与生产环境非常相似的环境中进行测试，包括**数据库交互**、网络通信和服务器交互。其目标是识别仅在组件集成和在系统范围上下文中交互时才会出现的缺陷。\n系统测试的关键方面包括：\n功能性测试: 确保软件的行为符合预期。 性能测试: 检查系统在负载下的响应时间、吞吐量和稳定性。 安全测试: 验证安全功能是否保护数据并按预期维护功能。 可用性测试: 评估用户界面和用户体验。 兼容性测试: 确认软件在不同设备、浏览器和操作系统上的工作。 自动化系统测试可以显著减少执行重复但必要检查所需的时间，从而实现更频繁和彻底的测试周期。它特别适用于**回归测试**，以确保新更改没有对现有功能产生不良影响。然而，它可能无法完全替代手工测试，特别是对于探索性、可用性和临时测试场景。\n什么是回归测试？ 回归测试是在进行增强、补丁或配置更改等变更后，验证先前开发和测试的软件仍然在正确执行的过程。它确保新的代码更改没有对现有功能产生不良影响。在自动化测试的背景下，回归测试通常作为经常运行的测试套件的一部分执行，通常在 CI/CD 流水线中运行，以提供有关代码修改影响的快速反馈。\n自动化回归测试对于随着代码库的增长和演变而保持软件稳定性至关重要。它允许对软件行为进行一致和可重复的验证，这比手动回归测试更为高效。可以在各种环境和配置上运行自动化测试，以确保广泛的覆盖范围。\n以下是一个简单的 JavaScript 测试框架（如Jest）中的自动化回归测试的示例：\ndescribe(\u0026#39;Calculator\u0026#39;, () =\u0026gt; { test(\u0026#39;should add two numbers correctly\u0026#39;, () =\u0026gt; { expect(add(1, 2)).toBe(3); }); }); 在这个例子中，add函数是先前经过测试的软件的一部分。回归测试将确保在对代码库进行更改后，add函数仍然产生期望的结果。\n有效的回归测试通常涉及选择涵盖关键功能的相关测试用例，频繁运行这些测试，并随着软件演进而更新它们。这有助于及早识别缺陷，降低引入错误到生产环境的风险。\n黑盒测试和白盒测试有什么区别？ 黑盒测试和白盒测试是两种评估软件功能和完整性的不同方法。\n**黑盒测试**将软件视为不透明的实体，主要关注输入和输出，而不考虑内部代码结构。测试人员根据规范验证功能，确保系统在各种条件下表现如预期。这种方法对内部工作毫不知情，因此被称为“黑盒”。\n相反，**白盒测试**要求了解内部逻辑。测试人员检查代码库以确保其正常运作和结构，通常寻找特定条件，如循环执行、分支覆盖和路径覆盖。这种方法也被称为清晰、开放或透明测试，因为内部代码是可见的。\n虽然这两种方法都可以自动化，但黑盒测试通常是更高层次的，例如用户界面测试，而白盒测试则更注重底层，如单元测试。黑盒自动化脚本模拟用户交互，而白盒脚本则直接与应用程序代码交互。\n在实践中，结合这两种方法提供了全面的测试策略，黑盒测试验证面向用户的功能，而白盒测试确保底层代码库的健壮性。\n什么是端到端 (e2e) 测试以及为什么它很重要？ 端到端（E2E）测试是一种在仿真真实使用场景的情况下对整个应用程序进行测试的技术，包括与数据库、网络、硬件和其他应用程序的交互。其目的在于验证系统从头到尾的集成和数据完整性，确保应用程序在各种情境下的所有组件都表现正常。\nE2E 测试至关重要，因为它验证系统的整体健康状况，而不同于侧重于单个组件或交互的单元测试或集成测试。它有助于捕捉在系统不同部分协同工作时可能出现的问题，这在孤立情况下可能不明显。这种测试对于直接影响用户体验或业务底线的关键工作流程尤为重要。\n通过模拟真实用户场景，E2E 测试确保应用程序满足业务需求，并在生产环境中正确运行。它可以揭示由于各个子系统组合而导致的意外行为，这对于在实际环境中防止问题非常宝贵。\n在**测试自动化**的背景下，E2E 测试通常作为 CI/CD 流水线的一部分执行，以确保新变更不会破坏关键功能。尽管相较于其他类型的测试，它们可能更为复杂且耗时，但在确认软件产品的可行性方面它们的重要性不可低估。\n深层理解 什么是测试驱动开发 (TDD) 以及它与自动化测试有何关系？ 测试驱动开发（TDD）是一种软件开发方法，它要求在编写代码之前先编写需要通过的测试。这一简单的循环包括：编写测试，运行测试（最初测试应该失败），编写最少量的代码以通过测试，然后在确保测试继续通过的同时重构代码。\nTDD 与自动化测试密切相关，因为它本质上依赖于在实现软件功能之前创建自动化测试。这些测试通常是单元测试，可以迅速运行并且易于自动化。TDD 循环确保每个新功能都始于相应的测试用例，这有助于随着时间的推移构建一套自动化测试。\n这种方法对测试自动化产生了几个影响：\n持续反馈：自动化测试为代码变更提供即时反馈。 回归安全性：随着代码库的增长，测试套件有助于防止回归问题。 设计影响：首先编写测试可以推动更好的软件设计和架构。 重构信心：自动化测试使开发人员能够在重构代码时确保现有功能仍然完好。 TDD 通过确保测试从开发过程的一开始就被考虑，而不是事后的事项，来补充其他自动化测试策略。它鼓励一种测试纪律，有助于构建更高质量的软件，并且与敏捷和持续集成/持续部署（CI/CD）工作流紧密配合。\n什么是行为驱动开发 (BDD) 以及它与自动化测试有何关系？ 行为驱动开发（BDD）是一种敏捷软件开发过程，鼓励开发人员、质量保障（QA）以及非技术或业务参与者在软件项目中进行协作。BDD通过与利益相关者进行讨论，专注于获得对期望的软件行为的清晰理解。它通过使用非程序员可以阅读的自然语言编写测试用例来扩展测试驱动开发（TDD）。\nBDD与自动化测试相关联，提供了编写测试的框架。测试用例使用**特定领域语言（DSL）**编写，通常使用类似Gherkin的语言，允许以人类可读的方式描述软件行为。这些描述随后可以由 Cucumber 或 SpecFlow 等工具自动化。\nFeature: User login Scenario: Successful login with valid credentials Given the user is on the login page When the user enters valid credentials Then the user is redirected to the homepage 在BDD中，场景在开发开始之前被定义，并作为测试用例的基础。这确保了自动化测试与用户的预期行为保持一致。随着开发的进行，这些场景被转化为自动化测试，并持续执行以验证应用程序的行为是否符合预期结果。\nBDD对共享理解和清晰沟通的强调使其特别有用，以确保自动化测试是相关的、可理解的和易于维护的。它有助于弥合技术和非技术团队成员之间的差距，确保自动化测试准确反映业务需求和用户需求。\n什么是数据驱动测试？ 数据驱动测试（DDT）是一种**测试自动化**策略，其核心是使用多组输入数据执行一系列测试步骤。这一方法通过验证应用程序在广泛的输入值范围内的行为，而无需为每个数据集编写多个测试脚本，从而提高了测试覆盖率。\n在 DDT 中，测试逻辑与测试数据分离，通常存储在外部数据源中，如 CSV 文件、Excel 电子表格、XML 或数据库。在测试执行过程中，自动化框架读取数据并将其输入测试用例。\n下面是一个简化的伪代码示例：\nfor each data_row in data_source: input_values = read_data(data_row) execute_test(input_values) verify_results() DDT 特别适用于应用程序行为在不同数据输入下保持一致的情况，并且对于确保测试涵盖边缘情况和边界条件非常重要。此外，它还简化了更新测试的过程，因为测试数据的更改不需要修改测试脚本。\n然而，需要谨慎设计 DDT，以避免产生维护负担，因为测试数据的数量和复杂性可能会显著增长。妥善管理测试数据是数据驱动测试成功的关键。\n什么是关键字驱动测试？ 关键字驱动测试，又称表驱动测试或基于动作关键字的测试，是一种在自动化测试中采用的方法，其中使用一组预定义的关键字编写测试用例。这些关键字代表了可以在被测试的应用程序（AUT）上执行的操作。每个关键字都对应执行特定操作的函数或方法，例如点击按钮、输入文本或验证结果。\n在关键字驱动测试中，测试脚本不是用编程语言编写的。相反，它们由一系列关键字组成，易于阅读和理解。这种抽象使得没有编程专业知识的个人能够设计和执行测试，促进了不同利益相关者之间的协作。\n以下是关键字驱动测试用例可能的简化示例：\n| Keyword | Parameter 1 | Parameter 2 | |---------------|----------------|-------------------| | OpenBrowser | Chrome | | | NavigateTo | https://example.com | | | ClickButton | Submit | | | VerifyText | Thank you for submitting! | | 测试自动化框架解释这些关键字并将它们转换为对 AUT 的操作。测试用例的设计与测试脚本的实施分离，使得测试用例更容易维护和扩展。当关键字的底层实现发生变化时，只需更新相关的函数或方法，而不必触及测试用例本身。\n人工智能和机器学习在自动化测试中的作用是什么？ 人工智能（AI）和机器学习（ML）正在改变自动化测试，提升了其能力和效率。基于 AI 的测试自动化可以分析应用程序数据以预测和优先考虑测试用例，检测依赖关系，并识别存在更高缺陷可能性的区域。这种预测性分析有助于优化测试套件，减少冗余，并聚焦于高风险区域。\n机器学习算法可以从过去的测试执行中学习模式并预测未来的故障。通过随着时间的推移分析结果，ML 可以提高测试的准确性，并适应应用程序的变化，而无需手动干预进行测试维护。\n自愈测试利用 AI 在检测到应用程序的 UI 或API发生变化时自动更新测试脚本，极大减轻了维护负担。这种能力确保测试随着应用程序的演进而保持稳健和可靠。\n增强 AI 的工具还可以提供视觉测试功能，比较应用程序的视觉方面，检测传统自动化测试可能未能捕捉到的 UI 差异。这对于确保跨设备和跨浏览器的一致性尤为有用。\n此外，AI 可以协助测试生成，通过分析用户行为和应用程序使用模式创建有意义的测试用例。这可以实现包括真实场景的更全面的测试覆盖。\n总的来说，AI 和 ML 在自动化测试中带来更智能的测试规划、维护、执行和分析，从而实现更高效和有效的测试流程。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-automated-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，重点关注 Automated Testing（自动化测试）。文章详细介绍了自动化测试的基础概念和其在软件测试中的重要性，包括自动化测试工具和技术的使用，编写测试用例和脚本的技巧，以及不同类型的自动化测试。读者将深入了解如何有效地实施自动化测试，提高测试效率和可靠性。博文还探讨了自动化测试的深层理解，以帮助读者更全面地理解自动化测试在软件开发生命周期中的作用。","title":"软件测试术语分享:Automated Testing 自动化测试"},{"content":"ASTQB 美国软件测试资格委员会 美国软件测试资格委员会 (ASTQB) 是国际软件测试资格委员会 (ISTQB 国际软件测试资格委员会) 的美国国家委员会。它负责美国的“ISTQB 认证测试员”计划。ASTQB 为软件测试专业人​​员提供和管理认证、认可培训师并批准培训材料。通过 ASTQB 获得 ISTQB 国际软件测试资格委员会 认证可确保个人满足软件测试方面的国际公认标准。此外，ASTQB 还宣传软件测试作为美国软件开发和 IT 行业中的一个职业的价值和重要性。\n相关术语：\nISTQB 国际软件测试资格委员会 也可以看看：\n官方网站 关于 ASTQB 美国软件测试资格委员会的问题 基础知识和重要性 ASTQB 代表什么？ ASTQB 是 美国软件测试资格认证委员会 的缩写，是国际软件测试资格认证委员会 (ISTQB) 在美国的国家分支。它为美国的软件测试专业人员提供了统一的资格认证标准。\nASTQB 的目的是什么？ 美国软件测试资格认证委员会 (ASTQB) 的使命是为美国软件测试人员提供符合国际软件测试资格认证委员会 (ISTQB) 标准的标准化资格认证。作为ISTQB认证的美国国家机构，ASTQB 确保认证与美国的工作环境和文化相契合。\nASTQB 的宗旨在于提升软件测试作为一门职业的价值，丰富软件测试人员的知识储备和技能，倡导正确测试实践的重要性。通过认证，ASTQB 为测试人员提供了职业发展的道路，帮助建立雇主在招聘时可信赖的能力标准。\n该机构还通过组织会议、研讨会和工作坊，以及提供持续学习和职业发展的资源，支持软件测试社群。ASTQB 认证持有人成为一个社群的一员，可以获取独家更新、就业机会和建立人际关系的机会。\n总的来说，ASTQB 的目标是提高美国软件测试人员的职业标准和认可度，为整个软件测试行业的发展贡献力量。\n为什么 ASTQB 认证对于软件测试人员很重要？ ASTQB 认证对于软件测试人员至关重要，因为它验证了他们对软件测试的最佳实践和原则的理解和熟练程度。这不仅展示了对该领域的承诺，还表明了保持高水平测试质量的决心。拥有这项认证的测试人员能够脱颖而出，向潜在雇主展示他们具备被外部机构认可的专业水平。\n对于经验丰富的测试自动化工程师，ASTQB 认证可作为其技能水平的基准，有望带来职业发展和更高薪资的机会。它还确保他们紧跟行业中最新的方法和工具，这对于在就业市场上保持竞争力至关重要。\n此外，拥有 ASTQB 认证对于一些职位可能是必要条件，尤其是在注重遵循行业标准的组织中。它还可以通过确保共同的语言和对测试流程的共同理解，促进与其他认证专业人员的合作。\n最后，认证过程本身也是一次有价值的学习经历，使测试人员接触到新的概念和技术，可以在日常工作中应用，以提高其测试自动化策略的效率和效果。\n获得 ASTQB 认证有哪些好处？ 成为 ASTQB 认证持有人有以下好处：\n专业知识的认可: ASTQB 认证证明了你在软件测试方面的知识和技能，可以增强你的专业可信度。 竞争优势: 拥有 ASTQB 认证可以在求职和晋升中使你脱颖而出。 资源获取: 认证个体可以获得独家的 ASTQB 资源，如网络研讨会、文章和建立人际关系的机会。 更好的工作表现: 通过认证获得的知识可以导致改进的测试实践和更高质量的工作。 提高自信心: 认证可以增强你对测试能力的信心，让你有信心处理复杂的项目。 职业发展: 为考试做准备鼓励持续学习，并让你了解最新的测试方法。 全球认可: ASTQB 在国际上获得认可，使你的认证在考虑在国外工作时更有价值。 更高薪资的潜力: 由于拥有经过验证的技能，认证专业人员通常有权谈判更高的薪资。 请记住，尽管认证可以打开大门并提供好处，但真正增强你作为测试自动化工程师职业生涯的是应用所获知识。\nASTQB 与 ISTQB 有何不同？ ASTQB，或美国软件测试资格认证委员会，是国际软件测试资格认证委员会 (ISTQB) 在美国的分支。尽管 ASTQB 和ISTQB为软件测试人员提供类似的认证计划，但它们主要的区别在于地理关注点和区域影响。\nASTQB 提供的认证服务是为美国的工作环境和文化度身定制的，可能提供额外的服务或支持，以满足美国的需求。例如，ASTQB 的考试可能包含本土内容或提供美国范围内的社交机会。\nISTQB 则是一个全球性的实体，在各个国家都设有成员委员会。通过ISTQB 获得的认证在国际上得到广泛认可，没有地域限制。\n对于在美国工作或计划在美国工作的专业人士来说，ASTQB 认证可能更受美国雇主的认可。然而，对于寻求国际机会的人来说，由于其全球认可，ISTQB 认证可能更有益处。\n两个机构都制定了大致相同的教学大纲，确保软件测试的核心原则和实践是一致的。ASTQB 和 ISTQB 的认证在许多情况下是互通的，也就是说，其中一个机构的认证通常会被另一个机构认可。\n总的来说，虽然 ASTQB 和 ISTQB 共同致力于标准化软件测试人员的知识和技能，ASTQB 更专注于美国市场，而ISTQB 具有更广泛的国际影响。\n认证流程 ASTQB 认证的先决条件是什么？ 要追求ASTQB 认证，你必须满足以下先决条件：\n基础级别认证：你需要获得**ISTQB认证测试员基础级别 (CTFL)** 认证，这是入门资格的必备条件。 实际经验：虽然没有强制要求，但建议在软件测试领域至少有6 个月的实际经验，以更有效地掌握相关概念。 理解考试内容：熟悉你所参加的具体 ASTQB 认证考试的大纲和知识体系至关重要。 培训课程：虽然不是必需的，但参加认可的培训课程对于考试准备可能是有益的。 身份证明：需要有效的照片身份证明以注册并参加考试。 在注册考试之前，请确保已经审阅了你所追求的 ASTQB 认证级别的具体指南，因为一些高级或专业认证可能有额外的要求。\n获得 ASTQB 认证的流程是什么？ 获得ASTQB 认证，请按照以下步骤操作：\n根据你的经验和职业目标选择要追求的认证。 通过 ASTQB 网站或认可的培训提供商注册考试。 使用 ASTQB 提供的大纲和推荐的阅读材料准备考试。利用学习指南、书籍、在线课程和模拟考试。 安排考试。根据可用性，你可以在实体测试中心或通过在线监控的环境中进行考试。 参加考试。如果选择在线考试，请确保有一个安静、无干扰的环境；如果在测试中心，请提前到达。 接收结果。完成考试后，你通常会立即获得在线考试的结果，或在几周内获得纸质考试的结果。 通过考试后，从 ASTQB 网站下载你的证书。你还将被列入 ASTQB 成功考生登记册。 请记住查阅尝试的认证级别的具体指南，因为可能有额外或不同的步骤。保持你的知识更新，因为软件测试领域一直在发展，考虑重新认证或提升到更高级别的认证以保持和提升你的职业地位。\n准备 ASTQB 认证需要多长时间？ 准备ASTQB 认证的时间因个人经验和对考试主题的熟悉程度而异。通常，如果候选人在软件测试领域有坚实的背景并且已经在该领域工作，那么他们可能会花费2 到 3 个月的时间来学习。对于那些对概念较新或兼职学习的人，准备时间可能会延长到4 到 6 个月。\n一个专注的方法可能包括：\n彻底审查ASTQB 大纲。 阅读推荐的书籍和材料。 完成在线课程或参加研讨会。 定期参加模拟考试以评估理解和准备情况。 重要的是要为重新学习困难的主题和进行模拟考试以建立信心和时间分配时间。由于你是有经验的测试自动化工程师，你可能会发现一些领域需要较少的准备时间，这样你就可以集中精力学习不熟悉或具有挑战性的主题。\n请记住，目标不仅仅是通过考试，而是确保对概念有深刻的理解，以便在工作中进行实际应用。\nASTQB 认证考试的形式是什么？ ASTQB 认证考试的格式通常由多项选择题组成，用于评估你对大纲内容的理解。考试的问题数量和考试时间取决于具体的认证级别和模块。例如，基础级别考试通常有40 道问题，考生有75 分钟的时间来完成。\n考试旨在测试你对软件测试原理的理论知识和实际理解。问题的范围从回忆型查询到需要在给定场景中分析和应用概念的问题。\n考试是闭卷的，意味着在考试过程中不允许使用任何材料作为参考。然而，一些考试可能允许你使用大纲或术语表。\n考试可以在在线或实体测试中心进行。在线考试是远程监考的，确保测试过程的完整性。\n为了通过考试，你必须达到最低分数，通常设定为65%。通过考试后，你将收到一份数字证书，并可以使用 ASTQB 认证来展示你在软件测试领域的专业知识。\n请记住要通过 ASTQB 或认可的培训提供商进行注册，并确保你熟悉你正在追求的认证的具体格式和规则。\nASTQB 认证费用是多少？ ASTQB 认证的费用取决于具体的考试和你所在的国家。截至我在 2023 年初的知识截止日期，美国的价格通常在**$200 到$250之间，适用于基础级别考试。高级级别考试可能成本更高，通常约$350**。要获取确切的价格信息，最好与当地的 ASTQB 委员会或授权的考试提供商联系，因为费用可能会波动，可能还包括培训课程或学习材料等额外费用。\n要注册考试，请访问官方 ASTQB 网站或联系当地的ISTQB委员会。通常在注册时需要支付费用。请记住，如果有必要重新参加考试，将会产生额外的费用。值得注意的是，一些雇主可能会在专业发展计划的一部分覆盖认证费用。\n学习材料和准备 ASTQB 认证的最佳学习材料是什么？ 要有效地准备 ASTQB 认证，考虑以下学习材料：\nASTQB 官方大纲：从 ASTQB 网站下载最新的大纲，以了解考试内容和结构。 ASTQB 推荐书籍：参考 ASTQB 提供的书籍列表，其中包括\u0026quot;Software Testing Foundations\u0026quot; by Spillner, Linz, and Schaefer 等书籍。 在线课程：像 Udemy 或 Coursera 这样的平台提供专为 ASTQB 考试准备的课程。 学习指南：购买将考试主题分解为可管理部分的学习指南，通常包含实践问题。 模拟考试：使用官方 ASTQB 模拟考试，熟悉问题格式并评估自己的知识。 ASTQB 术语表：查阅官方术语表，确保理解考试中使用的所有测试术语。 ASTQB 网络研讨会：参加由 ASTQB 或其合作伙伴主持的网络研讨会，从专家那里获取见解和建议。 讨论论坛：参与像 SQA 论坛或 Stack Overflow 这样的论坛，与同行讨论话题并澄清疑虑。 闪卡：创建或在网上找到闪卡，帮助记忆关键概念和定义。 配对学习小组：加入或组建学习小组，分享知识并共同解决难题。 记得安排定期的学习时间，并使用定时模拟测试模拟考试条件，以增强你的准备。\n我应该如何准备 ASTQB 认证考试？ 为了有效地准备 ASTQB 认证考试，请按照以下步骤进行：\n审查大纲：熟悉考试大纲，了解所需的知识领域和能力。\n学习知识体系：获取推荐的阅读材料和学习指南。专注于你经验有限的领域。\n参加模拟考试：利用模拟考试来评估你的理解并确定需要改进的领域。模拟考试还有助于适应考试格式和时间限制。\n加入学习小组：参与在线论坛或本地学习小组。与同行讨论话题可以提供新的见解并强化你的理解。\n应用实际经验：将学习材料与你的实际经验联系起来。实际应用有助于记忆信息和理解概念。\n制定学习计划：分配定期学习时间并设定目标。有计划的学习有助于保持专注并系统地涵盖所有主题。\n休息和放松：确保在考试前休息充足。充足的休息可以提高在考试期间的专注力和回忆能力。\n请记住，ASTQB 认证是一个验证你专业技能的专业证书。彻底的准备不仅有助于你通过考试，还能提高你在软件测试自动化领域的实际技能。\nASTQB 有可用的模拟测试吗？ 是的，ASTQB 认证的模拟考试是可以找到的，对于准备考试的候选人来说，这是一个有价值的资源。这些模拟考试通常模仿实际考试中你将遇到的问题的格式和风格，提供对考试经验的逼真模拟。\n要找到模拟考试，你可以访问官方 ASTQB 网站或寻找专门提供考试准备材料的第三方供应商。有些资源可能是免费的，而其他可能需要付费。重要的是确保你使用的任何模拟考试都是最新的，并符合当前 ASTQB 考试大纲。\n此外，许多学习指南和准备书籍包括模拟问题和模拟考试。在线论坛和学习小组也是找到模拟考试建议并与同样准备 ASTQB 认证的同行讨论问题的好地方。\n记得要仔细阅读每个模拟问题的解释，这将帮助你理解正确答案背后的推理，并巩固你的知识。定期参加模拟考试可以帮助你找到需要进一步学习的领域，并增强你参加实际考试时的信心。\nASTQB 认证考试涵盖哪些主题？ ASTQB 认证考试涵盖了对于软件测试自动化专业人员至关重要的一系列主题。这些主题包括：\n测试基础知识：理解基本原则、测试流程和测试心理学。 贯穿软件生命周期的测试：将测试整合到软件开发生命周期中，包括测试层次和类型。 静态技术：通过工具进行审查过程和静态分析。 测试设计技术：识别和应用适当的测试设计技术，如等价划分、边界值分析、决策表测试、状态转换测试、用例测试等。 测试管理：测试组织、计划、估算、监控和控制。还包括配置管理、风险和缺陷管理。 测试工具支持：测试工具的类型、有效使用工具以及管理工具支持，包括自动化工具。 考试还评估了对**测试自动化概念**的理解以及在实际场景中应用这些概念的能力。这包括：\n选择和实施测试自动化工具 设计和编写测试脚本 测试脚本的维护 将自动化整合到 CI/CD 流水线中 候选人应展示他们在测试自动化中的最佳实践知识，以及解决自动化过程中可能出现的问题的能力。该考试要求理论知识和实际技能的结合，以确保认证人员能够有效地为其组织的测试自动化工作做出贡献。\nASTQB 认证考试的及格分数是多少？ ASTQB 认证考试的及格分数通常为65%，这意味着候选人必须正确回答至少 65% 的问题才能通过。然而，重要的是要验证你所参加的具体考试的及格标准，因为这可能会根据认证的级别和模块略有不同。\n认证后 获得 ASTQB 认证后我可以申请哪些工作职位？ 在获得 ASTQB 认证后，你可以申请软件测试和质量保证领域内的多种职业角色，包括：\n测试分析师：负责设计和执行详细的测试用例，并分析结果。 质量保证工程师：确保软件符合质量标准，可能参与 QA 流程的制定。 测试自动化工程师：专注于编写自动化脚本和维护自动化框架。 测试经理：监督测试团队、策略，并确保交付高质量的软件产品。 测试顾问：就测试流程和改进提供专业建议，通常与不同的客户和项目合作。 测试主管：领导测试团队，管理资源、进度，并确保有效的测试覆盖。 敏捷测试人员：在敏捷开发团队中工作，通常关注自动化和持续集成。 这些角色可能因公司和行业而异，但 ASTQB 认证可以极大地提升你在这些职位上的可信度和市场竞争力。它表明了对该领域的承诺，以及雇主看重的标准化知识水平。\nASTQB 认证如何增强我的职业前景？ ASTQB 认证可以通过验证你的专业知识和展示对职业的承诺，显著提升你的职业发展。作为一名经验丰富的测试自动化工程师，拥有 ASTQB 认证可以：\n提升你的可信度：表明你已达到国际认可的能力标准。 增加就业机会：雇主通常更倾向或要求认证，将其视为你技能和知识的证明。 促进职业晋升：认证可能是晋升或获得新角色的关键因素，尤其是在竞争激烈的就业市场中。 提高收入潜力：认证专业人员可能因其经过验证的技能而获得更高的薪水。 扩展职业网络：成为 ASTQB 社区的一部分，与其他认证专业人员建立联系，开启网络机会。 提供职业优势：在竞争激烈的领域中，认证可能是决定你脱颖而出的关键因素。 通过获得 ASTQB 认证，你不仅向雇主证明了你的能力，还确保你的技能在一个快速发展的行业中保持着相关性和更新。\n我需要多久更新一次 ASTQB 认证？ ASTQB 认证是 ISTQB 认证计划的一部分，永久有效，不需要定期更新。然而，由于 软件测试 领域一直在不断发展，因此保持与最新知识和实践的同步是至关重要的。为了不断提升您在 测试自动化 领域的专业技能，ASTQB 和 ISTQB 提供了各种高级认证和专业模块供您选择。建议您在职业生涯中持续学习，并考虑获取其他相关认证。\n我可以在国际上使用 ASTQB 认证吗？ 是的，ASTQB 认证 在国际上获得了广泛认可。尽管 ASTQB 是美国 软件测试 资格委员会，但它是国际 软件测试 资格委员会 (ISTQB) 的美国分支。因此，ASTQB 的认证是 ISTQB 全球认可的认证计划的一部分。\n一旦获得 ASTQB 认证，您将被列入**ISTQB 成功考生注册表**。这意味着您的认证可以由全球雇主验证，提升您在国际上的专业可信度。\n此外，由于 ASTQB 认证与 ISTQB 的标准一致，您获得的知识和技能适用于全球范围内的测试实践。这种普遍认可使您能够利用认证在本国之外寻找更多的职业机会，使其成为软件 测试自动化 领域职业发展的有力助力。\nASTQB 认证专业人员的平均工资是多少？ ASTQB 认证专业人士的平均薪资因地理位置、工作经验、职务以及查询时的具体市场状况等因素而差异较大。截至我在 2023 年初的知识截止日期，美国的 ASTQB 认证测试人员可能期望年均薪资在 $60,000 到 $100,000 范围内。然而，这只是一个宽泛的估计，实际薪资可能超出此范围。\n值得注意的是，拥有 ASTQB 认证可能导致较非认证同行更高的薪水，因为认证被认可为在 软件测试 领域具有质量和专业知识的标志。此外，认证专业人士可能能够获得更高级别和更高薪水的职务，这进一步影响了平均薪资。\n为获取最准确和最新的薪资信息，建议查阅 Glassdoor、Payscale 或 LinkedIn Salary 等薪资 数据库，并按照认证、地点和职称进行数据筛选。请记住，薪资可能会发生变化，并受到市场对认证专业人士的需求的影响。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-astqb/","summary":"这篇博文是软件测试术语分享系列的一部分，专注于 ASTQB（美国软件测试资格委员会）。文章深入介绍了 ASTQB 的基础概念和其在软件测试领域中的重要性，包括 ASTQB 的认证流程、学习材料以及准备考试的方法。读者将了解如何通过 ASTQB 的认证获得专业资格，并了解认证后的进一步发展机会。通过这个系列分享，读者将更深入地了解 ASTQB 认证对于提升软件测试职业能力的价值，以及如何有效地准备和应对认证考试。","title":"软件测试术语分享:ASTQB 美国软件测试资格委员会"},{"content":"第二天任务 阅读有关测试中的 AI 的介绍性文章并分享\n在今天的任务中学习人工智能测试基础知识！\n对于今天的任务，您面临的挑战是查找、阅读并分享有关软件测试中人工智能的介绍性文章的关键要点。这可能涵盖人工智能的基础知识、其在测试中的应用，甚至包括用于测试自动化的机器学习等特定技术。\n任务步骤 查找一篇介绍软件测试中的人工智能的文章。它可以是指南、博客文章或案例研究——任何您认为有趣且内容丰富的内容。\n总结本文的主要内容。讨论了哪些基本概念、工具或方法？\n考虑本文中的见解如何应用于您的测试环境。您认为人工智能在您的项目中具有潜在用途吗？面临哪些挑战或机遇？\n通过单击“参与”按钮并回复主题并附上您所选文章的摘要和您的个人感想，在社区上分享您的发现。资源链接（如果适用）。\n奖励步骤！通读其他人的贡献。请随意提出问题、提供反馈或通过 ❤️ 表达您对富有洞察力的发现的赞赏\n为什么参加 扩展您的理解：掌握测试中人工智能的基础知识对于有效地将这些技术集成到我们的工作中至关重要。\n启发和受到启发：分享和讨论文章向我们介绍了我们可能没有考虑过的各种观点和应用。\n节省时间：受益于社区的集体研究，更有效地发现有价值的资源和见解。\n建立您的网络：参与他人的帖子有助于加强我们社区内的联系，营造一个支持性的学习环境。\n任务链接 https://club.ministryoftesting.com/t/day-2-read-an-introductory-article-on-ai-in-testing-and-share-it/74453\n我的第二天任务 https://club.ministryoftesting.com/t/day-2-read-an-introductory-article-on-ai-in-testing-and-share-it/74453\n看看文章 → 我查看了这篇文章 AppAgent：作为智能手机用户的多模式代理 文章的主要启示\n这篇论文介绍了一个新颖的基于大型语言模型（LLM）的多模态代理框架，旨在操作智能手机应用程序。该框架通过简化的动作空间使得代理能够模仿人类的交互行为，如点击和滑动，无需系统后端访问权限，从而扩大了其在各种应用程序中的适用性。代理的核心功能是其创新的学习方法，可以通过自主探索或观察人类演示来学习如何导航和使用新应用程序。这一过程生成了一个知识库，代理在执行不同应用程序中的复杂任务时会参考这个知识库。\n论文还讨论了与大型语言模型相关的工作，特别是集成了视觉能力的 GPT-4，这使得模型能够处理和解释视觉信息。此外，还测试了代理在 50 个任务中跨 10 个不同应用程序的性能，包括社交媒体、电子邮件、地图、购物和复杂的图像编辑工具。结果证实了代理在处理多种高级任务方面的熟练程度。\n在方法论部分，详细介绍了该多模态代理框架的背后原理，包括实验环境和动作空间的描述，以及探索阶段和部署阶段的过程。探索阶段中，代理通过尝试和错误来学习智能手机应用程序的功能和特性。在部署阶段，代理根据其累积的经验执行高级任务。\n论文最后讨论了代理的局限性，即不支持多点触控和不规则手势等高级控制，这可能限制了代理在某些挑战性场景中的适用性。尽管如此，作者认为这是未来研究和发展的一个方向。\n潜力：针对移动设备的全新 UI 自动化测试脚本编写方法和理念；自行探索和模仿人工步骤；支持多种模型，可根据应用程序的实际情况选择和切换模型。\n挑战：您需要让 agent 熟悉您的移动应用程序，还需要向 agent 提供足够多的场景。\n以下是我的个人思考：\n论文和项目提供了未来移动端应用程序自动化测试的方向，但落地真实的项目还需要一些时间\n但我认为它可以用来对移动应用程序进行探索性测试，将现有的测试用例作为知识库，通过 AppAgent 学习和探索，扩展测试场景，改进真实有效的测试场景。\n后期也可以接入自己训练数据的模型，进行适配\n项目链接：https://github.com/mnotgod96/AppAgent\n论文链接：https://arxiv.org/abs/2312.13771\n关于活动 30 天 AI 测试挑战活动是 Ministry 测试社区发起的活动，上一次我了解这个社区是关于他们发起的 30 天敏捷测试的活动。\n社区官网：https://www.ministryoftesting.com\n活动链接：https://www.ministryoftesting.com/events/30-days-of-ai-in-testing\n推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/event/30-days-of-ai-in-testing-day-2-read-an-introductory-article-on-ai-in-testing-and-share-it/","summary":"这篇博文是 30 天 AI 测试挑战活动的第二天，聚焦于参与者阅读与测试中人工智能相关的介绍性文章并分享的环节。博文或许包含了作者对所阅读文章的总结和个人观点，分享了在测试领域中应用人工智能的潜在好处和挑战。通过这样的分享，读者能够更好地理解 AI 在测试中的应用，并促使其他参与者共享他们的见解，促进博文的互动性。这个系列活动有望为测试专业人士提供一个深入了解 AI 测试的平台。","title":"30 天 AI 测试挑战活动：第二天：阅读有关测试中的人工智能的介绍性文章并分享"},{"content":"API Testing API 测试 API 测试旨在验证和确认 API 在性能、功能、可靠性和安全性方面的表现。测试流程包括向 API 发送请求并分析其响应，以确保其符合预期结果。这项测试可以手动完成，也可以借助自动化工具，有助于发现诸如无效输入、错误处理不当和未经授权访问等问题。\n相关术语：\nAPI Microservices Testing 微服务测试 Postman Swagger 关于 API 测试的问题 基础知识和重要性 什么是 API 测试？ API 测试 是一种 软件测试 类型，旨在验证和确认应用程序编程接口 (APIs) 及其与其他软件组件的交互。该测试专注于软件架构的业务逻辑层，确保 APIs 正常运作，数据准确交换，并在各种条件下保持服务的可靠性和性能。\n在没有用户界面的消息层进行测试，使用工具发送调用到 API，获取输出并记录系统的响应。输入可以采用 REST、SOAP 或其他 Web 服务调用的形式，而输出通常采用 HTTP 状态码、JSON、XML 或其他数据格式。\nAPI 测试的自动化是为了提高效率，包括以下方面：\n功能测试：确保 API 的行为符合预期。 可靠性测试：检查 API 连接的能力以及导致一致结果的能力。 性能测试：评估 API 的响应时间和吞吐量。 安全测试：识别 API 中的漏洞。 API 测试 对于验证依赖于多个相互连接的 API 服务的应用程序的核心功能至关重要。它允许早期发现问题，并有助于保持高水平的服务质量。测试用例是基于 API 的规格设计的，而断言用于验证响应是否符合预期结果。\n为什么 API 测试很重要？ API 测试 的重要性在于它直接审视软件架构的业务逻辑层，提供早期检测缺陷和安全漏洞的机会。它允许在没有用户界面的情况下测试各种软件组件之间的交互以及与外部系统的互动，从而实现更快的 测试执行 和更全面的 测试覆盖率，因为可以对 APIs 进行独立测试。\n此外，API 测试 对于现代开发实践，如DevOps和微服务至关重要，这些服务经常更新和部署。它确保在这些服务集成到应用程序之前，它们能够有效通信并按预期工作，从而降低集成问题的风险。\nAPI 测试 还支持自动化，这对于持续测试和持续交付至关重要。自动化 API 测试可以迅速而频繁地运行，为开发团队提供即时反馈。这在**回归测试**方面尤为重要，确保新的更改不会破坏现有功能。\n此外，API 测试 对于性能优化至关重要，因为它有助于在服务级别识别瓶颈和性能问题。它还在契约测试方面发挥着重要作用，确保 API 符合与其他服务或客户定义的期望和协议。\n总之，API 测试 是坚实的 软件测试 策略的基础要素，确保在软件交互的最关键层面上系统可靠性、性能和安全性。\nAPI 测试有什么好处？ API 测试 提供了多个有助于提高软件系统质量和可靠性的优点：\n早期问题检测：通过直接测试逻辑层，可以在开发周期的早期阶段识别问题，从而节省时间和资源。 语言无关性：可以测试 API，而不受构建应用程序时使用的语言的限制，实现更灵活的测试环境。 无 GUI 测试：可以在无需用户界面的情况下测试核心功能，尤其在 UI 尚未开发或正在变更时特别有益。 改进的 测试覆盖率：可以涵盖更多条件和情况，包括那些通过 UI 测试难以模拟的情况。 更快的 测试执行：API 测试通常比基于 UI 的测试更快，导致更快的反馈和更高效的开发周期。 稳定性：与 UI 测试相比，它们更不容易受到变更的影响，形成一个更稳定且需要更少维护的测试套件。 集成测试：API 测试可以作为集成测试的基础，确保应用程序的不同部分能够正确交互。 安全性：它允许测试人员评估应用程序的安全方面，如访问控制、身份验证和数据加密。 性能基准测试：可用于评估应用程序在负载下的性能和行为，有助于识别瓶颈并优化吞吐量和响应时间。 自动化：API 测试可以轻松自动化，集成到 CI/CD 流水线中，并在不同环境中执行，为系统健康提供持续反馈。 API 测试和单元测试有什么区别？ API 测试 和 单元测试 是具有不同范围和目标的独立测试方法。\n单元测试 专注于软件的最小部分，通常是类内的个别函数或方法。这是由开发人员执行的，目的是确保软件的每个单元都按设计执行。单元测试通过隔离依赖项，通常使用模拟或存根来模拟其他模块。\nAPI 测试 则涉及测试应用程序编程接口 (APIs)，以验证其是否符合功能、可靠性、性能和安全性的期望。它在比 单元测试 更高的层次上运作，通常不关心系统内部的工作，而是专注于软件架构的业务逻辑层。\nAPI 测试通过 HTTP 请求和响应与应用程序进行交互，验证集成各种软件模块的逻辑。与单元测试不同，API 测试可能没有那么精细，并且通常需要运行环境来与 API 交互。\n虽然 单元测试 确保各个组件在孤立环境中正常工作，API 测试 则验证系统的外部接口是否正确运作，有可能发现由于与其他系统组件集成而被单元测试忽略的问题。\nAPI 测试在集成测试中的作用是什么？ API 测试 在 集成测试 中发挥着至关重要的作用，通过确保不同软件模块通过 APIs 进行交互时能够按预期通信和协同工作。在 集成测试 中，API 测试 专注于验证 APIs 与系统其他组件集成时的端到端功能、可靠性、性能和安全性。\n在 集成测试 过程中，测试人员使用 API 调用来验证各种软件层和外部系统之间的交互。这包括检查在相互连接的模块之间发生的数据流、错误处理和业务逻辑。API 测试 在这个阶段有助于识别在 单元测试 中可能不会显露的问题，例如数据交换格式的不一致、身份验证问题以及处理并发进程失败的问题。\n通过在 集成测试 中自动化 API 测试，工程师可以快速检测集成缺陷，并确保系统作为整体无缝运行。这在代码变更频繁集成和测试的持续集成环境中尤为重要。\n总之，在 集成测试 中，API 测试 对以下方面至关重要：\n验证不同系统组件之间的交互。 确保数据一致性和正确的数据交换。 检测接口缺陷，这在单元测试中可能会被忽略。 验证贯穿多个模块的业务逻辑。 通过自动化 测试用例 促进在 CI/CD 流水线中进行持续测试。 API 测试类型 API 测试有哪些不同类型？ 不同类型的 API 测试 专注于 API 的功能、可靠性、性能和安全性的各个方面。以下是一些关键类型：\n功能测试：验证 API 是否按预期功能，处理请求并返回正确的响应。\n验证测试：确保 API 符合规范和要求，包括数据验证和架构遵从性。\n错误检测：识别错误条件并检查 API 如何处理不正确的输入或意外的用户行为。\nUI 测试：对于带有用户界面组件的 APIs，从用户的角度测试集成和功能。\n安全性测试：评估 API 的漏洞，确保数据得到正确加密、身份验证和授权。\n性能测试：衡量 API 在各种负载条件下的响应性、吞吐量和稳定性。\n模糊测试：向 API 发送随机、畸形或意外的数据，以检查是否存在崩溃、故障或安全漏洞。\n互操作性和 WS 合规性测试：对于 SOAP APIs，确保 API 符合 WS-* 标准并可以与其他符合 WS 标准的系统互操作。\n运行时/错误检测：在执行过程中监视 API，以检测在正常操作期间发生的运行时问题和错误。\n渗透测试：模拟攻击以识别 API 中的安全弱点。\n合规性测试：验证 API 是否符合法规标准和合规性要求。\n每种类型都针对 API 的不同方面和层次，确保全面的测试策略覆盖 API 的功能和潜在问题的全部范围。\nREST 和 SOAP API 在测试方面有什么区别？ 在测试 REST（表征状态转移）和 SOAP（简单对象访问协议）APIs 时，关键的区别在于所使用的 协议、数据格式、复杂性 和测试方法。\nREST APIs：\n明确使用 HTTP 方法（GET、POST、PUT、DELETE）。 支持多种数据格式，通常是 JSON 和 XML。 是无状态的；客户端到服务器的每个请求必须包含理解请求所需的所有信息。 测试涉及使用正确的参数和方法构造请求，并验证响应代码、标头和主体。诸如 Postman 的工具可用于模拟 API 调用并自动化测试。 SOAP APIs：\n使用 SOAP 协议，这是一组更为严格的消息模式。 主要使用 XML 作为消息格式。 可以是有状态的；服务器可以在多个请求之间保持会话状态。 测试需要分析 WSDL（Web 服务描述语言）文件以了解可用的操作。必须根据特定的 SOAP 包结构和其中包含的数据进行断言。诸如 SoapUI 的工具专为此目的而设计。 在测试方面，由于其使用标准 HTTP 和 JSON，通常认为 REST API 测试 更为 灵活 和 易于实施，而 SOAP 则需要更多关于协议和服务 WSDL 的 详细知识。此外，REST 测试可能更加 轻量级，因为它不需要像 SOAP 那样进行广泛的 XML 解析和验证。然而，SOAP 的严格规范对于测试可能是有益的，因为它强制执行必须遵守的契约，从而可能减少 测试用例 中的歧义。\nAPI 测试中什么是 CRUD 测试？ 在 API 测试 中，CRUD 测试侧重于验证对于 RESTful APIs 功能至关重要的 Create（创建）、Read（读取）、Update（更新）和 Delete（删除）操作。每个操作对应一个 HTTP 方法：创建使用 POST，读取使用 GET，更新使用 PUT/PATCH，删除使用 DELETE。\n在 CRUD 测试期间，您需要确保：\nPOST 请求成功创建新资源，并返回适当的状态码（例如 201 Created），以及资源的表示或位置。 GET 请求准确检索数据，支持查询和路径参数，并且在处理不存在的资源时能够优雅地处理（例如 404 Not Found）。 PUT 或 PATCH 请求正确修改现有资源，适当时遵循幂等性，并提供正确的响应代码（例如 200 OK 或 204 No Content）。 DELETE 请求按预期删除资源，并返回正确的状态码（例如 200 OK 或 204 No Content）。 CRUD 测试确保 API 遵循其规范并正确处理数据操作场景。这对于在应用程序内部保持数据完整性和一致性至关重要。测试用例 应该涵盖典型的 用例 和边缘情况，例如尝试删除不存在的资源或使用无效数据更新资源。\nAPI 测试中的负载测试是什么？ API 测试 中的 负载测试 涉及模拟对 API 终端点的大量请求，以评估系统在压力下的性能。这种类型的测试对于确定 API 的 可扩展性 和 可靠性 至关重要，因为它有助于在 API 面临大量流量时识别瓶颈和潜在的故障点。\n在 负载测试 期间，会测量各种指标，如 响应时间、吞吐量、错误率 和 资源利用率，以评估 API 的性能。其目标是确保 API 能够在维持可接受性能水平的同时处理预期的负载条件。\n诸如 JMeter、Gatling 和 LoadRunner 之类的工具通常用于自动化生成请求并收集性能数据的过程。这些工具允许测试人员通过调整并发用户数、请求频率和有效载荷大小来创建逼真的负载场景。\n负载测试 通常在尽可能模拟生产 设置 的受控环境中进行。这确保测试结果是相关且可操作的。逐渐增加负载是很重要的，以了解性能如何随着施加的负载而变化。\n通过早期识别性能限制，组织可以在对最终用户产生影响之前对其 APIs 进行必要的优化，确保在高峰时期仍然能够提供流畅、高效的用户体验。\nAPI 测试中的安全测试是什么？ API 测试 中的安全测试专注于验证 APIs 的机密性、完整性和可用性。其目标是发现可能导致未经授权访问、数据泄露或其他安全威胁的漏洞。关键方面包括：\n身份验证：确保只有经授权的用户可以访问 API。 授权：确认用户对请求的操作具有权限。 输入验证：检查 SQL 注入、XSS 和其他注入漏洞。 加密：验证数据在传输和静态状态下是否加密。 错误处理：确保敏感信息不会通过错误消息泄漏。 速率限制：通过限制 API 请求速率来防止 DoS 攻击。 安全测试 工具如 OWASP ZAP 或 Burp Suite 可以自动化漏洞扫描。将 安全测试 集成到 CI/CD 流水线中以进行持续安全保障至关重要。\nAPI 测试工具 API 测试常用的工具有哪些？ 常用于 API 测试 的工具包括：\nBruno/Postman：一种广受欢迎的手动和自动化测试工具，提供用户友好的界面和脚本功能。 SoapUI：专为 SOAP 和 REST API 测试设计的工具，提供丰富的测试功能。 Katalon Studio：一款集成工具，支持 API 和 UI 测试自动化。 JMeter：一款主要用于性能测试的开源工具，同时也支持 API 测试。 Rest-Assured：一个用于简化 RESTful API 测试的 Java DSL，在现有的基于 Java 的生态系统中能够无缝集成。 Insomnia：一款功能强大的 REST 客户端，支持测试 API，包括 GraphQL 和 gRPC。 Curl：用于通过 URL 传输数据的命令行工具，通常用于快速进行 API 交互。 Paw：一款专为 macOS 设计的 API 工具，具有原生的 macOS 界面，提供了用于 API 开发和测试的高级功能。 Karate DSL：一个开源工具，将 API 测试自动化、模拟、性能测试甚至 UI 自动化整合到一个统一的框架中。 Assertible：专注于持续测试和可靠性的工具，提供自动化的 API 测试和监控。 HTTPie：一款用户友好的命令行 HTTP 客户端，提供简单直观的方式进行 HTTP 请求，可用于 API 测试。 这些工具提供各种功能，包括测试脚本、响应验证和与 CI/CD 流水线的集成，以满足不同的测试需求和偏好。\nPostman 用于 API 测试有哪些功能？ Postman 是一款多功能的 API 测试 工具，具有简化 API 测试创建、执行和管理的功能：\n易于使用的界面：Postman 提供用户友好的图形界面，用于发送请求、保存环境和查看响应。 集合：将相关的 API 请求分组到集合中，以便更好地组织和执行。 环境和全局变量：存储和管理变量，方便在不同的测试环境之间切换。 预请求脚本和测试：编写 JavaScript 代码，在发送请求之前或收到响应后执行，以设置条件或断言结果。 自动化测试：使用集合运行器或 Newman（Postman 的命令行伴侣）运行集合，实现自动化测试执行。 数据驱动测试：从外部文件中提取数据到请求中，以验证在不同条件下的 API 行为。 监控：定期安排集合运行，监控 API 的性能和健康状况。 文档：从集合自动生成并发布 API 文档。 版本控制：将集合与 Postman 的云服务同步，实现协作和版本控制。 集成：使用 Newman 或 Postman API 与 CI/CD 流水线连接，实现与开发工作流的无缝集成。 API 模拟：创建模拟服务器以模拟 API 端点，进行测试而无需实际的后端服务。 工作区：在共享或个人工作区中与团队成员协作。 这些功能使 Postman 成为一款全面的 API 测试 工具，既方便手动的 探索性测试 又支持自动化的 测试执行。\nSoapUI 与其他 API 测试工具有何不同？ SoapUI 与其他 API 测试工具的主要区别在于它主要专注于**SOAP（Simple Object Access Protocol）**服务，尽管它也支持 RESTful 服务和其他 Web 协议。它提供了一个专门用于 SOAP 特定验证的环境，例如 WS-Security、WS-Addressing 和 MTOM（Message Transmission Optimization Mechanism），这在其他更偏向 REST 的工具中较为罕见。\n另一个不同之处是 SoapUI 对数据驱动测试的广泛支持。它允许测试人员轻松地从外部来源，如数据库和 Excel 文件，读取数据以创建动态请求并验证响应。这与其使用Groovy 脚本编写复杂场景的能力结合使用。\nSoapUI 还提供了模拟功能，使用户能够在实际实施之前模拟 Web 服务的行为。这在**面向服务的体系结构（SOA）**中特别有用，因为服务是并行开发的。\n对于性能测试，SoapUI 提供了LoadUI，这是一个集成工具，允许测试人员将功能测试用例重复使用作为性能测试，这是不是所有 API 测试工具都提供的独特功能。\n最后，SoapUI Pro，SoapUI 的商业版本，提供了高级功能，如**SQL查询构建器**、基于表单的输入和报告生成，这提高了用户体验和生产力，使其从许多开源替代品中脱颖而出。\n使用自动化工具进行 API 测试有哪些优势？ 使用自动化工具进行 API 测试 具有多重优势：\n高效性：自动化测试比手动测试运行速度更快，可以在更短时间内执行更多的测试。 一致性：自动化确保每次以相同方式执行测试，减少人为错误，提高可靠性。 可重用性：测试脚本可在不同 API 版本之间重复使用，省去为每个变更编写新测试的时间。 集成性：自动化测试可轻松集成到 CI/CD 流水线中，实现持续测试和部署。 可扩展性：自动化支持在各种条件和负载下运行测试，对性能测试至关重要。 覆盖面：工具能生成并执行大量测试用例，提高测试的广度和深度。 回归测试：可以迅速、频繁地运行自动化回归测试，确保新更改未破坏现有功能。 报告功能：工具通常提供详细的日志和报告，有助于识别和解决问题。 并行执行：测试可并行运行，减少测试执行时间。 程序控制：测试用例可包含难以手动执行的复杂逻辑和场景。 通过充分发挥这些优势，测试自动化 工程师能够确保更强大、可靠的 API，同时优化测试工作和资源利用。\n选择 API 测试工具应该考虑哪些因素？ 使用自动化工具进行 API 测试具有多重优势：\n高效性：自动化测试比手动测试更迅速，能够在更短的时间内完成更多测试。 一致性：自动化确保每次测试都以相同方式执行，减少人为错误，提高可靠性。 可重用性：测试脚本可以跨不同 API 版本重复使用，省去为每次变更编写新测试的时间。 集成性：自动化测试可轻松集成到 CI/CD 流程中，实现持续测试和部署。 可扩展性：自动化支持在不同条件和负载下运行测试，对性能测试至关重要。 覆盖全面：工具能够生成并执行大量测试用例，提高测试的广度和深度。 回归测试：自动化回归测试可以快速而频繁地运行，确保新更改没有破坏现有功能。 报告详尽：工具通常提供详细的日志和报告，有助于快速识别和解决问题。 并行执行：测试可以并行运行，缩短测试执行时间。 程序控制：测试用例可以包含复杂的逻辑和场景，手动执行难以实现。 通过充分发挥这些优势，测试自动化工程师可以确保更为强大和可靠的API，同时优化测试工作和资源利用。\nAPI 测试流程 API 测试涉及哪些步骤？ 进行 API 测试的步骤通常包括以下几个关键步骤：\n定义测试范围：明确定义需要测试的端点和操作（GET、POST、PUT、DELETE）。\n了解API需求：仔细研究API文档，了解所期望的请求格式、标头、负载和响应代码。\n设置测试环境：配置必要的参数，如基本 URL、身份验证凭据以及任何需要的初始数据设置。\n创建测试用例：制定各种测试用例，涵盖功能、可靠性、性能和安全性。包括正面、负面和边缘案例。\n自动化测试用例：使用 API 测试工具编写脚本，发送请求并验证响应。运用断言检查正确的状态代码、响应时间和数据准确性。\n执行测试：运行自动化测试用例对API进行测试。这可以手动进行，也可以作为 CI/CD 管道的一部分。\n验证和记录结果：分析测试结果是否存在任何差异。对于任何失败的测试，记录缺陷并详细记录发现。\n审查测试覆盖率：确保测试覆盖了API的所有方面，并根据需要更新测试用例以提高覆盖率。\n监控和维护：持续监控API以寻找任何性能问题，并维护测试用例以适应API的任何更改。\n报告：生成测试报告，总结测试活动，包括通过/失败的测试数量和任何未覆盖的问题。\n每个步骤都至关重要，以确保对API的功能、可靠性、性能和安全性进行全面评估。\n什么是 API 端点测试？ API 端点测试是验证客户端与API之间各个交互点的过程。其目的是确保端点对各种 HTTP 方法（如 GET、POST、PUT 和 DELETE）以及适当的输入参数能够正确响应。这种测试注重于以下几个方面：\n请求和响应结构：验证请求的格式是否正确，以及响应是否符合预期的模式。 数据验证：确保发送到端点和从端点接收的数据是正确的，并符合规定的约束。 HTTP 状态码：检查端点在不同情境下是否返回了正确的状态码。 错误处理：确认端点能够提供有意义的错误消息，并且能够优雅地处理错误。 性能：评估端点在负载下的响应时间以及其行为。 进行端点测试可以利用工具如Postman，也可以通过编写脚本来实现，比如在 Python 中使用requests或在 JavaScript 中使用axios。下面是使用axios在 JavaScript 中进行简单 GET 请求测试的示例：\nconst axios = require(\u0026#39;axios\u0026#39;); axios.get(\u0026#39;https://api.example.com/v1/users\u0026#39;) .then(response =\u0026gt; { if(response.status === 200) { console.log(\u0026#39;Success: Endpoint returned 200 OK\u0026#39;); } else { console.error(\u0026#39;Error: Unexpected status code\u0026#39;); } }) .catch(error =\u0026gt; { console.error(\u0026#39;Error: Endpoint request failed\u0026#39;); }); 在这一背景下，端点测试是 API 测试的一个关键环节，重点关注API的外部接口的正确性和可靠性。\n如何验证 API 测试中的响应？ 在进行 API 测试时，验证响应涉及多个检查，以确保API的行为符合预期。使用断言将实际响应与预期结果进行比较。主要的验证点包括：\n状态码：验证 HTTP 状态码（例如，200 OK，404 Not Found），以确认响应的成功或失败。 响应时间：确保 API 在可接受的时间范围内响应，表示性能良好。 头部：检查响应头部，确保内容类型、缓存策略和安全参数正确。 主体：验证响应负载的正确数据结构、数据类型和数值。在适用时使用 JSON 或 XML 模式验证。 错误码：对于错误响应，确保 API 返回适当的错误代码和消息。 业务逻辑：确认响应是否遵循业务规则和工作流程。 数据完整性：如果 API 与数据库交互，验证返回的数据是否与数据库状态一致。 以下是在 JavaScript 中使用 Chai 断言库的示例：\nconst expect = require(\u0026#39;chai\u0026#39;).expect; const request = require(\u0026#39;supertest\u0026#39;); const api = request(\u0026#39;http://api.example.com\u0026#39;); api.get(\u0026#39;/users/1\u0026#39;) .end((err, response) =\u0026gt; { expect(response.statusCode).to.equal(200); expect(response.body).to.have.property(\u0026#39;username\u0026#39;); expect(response.body.username).to.be.a(\u0026#39;string\u0026#39;); expect(response.headers[\u0026#39;content-type\u0026#39;]).to.equal(\u0026#39;application/json\u0026#39;); }); 通过使用您选择的 API 测试工具自动化这些验证，确保测试过程中的一致性和效率。\nAPI 测试中如何处理认证和授权？ 在 API 测试中处理身份验证和授权涉及验证API是否正确识别用户（身份验证）并授予适当的访问级别（授权）。以下是处理方法：\n了解身份验证机制：常见的方法包括基本身份验证、OAuth、API密钥和 JWT（JSON Web Tokens）。确定API使用的方法。\n获取有效凭据：对于自动化测试，您需要一组有效的凭据或令牌。这可能涉及初步API调用以生成令牌，或者使用预先生成的长期有效令牌进行测试。\n在API请求中包含凭据：根据身份验证方法，这可能意味着在 HTTP 请求中添加标头、Cookie 或参数。例如，在基本身份验证中，您将添加包含经过 base64 编码的用户名和密码的Authorization标头。\nAuthorization: Basic \u0026lt;base64-encoded-credentials\u0026gt; 使用无效/过期凭据进行测试：确保当提供无效凭据或令牌过期时，API正确拒绝访问。\n验证授权：测试API是否通过尝试使用不同用户角色访问资源来执行正确的权限级别。确认每个角色只能访问其应有的资源。\n自动化凭证管理：在您的测试自动化框架中，实施一种自动处理令牌生成和更新的方式，特别是如果令牌具有短有效期。\n安全存储凭据：使用环境变量或安全保险库来存储和访问您测试自动化环境中的凭据，避免硬编码敏感信息。\n检查响应代码和消息：确保API对身份验证和授权方案返回适当的 HTTP 状态代码和消息，如401 Unauthorized或403 Forbidden。\n测试期间需要查找哪些常见 API 错误？ 在测试API时，要留意以下常见错误：\n400 Bad Request：无效的请求格式；确保负载符合 API 规范。 401 Unauthorized：缺少或不正确的身份验证凭据；验证令牌或用户凭据。 403 Forbidden：已验证但缺少权限；检查用户权限。 404 Not Found：端点或资源不存在；确认 URL 和资源标识符。 405 Method Not Allowed：HTTP 方法不适用于端点；查阅 API 文档了解允许的方法。 408 Request Timeout：服务器等待请求时超时；调查网络问题或增加超时设置。 429 Too Many Requests：超过速率限制阈值；实施回退策略并遵守速率限制。 500 Internal Server Error：通用的服务器端错误；检查服务器日志以查找未处理的异常或配置错误。 502 Bad Gateway：上游服务器返回无效响应；确保所有后端服务都正常运行。 503 Service Unavailable：服务不可用或过载；监控系统健康和负载。 504 Gateway Timeout：上游服务器未能及时响应；类似于 408，但表示服务器之间通信存在问题。 对响应负载进行模式验证，检查数据一致性，并确保错误消息清晰而有帮助。使用自动化工具模拟各种场景和边缘情况。在评估错误响应时，要始终考虑API的上下文和业务逻辑。\n深层理解 API 测试在持续集成/持续部署 (CI/CD) 中的作用是什么？ API 测试在持续集成/持续部署（CI/CD）流水线中发挥着至关重要的作用，通过确保应用程序编程接口（API）符合功能、可靠性、性能和安全标准。在 CI/CD 中，每次代码提交都会触发自动构建和测试过程，其中包括API测试，以验证不同软件组件之间的交互。\n在 CI/CD 中，API 测试：\n验证新的代码更改是否未破坏现有的 API 功能。 实现及早检测缺陷，降低修复所需的成本和工作量。 促进在完整系统环境中集成服务之前，对 API 进行孤立测试。 支持对 DevOps 实践至关重要的快速反馈循环，使开发人员能够立即了解其更改的影响。 自动化API 的回归测试，确保增强或修复错误不会引入新问题。 协助在每次部署时监控 API 的性能，保持应用程序的响应性和效率。 为安全保障做出贡献，整合自动化安全测试，检查 API 中的漏洞。 通过将 API 测试集成到 CI/CD 流水线中，团队可以在保持高质量标准的同时加速软件更新的交付，从而实现在生产中更可靠和强大的应用程序。\nAPI 测试如何集成到敏捷方法中？ 将 API 测试整合到敏捷方法论中需要确保测试活动与迭代式开发周期相协调。首先，在用户故事和验收标准中引入 API 测试，确保从一开始就考虑API功能。在冲刺计划期间，分配任务以创建和自动化API 测试用例，与冲刺的开发工作相协调。\n利用测试驱动开发（TDD），在实际编写API代码之前编写API测试，确保代码从一开始就符合测试要求。在冲刺中，将 API 测试作为完成的定义的一部分，确保在考虑功能完成之前对API进行了全面测试。\n借助持续集成（CI）流水线，在代码提交时自动触发API测试，以确保变更的即时反馈。在每日站会中，讨论API测试的状态和结果，以保持团队的及时了解并及时解决问题。\n整合与敏捷项目管理工具良好集成的测试自动化框架，实现测试用例、用户故事和缺陷之间的可追溯性。应用模拟和服务虚拟化，独立于依赖项测试API，允许在隔离的环境中进行测试并与开发同时进行测试。\n最后，倡导协作文化，鼓励开发人员、测试人员和产品负责人共同负责API质量，并促使通过 API 测试发现的问题迅速解决。\nAPI 测试在微服务架构中的作用是什么？ 在微服务架构中，API 测试发挥着至关重要的作用，确保每个服务能够有效地与其他服务通信，并确保整个系统按预期运行。由于微服务被设计为松散耦合且可以独立部署，因此 API 测试成为验证服务间合同和相互作用的关键要素。\n在这一背景下，API 测试主要关注以下方面：\n服务隔离：在独立环境中测试各个微服务，确保它们正确执行其特定功能。 集成点：验证服务通过它们的 API 与其他服务无缝交互，包括检查数据流、错误处理和备用机制。 端到端工作流：确保微服务的综合操作符合整体业务需求。 版本管理：检查 API 版本管理是否得当，以避免独立更新服务时出现破坏性变更。 服务发现：确认服务能够在不断演化的生态系统中动态发现并相互通信。 通过在微服务架构中进行严格的 API 测试，团队能够早期发现问题，减少服务间的依赖关系，并保持高水平的服务自治性。这对于实现微服务所承诺的可扩展性、灵活性和弹性至关重要。此外，API 测试通过自动验证服务集成支持CI/CD流水线，这对于快速、可靠地交付基于微服务的应用程序至关重要。\nAPI 测试中的契约测试是什么？ 契约测试是 API 测试的一种类型，专注于验证不同服务之间的交互是否符合在“契约”中记录的共同理解。这个契约定义了消费者（例如客户端应用程序）和提供者（例如 Web 服务）之间期望的请求和响应。\n在契约测试中，消费者和提供者的测试是根据已同意的契约编写的，这个契约充当单一真相来源。消费者测试验证客户端是否能够正确生成符合契约规范的请求。提供者测试确保服务能够处理这些请求并返回符合契约的响应。\n契约测试的一个常用工具是Pact，它允许开发人员将契约定义为代码，并提供一个平台，用于在消费者和提供者之间共享这些契约。契约进行版本管理以安全管理更改。\n契约测试的主要目标是在将服务部署到生产环境之前检测服务之间的任何不兼容性。这在微服务架构中尤为重要，因为服务是独立开发和独立部署的。\n契约测试并不替代 API 测试的其他形式，而是通过专注于交互契约来补充它们，因为这可能是集成测试中的盲点。它提供了快速反馈，并确保应用程序的可独立部署单元将按照预期的方式一起工作。\nAPI 测试如何帮助性能优化？ API 测试在性能优化方面发挥着重要作用，它允许工程师在服务层次上发现并解决性能瓶颈。通过对API端点执行性能测试，团队可以评估在不同负载条件下的响应时间、吞吐量和资源利用率，从而找出需要优化的地方。\n例如，使用JMeter或 LoadRunner 等工具，测试人员可以模拟高并发场景，了解API在压力下的表现。如果API表现出长时间的响应或高错误率，这表明需要进行性能调优。这可能包括优化数据库查询、缓存响应或扩展基础架构。\n此外，API性能测试可以自动化，并纳入 CI/CD 流水线，确保在部署之前验证任何代码更改对性能的影响。这种积极的方法防止性能下降进入生产环境。\n通过隔离API层，工程师可以专注于优化服务级性能，而不必担心全面 UI 或端到端测试的复杂性。在微服务架构中，这尤其关键，因为必须确保各个服务以最佳性能运行，以保证整个系统的响应速度和可靠性。\n总体而言，API 测试是性能优化的有力工具，为工程师提供了洞察服务级性能的机会，使其能够基于数据做出决策，从而提高应用程序的速度和可靠性。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-api-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，重点关注 API Testing（API 测试）。文章深入探讨了 API 测试的基础概念和其在软件开发中的重要性，包括 API 测试的不同类型，常用的 API 测试工具，以及 API 测试的流程。读者将学到如何有效地进行 API 测试，确保 API 的稳定性和可靠性。此外，博文还深入了解 API 测试的深层理解，以便读者能更全面地应对复杂的 API 测试场景，提高测试的质量。","title":"软件测试术语分享:API Testing API 测试"},{"content":"关于活动 30 天 AI 测试挑战活动是 Ministry 测试社区发起的活动，上一次我了解这个社区是关于他们发起的 30 天敏捷测试的活动。\n社区官网：https://www.ministryoftesting.com\n活动链接：https://www.ministryoftesting.com/events/30-days-of-ai-in-testing\n活动介绍 通过 30 天 AI 测试挑战赛，在整个 3 月份升级您的测试游戏！\n2024 年 3 月 1 日 - 2024 年 4 月 1 日 00:00 - 23:00 英国夏令时 地点：线上 召集所有测试人员、人工智能爱好者以及任何对人工智能如何重塑软件质量感到好奇的人。准备好探索人工智能的世界了吗？今年 3 月，我们将启动 30 天人工智能测试，诚邀您加入这一使命！\n它是什么？ 在 30 多个启发性的日子里，与充满活力的社区一起，您将踏上探索人工智能在测试中的潜力的旅程。每天，我们都会探索和讨论新的概念、工具和实践，以揭开人工智能的神秘面纱并增强您的测试工具包。\n为什么要参加？ 逐步提升您的技能：每天都会有一项新的、可管理的任务建立在前一项任务的基础上。帮助您逐步加深对 AI 测试的理解。\n提高您的测试效率和有效性：探索人工智能可用于改进日常测试、提高效率和有效性的多种方式。\n联系与协作：在 The Club 论坛上与全球测试人员和 AI 爱好者社区互动，分享见解并获得灵感和支持。 实现 AI 雄心：利用此挑战作为实现 AI 测试目标的垫脚石。深入研究并解决满足您人工智能抱负的任务。 领导和启发：通过在挑战期间分享您的人工智能之旅和发现，您将在提升社区知识和技能方面发挥至关重要的作用。\n它将如何运作？ 整个三月，MoT 团队的一名成员将在俱乐部论坛上发布一项新的简短每日任务，这将增强您对测试中的 AI 的理解。\n然后，您将回复主题帖子以及对每项日常任务的回复。请随意分享您的想法、提出问题、寻求建议或向他人提供支持。\n最后，不要忘记通过参与其他人的回复来鼓励有意义的讨论。如果您发现某人的回复有趣或有帮助，请点击❤️按钮并让他们知道！\n不要害怕错过时机；现在注册！注册后，您将收到每项日常任务的电子邮件提醒。\n第一天任务 我们走吧！ 🚀 欢迎来到 30 天人工智能测试的第一天！我很高兴能够开始这一旅程，我们一起探索人工智能在测试中的潜力。\n任务详情 对于今天的任务，我们邀请您向社区介绍自己并分享您对人工智能的兴趣。这是一个表达您的好奇心、愿望以及您希望在这个为期一个月的挑战中实现的目标的机会。\n以下是一些可以帮助指导您的提示：\n自我介绍：告诉我们您的背景、您在测试或技术中的角色以及您如何找到这个社区。\n您对人工智能的兴趣：最初是什么激发了您对人工智能测试的兴趣？测试中的人工智能有哪些特定领域是您渴望了解更多的吗？\n您的目标：您希望在这次挑战中学习或实现什么？\n任务链接 https://club.ministryoftesting.com/t/day-1-introduce-yourself-and-your-interest-in-ai/74449/312\n我的第一天任务 https://club.ministryoftesting.com/t/day-1-introduce-yourself-and-your-interest-in-ai/74449/291\n大家好，我是 dengnao。你可以叫我 Nao，我现在是 thoughtworks 中国的一名资深 QA. 我最开始从硬件测试，系统测试到入行软件测试，也从手工测试，到接口自动化测试，UI 自动化测试，移动端自动化测试，性能测试到最后的全流程项目质量保障，截止到目前已经有十二年的 QA 工作经验了。\n目前也在我的个人博客上持续输出文章：https://naodeng.com.cn\n之前是通过 30 天敏捷测试活动才知道了这个社区。\n关于 AI 测试，一直是我持续关注的话题，从最开始的精准测试到现在的生成式 AI 和大模型。想通过 AI 测试领域的学习和投入，输出有效的工具或方法来提升手工测试和自动化测试的效率，当然也包括性能测试，质量管理的效率提升方面。\n参加这次活动的目的，更多是想获取到其他社区成员关于 AI 测试的想法和实践经验，和社区成员一起探讨 AI 测试可行的方向。\n推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/event/30-days-of-ai-in-testing-day-1-introduce-yourself-and-your-interest-in-ai/","summary":"这篇博文是关于 30 天 AI 测试挑战活动的第一天，介绍了活动的开端。博文开始于挑战的第一天，探讨了参与者自我介绍和对人工智能的兴趣。文章或许包括了作者的背景、工作经验以及对 AI 测试的期望。这个系列挑战活动有望为读者提供一个深入了解 AI 测试并不断学习的机会，也可能包含了一些鼓励和动力，鼓励读者积极参与整个挑战。","title":"30 天 AI 测试挑战活动：第一天：介绍你自己以及你对人工智能的兴趣"},{"content":"API 应用程序编程接口 应用程序编程接口（API）是一组允许两个应用程序进行通信的规则。在这里，“应用程序”一词指的是具有特定功能的任何软件。API 定义了这些应用程序如何发送和接收请求及响应。\n相关术语：\nAPI Testing API 测试 Microservices Testing 微服务测试 也可以看看：\n维基百科\n关于 API 的问题 基础知识和重要性 什么是 API 以及它如何工作？ API（应用程序编程接口）是一套用于构建软件应用程序的协议、例程和工具。它规定了软件组件的互动方式，使得不同系统能够轻松通信。将 API 视为一个中介层，它处理请求并确保企业系统的平稳运行。\nAPI 通过互联网上的“调用”或“请求”进行操作，数据通常以 JSON 或 XML 等格式进行交换。当对 API 发出请求时，它执行预定义的操作并返回响应。这可能包括数据检索、更新或其他 CRUD（创建、读取、更新、删除）操作。\n以下是使用 JavaScript 中的fetch函数调用 API 的基本示例：\nfetch(\u0026#39;https://api.example.com/data\u0026#39;, { method: \u0026#39;GET\u0026#39;, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Authorization\u0026#39;: \u0026#39;Bearer Your-API-Key\u0026#39; } }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); 在这个例子中，通过GET请求调用位于https://api.example.com/data的 API 以检索数据。fetch函数处理 HTTP 请求，响应被处理并记录到控制台。标头通常包括内容类型和授权信息，以确保 API 能够识别并允许执行请求。\n为什么 API 在软件开发中很重要？ 在软件开发中，APIs 对于促进不同软件组件或系统之间的通信至关重要。它们充当合同，规定软件元素如何互动，确保对一个部分的更改不会破坏其他地方的功能。这种解耦使得模块化成为可能，更容易设计、开发和维护应用程序。\nAPIs 促进了可重用性，允许开发人员利用现有功能而不必重新发明轮子。它们还实现了可扩展性，因为服务可以独立扩展以满足需求。在测试自动化的背景下，APIs 在**集成测试**中起到了关键作用，确保应用程序的不同部分按预期一起工作。\n此外，APIs 在持续集成/持续部署（CI/CD）流水线中至关重要，允许自动化工具与正在开发的软件进行交互，从而加速发布过程。它们还提供了一种进行监控和健康检查的手段，这对于维护实时系统的可靠性至关重要。\n总之，APIs 是现代软件开发的支柱，支持通信、模块化、可重用性、可扩展性和自动化。它们是创建复杂、健壮和高效软件系统不可或缺的组成部分。\nAPI 有哪些不同类型？ APIs 有各种形式，每种都有不同的用途。以下是不同类型的 APIs：\nREST（表征状态转移）：使用 HTTP 请求来获取、放置、提交和删除数据。它是无状态的，并使用标准 HTTP 状态代码来指示请求的成功或失败。\nSOAP（简单对象访问协议）：依赖基于 XML 的消息协议来交换信息。它是协议无关的，并带有内置的错误处理。\nGraphQL：允许客户端仅请求其需要的数据，使其对于具有许多实体和关系的复杂系统非常高效。\ngRPC（Google 远程过程调用）：使用协议缓冲作为接口定义语言，旨在进行高性能的 RPC 通信，特别适用于微服务。\nOData（开放数据协议）：使用 RESTful APIs 标准化数据的查询和更新。它对于在网络上公开和使用数据非常有用。\nJSON-RPC 和 XML-RPC：分别以 JSON 和 XML 编码的远程过程调用协议。它们允许发送多个参数并以结构化格式接收结果。\nWebSocket：在单个 TCP 连接上提供全双工通信通道，实现客户端和服务器之间的实时数据传输。\n每种 API 都有其自己的实施和测试标准和最佳实践。了解每种类型的特性对于有效的测试自动化至关重要。\nWeb API 和库 API 有什么区别？ Web API是一种接口，允许不同软件系统通过互联网进行通信，通常使用 HTTP/HTTPS 协议。它通过 Web 请求和响应使服务和客户端通过 JSON 或 XML 格式交换数据和功能。Web APIs 设计用于远程访问，并支持基于 Web 的交互。\n另一方面，库 API是由库提供的一组函数、类或协议，库是计算机程序使用的一组非易失性资源。这些 APIs 旨在直接在软件中使用，并且不通过网络公开。它们为开发人员提供了一种在不必从头编写代码的情况下利用预定义功能的方式，确保代码重用和模块化。\n总之，关键区别在于它们的使用上下文：Web APIs 用于在 Web 上进行系统间通信，而库 APIs 用于在应用程序代码库内部直接使用。\nAPI 在微服务架构中的作用是什么？ 在微服务架构中，APIs 充当服务之间的主要通信渠道，使每个服务能够独立运行，同时仍然是一个有机系统的一部分。它们允许服务无缝交换数据和功能，而无需共享代码或实现细节。\n在微服务中，APIs 被设计为轻量级和专注的，通常围绕特定的业务能力。这与单一职责的原则一致，其中每个微服务负责一个明确定义的特性或流程。\n在这种背景下使用 APIs 支持服务可伸缩性和灵活性，因为服务可以独立开发、部署和扩展。APIs 促进了服务之间的松耦合，这对于一个能够处理微服务的动态特性（如频繁更新和服务故障）的弹性系统是至关重要的。\n此外，APIs 实现了多语言编程，允许服务使用最适合其功能的不同编程语言编写。这是因为 APIs 提供了一种语言无关的交互接口。\n总之，APIs 对于微服务架构至关重要，为服务提供了一种在保持隔离和自治的同时相互交互的机制，支持微服务的灵活性、可伸缩性和弹性目标。\nAPI 设计与开发 设计 API 的最佳实践是什么？ 在设计 API 时，务必遵循以下最佳实践：\n一致性至关重要。确保端点命名、请求/响应结构和错误处理在整个 API 中保持一致。 在适用的情况下，设计应遵循RESTful 原则，适当使用 HTTP 方法（用于检索的 GET，用于创建的 POST 等）。 对资源名称使用名词，对操作使用动词。避免在 URL 中使用动词。 版本控制：实施 API 版本控制以避免对客户端的破坏性更改。使用简单的版本控制方案，例如 URL 路径或标头。 分页：对于大型集合，使用分页来限制响应大小，提供更好的客户端体验。 过滤、排序和搜索：允许客户端通过查询参数进行数据过滤、排序和搜索。 速率限制：通过实施速率限制来保护 API 免受滥用和过度使用。 缓存：使用 HTTP 缓存头以提高性能并减少服务器负载。 安全性：实施身份验证、授权和加密。使用令牌或 OAuth 进行安全访问。 错误处理：提供有意义的 HTTP 状态码和错误消息。包括唯一的错误标识符以便更容易进行故障排除。 内容协商：支持多种格式（如 JSON 和 XML），并使用Accept头进行格式选择。 文档：保持文档更新，并提供清晰、简洁的示例。使用 Swagger 或 API Blueprint 等工具。 反馈循环：鼓励并促使 API 使用者提供反馈，以不断改进 API。 // Example of a RESTful endpoint for retrieving a user GET /api/v1/users/{id} 记住，目标是创建一个易于理解、与之集成并随时间推移易于维护的 API。\n如何对 API 进行版本控制？ 对于保持兼容性和通知用户变更，API 的版本管理至关重要。以下是简明的指南：\n**语义版本控制（SemVer）**是一种流行的方案，采用 MAJOR.MINOR.PATCH 格式，其中：\n进行不兼容的 API 更改时，递增 MAJOR 版本， 在向后兼容的方式中添加功能时，递增 MINOR 版本， 在进行向后兼容的错误修复时，递增 PATCH 版本。 URI 版本控制包括在 API 端点路径中包含版本号，如 /v1/resource。\n参数版本控制使用请求参数指定版本，例如 ?version=1。\n头部版本控制利用自定义 HTTP 头部指示版本。\n媒体类型版本控制在Accept头部中指定版本，使用自定义媒体类型。\n选择与你的 API 需求和使用者期望相一致的版本控制策略。通过变更日志清晰地传达变更，并确保文档随着 API 一起更新。\n对于向后兼容性，考虑同时支持多个版本或提供弃用政策，以便给使用者迁移的时间。\n以下是使用 URI 版本控制的 API 端点的示例：\nGET /v2/users/123 Host: api.example.com 记得保持 API 中的版本控制策略一致，以避免混淆。\n什么是 API 优先设计以及为什么它很重要？ API 优先设计是一种在实施核心应用程序之前优先开发APIs的方法。这是一种将 APIs 视为软件开发过程中“一等公民”的策略。\n这种设计理念之所以重要，是因为它确保 APIs 是：\n一致和可重用的，使它们更有效地为各种客户端应用程序提供服务。 明确定义的，有助于为软件组件之间的交互设定清晰的契约。 易于测试的，因为它们从根本上设计了可以独立验证的端点。 灵活的，可以更容易地与将来的其他服务和系统集成。 可扩展的，因为它们可以开发以处理对核心应用程序的重负载而无需进行重大更改。 通过采用 API 优先设计，组织可以加速其上线策略，因为前端和后端团队可以并行工作。它还为开发人员、测试人员和业务利益相关者提供了一个更加协作的环境，使其能够在开发周期的早期对 API 的目的和功能达成一致。\n在**测试自动化**的背景下，API 优先设计简化了自动化测试的创建，提供了稳定且有文档的接口。这使得测试自动化工程师能够编写更不容易破碎、更专注于验证业务逻辑而不是处理 UI 变化或其他前端问题的测试。\n开发 API 时需要考虑哪些关键因素？ 在开发 API 时，一致性对于可维护性和可用性至关重要。确保端点之间的命名惯例、请求/响应格式和行为保持一致。\n性能必须进行优化；设计高效的数据检索，并考虑实施缓存、分页和压缩以减少延迟。\n可扩展性是至关重要的；设计你的 API 以优雅地处理用户和数据量的增长，使用负载平衡和水平扩展策略。\n错误处理应该健壮，提供有意义的 HTTP 状态码和错误消息，使客户端能够理解和解决问题。\n版本控制对于向后兼容性至关重要；使用清晰的策略，例如基于 URI 路径或标头的版本控制，以管理更改而不干扰客户端。\n安全性是至关重要的；实施身份验证、授权、输入验证和速率限制，以防范常见的漏洞。\n文档应该全面且及时，提供清晰的示例和解释，以便为开发人员提供易于集成的支持。\n测试是不可妥协的；编写自动化测试以覆盖各种场景，包括成功路径、失败和边缘案例。\n弃用政策应该明确，提供客户端对于重大更改的提前通知和足够的时间来适应。\n监控和日志记录对于维护健康的 API 至关重要；跟踪使用模式、性能指标和错误，以主动管理 API。\n用户反馈是无价的；与 API 消费者互动，收集见解并根据他们的经验进行改进。\nAPI 网关的作用是什么？ API 网关充当反向代理，接受所有应用程序编程接口（API）调用，聚合完成这些调用所需的各种服务，并返回适当的结果。在微服务架构中，它充当所有客户端的单一入口点，将请求路由到适当的微服务。\nAPI 网关可以处理横切关注点，如：\n身份验证和授权：验证身份，确保调用者有权限访问服务。 速率限制：控制用户在给定时间范围内可以发出的请求数量，以防止滥用。 负载平衡：将传入的 API 流量分发到多个后端服务，以确保可扩展性和可靠性。 缓存：存储频繁访问的数据副本，以提高响应时间并减少后端负载。 请求形状和协议转换：根据需要修改请求并在不同的 Web 协议之间进行转换。 对于测试自动化工程师来说，API 网关引入了有关**测试策略**的额外考虑因素。测试应该考虑到网关的行为，包括它如何路由流量和应用策略。自动化测试可能需要模拟网关的操作或绕过它，直接测试各个微服务。\n总之，API 网关在微服务架构中扮演着管理 API 调用流的关键角色，提供了一个集中点，用于共享在维护可扩展、安全和高效系统方面至关重要的通用功能。\nAPI 测试 什么是 API 测试以及为什么它很重要？ API 测试是一种软件测试类型，涉及验证和验证应用程序编程接口 (APIs) 及其与其他软件组件的交互。这对确保 APIs 按预期方式运行，高效处理负载并正确响应边缘情况和意外输入是至关重要的。\nAPI 测试的重要性在于它专注于软件架构的业务逻辑层。与评估前端界面的UI 测试不同，API 测试处理处理数据和交易的代码，这通常比 UI 更稳定。这种稳定性使得在软件开发生命周期的早期进行测试开发和执行成为可能，从而实现更快的反馈和更快的迭代。\nAPI 测试对于以下方面至关重要：\n验证通过 APIs 暴露的软件的核心功能。 确保数据一致性、响应时间和错误处理符合所需的标准。 检测安全漏洞和访问控制问题。 在不同条件下（包括负载和压力测试）评估性能。 通过检查不同软件组件之间的交互促进**集成测试**。 鉴于微服务和分布式架构的崛起，API 测试变得更加重要，因为系统越\n来越多地依赖多个 APIs 协同工作。自动化 API 测试是一种最佳实践，支持持续测试和集成，这是敏捷和 DevOps 方法论的基石。\nAPI 测试有哪些不同类型？ 不同类型的API 测试侧重于 API 的功能、可靠性、性能和安全性的各个方面。以下是主要类型：\n功能测试: 验证 API 是否按预期行为，涵盖单个功能和端到端场景。 负载测试: 评估高流量下的性能，确保 API 能够处理预期的负载。 压力测试: 通过超过正常运行能力来确定 API 的破坏点。 安全测试: 识别漏洞，确保数据加密和安全，并验证认证和授权机制的健壮性。 集成测试: 检查 API 与其他服务和数据库的交互，确保无缝集成。 兼容性测试: 确保 API 在不同设备、操作系统和网络环境中正常工作。 可靠性测试: 验证 API 是否可以持续连接并保持稳定性能。 互操作性测试: 确认 API 是否遵循与其他 API 交互的标准和协议。 回归测试: 在对 API 进行更改后执行，确保新代码不会对现有功能产生不利影响。 性能测试: 在不同条件下测量 API 的响应速度和稳定性。 API 监控: 持续检查生产中的 API，以确保正常运行、响应时间和正确行为。 每种测试类型对于确保 API 的可靠性、安全性、良好性能和与其他系统组件的平滑集成都至关重要。\nAPI 测试常用的工具有哪些？ 常用的API 测试工具包括：\nPostman: 用于 API 开发和测试的热门工具，提供用户友好的界面和各种功能，用于发送请求、分析响应和自动化测试。 SoapUI: 专为 SOAP 和 REST API 测试而设计的开源工具，提供全面的测试功能，包括功能测试、回归测试和负载测试。 JMeter: 主要是性能测试工具，也可用于 API 测试，特别是压力测试和负载测试。 Rest-Assured: 用于简化 RESTful API 测试的 Java DSL，与现有的基于 Java 的测试框架无缝集成。 Insomnia: 强大的 REST 客户端，具有 API 探索和调试功能，以及基本的自动化测试功能。 Katalon Studio: 一体化的自动化解决方案，支持 API 和 UI 测试，提供用户友好的界面用于创建自动化测试。 Paw: 专为 Mac 设计的 API 测试和描述工具，具有完整功能的开发环境。 Karate DSL: 一个开源工具，将 API 测试自动化、模拟、性能测试甚至 UI 自动化集成到一个统一的框架中。 Cypress: 主要用于端到端测试 Web 应用程序，但也可通过在测试中直接发送 HTTP 请求进行 API 测试。 这些工具提供各种功能，如测试自动化、请求链接、环境变量和与 CI/CD 管道的集成，以简化和增强API 测试过程。\nAPI 测试的关键步骤是什么？ API 测试涉及多个关键步骤，以确保应用程序编程接口的功能性、可靠性、安全性和性能。以下是这些基本步骤：\n理解 API 需求：深入了解 API 的预期功能、输入、输出和错误代码。\n设置测试环境：配置进行 API 测试所需的参数、数据库和服务器。\n编写测试用例：创建覆盖 API 各个方面的测试用例，包括正向、负向、边界和安全测试。\n选择合适的工具：选择符合您需求并与您的 CI/CD 流水线集成的API 测试工具。\n执行测试用例：运行测试，验证 API 是否符合定义的需求。这包括对以下方面进行测试：\n功能性 可靠性 性能 安全性 检查 API 响应：确保 API 返回正确的状态码、响应时间和数据结构。\n验证数据完整性：验证在创建、读取、更新或删除资源时，API 是否保持数据一致性和完整性。\n使用自动化脚本：实施自动化的测试脚本以使测试过程高效且可重复。\n监控性能：在各种负载条件下评估 API 的响应时间和吞吐量。\n分析和报告：评估测试结果，记录发现，并报告任何缺陷或性能问题。\n审查和重构：持续审查测试用例和脚本，以寻求改进和可维护性。\n通过遵循这些步骤，您可以确保对API 测试进行全面覆盖，实现强大可靠的 API 集成。\n如何自动化 API 测试？ 要实现API 测试的自动化，按照以下步骤操作：\n定义测试用例：明确各种 API 请求的预期结果，包括成功和错误的情景。\n选择测试工具：选择支持 API 自动化的工具，如Postman、RestAssured 或 SoapUI。\n设置测试环境：配置测试环境，包括必要的标头、身份验证令牌和其他前提条件。\n编写测试脚本：创建脚本进行 API 调用并验证响应。根据工具的不同，可以使用 JavaScript、Python 或 Java 等编程语言。\n// Example using JavaScript with a testing framework like Mocha describe(\u0026#39;GET /users\u0026#39;, () =\u0026gt; { it(\u0026#39;should return a list of users\u0026#39;, async () =\u0026gt; { const response = await request(app).get(\u0026#39;/users\u0026#39;); expect(response.status).to.equal(200); expect(response.body).to.be.an(\u0026#39;array\u0026#39;); }); }); 为测试参数化：使用变量作为输入，轻松测试不同的场景。\n断言条件：使用断言检查响应状态码、响应时间和有效负载。\n与 CI/CD 集成：在 CI/CD 流水线中自动执行测试，实现持续测试。\n分析测试结果：查看测试报告，识别任何失败或性能问题。\n维护测试：定期更新测试以反映 API 中的更改。\n通过自动化 API 测试，确保对 API 功能、可靠性和安全性进行一致高效的验证。\nAPI 安全 与 API 相关的常见安全风险有哪些？ 与 APIs 相关的一些常见安全风险包括：\n注入攻击：将恶意代码或命令注入到 API 中，以利用漏洞获取未经授权的访问或数据。例如SQL注入、命令注入和跨站脚本（XSS）攻击。\n身份验证失效：身份验证机制存在缺陷，可能允许攻击者冒充合法用户或完全绕过身份验证。\n敏感数据暴露：不足的保护机制可能导致敏感数据（如个人信息、凭据或财务数据）的泄露。\n访问控制问题：访问控制的不正确实施可能导致未经授权访问 API 功能或数据，即访问控制失效。\n安全配置错误：默认配置、不完整的设置或配置不当的 HTTP 头可能使 APIs 容易受到攻击。\n大规模赋值：未经适当过滤的接受 JSON 或 XML 输入的 APIs 可能允许攻击者修改其不应访问的对象属性。\n日志记录和监控不足：不足的 API 活动记录和缺乏实时监控可能阻止对主动入侵的检测和响应。\n不安全的反序列化：在未经验证的情况下对不受信任的数据进行反序列化可能导致远程代码执行、重放攻击、注入攻击和权限升级。\n使用已知漏洞的组件：依赖于具有已知漏洞的库或软件的 APIs 可能容易受到攻击。\n缺乏速率限制和节流：没有速率限制，APIs 容易受到暴力攻击和拒绝服务（DoS）攻击。\n减轻这些风险涉及实施强大的身份验证和授权、在传输和静态状态下对数据进行加密、验证和清理输入、使用安全的编码实践以及保持所有组件更新。定期进行安全审计和渗透测试对于维护 API 安全也至关重要。\n如何保护 API 的安全？ 如何确保 API 的安全性？\n确保 API 的安全性涉及采取措施以防止未经授权的访问和各类威胁。以下是一些关键策略：\n身份验证：使用 API 密钥、令牌或 HTTP 基本身份验证等机制验证身份。可以考虑使用OAuth以实现更精细的访问控制。\n授权：确保用户有权执行操作。可以实施基于角色的访问控制（RBAC）或基于属性的访问控制（ABAC）。\n传输安全：使用HTTPS与SSL/TLS加密传输中的数据，以防止被截取或篡改。\n输入验证：验证所有输入，以防止注入攻击。使用严格的类型、格式和范围检查。\n输出编码：在输出时对数据进行编码，以避免注入漏洞，特别是在 JSON 或 XML API 中。\n速率限制：通过限制用户在给定时间内的请求次数来防御 DDoS 攻击。\n日志记录和监控：保留详细的日志并监控 API 的使用情况，以便快速检测和响应可疑活动。\n安全头：使用 HTTP 头，如Content-Security-Policy、X-Content-Type-Options和X-Frame-Options，以减轻常见攻击。\n错误处理：避免在错误消息中显示堆栈跟踪或敏感信息。使用通用错误消息并在服务器端记录详细信息。\n补丁管理：定期更新软件，修补 API 平台和依赖项中已知的漏洞。\n安全测试：在自动化测试套件中包含安全测试。进行静态分析、动态分析和渗透测试。\n通过实施这些实践，您可以为 API 打造一个强大的安全防线。\n什么是 API 密钥认证？ API 密钥认证是一种简单的安全方法，涉及在请求中发送一个秘密令牌以访问 API。API 密钥是服务器用于验证请求者身份并授权访问 API 资源的唯一标识符。\n要实施 API 密钥认证，客户端必须在请求头或作为查询参数中包含 API 密钥。以下是使用 JavaScript 将 API 密钥包含在请求头中的示例：\nfetch(\u0026#39;https://api.example.com/data\u0026#39;, { method: \u0026#39;GET\u0026#39;, headers: { \u0026#39;Authorization\u0026#39;: \u0026#39;ApiKey YOUR_API_KEY_HERE\u0026#39; } }) .then(response =\u0026gt; response.json()) .then(data =\u0026gt; console.log(data)) .catch(error =\u0026gt; console.error(\u0026#39;Error:\u0026#39;, error)); API 密钥通常由 API 提供者在注册过程中提供，并应保持保密以防止未经授权的访问。虽然 API 密钥认证易于实施，但单独使用时安全性不是最高的，因为如果未正确处理，密钥可能会被拦截或泄漏。通常与其他安全措施（例如HTTPS）一起使用，以确保密钥传输安全。\n什么是 OAuth 以及它如何在 API 安全中使用？ OAuth 是一种开放标准，通常用于允许网站或应用在不需要用户提供密码的情况下访问其他网站上的用户数据。它充当中间层，提供令牌而不是用户凭证，用于访问资源。\n在 API 安全中，OAuth 允许客户端代表资源所有者访问服务器资源。它规定了资源所有者在不共享凭证的情况下授权第三方访问其服务器资源的过程。设计时特别考虑了与HTTP的兼容性，为发放、验证令牌以及定义访问权限的范围和持续时间提供了安全且标准化的方法。\nOAuth 2.0 是目前最广泛使用的版本，定义了四个角色：\n资源所有者：授权应用访问其账户的用户。 资源服务器：托管受保护资源的服务器。 客户端：请求访问资源服务器的应用。 授权服务器：在成功验证资源所有者并获得授权后，向客户端发放访问令牌的服务器。 OAuth 的流程通常包括以下步骤：\n应用请求用户对其访问服务资源的授权。 如果用户授权该请求，应用收到一个授权授予。 应用通过提供其自身身份和授权授予，向授权服务器请求访问令牌。 如果确认了应用的身份并且授权授予有效，授权服务器向应用发放访问令牌。 应用请求资源服务器的资源并呈现访问令牌进行身份验证。 如果访问令牌有效，资源服务器向应用提供资源。 OAuth 因其能够提供对不同类型访问的细粒度授权而在 API 安全领域得到广泛使用。\nSSL/TLS 在 API 安全中的作用是什么？ SSL/TLS通过在客户端和服务器之间建立加密链接，在API 安全中发挥着至关重要的作用。这确保了两方之间传输的所有数据都是私密和完整的，从而防止窃听、篡改和消息伪造。\n当 API 通过 HTTPS 提供服务时，实际上是在 SSL/TLS 上层的 HTTP，因此可以受益于底层的安全特性：\n加密：传输过程中对数据进行加密，防止未经授权的访问敏感信息。 认证：使用 SSL/TLS 证书对服务器进行认证，确保客户端与合法服务器进行通信。 完整性：执行数据完整性检查，以检测对传输数据的任何更改。 在进行API 测试时，验证 SSL/TLS 是否得到正确实施变得非常重要：\n证书验证：确保 API 服务器提供由受信任的证书颁发机构（CA）颁发的有效证书。 协议版本：确认 API 是否支持协议的安全版本（例如 TLS 1.2、TLS 1.3），并禁用不推荐使用的版本（例如 SSL 3.0、TLS 1.0）。 密码套件：检查 API 是否配置为使用提供强大加密的强密码套件。 将 SSL/TLS 检查纳入到自动化的API 测试中，有助于保持安全姿态并符合最佳实践，使其成为API 测试过程中不可或缺的一环。\nAPI 文档 为什么 API 文档很重要？ API 文档有几个至关重要的原因：\n清晰性：文档清晰地描述了 API 提供的内容，包括端点、方法、参数和数据格式。 可用性：良好的文档使开发人员能够快速理解并无需外部支持即可集成 API。 效率：文档降低了学习曲线，有助于在敏捷环境中进行更快的开发和集成。 测试：文档作为测试自动化工程师验证 API 行为是否符合规范的参考。 维护：文档有助于随时间的推移维护 API，使其更容易更新、重构或扩展功能。 入职：新团队成员可以迅速上手，确保连续性和生产力。 社区：对于开源或公共 API，它可以培养一个开发者社区，他们可以为 API 的生态系统做出贡献。 在测试自动化领域，文档有以下应用：\n生成测试用例：自动化工具可以利用文档生成不同场景的测试用例。 模拟服务：可以创建模拟服务，模拟 API 响应进行测试。 验证响应：确保 API 的输出与文档中预期的响应相匹配。 总体而言，API 文档是支持整个 API 生命周期的基础要素，从设计和开发到测试和维护。\n好的 API 文档中应该包含哪些内容？ 良好的 API 文档应包含以下要素：\n概述：对 API 进行简要描述，说明其目的和高层功能。 身份验证：清晰说明如何对 API 进行身份验证，包括任何必需的密钥或令牌。 端点：全面列出可用端点，包括路径、HTTP 方法和每个端点的简要描述。 参数：详细说明请求参数，包括名称、数据类型、是否为强制或可选，以及适用的默认值。 请求示例：每个端点的示例请求，最好用多种语言或工具（如curl、JavaScript、Python）编写。 curl -X POST https://api.example.com/v1/resource \\ -H \u0026#34;Authorization: Bearer {token}\u0026#34; \\ -d \u0026#39;{ \u0026#34;param1\u0026#34;: \u0026#34;value1\u0026#34;, \u0026#34;param2\u0026#34;: \u0026#34;value2\u0026#34; }\u0026#39; 响应示例：每个端点的示例响应，包括状态代码、标头和主体内容。 错误代码：列出可能的错误代码、它们的含义以及可能的解决方案或故障排除提示。 速率限制：提供适用于 API 的任何速率限制的信息，包括计算方法以及超出限制时的处理方式。 更改日志：记录 API 所做的所有更改，包括新功能、更新、弃用和删除。 联系信息：提供如何联系 API 提供商以获取支持或反馈的详细信息。 请记住，保持文档更新和准确，以确保用户获得无缝的集成和测试体验。\n有哪些工具可用于创建 API 文档？ 使用旨在简化流程的各种工具，可以更高效地创建 API 文档。以下是一些广泛使用的选项：\nSwagger/OpenAPI：提供规范和一套工具，用于生成、可视化和与 API 文档交互。Swagger UI 提供了一个基于 Web 的界面，供用户探索 API，而Swagger Editor 允许编辑 OpenAPI 规范。 paths: /users: get: summary: \u0026#34;List all users\u0026#34; Postman：主要是一个用于API 测试的平台，Postman还包括用于文档化 APIs 的功能。它可以生成和托管交互式文档，并允许直接从文档页面调用 API。\nApiary：使用 API Blueprint，这是一种基于 Markdown 的文档格式。Apiary 提供一个模拟服务器和其他工具，用于在文档旁边设计和原型化 APIs。\nRead the Docs：与您的版本控制系统集成，以每次提交都自动更新文档。它支持 Sphinx，这是一个创建智能且美观文档的工具。\nDocusaurus：用于轻松构建、部署和维护开源项目网站的项目。它支持 Markdown，并且与 JSDoc 等文档生成器结合使用时可用于文档化 APIs。\nMkDocs：一个面向项目文档的静态站点生成器。通过使用插件，它也可以成为文档化 API 的不错选择。\n每个工具都提供独特的功能和集成，因此选择取决于具体的项目要求、首选工作流程以及正在使用的技术栈。\nAPI 文档应该多久更新一次？ 在对 API 进行更改时，应立即更新文档。这样可以确保文档准确地反映了 API 的当前状态，对于那些依赖文档进行集成和测试的开发人员来说，这是至关重要的。更新内容应该包括新的端点、对现有端点的更改、不再建议使用的操作以及对请求或响应结构的任何修改。\n对于持续交付的环境，考虑将文档过程纳入 CI/CD 流水线。这可以通过使用能够直接从代码或 API 规范生成文档的工具（如 OpenAPI/Swagger）来实现。这样，文档将在每次代码发布时自动生成和发布，确保其保持最新状态。\n除了自动更新之外，还应定期进行手动审查，以确保文档清晰、准确且完整。这可以作为敏捷团队冲刺审查的一部分，也可以按计划定期进行，例如每季度一次。\n请记住，过时或不正确的文档可能导致在开发和测试中浪费时间，并有可能引起团队之间的误解。因此，保持 API 文档的实时性不仅是良好实践，也是维护软件开发和测试自动化过程的必要条件。\nAPI 文档在 API 测试中的作用是什么？ API 文档在API 测试中至关重要，就像一张路线图，帮助我们了解 API 的功能、期望行为和集成方式。文档详细介绍了端点、方法、参数以及请求/响应结构，测试人员依此创建有实际意义的test cases。优秀的文档还包括对请求和响应的示例，使得验证 API 是否符合其合同变得更加轻松。\n测试人员依赖文档以确保 API 遵循其规范。没有准确的文档，测试人员无法有效地执行合同测试，验证 API 是否符合服务之间的协定标准。\n此外，文档通常详细说明错误代码和消息，这对于**负向测试**至关重要。了解 API 在各种故障场景下的行为对于确保错误处理强大且在使用应用程序中出现问题时平滑降级至关重要。\n在自动化测试中，文档可以用于生成在隔离环境中测试的存根和模拟API 响应。支持OpenAPI或其他 API 规范格式的工具可以自动生成这些测试工件，从而简化测试开发流程。\n最后，及时更新的文档对于维护和扩展测试套件尤为重要，特别是在 APIs 发生变化时。\n它使测试人员能够快速识别变更并调整其测试，确保 API 在更新后仍然能够按预期运行。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-api/","summary":"这篇博文是软件测试术语分享系列的一部分，聚焦于 API（应用程序编程接口）。文章详细探讨了 API 的基础概念和其在软件开发中的重要性，包括 API 设计与开发、API 安全、API 测试和 API 文档等方面。读者将深入了解如何规划和设计可靠的 API，确保其安全性，以及在软件测试中如何有效地进行 API 测试。通过这个系列分享，读者将更全面地了解 API 在软件开发中的关键作用，并学到相关方面的最佳实践。","title":"软件测试术语分享:API 应用程序编程接口"},{"content":"Alpha Testing Alpha 测试 Alpha 测试 (α 测试) 的目的是在产品到达最终用户之前识别错误。在开发过程后期但在 Beta 测试之前进行，有助于确保产品不存在重大问题。\n相关术语：\nBeta Testing Beta 测试 关于 Alpha 测试的问题 基础知识和重要性 什么是 Alpha 测试？ Alpha 测试是一种在产品面向真实用户之前旨在识别缺陷的内部验证过程。通常在软件经过初始开发和测试阶段但在beta 测试之前，在开发者的现场进行。这个阶段包括白盒和黑盒测试技术，测试团队可以访问源代码。\n在 Alpha 测试期间，软件会在真实用户环境中进行测试，以模拟实际用户的行为。测试的重点是功能的正确性、系统的稳定性和数据的完整性。测试人员通常使用自动化脚本执行重复的test cases，同时也经常使用探索性测试来发现不太明显的问题。\nAlpha 测试的有效性通过指标（如发现的缺陷数量、严重程度和解决它们所需的时间）来衡量。与开发团队的持续沟通对于及时解决问题至关重要。\nAlpha 测试人员通常是组织内没有直接参与项目开发的员工。他们从用户的角度提供宝贵的反馈，这对于软件的成功至关重要。\n为了克服有限的用户视角和潜在的偏见等挑战，采用了诸如轮换测试人员和整合**多样化的测试场景**等策略。通过分析反馈、完善测试用例和改进测试环境来进行改进。\n总之，Alpha 测试是确保软件质量并使其准备好进入下一阶段测试的关键步骤，从而使其面向更广泛用户的重要步骤。\n为什么 Alpha 测试在软件开发生命周期中很重要？ Alpha 测试在软件开发的整个生命周期中扮演着至关重要的角色，它是对可能影响用户体验的缺陷和问题的首要防线。通常在受控环境中进行，这个环境通常是开发软件的组织内部，而且它是在将产品交付给真实用户之前的最后一道测试。\n这个测试阶段的重点是发现在早期测试阶段（如单元测试或集成测试）中未被发现的缺陷。虽然它是**用户验收测试**的一部分，但由内部员工执行，这意味着可以快速获得反馈并与开发团队直接沟通。这有助于在软件进入由实际用户测试的 beta 阶段之前，微调软件的功能、可用性和稳定性。\nAlpha 测试还提供了根据业务需求和目标验证产品的机会，确保软件符合预期的用途并为最终用户提供价值。这是建立对产品质量信心的一个关键步骤，同时通过及时发现和解决问题，降低发布后的维护成本。\n通过模拟真实用户行为，Alpha 测试有助于发现自动化测试可能未覆盖的复杂场景，为软件在各种条件下的性能提供更全面的评估。这个阶段对于成功的产品发布非常关键，因为它有助于确保软件的健壮性、可靠性，并且已经准备好进入下一个测试或发布的阶段。\nAlpha 测试的主要目的是什么？ Alpha 测试 的主要目的是在软件产品进入β测试阶段之前验证其核心功能。其进行的目的是确保最关键的功能按预期运行，并在开发周期的早期发现主要缺陷。这个阶段通常采用白盒测试和黑盒测试技术，重点是模拟真实用户的行为，并在一个尽可能接近生产环境的环境中测试软件。\nAlpha 测试的目标是识别和修复与功能、可用性、安全性和性能相关的问题，这些问题可能会显著影响用户体验或导致系统故障。这是质量保证过程中的关键步骤，为开发团队提供有关产品稳定性和准备好进入下一阶段测试及最终发布给实际用户的宝贵反馈。\nAlpha 测试与其他类型的测试有何不同？ Alpha 测试与其他测试类型的主要区别在于其在开发生命周期中的位置和受众范围的广度。它在**单元测试、集成测试之后进行，通常也在某种形式的系统测试**之后进行。与由外部用户执行的β测试不同，Alpha 测试通常由开发软件的组织内部的员工进行。\nAlpha 测试侧重于产品在受控环境下的功能正确性、可用性和总体行为，通常使用白盒测试技术。它比单元测试和集成测试更严格，但在实际使用方面不如β测试那样。在 Alpha 测试期间，测试人员与开发人员之间的反馈循环更加紧密，允许进行**快速的迭代**和修复。\n相比之下，**β测试涉及更广泛的受众，对环境的控制较少，旨在揭示仅在实际条件下出现的问题。另一方面，性能测试**专门针对系统在各种负载下的响应性和稳定性，这可能不是 Alpha 测试的关注点。\nAlpha 测试还与**验收测试**有所不同，验收测试通常是发布前的最后阶段，其中软件根据业务需求进行验证，通常由最终用户或客户进行。\n总而言之，Alpha 测试 是一种内部、受控和早期的测试，在β测试之前进行，侧重于在暴露给外部用户或利益相关者之前提高软件质量。\n进行 Alpha 测试的主要好处是什么？ 进行 Alpha 测试的主要好处包括：\n早期发现关键问题：Alpha 测试在产品进入β测试或公开发布之前发现严重的缺陷，降低主要故障的风险。 用户体验反馈：测试人员通常模拟真实用户行为，为用户体验和界面设计提供宝贵见解。 成本节约：早期识别和修复问题可以显著降低发布后补丁和更新的成本。 质量保证：在软件面向更大受众之前，有助于确保一定水平的质量，维护产品的声誉。 压力测试：Alpha 测试可以包括压力测试，评估软件在负载较重或资源有限的情况下的性能。 安全评估：可以识别并解决潜在的安全漏洞，对于保护用户数据和维护信任至关重要。 功能验证：确保所有功能按预期工作并符合指定的要求。 内部反馈循环：测试人员与开发人员之间的紧密合作促使快速修复和功能改进，提升开发流程。 通过关注这些好处，Alpha 测试在开发强大、用户友好且安全的软件产品方面起到了重要作用。\n流程与技巧 Alpha 测试过程涉及哪些步骤？ Alpha 测试过程通常包括以下步骤：\n规划：明确目标、范围和计划。选择跨职能团队，包括开发人员、测试人员和最终用户。\n设计测试用例：创建覆盖所有功能的测试用例。关注真实世界的使用场景。\n设置环境：准备类似于生产环境但在组织内部的测试环境。\n执行测试：运行测试用例，进行探索性测试，并记录结果。测试人员应模拟最终用户行为。\n缺陷报告：记录缺陷，包括重现步骤、预期与实际结果以及严重程度等详细信息。\n反馈循环：与开发团队分享发现，以进行修复。根据影响对问题进行优先排序。\n回归测试：重新测试已修复的问题，并执行健全性检查，确保新更改未引入其他问题。\n性能监测：评估系统在负载下的行为（如果适用）。检查内存泄漏、响应时间和稳定性。\n可用性评估：收集用户对界面和体验的反馈。可能根据此反馈进行调整。\n安全检查：进行基本的安全评估，以识别明显的漏洞。\n文档审查：确保所有相关文档都已更新，以反映经过测试的系统的当前状态。\n验收：一旦解决了所有关键问题，软件符合验收标准，就可以结束 Alpha 阶段。\n回顾：分析过程，识别未来周期的改进，并记录所学到的经验。\n在这些步骤中，保持清晰的沟通渠道，确保所有团队成员对 Alpha 测试阶段的目标和进展保持一致。\nAlpha 测试中常用哪些技术？ 在 Alpha 测试中，常见的测试技术包括：\n探索性测试：测试人员在没有预定义测试用例的情况下，探索软件以发现意外行为。 可用性测试：专注于用户界面和用户体验，确保软件直观且易于使用。 白盒测试：涉及测试应用程序的内部结构或工作原理，通常由了解源代码的开发人员使用。 黑盒测试：测试人员在不了解内部工作原理的情况下评估功能，模拟最终用户的视角。 回归测试：确保新的更改没有对现有功能产生不良影响。 用户验收测试 (UAT)：最终用户的子集在受控环境中测试软件，验证其是否符合其需求。 自动化测试：使用脚本和工具重复运行测试，适用于回归和性能测试。 性能测试：评估应用程序在特定工作负载下的响应性、稳定性、可伸缩性和速度。 安全测试：识别软件内部可能导致安全漏洞的问题。 调试：开发人员使用工具和技术来识别、隔离和修复在 Alpha 测试期间报告的错误。 测试人员通常使用这些技术的组合，以确保全面覆盖。技术的选择受软件复杂性、开发阶段以及 Alpha 测试阶段的目标的影响。\nAlpha 测试的测试环境是如何设置的？ 为 Alpha 测试建立测试环境通常包括以下步骤：\n复制生产环境：尽可能模仿生产环境，以确保在测试期间软件的行为类似。这包括硬件、软件、网络配置和数据库。\n数据准备：使用逼真的数据集，必要时进行匿名化。这有助于模拟真实的使用场景。\n版本控制：确保要测试的软件版本足够稳定，并处于版本控制中以跟踪更改和管理构建。\n部署：自动化将新构建部署到 Alpha 环境的过程，以简化发布流程。\n监控工具：实施监控工具以跟踪系统性能、错误日志和应用程序内用户活动。\n访问控制：限制对 Alpha 环境的访问仅限于授权人员，通常是内部测试团队和开发人员。\n测试工具：设置必要的测试工具和框架，支持自动化测试执行、缺陷跟踪和报告。\n文档：提供有关设置的文档，包括访问详细信息，以确保团队成员能够高效工作。\n备份和恢复：建立备份和恢复程序，以防数据丢失，并在必要时快速恢复环境。\n安全：确保环境安全，以保护敏感数据并防止未经授权的访问。\n持续集成：集成持续集成系统，以自动对新构建运行测试。\n反馈机制：为测试人员实施反馈机制，以便有效报告问题和提供建议。\nAlpha 测试期间通常会发现哪些类型的缺陷或问题？ 在 Alpha 测试期间，通常会发现以下类型的缺陷或问题：\n功能性缺陷：这些是与功能不按照需求中预期或规定的问题。 用户界面故障：可能影响用户体验的界面布局、设计或可用性方面的问题。 性能问题：影响软件速度和流畅性的慢、卡或其他效率问题。 安全漏洞：可能被恶意实体利用的弱点。 集成缺陷：不同组件或系统相互交互时出现的问题。 数据处理错误：与数据输入、存储、检索或处理相关的问题。 安装和配置问题：在设置或定制软件过程中遇到的挑战。 硬件兼容性问题：在各种硬件配置上运行软件时出现的困难。 本地化和国际化问题：在为不同语言和地区适应软件时出现的错误。 无障碍问题：阻碍残障人士轻松使用软件的障碍。 Alpha 测试旨在在软件进入beta 测试或发布给公众之前发现这些问题，确保产品质量更高，用户体验更好。\n角色和责任 谁通常执行 Alpha 测试？ Alpha 测试通常由软件开发组织的内部团队执行。这个团队包括开发人员、质量保证 (QA) 工程师，有时还有产品经理。他们紧密合作，模拟真实用户行为进行测试，目的是在软件交付给外部用户之前发现缺陷和问题。\n这些内部测试人员对软件的功能和目标有深刻的了解，这使得他们能够就功能、用户体验和整体系统性能提供宝贵的反馈。他们还了解软件的设计和开发流程，有助于他们创建有效的测试用例和测试场景。\n在某些情况下，尤其是在较小的公司或初创公司中，Alpha 测试可能还会涉及特定的外部用户或公司利益相关者，他们并非开发团队的一部分，但对软件有着浓厚的兴趣。然而，在测试的早期阶段，他们通常会签署保密协议，以确保信息的机密性。\nAlpha 测试人员与开发团队密切协作，报告问题，提出改进建议，并验证修复，以确保软件在进入下一个测试阶段（如beta 测试）之前达到必要的质量标准，从而为外部用户的评估做好准备。\nAlpha 测试员的角色和职责是什么？ Alpha 测试人员在软件测试的早期阶段发挥着关键作用，着重于在产品进入beta 测试或公开发布之前进行功能验证。他们的责任包括：\n执行测试用例：Alpha 测试人员遵循一组预定义的测试用例，确保软件的行为符合预期。 探索性测试：他们通常参与探索性测试，以发现脚本测试可能无法捕捉到的问题。 报告缺陷：他们详细记录并报告测试期间发现的任何缺陷或异常给开发团队。 提供反馈：除了技术问题，Alpha 测试人员还就用户体验、可用性和功能集提供反馈。 回归测试：在进行修复或更改后，他们执行回归测试，确保新的代码变更没有引入新的错误。 修复的验证：他们验证在后续构建中已经正确解决了报告的问题。 沟通：与开发团队进行有效沟通至关重要，以澄清功能，讨论问题并提出改进建议。 Alpha 测试人员必须对软件的目标有深刻的理解，并具备识别不仅仅是明显的缺陷，还包括可能影响性能、安全性和用户满意度的微妙问题的技能。他们的意见对于开发团队在软件进入下一个测试阶段之前优先处理问题和改进至关重要。\nAlpha 测试团队如何与开发团队互动？ Alpha 测试团队通常通过定期的会议、电子邮件、即时通讯和问题跟踪系统等常见沟通渠道与开发团队保持互动。他们直接向开发人员提供反馈和报告缺陷，通常使用**缺陷跟踪系统**，以记录、跟踪和分配问题以供解决。\n这种互动是协作性的，其目的是在软件进入beta 测试或发布之前识别和解决问题。Alpha 团队还可能提供改进或增强的建议，为软件的整体质量做出贡献。开发人员有责任优先考虑并及时解决反馈，通常需要与测试人员密切合作，以了解问题背后的背景。\n整个过程旨在建立一个反馈循环，使开发团队能够快速实施修复，而 Alpha 测试团队则可以重新测试以确认问题是否已解决。这种密切的协作有助于确保软件在进入开发周期的下一阶段之前是稳定的，并且符合质量标准。\n挑战与解决方案 Alpha 测试期间通常会遇到哪些挑战？ 在 Alpha 测试期间常见的挑战包括：\n用户反馈有限：由于 Alpha 测试通常在内部进行，因此相比于与真实用户进行的 beta 测试，反馈的多样性可能有限。 资源限制：分配足够的资源，如时间和人员，可能很困难，可能会影响测试的全面性。 环境差异：测试环境可能无法完美复制生产环境，导致只有在发布后才会出现的问题。 功能完备性：Alpha 测试通常发生在所有功能最终确定之前，这可能使得全面测试软件变得具有挑战性。 缺陷优先级：决定首先修复哪些错误可能很具挑战性，特别是在处理大量问题时。 测试覆盖率：实现足够的测试覆盖以确保检查软件的所有方面可能很困难。 回归测试：确保新的代码更改不会破坏现有功能需要认真进行回归测试，这可能会耗费时间。 集成问题：测试不同组件的集成可能会揭示难以诊断和修复的复杂缺陷。 性能测试：Alpha 测试可能不关注性能问题，这可能导致未发现的瓶颈。 为了克服这些挑战，可以采用一些策略，如自动回归测试、持续集成、模块化测试和**增量测试。此外，使用虚拟化环境可以更准确地模拟生产环境，而根据严重程度和影响进行缺陷修复的优先级排序**可以简化流程。\n可以使用什么策略来克服这些挑战？ 为了应对 Alpha 测试中的挑战，可以考虑以下策略：\n根据风险和影响优先处理测试用例。首先关注关键功能，以确保及早发现重大问题。 实施自动回归测试，快速验证新更改后现有功能是否按预期工作。 使用虚拟化或容器化来复制测试环境，确保一致性和便捷的设置。 与开发团队密切合作，建立清晰的沟通渠道，以迅速解决问题。 从不同团队成员收集反馈，以获取对产品可用性和功能的不同视角。 通过采用敏捷方法快速迭代，允许渐进性改进和对发现的缺陷的迅速响应。 利用**缺陷跟踪工具**高效管理和优先处理测试中发现的问题。 详细记录测试用例和结果，为未来的测试周期和开发工作提供有价值的见解。 通过采用这些策略，Alpha 测试可以变得更加有效，从而产生更可靠且用户友好的产品。\n如何衡量和提高 Alpha 测试的有效性？ 如何衡量和提高 Alpha 测试的有效性可以通过各种指标和持续改进实践来实现：\n缺陷检测效率（DDE）：计算在 Alpha 测试期间发现的缺陷与发布前总缺陷数量的比率。较高的比率表示测试效果更好。 测试覆盖率：确保测试所有关键路径和功能。使用代码覆盖工具识别应用程序未测试的部分。 用户反馈：从 Alpha 测试人员收集关于可用性、功能和整体体验的定性反馈。 修复时间：监控解决在 Alpha 测试期间发现的问题所需的平均时间。较短的时间可能表示更好的响应速度和开发效率。 测试用例的有效性：审查测试用例的相关性和完整性。定期更新以反映应用程序的变化。 提高 Alpha 测试的有效性涉及：\n定期修订和更新测试用例，以与应用程序中的新功能和变更保持一致。 加强测试人员和开发人员之间的沟通，以促进更快的问题解决。 引入自动回归测试，快速验证最近的更改是否对现有功能产生了负面影响。 利用基于风险的测试，将测试工作重点放在应用程序的高风险区域。 在 Alpha 测试后进行回顾会议，讨论取得的成果、存在的问题以及改进的行动项。 参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-alpha-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，专注于 Alpha Testing（Alpha 测试）。文章深入探讨了 Alpha 测试的基础概念和其在软件开发中的重要性，包括测试流程和技巧。读者将了解在 Alpha 测试中各个角色与职责的分工，以及应对可能遇到的挑战和相应的解决方案。通过这个系列分享，读者将更深入地理解 Alpha 测试在软件开发生命周期中的作用，以确保软件系统在初期阶段的稳定性和可靠性。","title":"软件测试术语分享:Alpha Testing Alpha 测试"},{"content":"Agile Testing 敏捷测试 敏捷测试符合敏捷软件开发的原则。与传统方法不同，测试从项目一开始就开始，开发和测试同时进行。这种密切的协作确保了任务的高效完成。\n相关术语：\nAgile Development 敏捷开发 Iteration 迭代 Scrum 也可以看看：\n敏捷测试维基百科\n关于敏捷测试的问题 基础知识和重要性 什么是敏捷测试？ 敏捷测试是一种遵循敏捷软件开发原则的**软件测试实践**。它是一个循环的测试过程，通过自组织的跨职能团队协作，需求在不断演变。敏捷测试符合迭代开发的方法，并确保测试不是独立的阶段，而是开发生命周期的一部分。\n在敏捷测试中，测试人员从项目一开始就积极参与，确保持续反馈和逐渐的改进。测试与开发同时进行，在被称为冲刺的短小的迭代中进行，以实现持续集成和频繁验证功能。\n敏捷团队的测试人员与开发人员、业务分析师以及其他团队成员密切合作，基于用户故事和验收标准创建**测试用例并进行自动化测试**。他们专注于**探索性测试、测试驱动开发 (TDD)，以及行为驱动开发 (BDD)**，以确保软件满足业务需求并且质量高。\n敏捷测试强调了需要有灵活的测试计划，可以适应需求变化，并鼓励面对面的沟通而非文档。其目标是快速提供有关产品质量的反馈，并确保及时解决任何问题。\n测试自动化是敏捷测试的至关重要的组成部分，它使团队能够快速而频繁地执行回归测试。常用工具包括Selenium、JUnit、TestNG、Cucumber 和 SpecFlow，这些工具支持自动化测试脚本的快速开发和执行。\n敏捷测试是一个持续的过程，要求测试人员积极主动、适应性强，并具备协作能力，以确保软件满足客户期望并且以最小的缺陷交付。\n敏捷测试在软件开发中的重要性是什么？ 敏捷测试在软件开发中有着至关重要的作用，原因有几点。首先，它确保了质量从一开始就融入产品，而不是事后的附加。通过将测试活动与迭代开发过程紧密结合，敏捷测试实现了早期缺陷检测和解决，从而降低了在开发周期后期修复缺陷的成本和工作量。\n其次，敏捷测试注重持续反馈，允许团队迅速响应变化，无论是因为客户需求变更还是对产品使用的新认识。这种灵活性对于提供真正满足用户需求且在需要时能够迅速调整的产品至关重要。\n此外，敏捷测试倡导一种协作文化，在这种文化中，测试人员与开发人员、业务分析师以及其他利益相关方密切合作。这种协作促进了对产品目标和质量标准的共同理解，从而带来更紧密、高效的团队。\n在敏捷测试中引入自动化也至关重要，因为它支持频繁且可靠的测试，使团队能够在不牺牲质量的前提下保持高速交付。自动化测试提供了一个安全网，有助于持续集成和部署实践，这在敏捷方法中是至关重要的。\n最终，敏捷测试的目标是更快、更高效地向客户交付价值，同时保持高质量标准，并在变化发生时进行灵活调整。它是敏捷理念的一部分，这种理念将客户满意和团队的有效协作视为比死板的流程和文档更为重要的事项。\n敏捷测试与传统测试方法有何不同？ 敏捷测试与传统测试方法有着几点不同，主要体现在其灵活性、协作性和与开发周期的紧密整合。与传统方法不同的是，敏捷测试是持续和迭代的，测试是在开发功能的同时编写和执行的。\n在传统测试中，需求是提前定义的且通常保持不变，导致采用了瀑布方法。然而，敏捷测试鼓励对需求的变化，即使在开发过程的后期，也确保产品与用户需求保持一致。\n敏捷团队的测试人员是跨职能团队的一部分，与开发人员、产品所有者和其他利益相关者密切合作。这与传统方法形成鲜明对比，传统方法中测试人员通常在开发阶段之后才开始参与，形成了独立工作的模式。\n敏捷测试在很大程度上依赖自动化来保持快速的迭代步伐。自动化测试用于回归测试并集成到**持续集成（CI）**流程中，以提供对代码更改的即时反馈。\n沟通在敏捷测试中至关重要，每日站立会议和频繁的协作取代了正式的文档和状态会议。测试人员被期望积极主动，及早发表关切和建议，而不是在长时间的测试周期结束时才报告问题。\n总的来说，敏捷测试以其适应性、团队整合和持续反馈循环为特征，与传统测试方法的顺序和通常死板的方式形成了鲜明的对比。\n敏捷测试的关键原则是什么？ 敏捷测试的关键原则包括：\n持续反馈：敏捷测试向开发团队提供有关产品当前状态的持续反馈，确保问题能够及时识别和解决。\n协作：测试人员与开发人员、业务分析师和其他团队成员密切合作，确保对产品及其需求有共同的理解。\n增量测试：测试是在开发过程中逐步进行的，可以早期发现缺陷并降低修复成本。\n测试驱动开发 (TDD)：在编写代码之前编写需要测试的测试，确保代码从一开始就满足需求。\n简单性：专注于简单而有效的测试，提供价值，避免不必要的复杂性，以免拖慢开发过程。\n适应性：敏捷测试能够适应需求或优先级的变化，使团队能够迅速而高效地进行调整。\n持续改进：敏捷测试实践会定期进行审查和改进，培养持续学习和提升的文化。\n以用户为中心：测试是以最终用户为考量对象进行设计，确保产品满足用户的需求和期望。\n自动化：在可能的情况下，测试会自动化，以加速测试过程，并允许在不增加额\n外成本的情况下进行频繁的回归测试。\n整个团队的责任：测试不仅仅是测试人员的责任；整个团队对产品的质量负有责任。 通过遵循这些原则，敏捷测试旨在以及时而高效的方式交付高质量的软件，重点关注客户满意度和对变化的响应能力。\n流程与技巧 敏捷测试有哪些不同阶段？ 敏捷测试包含多个与敏捷开发的迭代性质相一致的阶段。这些阶段不是严格线性的，而是在项目演进的过程中常常交叉和重复：\n冲刺计划：测试人员与开发人员和产品所有者合作，定义可测试的用户故事和验收标准。\n测试设计：一旦用户故事被定义，测试人员开始设计测试。他们创建测试用例并确定必要的测试数据。\n// 示例：[测试用例](https://github.com/naodeng/QA-Glossary-Wiki/blob/main/Sections/wiki/test-case.md) 伪代码，用于登录功能 describe(\u0026#34;登录功能\u0026#34;, () =\u0026gt; { it(\u0026#34;应使用有效凭据对用户进行身份验证\u0026#34;, () =\u0026gt; { expect(authenticate(\u0026#39;validUser\u0026#39;, \u0026#39;validPass\u0026#39;)).toBeTruthy(); }); } ); 测试开发：测试人员在开发过程中编写自动化测试脚本，以确保新功能完成后能够立即进行测试。\n持续测试：经常运行自动化测试，即时提供代码库质量的反馈。\n测试执行：手动和自动化测试被执行，验证功能是否符合验收标准。\n探索性测试：测试人员执行非脚本化测试，发现自动化测试可能忽略的缺陷。\n回归测试：运行自动化回归测试，确保新更改不会对现有功能产生不良影响。\n审查和回顾：团队审查测试结果并讨论下一次迭代的改进。\n发布测试：在发布之前，测试人员执行最终验证，确保产品准备好投入生产。\n发布后测试：部署后，测试继续监控性能和用户反馈，发现未来冲刺中需要解决的任何问题。\n有哪些常见的敏捷测试方法？ 常见的敏捷测试方法包括：\n行为驱动开发 (BDD)：专注于以可读和可执行的格式定义应用程序的业务行为。工具如 Cucumber 和 SpecFlow 支持BDD。\n测试驱动开发 (TDD)：在实际编写代码之前编写测试。这有助于确保代码满足需求，并鼓励简单的设计。通常使用像 JUnit 和NUnit这样的 xUnit 框架。\n验收 测试驱动开发 (ATDD)：类似于 TDD，但重点放在捕捉用户故事的验收标准上。这鼓励业务、测试人员和开发人员之间的协作。\n探索性测试：鼓励测试人员在没有预定义测试的情况下探索软件，促进创造力，并发现脚本化测试可能忽略的问题。\n基于会话的测试：结构化的探索性测试，包括专注于特定领域的不间断测试会话，记录结果和指标以供审查。\n结对测试：两名团队成员（通常是开发人员和测试人员）共同进行测试活动，共享想法和见解，早期发现缺陷。\n持续测试：作为持续集成/持续部署（CI/CD）的一部分，经常运行自动化测试，为软件发布候选版本的业务风险提供即时反馈。\n每种方法都与敏捷原则的协作、灵活性以及在短迭代内交付高质量软件的理念相辅相成。敏捷测试人员通常结合这些方法，以适应其团队的独特背景和需求。\n敏捷测试中使用的关键技术是什么？ 敏捷测试中使用的关键技术包括：\n测试驱动开发 (TDD)：在编写代码之前编写测试，以定义期望的功能。\n行为驱动开发 (BDD)：通过用自然语言指定行为，扩展了 TDD。\n验收 测试驱动开发 (ATDD)：在实施之前，共同定义验收标准和测试。\n探索性测试：同时学习、测试设计和执行，以发现脚本测试未涵盖的缺陷。\n结对测试：两名拥有不同视角的团队成员共同测试同一功能，以增强覆盖范围。\n持续测试：自动化测试，持续在开发过程中运行，以获得即时反馈。\n基于会话的测试：具有特定目标和时间框架的结构化探索性测试会话。\n风险驱动测试：根据失败风险和潜在缺陷的影响进行测试优先排序。\n实例驱动规范：与利益相关者合作创建澄清需求的实例，推动开发和测试。\nMob Testing：整个团队一起测试软件，共享见解和知识。\n通过采用这些技术，敏捷团队旨在确保在整个开发过程中保持质量，而不是将测试视为一个独立的阶段。这种方法实现了更快的反馈，促进了协作，并始终专注于为客户提供价值。\n如何将测试集成到敏捷开发过程中？ 测试是通过持续协作和**迭代紧密融入到敏捷开发周期中的。每个迭代都以计划会议开始，在这里测试人员和开发人员共同定义用户故事和验收标准**，确保对功能及其测试方式有共享的理解。\n在开发过程中，测试人员与开发人员并行工作，通常使用**测试驱动开发 (TDD)** 或 行为驱动开发 (BDD)，在编写代码之前创建自动化测试。随着功能的完成，运行这些测试以立即验证功能，促进持续反馈。\n每日站会包括测试状态更新，促进透明度，使团队能够迅速解决问题。测试人员参与精化会议，澄清需求并为即将到来的迭代做准备，确保对测试计划采取主动的方法。\n在持续集成 (CI) 环境中，自动化测试随着每次代码提交而触发。这提供了快速验证，并有助于早期识别回归。团队审查测试结果，并根据需要调整需求和测试用例。\n在每个迭代结束时，团队进行迭代审查，展示已完成的功能，并进行回顾以反思过程并改进实践。测试人员贡献有关测试覆盖率、质量指标和风险评估的见解，影响下一次迭代。\n总之，在敏捷中，测试是一项持续的、协作的努力，与开发活动密切配合，确保从一开始就将质量构建到产品中，并通过频繁的迭代周期进行维护。\n角色和责任 测试人员在敏捷团队中的角色是什么？ 在敏捷团队中，测试人员的角色是非常多元化的。他们是开发生命周期中不可或缺的一部分，从产品概念的初期阶段一直到最终发布。他们与开发人员、业务分析师、产品负责人以及其他相关方密切合作，以确保对产品及其需求有共同的理解。\n在敏捷环境中，测试人员的职责包括：\n创作与用户故事和验收标准一致的**测试用例和测试计划**。 进行**探索性测试**，发现结构化测试可能遗漏的问题。 作为开发周期的一部分进行持续测试，确保新功能在开发完成时立即进行测试。 向开发团队提供及时反馈，促进缺陷的迅速解决。 在整个开发过程中倡导质量，而不仅仅是在最后的阶段。 协助完善用户故事和验收标准，确保它们是可测试且清晰的。 参与敏捷仪式，如每日站会、迭代计划、审查和回顾，以确保与团队的目标和进展保持一致。 与开发人员共同创建作为连续集成流程一部分的自动化测试。 协助维护和改进**测试自动化框架和测试套件**，确保它们是有效且高效的。 在敏捷环境中，测试人员是积极主动的，不断适应变化，并专注于通过高质量的软件为客户提供价值。他们不仅仅是测试专家，更是团队成功的关键贡献者。\n敏捷中测试人员的职责与传统测试角色有何不同？ 在敏捷团队中，测试人员的角色是多方面的。他们在开发生命周期中发挥着关键作用，从产品构思的最初阶段到最终发布的各个阶段都积极参与其中。他们与开发人员、业务分析师、产品负责人和其他利益相关者密切合作，确保对产品及其需求有共同的理解。\n敏捷中的测试人员负责：\n创建与用户故事和验收标准一致的**测试用例和测试计划**。 进行**探索性测试**，发现结构化测试可能无法揭示的问题。 作为开发周期的一部分进行持续测试，确保新功能在开发完成时进行测试。 向开发团队提供即时反馈，促使迅速解决缺陷。 在整个开发过程中倡导质量，而不仅仅是在最后阶段。 协助完善用户故事和验收标准，确保它们是可测试且清晰的。 参与敏捷仪式，如每日站会、迭代计划、审查和回顾，以保持与团队目标和进度的一致性。 与开发人员合作创建自动化测试，作为持续集成流程的一部分。 帮助维护和改进**测试自动化框架和测试套件**，确保其有效和高效。 在敏捷环境中，测试人员是主动的，不断适应变化，并专注于通过高质量软件为客户提供价值。他们不仅仅是测试专家，而且是团队成功的关键贡献者。\n对于敏捷测试人员来说哪些技能很重要？ 敏捷测试人员成功所需的关键技能包括：\n适应能力：敏捷环境快速变化，要求测试人员能够迅速适应需求或项目方向的变化。 技术熟练度：深厚理解各种测试工具和编程语言（如 Java、Python）对于创建和维护自动化测试脚本至关重要。 沟通能力：在与开发人员、产品负责人和其他利益相关者合作时，清晰而简明的沟通对于成功至关重要。 批判性思维：敏捷测试人员必须能够分析需求和用户故事，以创建有效的测试用例。 持续学习：保持对最新测试方法和工具的了解对于提高流程和效率至关重要。 协作能力：与跨职能团队紧密合作，确保质量成为共同的责任。 以用户为中心：在设计测试时，优先考虑最终用户的体验，以确保产品满足其需求。 了解敏捷原则：了解敏捷方法论，以将测试活动与团队的方法相一致。 探索性测试技能：能够快速学习和深入测试新功能，而无需形式化的测试用例。 解决问题的能力：在测试过程中识别、分析和解决问题。 自动化策略：了解何时以及何种内容自动化，以最大化测试套件的价值和可维护性。 这些技能有助于敏捷测试人员在团队中有效地实现快速交付高质量软件的目标。\n测试人员如何与其他团队成员进行敏捷协作？ 在敏捷开发中，测试人员与开发人员、产品负责人以及其他团队成员的合作至关重要，以确保对产品及其需求有共享的理解。他们参与每日站会，讨论进展、障碍和计划。在冲刺计划期间，测试人员帮助定义验收标准，并就用户故事的可测试性提供建议。\n测试人员与开发人员一起参与配对编程或集体测试会话，早在开发周期的初期创建和执行测试。他们还参与代码审查，以在代码合并之前发现潜在问题。\n持续沟通至关重要，测试人员经常嵌入跨职能团队，营造一个分享知识和技能的环境。他们使用即时通讯工具、问题跟踪系统和维基页面，以保持测试活动的透明度和最新信息。\n在冲刺回顾中，测试人员就质量和流程改进提供见解，确保测试随着团队的实践而发展。通过倡导质量，他们帮助团队优先考虑技术债务和**缺陷**修复。\n测试人员还支持产品负责人，通过验证用户故事是否符合验收标准，并从用户角度提供对产品行为的反馈。这种合作确保产品不仅按预期运行，还满足用户的需求和期望。\n工具和技术 敏捷测试中常用的工具有哪些？ 在敏捷测试中，常用的工具包括：\nSelenium：一种用于自动化浏览器的开源工具。支持多种语言和浏览器。 JIRA：广泛用于缺陷跟踪、问题跟踪和项目管理。 Cucumber：支持使用简单语言规范进行行为驱动开发（BDD）。 Jenkins：一种开源的 CI/CD 工具，自动化软件交付过程的各个阶段。 Git：用于在软件开发过程中跟踪源代码更改的版本控制系统。 TestRail：一种测试用例和测试管理软件工具，可与问题跟踪系统集成。 Appium：一种用于在 iOS 和 Android 平台上自动化移动应用程序的开源工具。 Postman：用于 API 测试，允许用户快速构建复杂的 HTTP 请求。 SpecFlow：一种.NET 工具，将业务需求绑定到.NET 代码并支持 BDD。 JUnit/TestNG：用于 Java 单元测试的框架，提供注释以标识测试方法。 Mockito：用于 Java 单元测试的模拟框架。 REST-assured：简化 RESTful API 测试的 Java DSL。 Puppeteer：一个 Node 库，提供控制 Chrome 或 Chromium 的高级 API，基于 DevTools 协议。 这些工具支持敏捷测试的各个方面，从测试用例管理到持续集成，并满足不同的测试需求，如单元测试、集成测试、功能测试和验收测试。它们促进了敏捷方法论中快速反馈和持续改进的特点。\n这些工具如何支持敏捷测试过程？ 测试自动化工具通过实现快速反馈和持续改进来支持敏捷测试过程，这是敏捷方法论的核心。这些工具通过允许团队频繁执行测试并早期检测问题，促进了持续集成和持续交付。\n自动化测试可以整合到构建流水线中，每当有更改提交时就会自动运行。这确保新代码不会破坏现有功能，从而在整个开发过程中保持软件的健康状态。\n版本控制集成是这些工具的另一个功能，允许测试脚本与应用程序代码一起演变。测试人员可以更新自动化测试以反映用户故事或验收标准的变化，保持test suite的相关性和有效性。\n并行执行能力减少了运行庞大的test suite所需的时间，为开发人员提供更快的反馈。在敏捷中，被时间框定的迭代中，这是至关重要的。\n此外，测试自动化工具通常具有提供对测试覆盖率和缺陷趋势的洞察的报告功能。这些数据对于敏捷团队在迭代回顾期间识别流程改进领域是有价值的。\n这些工具中的协作功能有助于测试人员、开发人员和其他利益相关者共享结果并共同解决问题。这符合敏捷对团队协作和对质量的集体责任的强调。\n最后，许多测试自动化工具支持行为驱动开发 (BDD)和测试驱动开发 (TDD)，这些方法常常在敏捷中使用，以确保测试从一开始就与客户需求保持一致。\n自动化在敏捷测试中的作用是什么？ 在敏捷测试中，自动化发挥着关键作用，以保持快速开发周期的步伐并确保对产品质量的即时反馈。自动化通过快速、可靠地执行一套测试来支持持续集成和持续交付，这对于频繁发布至关重要。\n自动化测试就像一个安全网，有助于及早捕捉到回归和缺陷。它们通过自动化重复且耗时的任务，使测试人员能够将注意力集中在更为复杂的探索性测试上。在敏捷环境中，变更频繁，自动化确保在引入新变更后现有功能保持完整。\n此外，自动化促进了**测试驱动开发 (TDD)和行为驱动开发 (BDD)**，在这些实践中，测试在编写代码之前就被编写，并作为开发的指南。这些实践中的自动化测试确认代码符合预定义的标准并且表现如预期。\n为了无缝集成到敏捷过程中，自动化测试必须是：\n可维护的：易于根据应用程序的变化进行更新。 可靠的：始终提供准确的结果。 快速的：在支持快速迭代的时间范围内执行。 在敏捷中，自动化不仅仅关乎测试本身，还包括**测试数据生成**、环境设置和部署过程的自动化。这种全面的自动化方法有助于敏捷团队以符合快速交付的敏捷理念的速度提供高质量的软件。\n敏捷测试中如何实现持续集成？ 在敏捷测试中，实现持续集成（CI）可以通过设置一个 CI 服务器来完成。该服务器在每次向版本控制系统提交新代码时都会自动触发一套测试。在这个过程中，**测试自动化**起到了至关重要的作用，因为它能够迅速提供有关应用程序状态的反馈。\n首先，要配置你的 CI 服务器（例如 Jenkins、CircleCI、Travis CI）以监控代码仓库的变化。一旦检测到变化，CI 服务器应该执行以下步骤：\n拉取最新的代码，来自主分支。 构建应用程序，以确保新代码能够无问题地集成。 运行自动化测试，其中应包括单元测试、集成测试以及其他相关的自动化检查。 使用类似 Git Flow 的分支策略来管理不同的开发线，确保主分支保持稳定。可以使用特性分支进行新工作，然后在测试后将其合并到主分支。\n实施**测试驱动开发 (TDD)或行为驱动开发 (BDD)**，以确保在编写代码之前就编写了测试，推动测试覆盖率和质量。\n确保测试套件是可维护且可扩展的。测试应该快速、可靠且相关。必须修复或移除不稳定的测试以保持对 CI 过程的信任。\n最后，在 CI 流程中集成测试结果报告。这应该提供关于测试结果的清晰反馈，便于团队迅速解决问题。\n通过遵循这些步骤，持续集成成为敏捷测试的一个不可或缺的部分，使团队能够及早发现和解决问题，从而在整个开发过程中保持高水平的软件质量。\n挑战和解决方案 敏捷测试面临哪些常见挑战？ 在敏捷测试中，常见的挑战包括：\n在快速发布周期下保持测试质量可能会很困难，因为测试时间较短。 适应变化的需求通常会导致重新工作，并可能破坏测试策略。 在不断演进的动态环境中确保足够的**测试覆盖率**是具有挑战性的。 平衡自动化和**手动测试**至关重要；过度依赖其中之一可能是有害的。 集成新的工具和技术可能复杂且耗时。 跨职能团队之间的协作和沟通必须始终保持高效，以避免误解，并确保所有人都与目标保持一致。 如果测试没有得到足够的关注，技术债务可能会累积，导致潜在的缺陷和未来维护工作的增加。 资源约束，如对测试环境或数据的有限访问，可能会阻碍测试过程。 **不稳定的测试**可能成为一个重要问题，特别是随着自动化的增加，可能导致对测试结果的不信任。 性能和**安全测试**通常会被留到周期的后期，这可能导致过晚发现重要问题。 为克服这些挑战，团队可以：\n优先考虑并持续完善测试套件。 采用“向左移”方法，早期将测试纳入开发过程。 使用测试驱动开发（TDD）和行为驱动开发（BDD）确保满足需求。 实施服务虚拟化以缓解环境和数据的约束。 定期审查和维护自动化测试以减少不稳定性。 在每个迭代中分配时间来解决技术债务。 确保性能和安全性从开发过程的开始就得到考虑。 如何克服这些挑战？ 在敏捷测试中克服挑战需要一种战略性的方法，并采用适应敏捷环境的最佳实践。以下是一些建议的策略：\n拥抱变化：敏捷就是适应变化。使用重构来保持测试代码的可维护性，使其能够适应应用程序频繁的变化。\n持续学习：保持对最新测试技术和工具的了解。鼓励团队内部进行知识分享，促进集体专业知识的发展。\n测试驱动开发 (TDD)：实施 TDD 以确保在编写代码之前编写测试，从而获得设计更好、更可测试和更可靠的软件。\n配对编程：将测试人员与开发人员配对，增进理解，提高测试覆盖率。这种协作也有助于早期发现潜在问题。\n自动化回归测试：投资于强大的自动化回归套件，快速验证新更改没有对现有功能产生负面影响。\n优先考虑测试：专注于提供最大风险覆盖的高价值测试。使用基于风险的测试来优先考虑测试用例。\n持续集成 (CI)：将测试集成到 CI 流水线中，以确保对应用程序健康状况的即时反馈。\n可扩展的测试环境：使用容器化和虚拟化，根据需要快速建立和拆除测试环境。\n性能测试：在开发周期的早期阶段进行性能测试，以在问题升级之前检测和解决问题。\n反馈循环：建立短的反馈循环，迅速将发现传达给开发团队，实现及时行动。\n迭代回顾：利用回顾来反思测试过程，并识别需要改进的领域。\n通过实施这些策略，敏捷测试可以变得更加高效、有效，并与敏捷软件开发的动态性质保持一致。\n有效敏捷测试的最佳实践有哪些？ 实施有效的敏捷测试的最佳实践包括：\n与开发人员、业务分析师和产品负责人密切协作，确保对需求有共同的理解，并促进快速的反馈循环。 基于业务价值和风险对测试进行优先排序。专注于可能显著影响用户体验的高影响区域。 与开发代码同时编写自动化测试，而不是之后。这确保了对新功能的即时验证。 保持测试套件的清洁，定期重构测试并删除过时或多余的测试。 实施测试驱动开发 (TDD) 或 行为驱动开发 (BDD)，在编写实际代码之前创建测试，确保代码从一开始就满足要求。 使用持续集成 (CI) 在提交新代码时自动运行测试，及早发现问题。 早早而频繁地进行测试，在问题更容易、成本更低的情况下发现缺陷。 使测试成为每个人的责任，而不仅仅是测试人员。鼓励开发人员编写单元测试并参与测试计划。 利用配对编程 或 共同编程 提高质量，共享关于系统和测试的知识。 根据反馈和项目变化的需求调整和演进测试策略。 明智地使用度量标准，以衡量测试工作的效果并指导改进。 通过遵循这些实践，敏捷团队可以确保测试是开发过程的一个组成部分，从而实现更高质量的软件和更有效的交付。\n随着时间的推移，敏捷测试如何得到改进？ 随着时间的推移，如何改进敏捷测试需要建立一个持续的反馈循环并进行灵活调整。经常性的回顾至关重要，让团队深入思考目前的有效实践和存在的问题。在这些回顾会议上，可以讨论测试策略、工具的效能以及协作中遇到的问题。\n需要慎重选择和监控测试度量指标，以便追踪进展并找出需要改进的方面。例如缺陷密度、测试覆盖率和周期时间等指标可以帮助了解测试过程的效率和有效性。\n**测试自动化是一个需要持续改进的关键领域。定期审查和重构自动化测试套件，确保其保持可靠且易于维护。引入向左转测试**的实践，能够更早地发现问题，从而降低修复缺陷的成本和工作量。\n**结对测试**有助于促进知识共享，提高测试覆盖率。将测试员与开发人员或其他测试员配对，可以带来不同的视角，并增强测试场景的覆盖。\n跨职能培训有助于打造一个多才多艺的团队，能够胜任各种任务。鼓励团队成员相互学习，无论是关于测试、开发还是领域知识。\n尝试新的工具和技术可能带来改进。但是，需要确保新工具能够与现有工作流程良好地集成，并真正为团队增加价值。\n最后，始终保持以用户为中心的关注。定期收集用户反馈，并将其纳入测试过程，以确保产品能够满足真实用户的需求和期望。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-agile-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，专注于 Agile Testing（敏捷测试）。文章深入探讨了敏捷测试的基础概念和其在软件开发中的重要性，涵盖了敏捷测试流程和技巧，以及在敏捷环境中采用的工具和技术。读者将了解敏捷测试中各个角色与职责的分工，以及应对敏捷开发中可能遇到的挑战和相应的解决方案。通过这个系列分享，读者将更深入地理解敏捷测试的核心原则，为在敏捷团队中高效测试提供指导。","title":"软件测试术语分享:Agile Testing 敏捷测试"},{"content":"Agile Development 敏捷开发 敏捷软件开发是一种迭代方法，通过跨职能团队的协作来共同开发需求和解决方案。其着重点在于适应性和灵活性，而非死板的规划。\n也可以看看： 敏捷软件开发维基百科\n关于敏捷开发的问题 基础知识和重要性 什么是敏捷开发，为什么它很重要？ 敏捷开发是一种以协作、迭代和增量为特点的软件开发方法，注重灵活性、客户满意度和快速交付功能性软件。其重要性在于使团队能够灵活应对变化的需求，通过持续反馈提高产品质量，并通过分阶段发布来缩短上线时间。\n在 测试自动化领域，敏捷开发至关重要，因为它将测试融入到开发流程中，确保问题能够迅速被发现和解决。自动化测试在敏捷中扮演关键角色，提供迅速反馈，并支持持续集成和部署。敏捷团队的测试人员与开发人员和产品负责人密切合作，共同贡献于用户故事，并确保满足验收标准。敏捷测试的核心思想是从发现缺陷转向预防缺陷，与敏捷强调质量和可持续性的理念一致。\n在敏捷环境中，测试自动化工程师需要善于设计、实施和维护可靠、可维护且提供快速反馈的自动化测试。他们通常采用**测试驱动开发（TDD）和行为驱动开发（BDD）**等方法，确保测试是从用户角度出发的，并且能够引导开发过程。\n敏捷开发在 测试自动化中的重要性不可低估，因为它使团队能够在现代软件交付的快节奏环境中保持高质量。\n敏捷开发的主要原则是什么？ 敏捷开发的核心是敏捷宣言中概述的四个关键原则：\n个体与交互优先于流程和工具：敏捷强调直接沟通和协作，更看重团队对变化的响应能力，而非严格遵循繁琐的流程。\n可工作的软件优先于详尽的文档：敏捷专注于频繁交付功能性软件，对详尽文档的侧重较少。这并不意味着文档不重要，而是强调主要的进展衡量标准是交付可工作的软件。\n与客户的协作优先于合同谈判：敏捷鼓励与客户或利益相关者持续互动。与其仅仅依赖合同规定，敏捷团队与客户密切合作，确保产品能够根据他们的需求和反馈不断演进。\n响应变化优先于遵循计划：敏捷团队灵活适应变化的需求，即使在开发过程的后期。这种适应能力被认为比严格遵循计划更有价值。\n这些原则指导着敏捷团队的日常工作和决策过程，确保适应性、客户满意度和有效沟通一直是开发工作的核心。作为经验丰富的 测试自动化工程师，将这些原则融入到你的测试策略中将使你的工作与敏捷开发的整体目标保持一致，促进一个欢迎变化并专注于交付高质量、功能性软件的协作环境。\n敏捷开发与传统软件开发方法有何不同？ 敏捷开发注重迭代进展、协作和灵活性，与传统的软件开发方法有着明显的区别。传统方法通常依赖顺序进行的各个阶段和严格的计划。例如，在瀑布模型中，必须在进入下一阶段之前完成每个阶段的工作，形成线性和有序的过程。\n相反，敏捷开发将产品划分为小的、可操作的增量，允许频繁地评估和调整计划。这种迭代的循环使得每次发布都能向客户提供持续的价值，而不是等到最终产品完全完成。敏捷开发还鼓励直接的沟通而非过度的文档，与客户的协作而非依赖合同，以及灵活地应对变化而非严格遵循既定计划。\n在实践中，敏捷团队采用称为 sprint 或 迭代的短周期进行工作，通常持续几周，以构建和交付功能性的产品增量。团队会定期举行各种会议，例如每日站会、冲刺计划和回顾会议，以确保工作同步进行并反思改进之处。测试从一开始就得到整合，通过持续的反馈循环来确保质量和相关性。\n敏捷开发的适应性使其特别适用于需求不确定或经常变化的项目，而传统的开发方法可能在需求已经充分理解且相对稳定时更为有效。敏捷开发通过关注客户满意度和团队协作通常能够产生更高质量的产品并实现更有效的开发流程。\n敏捷方法论 有哪些常见的敏捷方法，它们有何不同？ 除了已经提到的**Scrum和Kanban**，还有其他一些常见的敏捷方法：\n极限编程 (XP): 专注于技术实践，如**测试驱动开发 (TDD)、重构和持续集成**。XP 强调客户满意度和迭代开发。它鼓励在短时间内频繁发布，从而提高了生产效率，并引入了检查点，可以在其中采纳新的客户需求。\n特征驱动开发 (FDD): 该方法以设计和构建功能为中心。与Scrum不同，FDD 是模型驱动的，并有特定的角色，如类拥有权和特征团队。它涉及创建总体模型，构建功能列表，然后通过功能进行规划、设计和构建。\n精益软件开发： 受到精益制造实践的启发，Lean 注重通过消除浪费（任何对客户没有附加值的事物）向客户提供价值。它强调通过优化工作流程和管理工作量，通过减少批处理大小来实现快速交付。\n动态系统开发方法 (DSDM): 该方法侧重于项目，并强调整个项目生命周期。DSDM 整合了项目管理和产品开发的最佳实践。其特点包括用户参与、团队有权做决定、频繁交付产品以及以交付的业务目的为主要标准。\n水晶： 这是一系列敏捷方法，注重人和他们的互动，而非过程和工具。水晶方法根据项目的不同\n大小和关键性定制，强调频繁交付、反思改进和紧密沟通。\n每种方法都有其独特的实践和差异，但共享敏捷原则，包括协作、迭代开发和灵活适应变化。\n什么是 Scrum，它与敏捷开发有什么关系？ Scrum是敏捷方法中的一个框架，用于管理和完成复杂项目，包括软件测试自动化。它强调迭代进展、团队协作和适应变化。\n在Scrum中，工作被分成冲刺，通常持续一到四周，期间从产品积压中选择特定的项目进行开发和测试。每个冲刺开始时都有一个冲刺计划会议，用于确定要完成的工作。**每日Scrum**或站立会是一个简短的、时间固定的会议，用于同步团队活动并制定下一天的计划。\nScrum Master推动整个过程，确保团队遵循Scrum实践并解决障碍。产品负责人管理产品积压并确保团队提供价值。\n在每个冲刺结束时，团队进行冲刺回顾，向利益相关者展示完成的工作，并进行冲刺反思，以反思冲刺并进行流程改进。\nScrum在测试自动化中的重要性在于其适应性和对持续反馈的强调。测试自动化工程师在Scrum框架内工作，与冲刺目标保持一致，开发、执行和完善自动化测试，确保测试与开发同步，为交付高质量软件做出贡献。\n什么是 Kanban，它如何用于敏捷开发？ Kanban 是一种视觉化的工作流程管理方法，能够帮助团队优化工作流程。在敏捷开发中，Kanban 通过提供清晰的工作项可视化和其状态的 Kanban 板来辅助团队。这个板被划分为不同开发阶段的列，比如“待办”，“进行中”和“完成”。\n工作项通常以卡片的形式从左到右移动穿过板，使团队能够跟踪进度并识别瓶颈。Kanban 强调限制在制品（WIP），这鼓励专注并减少多任务。通过为每个阶段设置 WIP 限制，团队可以平衡需求与吞吐量，提高工作流程。\nKanban 通过促进持续改进、灵活性和客户关注来与敏捷原则保持一致。与 Scrum的不同之处在于它不规定有时间框限制的迭代；相反，它关注周期时间和吞吐量。团队在完成当前任务后即拉取新工作，使 Kanban 成为一种更加流畅和连续的方法。\n在测试自动化中，Kanban 在管理测试用例的开发、执行和维护流程中特别有用。它允许根据反馈和变化的优先级快速调整，确保测试工作始终与项目最新需求保持一致。\n以下是 Markdown 中简单 Kanban 板布局的示例：\nTo Do | In Progress | Done ------|-------------|----- Task1 | Task2 | Task3 Task4 | | Task5 通过可视化测试活动，团队可以更有效地沟通并实时调整他们的测试策略，从而增强开发过程的整体敏捷性。\n角色和责任 敏捷团队中的角色是什么以及他们的职责是什么？ 在敏捷团队中，角色通常不像传统方法那样刻板，但关键职位包括：\n开发团队：负责在每个迭代结束时交付可能可交付的产品增量。他们紧密合作，通常具有跨职能的技能，以确保产品按照用户需求发展。\n业务分析师 (BA)：充当利益相关者和开发团队之间的桥梁。他们帮助将业务需求转化为用户故事和验收标准，确保团队理解业务背景。\nUX/UI 设计师：专注于用户体验和界面设计。他们确保产品不仅功能强大，而且直观易用。\n质量保证 (QA) 工程师：与开发人员一起工作，创建测试计划，编写自动化测试，并通过各种测试方法确保产品质量。\nDevOps 工程师：促进持续集成和部署 (CI/CD) 实践，维护支持自动化测试和高效发布管理的工具和基础架构。\n技术领导/架构师：提供技术方向，确保架构支持产品的需求。他们在技术决策和编码标准方面指导团队。\n每个角色都密切合作，通常兼具多重角色，以支持敏捷的迭代开发和持续反馈的过程。重点是团队合作、适应性和致力于为客户提供价值。\nScrum Master 在敏捷开发中的角色是什么？ Scrum Master 在敏捷Scrum团队中充当促进者和教练的角色，专注于使团队能够以最高效的方式工作。他们的责任是确保团队遵循Scrum的实践和原则。为实现这一目标，Scrum Master 会通过以下方式进行：\n排除障碍：他们积极识别和消除可能妨碍团队进展的问题。 促进会议：这包括每日站会、冲刺计划、冲刺回顾和回顾等会议。 保护团队：他们保护团队，使其免受外部打扰和干扰，以确保专注于手头的任务。 指导团队：Scrum Master 帮助团队改进其工作流程，使其能够更有效地协同工作。 确保协作：他们鼓励团队内部以及与外部利益相关者之间的沟通和协作。 支持产品负责人：他们协助维护产品待办事项，并确保为下一个冲刺做好准备。 促进持续改进：Scrum Master 培养一种学习和适应的文化，鼓励团队对其实践进行反思并不断改进。 总的来说，Scrum Master 是一位服务型领导者，致力于支持团队遵循敏捷框架，优化其工作流程，并交付高质量的产品。\n产品负责人在敏捷开发中的角色是什么？ 在敏捷开发中，产品负责人（PO）是代表业务或用户社区的关键利益相关者。PO 负责定义和优先安排产品待办事项，确保团队致力于完成对业务价值最大的任务。\n产品负责人的角色包括：\n阐明产品愿景，并确保团队理解长期目标。 创建和维护产品待办事项，包括编写用户故事和验收标准，并根据优先级排序项目。 基于利益相关者和客户的反馈做出决策，关于产品的功能和特性。 与开发团队合作，澄清需求并接受或拒绝工作成果。 参与敏捷仪式，如冲刺计划、回顾和回顾，提供反馈和指导。 与利益相关者沟通，管理期望并汇报产品进展。 对于 测试自动化工程师而言，产品负责人是理解自动化功能背后业务背景的关键资源，也是澄清需求中的任何模糊之处的重要角色。PO 对待办事项的优先级排序也影响测试自动化策略，因为测试应与最关键和最高优先级的功能保持一致。\n敏捷实践 什么是结对编程以及它如何融入敏捷开发？ 配对编程是一种敏捷软件开发技术，两名程序员在一个工作站上共同工作。一名是驱动者，负责编写代码，而另一名是观察者或导航者，在代码键入时审查每一行。两名程序员经常交换角色。\n在敏捷开发的背景下，配对编程融入了协作和持续反馈的敏捷原则。它鼓励实时的代码审查和知识分享，可以提高代码质量和团队成员的技能水平。这种做法与敏捷对团队合作、沟通和迭代进展的强调相一致。\n配对编程还有助于集体代码拥有权和可持续的工作节奏，这在敏捷环境中非常关键。通过成对工作，团队成员可以避免专业知识的孤立，确保关于系统不同部分的知识分布在整个团队中。\n对于 测试自动化工程师而言，当创建或完善自动化测试套件时，配对编程可能特别有益。它允许对测试用例和脚本进行即时反馈，确保它们是健壮的、可理解的和可维护的。在测试自动化中的配对编程可以导致更可靠、更有效的测试流程，这对于敏捷方法论中通常包含的持续集成和持续交付实践至关重要。\n总之，配对编程通过促进协作、提高代码质量和分享知识，增强了敏捷开发，这对于快速而灵活的软件开发是至关重要的。\n什么是测试驱动开发以及它如何在敏捷中使用？ 测试驱动开发（TDD）是一种软件开发实践，其中编写测试用例发生在实际代码之前。在敏捷环境中，TDD 支持迭代开发和快速反馈循环。\n以下是 TDD 在敏捷中的典型用法：\n编写一个失败的测试：从一个尚不存在的新功能或特性的测试开始。由于代码尚未实现，此测试应该失败。\n编写最简单的代码：编写使测试通过所需的最少量代码。\n重构：清理新代码，确保其与现有代码库良好配合。测试套件确保重构不会破坏任何东西。\n重复：继续下一个测试。\n在敏捷中，TDD 确保代码质量得以保持，回归被最小化，并且代码库保持对变更的灵活性。它与敏捷强调通过连续交付有价值的软件来实现可持续开发和客户满意度的目标一致。在敏捷团队中，测试自动化工程师利用 TDD 创建了一套健壮的自动化测试，随着代码库的演变而不断更新，为频繁发布和重构提供信心。\n什么是持续集成以及它如何融入敏捷开发？ 持续集成（Continuous Integration，CI）是一种开发实践，其核心是开发人员频繁地将代码更改合并到共享存储库中，通常一天多次。每次集成都会通过自动构建和测试过程自动验证，使团队能够及早发现问题。\n在敏捷开发的背景下，持续集成支持快速反馈和持续改进的原则。敏捷团队追求增量开发，定期交付小块功能。持续集成完美地融入这个模型，确保新的代码贡献不会破坏现有功能，从而保持一个随时可以发布的稳定代码库。\n对于 测试自动化工程师，持续集成至关重要，因为它提供了在集成过程中运行自动化测试的框架。这意味着每次代码提交都会触发一个包括单元测试、集成测试，甚至可能是验收测试的自动化测试套件。这些测试的即时反馈使开发人员能够迅速解决问题，通常在编写代码的几分钟内完成，这符合敏捷对适应性和客户满意度的强调。\n这里是使用 Jenkins 的一个基本 CI 流水线脚本的示例：\npipeline { agent any stages { stage(\u0026#39;Build\u0026#39;) { steps { // Commands to build the application sh \u0026#39;make\u0026#39; } } stage(\u0026#39;Test\u0026#39;) { steps { // Commands to run automated tests sh \u0026#39;make test\u0026#39; } } } post { always { // Actions to take after the pipeline runs, like notifications mail to: \u0026#39;team@example.com\u0026#39;, subject: \u0026#39;Build Finished\u0026#39; } } } 通过定期集成，敏捷团队可以最小化在等待发布日期合并特性分支时经常发生的集成问题，从而保持一个高质量的产品。\n敏捷和软件测试 测试如何融入敏捷开发？ 在敏捷开发中，测试是一个不可或缺且持续的过程，与敏捷的迭代性质相一致。它强调早期和频繁的测试，确保质量从一开始就内建于产品中，而不是在最后进行检查。\n敏捷测试涉及整个团队，包括开发人员、测试人员和业务利益相关者的密切协作。测试人员从项目开始就参与其中，参与需求讨论和设计会议，以了解用户故事和验收标准。这种早期的参与有助于创建相关且全面的测试用例。\n自动化在敏捷测试中起着至关重要的作用。自动化测试不仅针对新功能进行创建，还用于回归测试。这些自动化测试通常作为**持续集成（CI）**流水线的一部分频繁运行，为应用程序的健康状况提供快速反馈。\n**测试驱动开发（TDD）**是一个常见的实践，其中在编写代码之前编写测试。这确保了在开发的每个步骤中都考虑到了测试，并且在被视为完成之前，代码就满足了预定义的标准。\n在敏捷中，测试不是一个阶段，而是一个与开发平行的活动。随着功能的完成，它们会进行测试，并立即解决任何问题，从而降低了累积缺陷和技术债务的风险。\n敏捷测试是一种协作的、持续的、自适应的过程，强调自动化以支持敏捷开发的快速节奏。\n测试人员在敏捷团队中的角色是什么？ 在敏捷团队中，测试人员的角色是多方面的，围绕着协作、反馈和持续改进展开。测试人员直接与开发人员、产品负责人和其他利益相关者互动，以确保对产品及其需求有共享的理解。他们参与以下活动：\n用户故事细化：提供对验收标准的意见，并确保它们可以进行测试。 规划：估算测试工作量并为冲刺计划做出贡献。 设计和执行：创建并执行测试用例，包括手动和自动化测试，以验证用户故事。 自动化：开发和维护自动化测试套件，通常使用 Selenium 或 Cypress 等工具。 持续测试：实施持续测试实践，以迅速提供有关应用程序健康状况的反馈。 探索性测试：执行非脚本化的测试，揭示结构化测试可能无法揭示的问题。 缺陷管理：识别、记录和追踪缺陷直至解决。 协作：与开发团队密切合作，确保质量从一开始就内嵌于产品中。 反馈：在迭代中对新功能和错误修复提供快速反馈。 回顾：参与回顾会议，讨论做得好的地方、做得不好的地方以及如何改进流程。 在敏捷团队中，测试人员是积极主动的，不断适应变化，并专注于在短迭代中交付高质量的软件。他们在通过质量视角推动开发过程中扮演着至关重要的角色。\n什么是敏捷测试以及它与传统测试方法有何不同？ 敏捷测试是一种与敏捷软件开发原则一致的迭代方法。它强调持续反馈、团队协作和灵活性，以适应变化。与传统方法不同，传统方法中测试是在开发之后的一个独立阶段，而敏捷测试则被整合到了开发周期中。\n主要区别包括：\n持续测试：在敏捷中，测试是持续的，从第一天开始，每个迭代都会重复进行，确保对最新更改的即时反馈。 协作方法：测试人员与开发人员、产品所有者和其他团队成员密切合作，促进对质量的共同责任。 适应性：敏捷测试迅速适应需求或范围的变化，无需进行大量测试计划修订。 用户故事验证：测试通常基于用户故事，确保软件满足实际用户需求。 自动化：敏捷团队在很大程度上依赖于**测试自动化**，以保持迭代开发的节奏，通常实施持续集成（CI）以频繁验证代码更改。 在敏捷中，测试人员的角色不仅仅是发现缺陷，更是通过提供用户故事验收标准的输入、完善测试用例和从开发周期的开始改进产品的整体质量，以防止缺陷的发生。敏捷测试不太关注遵循预定的测试计划，而更关注根据团队和产品的独特需求演进测试实践。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-agile-development/","summary":"这篇博文是软件测试术语分享系列的一部分，集中讨论 Agile Development（敏捷开发）。文章深入解析了敏捷开发的基础概念和其在软件开发中的重要性，探讨了敏捷方法论的原则，各个角色与职责的分工，以及敏捷实践中软件测试的关键作用。读者将了解如何在敏捷团队中协同工作，提高交付效率，并应对变化。通过这个系列分享，读者将对敏捷开发的理念、方法和软件测试在敏捷环境中的实践有更深刻的了解。","title":"软件测试术语分享:Agile Development 敏捷开发"},{"content":"Ad Hoc Testing 随机测试 “Ad-Hoc”原意是指“特定的，一次性的”,故 Ad hoc testing 一般成为即兴测试，一次性测试或随机测试。 这里把 Ad Hoc Testing 翻译为随机测试，也感觉有些歧义，个人觉得即兴测试，临时测试，临场测试貌似更准确。（大家有好的想法，可以提 PR 来更新）\nAd hoc testing（随机测试） 是一种非正式、即兴的软件测试方法。其主要目标是尽快发现漏洞或问题。这种方法没有详细的计划或文档支持，属于一种不受限、灵活应对的测试方式。\n相关术语： Exploratory Testing 探索性测试\n关于随机测试的问题 基础知识和重要性 什么是软件测试中的随机测试？ 随机测试 是一种非正式且非结构化的软件测试技术，测试人员在没有具体计划或文档的情况下探索软件。它凭借测试人员的直觉、经验和对应用程序的理解来引导测试过程。这种测试通常用于发现传统、结构化测试方法可能遗漏的缺陷。\n在 随机测试 中，测试人员可以自由选择应用程序的任何路径，并使用任何有效或无效的输入数据。这是一种探索性测试，其主要目标是通过超越传统思维方式、以创造性的方式尝试破坏系统来发现错误。\n由于 随机测试 是无脚本的，要重现问题通常需要测试人员详细记录他们的操作。通常在正式执行测试用例后的测试后阶段使用，以补充更加结构化的测试方法。\n关键点：\n非结构化和非正式的测试方法。 依赖于测试人员的直觉和经验。 用于发现结构化测试未捕捉到的缺陷。 允许创造性和无约束的探索。 没有详细记录的情况下难以重现问题。 在后期阶段与结构化测试相辅相成。 为什么随机测试在软件开发生命周期中很重要？ 随机测试 在软件开发生命周期（SDLC）中至关重要，因为它提供了一种独特的方法来发现结构化测试可能忽略的缺陷。它依赖于测试人员的直觉、经验和对系统的理解，以在没有预定义 测试用例 或文档的情况下探索应用程序。这可能导致发现意外问题，特别是在应用程序的复杂或较不清晰的领域。\n由于 随机测试 是无脚本的，它允许测试人员更自然地模拟用户的视角，潜在地识别正式 测试用例 无法发现的可用性问题。它还对应用程序进行**压力测试**提供了价值，这是在设计阶段未预料到的方式。\n将 随机测试 纳入 SDLC 可以增强整体的**测试覆盖率**，并提供了一种结构化测试的补充方法。在开发的后期阶段，尤其是在正式测试周期完成后，在发布前进行最终检查或在快速测试补丁和小更新之前，它变得尤为重要。\n此外，随机测试 可以是一种高效利用时间的测试应用程序的方式，特别是在截止日期紧迫的情况下，因为它不需要提前准备。这是一种灵活的测试方法，可以在任何机会使用，使其成为 SDLC 中持续改进的有价值工具。\n随机测试与其他测试形式的主要区别是什么？ 随机测试 与其他测试形式的主要区别在于其缺乏正式结构和预定义的 测试用例。与诸如单元测试、集成测试或系统测试等系统测试方法不同，随机测试 是无脚本的，依赖于测试人员的直觉、经验和对系统的理解来探索应用程序并发现缺陷。\n其他形式的测试通常遵循记录的过程，基于事先设计的**测试计划、测试用例和测试脚本。这些测试通常是可重复的**，可以自动化，确保在测试周期内保持一致的覆盖范围。\n相反，随机测试 是自发的和非正式的，使其不可重复。它主要是一个手动测试过程，因为它需要人类的创造力和洞察力来执行。执行 随机测试 的测试人员可能会关注难以自动化或需要人工判断的应用程序区域。\n虽然其他测试方法通过详细的测试场景旨在实现全面覆盖，随机测试通常用于发现结构化测试可能忽略的边缘案例或异常缺陷。它通常在时间有限时使用，并作为其他测试策略的补充，而不是作为一种独立的方法。\n随机测试 的灵活性使测试人员能够在无需更新正式测试文档的情况下快速适应应用程序的更改。然而，由于其非结构化的性质，跟踪和衡量其有效性可能会具有挑战性。\n随机测试有哪些优缺点？ 随机测试的优势：\n灵活性：允许测试人员在没有预定义案例的情况下探索应用程序，鼓励创造性的测试场景。 经济高效：无需进行广泛的准备或文档编制，降低了初期成本。 快速反馈：提供对应用程序功能和潜在问题的即时见解。 发现意外的缺陷：由于其不可预测的性质，可以揭示结构化测试可能忽略的缺陷。 随机测试的劣势：\n不可重复：如果步骤未经记录，找到一个错误可能是一次性事件，使得跟踪和修复变得困难。 测试范围不足：没有结构化的方法，应用程序的某些部分可能保持未经测试状态。 主观结果：严重依赖于测试人员的专业知识和直觉，可能导致不一致的结果。 不适用于所有阶段：在需要更多形式化验证的开发后期阶段可能效果不佳。 请记住，随机测试是其他测试方法的一种补充，而不是独立的解决方案。它在由经验丰富的测试人员使用时效果最好，这些测试人员能够快速识别和探索复杂的应用程序区域。\n实施和技术 如何执行随机测试？ 随机测试是在没有任何正式的测试计划或文档的情况下执行的。测试人员凭借他们的理解力和探索软件来发现缺陷。这种方法在很大程度上依赖于测试人员的直觉、经验和创造力。\n以下是执行随机测试的一般过程：\n了解应用程序：对软件的功能和目的有一个基本的了解。 定义范围：尽管是非正式的，但决定要关注的应用程序区域。 执行测试：以各种方式与软件进行交互，以发现问题，包括： 尝试不同的输入 以意想不到的方式浏览应用程序 尝试用不寻常的行为破坏应用程序 记录观察：跟踪测试过程中观察到的任何缺陷或奇怪的行为。 报告缺陷：将发现的问题通报给开发团队以供解决。 在随机测试期间，测试人员可能会采用**错误猜测或探索性测试等技术来指导他们的方法。该过程本质上是灵活和非结构化**的，使测试人员能够快速识别结构化测试可能忽略的问题。\n值得注意的是，尽管随机测试可能是自发的，但对系统的广泛了解及其潜在弱点可以导致更有效的测试会话。\n有哪些常用的随机测试技术？ 在随机测试中常见的技术包括：\n探索性测试：测试人员在没有预定义测试用例的情况下探索软件，使用他们的理解和直觉来引导他们的操作。 错误猜测：测试人员依赖经验猜测软件中可能发生缺陷的最有可能的区域。 猴子测试：向系统提供随机输入，观察其行为，通常自动化生成大量随机数据。 对测：两名测试人员在一台键盘上共同工作；一人操作测试，另一人提供指导并记录发现。 基于会话的测试：测试被结构化成专注于特定区域的不间断会话，测试人员记录他们的发现和思考过程。 这些技术通常以一种互补的方式使用，取决于测试会话的背景和目标。它们充分利用测试人员的创造力、经验和直觉，以发现结构化测试可能忽略的问题。\n有效执行随机测试需要哪些技能？ 要有效执行随机测试，个体需要一系列技能，使他们能够在没有预定义的 测试计划 的情况下探索软件。这些技能包括：\n探索技能：有创造性地探索和导航软件，以发现结构化测试可能忽略的问题的能力。 分析技能：强大的分析思维，能够假设缺陷可能存在的位置并理解软件的行为。 注重细节：敏锐的观察力，注意到可能导致更大问题的细微差异和潜在问题。 技术知识：对软件的架构、特性和潜在弱点有扎实的了解。 经验：熟悉被测试系统和类似系统，以便利用过去的知识并识别模式。 直觉：对缺陷可能发生的位置有直观的感觉，通常是从经验中发展而来。 沟通技能：能够清晰地记录和传达发现，向开发团队和其他利益相关者沟通。 适应能力：灵活切换焦点，并根据测试过程中出现的新信息或关注的领域进行调整的能力。 时间管理：有效管理时间的技能，因为即兴测试通常是有时间限制的或在有限的时间内进行的。 这些技能帮助测试人员以既高效又有效的方式执行随机测试，为软件的质量和可靠性提供有价值的见解。\n随机测试可以自动化还是只能严格手动测试？ 由于其本质是一种非正式和无结构的测试方法，测试人员在随机测试中积极地在没有预定义的 测试用例 或计划的情况下探索软件。另一方面，自动化依赖于预先脚本化的测试，可以自动运行。因此，随机测试主要是一个手动过程。\n然而，随机测试的某些方面可以通过自动化工具支持。例如，自动化脚本可以用于设置应用程序内的复杂环境或状态，然后测试人员可以手动探索。这种混合方法使测试人员能够专注于随机测试的探索方面，而无需进行重复的 设置 任务。\n此外，虽然随机测试的探索部分是手动的，自动化可以帮助记录和捕获发现问题时系统的状态。工具可以自动记录采取的步骤、系统状态和其他相关数据，有助于缺陷的再现和报告。\n总体而言，虽然随机测试的核心活动是手动的，但自动化可以在增强测试过程的效率和效果方面发挥支持性作用。\n场景和用例 有哪些实际场景的示例来介绍如何使用随机测试？ 随机测试通常在存在有限结构或文档，并且需要对软件行为进行快速、直观评估的情况下使用。以下是一些实际场景的例子：\n探索性测试：在开发新功能时，测试人员可能会使用即兴方法在正式编写测试用例之前探索该功能的功能性。 发布后：在软件发布后，可以使用即兴测试快速检查实时环境，以确保没有引入重大问题。 缺陷 验证：一旦修复了缺陷，测试人员可能会围绕修复进行即兴测试，以确保问题得到解决，并且没有引入新问题。 高风险区域：在已知存在高风险组件的系统中，可以使用即兴测试快速评估这些区域的稳定性，特别是在进行更改后。 有限时间：当存在时间限制且无法完成正式测试时，即兴测试可以提供快速的合理性检查，以评估关键功能。 用户反馈：如果用户报告了意外行为，测试人员可能会使用即兴测试来复制问题并探索可能受到影响的相关功能。 技术更改：当底层技术或框架更新时，即兴测试可以帮助快速识别任何兼容性问题或回归。 在这些场景中，测试人员的经验、直觉和对系统的了解引导测试过程，通常导致发现结构化测试可能忽视的缺陷。\n你能提供一个随机测试发现关键缺陷的场景吗？ 情景：在一个开发的晚期阶段，一位测试工程师正在探索一个新实施的金融应用功能，该功能允许用户在账户之间进行资金转账。正式的 测试用例 已经执行过，未发现重大问题。然而，工程师决定进行一些随机测试，模拟可能做出不合理和非传统选择的用户。\n在随机导航应用程序的过程中，工程师试图从资金不足的账户发起转账，期望看到标准错误消息。然而，应用程序崩溃了，重新启动后，账户余额损坏，显示不正确的数字。\n这个关键的 缺陷在结构化测试中被忽略了，因为 测试用例 假设用户行为是理性的，并且没有考虑到工程师在即兴会话期间采取的特定操作序列。这个 缺陷 是在处理具有特定时间和数据条件的交易时发生未处理异常的结果，而这些条件在 测试脚本 中没有涵盖。\n发现这个 缺陷 是重要的，因为它可能导致在生产环境中出现严重的财务差异。随机测试 方法使工程师能够发现结构化测试忽视的关键问题，展示了这种测试方法在发现不可预测的现实问题方面的价值。\n随机测试如何融入端到端（e2e）测试方案？ 随机测试，虽然主要是手动和探索性的，通过发现结构化测试可能忽略的问题，为端到端（E2E）测试提供了补充。在 E2E 场景中，随机测试可以被战略性地使用，在正式执行 测试用例 之后，模拟真实的使用情况。这是一种在没有预定义脚本的情况下验证整个系统行为和用户体验的方式。\n想象一下一个覆盖应用程序中典型用户流程的 E2E 测试。一旦自动化确认流程按预期工作，随机测试介入探索用例的边缘。测试人员可能尝试意外的输入组合，以非线性方式导航，或超出典型使用模式的系统压力测试。这可以揭示诸如内存泄漏、处理边缘情况或在不同设备上的 UI 不一致性等漏洞。\n虽然随机测试不是 E2E 场景的主要焦点，但它是一种全面评估的有价值工具。这就是像一个不受测试脚本限制的最终用户思考的方式。自动化工程师可以通过使用随机测试会话的见解，以更强大的测试用例增强自动化套件的方法受益。\n将即兴测试的发现纳入自动化的 E2E 测试中，确保自动化保持相关并适应现实世界的复杂性。这是一个持续改进的循环，随机测试为自动化提供信息，而自动化则为更多探索性测试释放时间。\n最佳实践 随机测试有哪些最佳实践？ 进行随机测试的最佳实践包括：\n优先考虑高风险或变更的区域：专注于应用程序中最近修改或已知容易出错的部分。 利用领域知识：利用您对业务和用户行为的理解，探索对最终用户至关重要的功能。 记录发现：虽然随机测试是非脚本化的，但重要的是记录测试内容和发现的任何问题，以供将来参考和跟踪缺陷。 使用多样化的测试技术：结合不同的方法，如探索性测试、错误猜测和结对测试，以发现各种问题。 限时会话：为随机测试设定特定的持续时间，以保持专注和高效率。 与他人合作：与团队中的不同成员合作，以获得新的视角并发现更多的缺陷。 重复测试：在开发的不同阶段进行随机测试，以捕捉在代码更改后可能出现的新问题。 与正式测试集成：利用随机测试的见解来增强您的正式测试用例和自动化脚本。 请记住，虽然随机测试是非正式的，但它仍应具有战略性和针对性，以最大化其在发现潜在缺陷方面的有效性。\n如何衡量随机测试的效果？ 衡量随机测试的效果可能会有挑战，因为它的非结构化性质。然而，可以使用一些指标来评估其影响：\n发现的缺陷数量：跟踪通过即兴测试特别发现的缺陷，尤其是其他测试方法未能发现的缺陷。 缺陷的严重程度：评估所发现缺陷的严重程度。高严重程度的缺陷可以表明即兴测试在发现关键问题方面的效果。 测试覆盖率：尽管在即兴测试中很难量化，但可以在测试后使用代码覆盖工具评估意外测试的应用程序哪些区域。 发现缺陷的时间：测量发现缺陷所需的时间。即兴测试可能比结构化测试更快地发现某些缺陷。 缺陷的成本：分析通过早期发现和修复缺陷带来的成本节省，这可以归因于即兴测试的非正式和快速性质。 测试人员的反馈：收集测试人员对于发现缺陷的难易程度以及他们对于即兴测试的全面性的看法的定性反馈。 将这些指标与您测试环境的背景结合使用，以确定随机测试的效果。请记住，虽然这些指标\n可以提供见解，但即兴测试的非脚本化性质意味着其真正的价值通常在于测试人员的专业知识和直觉，这可能更难以量化。\n如何将随机测试集成到持续集成/持续部署流水线？ 将随机测试集成到 CI/CD 流水线中需要有策略性但非正式的测试工作，以补充自动化和结构化测试。由于即兴测试是探索性的且通常是手动的，因此不能直接适用于自动化流水线。然而，可以通过以下方式进行集成：\n部署后的合理性检查：在自动化部署后，工程师可以在实际系统上进行即兴测试，以快速验证功能和特定于环境的问题。\n定期手动测试会话：在 CI/CD 流程中预留时间段，供测试人员对最新构建执行随机测试，确保对最新更改进行即时反馈。\n反馈集成：使用反馈机制将随机测试的发现结果报告回 CI/CD 流水线。这可能涉及创建自动化工单或更新测试用例。\n基于风险的测试触发器：实施一个系统，在代码更改或高风险区域的基础上，通知测试人员执行有针对性的随机测试。\n探索性测试工具：利用在 CI/CD 上下文中支持探索性测试的工具，允许基于会话的测试管理和报告。\n文档和追踪：确保即兴测试的发现结果像其他测试用例一样进行文档化和追踪，以指导未来的自动化测试并改进回归套件。\n请记住，虽然随机测试不能自动化，但其结果可以为自动化测试套件提供信息并加以增强，使其成为持续交付生态系统中的有价值的资产。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-ad-hoc-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，聚焦于 Ad Hoc Testing（随机测试）。文章详细介绍了随机测试的基础概念和重要性，阐述了在测试实践中实施和应用随机测试的技术。读者将了解随机测试的场景和用例，以及如何在项目中有效地运用这一测试方法。博文还提供了随机测试的最佳实践，帮助测试人员更好地利用这一方法发现潜在问题。通过这个系列分享，读者将更全面地了解 Ad Hoc Testing 的价值，并在测试策略中灵活地运用这一方法。","title":"软件测试术语分享:Ad Hoc Testing 随机测试"},{"content":"Actual Result 实际结果 实际结果（又称为测试结果）\n实际结果是在进行测试后获得的结果。在测试阶段，实际结果会与测试用例一起记录。在所有测试结束后，它将与预期结果进行比较，注意任何差异。\n关于实际结果的问题 基础知识和重要性 在软件测试中“实际结果”的定义是什么？ 在软件测试中，实际结果指的是执行测试时观察到的系统行为。它是测试步骤执行后应用程序的输出、响应或状态。然后，将这个结果与**预期结果**进行比较，以确定测试是通过还是失败。实际结果对于发现可能存在缺陷或需要改进的地方至关重要。\n实际结果通常记录在测试管理工具中或直接在自动化测试代码中。它们作为测试执行的证据，对于测试过程中的可追溯性和责任制非常重要。当实际结果与预期结果不一致时，会引发调查，可能导致缺陷修复和功能增强，以确保软件符合其要求并能够按照预期运行。\n为什么在 e2e 测试中确定 \u0026ldquo;实际结果 \u0026ldquo;很重要？ 在端对端（e2e）测试中，确定实际结果对于验证整个应用程序流程的完整性至关重要。这确保了每个集成组件在按顺序操作时（从开始到结束）都能按预期运行。通过将实际结果与预期结果进行比较，测试人员可以确认系统在各种条件下，包括用户交互、数据处理和连接性时是否按照设计行为。\n在 e2e 测试中，实际结果是测试执行的结果。它为评估系统是否符合业务需求和用户需求提供了具体的依据。当存在不一致时，它们突显了可能影响用户体验或系统可靠性的潜在问题，促使进一步的调查和改进。\n此外，实际结果在保持测试可信度方面起着重要作用。它为利益相关方提供了关于系统当前状态和测试策略有效性的有形证据。这种透明性对于建立对软件质量的信心以及对发布和部署做出明智决策至关重要。\n在自动化测试中，捕获实际结果通常由自动化框架处理，该框架记录结果以供后续分析。这种自动化捕获不仅简化了测试过程，还减少了人为错误，确保结果能够一致和准确地报告。\n通过专注于实际结果，测试自动化工程师可以直接影响软件的开发周期，确保每个发布都符合成功产品所需的质量标准。\n“实际结果”对整个测试过程有何贡献？ 在测试过程中，实际结果是至关重要的，因为它直接反映了系统在测试条件下的当前行为。通过将实际结果与预期结果进行比较，测试人员可以立即判断测试用例是否通过或失败。这种比较对于验证软件的功能并确保其满足指定要求至关重要。\n在自动化测试中，实际结果通常由测试脚本捕获和记录，然后自动将其与预期结果进行比较。这有助于形成快速的反馈循环，快速识别失败，并根据测试结果决定是否继续或中止持续集成和交付流程。\n当出现差异时，实际结果是调试的起点。它有助于准确定位缺陷的确切性质，引导开发人员找到根本原因。此外，分析跨多次测试运行的实际结果中的模式可以揭示出诸如性能下降或应用程序特定区域的不稳定性等更大问题。\n总之，实际结果对于：\n验证软件行为是否符合期望。 在测试脚本中进行自动化通过/失败决策。 通过提供系统行为的具体证据进行调试。 分析趋势和模式以指导未来的开发和测试工作。 通过有效利用实际结果，团队可以保持较高的软件质量并加速开发生命周期。\n比较与对比 “预期结果”和“实际结果”有什么区别？ 在软件测试自动化中，**预期结果**是基于需求或设计规范的测试用例的预定义结果。它代表了系统在特定条件下应该表现出的行为。\n另一方面，实际结果是系统在执行测试用例时实际表现出的行为。它是从被测试系统中获得的实时结果。\n预期结果和实际结果之间的比较对于确定测试用例的成功或失败至关重要。匹配表示系统表现如预期，而不匹配可能揭示缺陷或与预期行为的偏差。这种比较通常在测试脚本中自动化进行，其中使用断言或检查点来验证实际结果是否与预期结果一致。\n这些结果之间的差异会触发进一步的调查，以了解根本原因并纠正任何问题，确保软件符合其质量标准。\n“实际结果”与“测试用例”有何关系？ 在**测试用例的情境下，实际结果是测试执行时所观察到的结果。它直接与预期结果**进行比较，以确定测试是否通过或失败。这种比较对于验证被测试软件的行为至关重要。\n对于自动化测试，实际结果通常由测试脚本本身捕获。例如，在基于Selenium的测试中，脚本可能包含如下断言：\nassert.equal(element.getText(), \u0026#34;Expected Text\u0026#34;); 这里，element.getText()是与预期文本进行比较的实际结果。如果它们匹配，测试通过；否则，测试失败。\n实际结果对于准确定位**测试用例**中故障发生的确切步骤至关重要。在复杂的场景中，它有助于将缺陷隔离到特定的模块或功能。此外，当测试失败时，实际结果可以深入了解缺陷的性质，有助于调试和解决问题。\n在持续集成环境中，实际结果通常被记录并作为测试报告的一部分。这对于利益相关者了解软件的当前状态以及开发人员在发布软件之前解决任何问题非常有价值。\n在什么情况下“实际结果”可能与“预期结果”不同？ 实际结果与**预期结果**之间可能存在差异的原因有很多：\n代码缺陷：应用代码中的错误可能导致意外行为。 环境问题：测试环境的差异，如配置、数据库或网络条件的不同。 测试数据的变化性：不一致或不正确的测试数据可能导致不同的结果。 不稳定的测试：表现出非确定性行为的测试通常会间歇性地失败。 错误的期望：预期结果可能基于过时或被误解的需求。 并发问题：仅在多个进程或用户同时与系统交互时才显现的问题。 集成依赖：应用程序依赖的外部服务或组件的故障。 时间问题：影响应用程序行为的竞态条件或超时。 平台特定行为：不同操作系统、浏览器或设备处理某些操作的方式的差异。 测试脚本错误：自动化脚本本身中的错误，如不正确的断言或同步问题。 识别差异的原因对于解决问题和提高软件质量至关重要。\n实际应用 测试过程中如何记录“实际结果”？ 在测试过程中记录实际结果通常包括对测试执行后系统行为的清晰而简明的描述。它记录在测试管理工具或测试用例文档中，通常与相应的**测试用例和预期结果**一起，以便进行轻松比较。\n以下是一般的方法：\n执行测试用例：按照规定的步骤运行测试。 观察：仔细观察系统的行为或输出。 记录：立即记录观察到的行为。使用清晰的语言描述发生了什么，包括任何错误消息、系统响应或结果。 截图/日志：如果截图、日志文件或视频能够清晰地说明问题，特别是对于界面问题或复杂错误，请附加它们。 时间戳：记录测试的时间和日期，因为这对于调试可能是至关重要的。 环境详细信息：包括有关测试环境的详细信息，如浏览器版本、设备或系统配置。 可重现性：指示结果在重新测试时是否一致。 链接缺陷：如果结果表示存在缺陷，请创建缺陷报告并将其链接到测试用例，以实现可追溯性。 确保实际结果足够详细，以使开发人员能够清楚地理解问题，避免歧义，促进更快的解决和重新测试。\n有哪些常用工具或方法可用于获取 \u0026ldquo;实际结果\u0026rdquo;？ 在测试自动化中捕获实际结果通常涉及多种工具和方法：\n自动化测试脚本：在诸如**Selenium、Cypress或Appium**等框架中编写的脚本在测试执行期间自动捕获输出。例如： // 示例：使用 Selenium 进行文本验证 String actualText = driver.findElement(By.id(\u0026#34;elementId\u0026#34;)).getText(); 日志记录：通常，自动化测试被设计为记录结果和错误。诸如 Java 的Log4j或Node.js的Winston之类的工具可用于记录实际结果。\n截图：诸如**Selenium**之类的工具可以在执行测试步骤时捕获应用程序状态的截图，这对于 UI 测试很有用。\n视频录制：一些测试框架，如TestCafe或云服务如Sauce Labs，提供视频录制功能以捕获测试执行。\nAPI响应：对于API 测试，诸如**Postman或RestAssured**之类的工具捕获 HTTP 响应数据，这代表了实际结果。\n性能数据：诸如**JMeter或Gatling**之类的工具捕获时间和吞吐量数据作为实际结果进行性能测试。\n测试报告：诸如JUnit、TestNG或Mocha之类的框架生成包含实际结果的报告。这些报告可以进一步与Jenkins或GitLab CI等 CI/CD 工具集成，以进行全面的报告。\n自定义处理程序：在测试代码中实现自定义事件处理程序或回调，以捕获特定的数据点或应用程序状态。\n数据库验证：使用SQL或 NoSQL 命令直接查询数据库以捕获数据更改。\n文件输出：将结果写入文件，如 CSV 或 JSON\n，以便以后解析和分析。\n每种方法的选择基于需要捕获的内容的上下文和正在执行的测试的类型。\n如何使用 \u0026ldquo;实际结果 \u0026ldquo;来识别和诊断软件缺陷或问题？ 实际结果在识别和排除软件缺陷方面充当着至关重要的诊断工具。当测试用例执行产生一个与期望结果不符的实际结果时，这种差异标志着软件中可能存在缺陷。\n为了诊断问题，工程师会在测试环境和输入数据的背景下分析实际结果。他们可能会查找在不同测试用例或条件下结果的模式或不一致性。例如，如果某个功能在一个输入集下按预期工作，而在另一个输入集下却没有，这可能表明存在边界情况问题或数据处理缺陷。\n工程师还使用实际结果来准确定位故障发生的确切步骤。通过检查应用程序在此时的状态，包括日志、堆栈跟踪或数据库状态，他们可以确定故障的根本原因。\n在实际结果表明存在性能问题（例如响应时间较慢或资源瓶颈）的情况下，工程师可以使用性能分析工具深入挖掘系统在测试时的行为。\n自动化测试框架通常提供捕获和报告详细实际结果的功能，包括测试执行的截图或视频录制，这对于诊断 UI 问题非常有价值。\n通过系统地分析实际结果，工程师可以提出关于缺陷来源的假设，然后进行\n测试和验证，从而实现更高效的缺陷修复流程。\n深层理解 “实际结果”如何影响回归测试？ 在回归测试中，实际结果对于验证最近的代码更改是否对现有功能产生不良影响至关重要。它是在软件被修改后测试用例的结果。通过将实际结果与**期望结果**进行比较，测试人员可以确定是否发生了回归错误。\n对于自动化回归测试，实际结果通常由测试脚本捕获，并与**期望结果**进行程序化比较。差异会触发测试失败，提醒工程师可能存在回归。这种比较通常通过测试代码中的断言完成。\nassert.equal(actualResult, expectedResult, \u0026#39;The actual result does not match the expected result.\u0026#39;); 当实际结果与**期望结果**匹配时，表明应用程序的行为与其先前状态保持一致。相反，不匹配可能表示最近的更改引入了一个缺陷，需要进一步调查和潜在的代码修复。\n在持续集成环境中，实际结果是反馈循环的一部分，通知开发团队关于每次代码提交后其应用程序稳定性的情况。这种即时反馈对于保持软件质量和加速开发周期至关重要。\n具有清晰实际结果的自动化回归测试可以快速确定已经发生回归的具体功能，简化调试过程，并确保软件发布符合质量标准。\n“实际结果”在自动化测试中扮演什么角色？ 在自动化测试中，实际结果作为验证软件行为是否符合预期结果的关键数据点起着重要作用。这是由测试脚本执行时产生的输出。然后，此结果会自动与**期望结果**进行比较，以确定测试是否通过或失败。\n// 捕获自动化测试中的实际结果的示例 const actualResult = performAction(); assert.equal(actualResult, expectedResult, \u0026#39;测试失败：实际结果与期望结果不匹配。\u0026#39;); 在自动化测试场景尤其是复杂场景中，实际结果对于确定差异发生的确切步骤至关重要。当测试失败时，实际结果立即提供有关失败性质的反馈，使工程师能够在无需手动干预的情况下启动调试和根本原因分析。\n自动化测试通常将实际结果记录到报告或仪表板中，提供测试执行的历史记录。这有助于趋势分析，并有助于了解软件随时间的稳定性。\n在持续集成和部署（CI/CD）管道中，实际结果可以触发工作流，如通知、回滚或根据测试用例的成功或失败而执行其他测试套件。\n总体而言，实际结果是自动化测试的基石，以系统化和可扩展的方式推动质量保证流程，从而高效而准确地验证软件功能。\n“实际结果”差异如何有助于软件优化和改进？ 实际结果与**期望结果**之间的差异对于软件的优化和改进至关重要。当测试用例的实际结果偏离预期时，这表明存在潜在的缺陷或需要改进的领域。这些差异可能导致：\n需求的完善：不一致性可能揭示需求理解不足或存在漏洞，促使更清晰和精确的规范。 代码优化：在测试中暴露的性能问题或意外行为可以引导开发人员优化算法和重构代码。 增强用户体验：在用户界面或工作流中出现差异的实际结果可能突显出可用性问题，从而引导改进，使软件更直观和用户友好。 更好的错误处理：遇到未在期望结果中考虑的错误或异常可以通过改进错误处理和消息传递来提高软件的健壮性。 增加测试覆盖率：差异通常揭示了未经测试的路径或边缘情况，扩展了测试套件，实现更全面的覆盖。 通过分析这些差异，团队可以迭代地完善他们的软件，从而打造更可靠、高性能和用户中心的产品。记录和跟踪这些发现是确保它们在未来的开发周期中得到解决的关键。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-actual-result/","summary":"这篇博文是软件测试术语分享系列的一部分，聚焦于 Actual Result（实际结果）。文章深入探讨了实际结果在软件测试中的基础概念和重要性，阐述了在测试流程中记录和分析实际结果的技巧。同时，文章介绍了相关工具和技术，帮助测试人员更有效地管理和报告测试结果。此外，博文还涉及了实际结果测试中可能面临的挑战，提供了解决方案以确保测试的准确性和可靠性。通过这个系列分享，读者将更深入地理解 Actual Result 在测试中的关键作用，提高测试流程的质量。","title":"软件测试术语分享:Actual Result 实际结果"},{"content":"Accessibility Testing 无障碍测试 无障碍测试旨在确保移动和 Web 应用对每个人都是可用的，包括那些具有视觉或听觉障碍，以及其他身体或认知挑战的个体\n相关术语： Usability Testing 易用性测试\n关于无障碍测试的问题 基础知识和重要性 什么是无障碍测试？ 无障碍测试是一种确保软件和 Web 应用能够被广泛残障人群使用的过程，包括视觉、听觉、身体、语音、认知、语言、学习和神经方面的障碍。这种测试方式旨在验证应用是否能够被使用辅助技术，如屏幕阅读器、盲文终端和替代输入设备的个体有效操作和理解。\n无障碍测试 的关键方面包括：\n导航性：用户是否可以使用键盘或辅助设备浏览应用？ 可读性：内容是否对视觉障碍用户可读且易理解？ 兼容性：应用是否与各种辅助技术协同工作？ 语义化 HTML：HTML 元素是否用于传达含义和结构？ 动态内容：动态内容是否可通过屏幕阅读器访问？ 视觉设计：文本和背景之间是否有足够的对比度，以满足视力较差用户的需求？ 多媒体：视频和音频内容是否提供字幕和文本稿？ 测试技巧 既包括自动化，也包括手工测试方法。自动化工具可扫描特定类型的问题，如缺失的 alt 文本或错误的 ARIA 角色，而手工测试可能涉及使用屏幕阅读器或仅通过键盘浏览应用。\n代码示例 用于使用自动化工具检查图像 alt 文本：\nit(\u0026#39;应对所有图像提供 alt 文本\u0026#39;, () =\u0026gt; { cy.get(\u0026#39;img\u0026#39;).each(($img) =\u0026gt; { expect($img.attr(\u0026#39;alt\u0026#39;)).to.be.a(\u0026#39;string\u0026#39;).and.not.be.empty; }); }); 总体而言，无障碍测试是软件质量保证的关键组成部分，确保包容性和法律合规性。\n为什么无障碍测试很重要？ 无障碍测试的重要性在于确保所有用户，包括残障人士，都能有效地访问和使用软件产品。通过识别和解决无障碍障碍，它推动了包容性设计，提升了各种用户的用户体验。这种测试不仅涉及到道德责任和用户倡导，还在许多地区是法律要求，帮助组织遵守法规，避免潜在的法律风险。\n此外，无障碍测试还可能带来SEO 改善，因为搜索引擎更青睐无障碍网站，可能提高网站的可见性和覆盖范围。它还鼓励采用最佳编码实践，产生更干净、更易维护的代码。通过在开发过程的早期融入无障碍考虑，公司可以降低在后期追加无障碍功能所需的成本和工作量。\n简而言之，无障碍测试之所以重要，原因如下：\n促进包容性，确保软件能够被各种能力的人使用。 履行法律义务，帮助组织遵守无障碍标准，避免法律问题。 提升 SEO，可能增加软件的可见性和覆盖范围。 鼓励更好的编码实践，产生更易维护、更健壮的软件。 忽视无障碍测试可能导致较小的用户群、潜在的法律挑战，以及产品改进的遗憾机会。\n无障碍测试的目标是什么？ 无障碍测试的目标在于确保软件产品对具有各种能力和障碍的人都是可用的。这包括验证产品是否符合无障碍标准和指南，如 Web 内容无障碍指南（WCAG）和第 508 条。通过这一过程，旨在提供一种包容性用户体验，使具有视觉、听觉、身体、语音、认知、语言、学习和神经障碍等障碍的个体能够有效地导航、与之交互和访问内容。\n无障碍测试还寻求识别和消除可能阻碍残障人士使用产品的障碍，确保所有用户对信息和功能都有平等的访问权。为此，它采用了自动化工具和手动技术的组合，以涵盖自动化本身可能无法捕捉的各个方面。\n最终目标是维护法律和伦理标准，避免歧视，通过使产品面向更广泛的受众，拓展市场覆盖范围。这不仅仅是合规性问题；更关涉到接纳多样性和提高用户满意度。\n无障碍测试如何让用户受益？ 无障碍测试通过确保软件产品可供具有各种能力和残疾的人使用，使更广泛的用户能够有效地与应用程序、网站或工具进行互动，而不受身体或认知挑战的影响。通过适应屏幕阅读器、盲文终端和语音识别软件等辅助技术，无障碍测试有助于打造更加公正的用户体验。\n对于残障用户，无障碍测试可能意味着能否在网上执行基本任务与面临重大障碍之间的区别。它实现了独立导航和交互，这对于个人的自主权和尊严至关重要。此外，对于用户来说，它可以减少挫折感，提高效率，因为他们可以在不受不必要阻碍的情况下访问和使用功能和信息。\n除了直接惠及用户外，无障碍测试还可能导致对所有用户的可用性的提升。许多无障碍功能，如清晰的导航和易读的字体，都会提升整体用户体验。通过专注于无障碍性，开发人员可能会无意中改善更广泛用户群体的设计和功能，从而实现更直观和用户友好的产品。\n最后，无障碍测试还可以帮助避免由于不遵守无障碍法律法规而可能产生的法律后果，确保软件不仅具有包容性，而且在法律上合规。\n不进行无障碍测试会有什么影响？ 不进行无障碍测试可能带来严重的影响：\n排斥用户：没有进行无障碍测试，可能导致残障人士无法使用软件，从而有效地将他们排除在访问产品或服务的范围之外。 法律责任：未遵守《美国残疾人法案》（ADA）或第 508 条等法律标准可能引发诉讼和财务处罚。 品牌受损：不可访问性可能损害公司的声誉，表明公司对所有用户的考虑不足。 市场覆盖减少：忽视无障碍测试限制了潜在用户群，因为残障人士代表了一个重要的市场部分。 用户体验差：无障碍问题可能导致用户体验令人沮丧，不仅对残障用户如此，对于那些暂时或特定限制的用户也是如此。 成本增加：在开发后期或发布后识别和修复无障碍问题通常比在常规测试周期内解决它们更为昂贵。 总之，忽视无障碍测试可能会在道德、法律、财务和声誉方面产生后果，同时也损害软件的整体质量和可用性。\n标准和指引 无障碍测试的关键标准和指南是什么？ 无障碍测试的关键标准和指南包括：\nWeb Content Accessibility Guidelines (WCAG)：这是网络无障碍的主要国际标准，详细说明了如何使网络内容对残障人士更加无障碍。请遵循最新版本，目前是 WCAG 2.1，并力争至少达到 AA 级的合规标准。 Accessible Rich Internet Applications (ARIA)：ARIA 定义了一种使网络内容和网络应用对残障人士更加无障碍的方式。使用 ARIA 角色和属性来增强动态内容和复杂用户界面组件的可访问性。 Section 508：这是美国的联邦法律，要求联邦政府开发、采购、维护或使用的所有电子和信息技术都应对残障人士具备可访问性。如果软件将被联邦机构或承包商使用，请确保符合这些标准。 EN 301 549：这是欧洲数字可访问性的标准，规定了信息通信技术产品和服务的要求，以确保它们对残障人士更加可访问。 ISO/IEC 40500：这是与 WCAG 2.0 相同的国际标准，提供一个稳定的、可引用的技术标准。 在进行无障碍测试时，请遵循以下准则：\n尽量自动化：使用自动化工具来捕捉易于检测的问题，但请记住它们无法捕捉所有问题。 手工测试：结合自动化测试进行手动检查，特别是对于主观标准，如导航和理解的便利性。 用户测试：让真实的残障用户参与测试，以获取有关可访问性的真实反馈。 持续合规性：将无障碍测试整合到您的持续集成/持续部署（CI/CD）管道中，以确保持续合规。 保持更新：随时关注无障碍标准和指南的更新，因为它们会随时间而演变。 什么是 WCAG？为什么它很重要？ WCAG，或Web Content Accessibility Guidelines（网络内容可访问性指南），是一系列旨在使网络内容对残障人士更加无障碍的建议。这一标准是通过与世界各地的个人和组织合作，在 W3C 的流程中制定的，其目标是提供一个全球共享的网络内容可访问性标准，以满足全球个人、组织和政府的需求。\nWCAG 的重要性在于它作为全球可访问性的基准，确保网站、应用程序和数字工具对所有人都可用，包括那些具有听觉、认知、神经、肢体、言语和视觉障碍的人。遵循 WCAG 有助于消除阻碍残障人士与网站进行交互或访问的障碍。当网站经过正确的设计、开发和编辑时，所有用户都能平等地访问信息和功能。\n遵循 WCAG 的指南不仅是一种道德责任和包容性，在许多司法辖区中也是法律要求。不遵守可能导致法律后果，并损害组织的声誉。此外，遵守 WCAG 可以改善整体用户体验，潜在地扩大受众范围，因为无障碍站点往往更符合 SEO 标准，并对所有用户，而不仅仅是残障用户，具有更好的可用性。\nWCAG 合规性有哪些不同级别？ WCAG 合规性被划分为三个符合级别：\nA 级：最基本的网络可访问性功能。为了不排除残障人士群体，网站必须满足此级别。这包括提供非文本内容的文本替代以及确保可以使用键盘进行导航等功能。 AA 级：解决残障用户面临的最大和最常见的障碍。此级别引入了一些标准，例如为音频内容提供字幕，并确保文本可读且可理解。在许多组织和政府中，满足此级别通常是法律要求。 AAA 级：WCAG 合规性的最高和最严格级别。此级别包括更广泛的标准，以提高不同类型残障人士的可访问性。它涵盖了所有 A 级和 AA 级的要求，并增加了更多内容，例如为音频内容提供手语翻译，确保实时音频内容的背景噪音水平较低。然而，并非总是可能满足所有 AAA 级成功标准，因此这不是完全合规的严格要求。 每个级别都是在前一个级别的基础上构建的，AAA 级包含 AA 和 A 的所有标准。在追求合规性时，重要的是要注意，AA 级通常是大多数网站的目标标准，因为它在提高可访问性和实际可实现性之间取得了平衡。\n什么是第 508 条以及它与无障碍性测试有何关系？ Section 508 是 1973 年康复法案的一部分，要求联邦机构使其电子和信息技术（EIT）对残障人士可访问。在软件测试自动化的情境中，Section 508 合规性意味着确保应用程序和网站可供具有各种残障的个体使用，包括视觉、听觉、身体、言语、认知、语言、学习和神经系统残障。\n为了遵守 Section 508，自动化测试应包括以下检查：\n键盘导航性：确保所有功能都可以通过键盘命令操作，而无需鼠标。 屏幕阅读器兼容性：验证内容是否以屏幕阅读器能够正确解释和朗读的方式结构化。 颜色对比度：测试文本与背景之间是否有足够的对比，以帮助视觉障碍用户。 图像的替代文本：检查所有图像是否为不能看到它们的用户提供了描述性的替代文本。 字幕和音频描述：确保多媒体内容对于听力或视觉障碍的用户具有字幕和描述。 自动化工具可以帮助识别一些 Section 508 合规性问题，但手工测试也是必要的，以确保完全的可访问性。测试自动化工程师应将自动和手动的可访问性检查集成到其测试策略中，以涵盖 Section 508 中概述的广泛要求。这种集成有助于创建一个包容性的用户体验，并减轻与不合规相关的法律和声誉风险。\nARIA 角色是什么以及它们如何在无障碍性测试中使用？ ARIA 角色是可访问丰富互联网应用规范的一部分，该规范旨在定义使网络内容和网络应用对残障人士更具可访问性的方法。ARIA 角色提供了关于功能、结构和行为的语义信息，使辅助技术能够向用户传达适当的信息。\n在无障碍测试中，ARIA 角色用于：\n通过定义button、dialog、menu和progressbar等角色，向辅助技术（如屏幕阅读器）识别 UI 元素。 通过使用aria-expanded（用于可折叠内容）或aria-checked（用于复选框）等角色，传达 UI 元素的状态。 利用navigation、main、complementary和contentinfo等角色，定义 Web 内容的结构。 为测试 ARIA 角色：\n使用自动化工具或手动检查，验证角色和属性的正确实现。 确保角色与元素的功能匹配（例如，对于可点击元素，使用role=\u0026quot;button\u0026quot;）。 随用户交互检查 ARIA 状态和属性的动态变化。 使用屏幕阅读器确认角色和状态是否被正确宣读。 ARIA 角色示例：\n\u0026lt;button role=\u0026#34;button\u0026#34; aria-pressed=\u0026#34;false\u0026#34;\u0026gt;Toggle\u0026lt;/button\u0026gt; 在此示例中，role=\u0026quot;button\u0026quot;传达了元素的功能，而aria-pressed指示了切换状态。\n测试自动化工程师应将 ARIA 角色验证整合到其测试套件中，以确保 Web 应用具有可访问性并为辅助技术提供必要的上下文。\n工具和技术 无障碍性测试常用哪些工具？ 常用的无障碍测试工具有：\nAxe：这是一个开源库，可集成到测试框架中，可以作为浏览器扩展和 CLI 工具使用。 npm install axe-core --save-dev WAVE（Web Accessibility Evaluation Tool）：WAVE 是一套评估工具，帮助作者使他们的网络内容更具可访问性，包括浏览器扩展和在线服务。\nLighthouse：Lighthouse 是一个用于提高网页质量的开源自动化工具，它有性能、可访问性、渐进式 Web 应用等审核。\nlighthouse https://example.com --only-categories=accessibility JAWS（Job Access With Speech）：这是 Windows 上的一个屏幕阅读器，允许视力受损的用户通过文本转语音输出或使用盲文显示屏读取屏幕。\nNVDA（NonVisual Desktop Access）：这是 Windows 上的一个免费开源屏幕阅读器。\nVoiceOver：这是内置在 Apple Inc.的 macOS 和 iOS 操作系统中的屏幕阅读器。\n颜色对比分析工具：比如颜色对比分析仪（CCA），它可以帮助您确定文本的可读性以及视觉元素的对比度。\nTenon.io：这是一个以 API 为先的自动化无障碍测试工具，可以集成到开发流程中。\nPa11y：这是一个运行 HTML CodeSniffer 的命令行工具，用于编程化的无障碍报告。\npa11y http://example.com Accessibility Insights：这是一个提供无障碍测试指导和解决方案的工具，可以作为浏览器扩展和 Windows 应用程序使用。 这些工具有助于自动检测无障碍问题，从而可以解决确保软件产品对具有各种残障的人可用。\n有哪些无障碍测试的人工技术？ 人工进行无障碍测试的技术包括用户模拟、辅助技术使用和检查表的综合应用，以确保软件能够被具有不同残障的人使用。以下是一些手动技巧：\n键盘导航：使用键盘浏览应用程序，确保所有交互元素都可以在没有鼠标的情况下轻松访问和使用。 屏幕阅读器测试：使用屏幕阅读器如 NVDA 或 JAWS，模拟视觉受损用户的体验。检查元素的正确阅读、顺序和上下文的呈现。 颜色对比度分析：使用工具如颜色对比度分析器手动检查颜色组合，确保对于有色觉缺陷的用户有足够的对比度。 手动代码检查：审查 HTML/CSS 代码，检查语义结构、标题、标签和辅助技术所依赖的角色的正确使用。 缩放和放大：在不同的缩放和放大级别下测试应用程序，确保内容仍然可读且功能正常。 内容可读性：评估内容的可读性，确保语言清晰简单，符合认知障碍用户的需求。 焦点管理：确保焦点顺序合理可见，这对通过键盘或辅助技术导航的用户至关重要。 残障参与者的用户测试：让残障用户参与测试过程，直接获取应用程序可访问性的反馈。 这些手动技巧与自动化测试相辅相成，弥补了需要人类判断和视角的方面，这些方面通常被自动化工具所遗漏。\n如何在无障碍测试中使用自动化工具？ 自动化工具通过迅速扫描网页和应用程序，寻找常见的可访问性问题，从而简化了无障碍测试。它们可以集成到 CI/CD 流程中，以确保与可访问性标准的持续合规。像axe-core、WAVE或**Lighthouse**这样的工具提供了APIs和插件，可与测试框架（如Selenium、Jest或Cypress）集成。\n使用自动化工具可以：\n检测代码级问题：识别问题，如缺少 alt 文本、错误使用 ARIA 角色和颜色对比度不足。 运行回归测试：确保新代码不引入可访问性退化。 生成报告：为技术和非技术干系人创建详细报告。 优先处理修复：突出显示影响最大的关键问题。 集成无障碍测试工具与测试框架的示例：\nconst axe = require(\u0026#39;axe-core\u0026#39;); const { browser, by, element } = require(\u0026#39;protractor\u0026#39;); describe(\u0026#39;Accessibility checks\u0026#39;, () =\u0026gt; { it(\u0026#39;should analyze the page\u0026#39;, async () =\u0026gt; { await browser.get(\u0026#39;https://example.com\u0026#39;); const results = await axe.run(); expect(results.violations.length).toBe(0, \u0026#39;Accessibility violations found\u0026#39;); }); }); 自动化工具不能取代手工测试或与残障人士进行用户测试，但它们是识别和缓解可访问性障碍的有价值的第一步。它们有助于保持可访问性的基线水平，并减少需要手动审查的问题数量。\n自动无障碍测试工具有哪些局限性？ 自动化无障碍测试工具存在一些限制：\n误报或漏报：工具可能报告并非真正存在的问题（误报），或者漏掉真实的问题（漏报）。 上下文理解：它们缺乏理解上下文和含义的能力，这对某些无障碍检查来说可能至关重要。 用户体验：自动化工具无法全面评估用户体验，包括残疾用户的导航和理解是否方便。 动态内容：它们常常难以处理根据用户操作而变化的动态内容或复杂的 JavaScript 交互。 视觉设计和可读性：工具可能无法准确评估视觉设计元素，尤其是在图形内容中，比如对比度和可读性。 键盘导航：尽管一些工具可以模拟键盘导航，但它们可能无法有效地识别仅使用键盘的用户所遇到的所有问题。 屏幕阅读器兼容性：真实屏幕阅读器的测试是必要的，因为工具无法复制屏幕阅读器用户的体验。 辅助技术差异：存在各种辅助技术，自动化工具无法测试与所有这些技术的兼容性。 全面测试：没有单一工具能够涵盖所有无障碍准则；通常需要多个工具和手动测试以进行全面的测试。 为了缓解这些限制，应将自动化测试与**手工测试和与残疾人士的用户测试**相结合。这种方法提供了更准确、全面的可访问性评估。\n如何测试不同类型的残障？ 测试不同类型的残障涉及模拟具有各种障碍的个体的用户体验。这包括视觉、听觉、运动和认知残障。以下是一些策略：\n视觉障碍：使用屏幕阅读器，如 NVDA 或 JAWS，浏览您的应用程序。确保所有内容都是可读的，可以在没有视觉提示的情况下进行导航。测试不同的对比度设置和字体大小，以适应视力较差的用户。\n听觉障碍：验证所有音频内容是否具有文本替代，例如字幕或文字转录。测试应用程序在没有声音的情况下是否可用，并且没有基本信息仅通过音频传达。\n运动障碍：通过仅使用 tab 键、enter 键、空格键和箭头键测试键盘导航。确保所有交互元素都可以通过键盘到达和操作。考虑不能使用鼠标或运动控制有限的用户的需求。\n认知障碍：简化和结构化内容，以支持认知障碍的用户。测试一致的导航和可预测的交互。使用清晰的语言，并在适用的情况下提供延长时间限制的能力。\n在测试环境中结合辅助技术和用户偏好，模拟不同的残障场景。这包括语音控制软件、替代输入设备和修改显示设置的浏览器扩展。\n请记住，尽管自动化工具可以捕捉许多可访问性问题，但它们无法检测到所有残障人士的用户体验的微妙之处。与真实用户或无障碍专家进行的**手工测试**对于全面评估至关重要。\n实施与最佳实践 实施无障碍测试有哪些最佳做法 无障碍测试通过确保软件产品适用于各种能力和残疾的人使用，使用户受益匪浅。这种包容性设计使更广泛的受众能够有效地与应用程序、网站或工具进行交互，无论他们的身体或认知挑战如何。通过适应辅助技术，如屏幕阅读器、盲文终端和语音识别软件，无障碍测试有助于创造一个更加平等的用户体验。\n对于残疾用户而言，无障碍测试可能意味着能否在网上执行基本任务与面临重大障碍之间的区别。它实现了独立导航和互动，对于个人自主性和尊严至关重要。此外，它可以减少沮丧并提高效率，因为用户可以在没有不必要障碍的情况下访问和使用功能和信息。\n除了直接的用户益处外，无障碍测试还可能导致所有用户的改进的可用性。许多无障碍功能，如清晰的导航和易读的字体，提高了整体用户体验。通过专注于无障碍性，开发人员可能会在不经意间改进更广泛用户群体的设计和功能，从而创建更直观和用户友好的产品。\n最后，无障碍测试还有助于避免法律后果，这可能是由于不符合无障碍法律和法规而引起的，确保软件不仅是包容的，而且还符合法律要求。\n如何将无障碍测试纳入软件开发生命周期？ 将无障碍测试纳入软件开发生命周期 (SDLC) 需要在每个阶段进行集成，以确保从一开始就考虑到了无障碍性，并在整个过程中贯穿无障碍考虑。具体操作如下：\n在需求收集阶段，基于 WCAG 和 Section 508 等标准定义无障碍性准则。明确合规级别，并包括着眼于残障人士需求的用户故事。\n在设计阶段，使用线框图和原型来评估无障碍性考虑因素，如颜色对比和导航顺序。可以提前使用颜色对比分析工具，以避免后续的设计修改。\n在开发阶段，实施语义化的 HTML 和 ARIA 角色以增强无障碍性。开发人员应使用自动化工具来运行初步检查，并在编写代码时解决问题。例如：\n// 使用 Axe-core 进行自动化测试的示例 const { AxePuppeteer } = require(\u0026#39;axe-puppeteer\u0026#39;); async function checkAccessibility(page) { const results = await new AxePuppeteer(page).analyze(); console.log(results); } 在测试阶段，将无障碍性纳入测试用例中，并执行自动化和手动测试。自动化测试可以捕获各种问题，但手工测试对于从人的角度评估可用性至关重要。\n在部署阶段，执行最终的无障碍性审查和验证，以确保没有引入新问题。\n在部署后，建立与用户的反馈循环，以捕获可能被忽略的无障碍问题，并对用户需求做出响应。定期更新测试套件和工具，以\n适应不断发展的标准和技术。\n通过将无障碍性融入 SDLC，确保它是一个持续考虑的因素，降低昂贵的重做风险，并确保产品更具包容性。\n如何确保持续符合无障碍要求？ 为了在软件测试自动化中确保持续的无障碍性合规性：\n将无障碍性检查融入到您的常规测试套件中。使用 Axe 或 Wave 等工具自动进行这些检查。 实施持续集成（CI）流程，其中包括无障碍性测试，确保它们在每次构建时都得到运行。 jobs: accessibility_test: runs-on: ubuntu-latest steps: - name: Run accessibility checks run: npm run test:accessibility **采用左移方法**，在开发周期的早期将无障碍性测试纳入其中，以更早地发现问题。 **定期更新测试用例**，以涵盖新的无障碍性标准和指南的演变。 **教育您的团队**，鼓励开发人员从一开始就编写具有无障碍性的代码。 **定期进行手动审核**，以捕获自动化工具可能遗漏的问题。 **使用实际用户指标**（RUM）监控实际用户如何与您的应用程序交互，有助于识别无障碍性障碍。 **与残障用户互动**，获取反馈并将他们的见解纳入您的测试策略。 **保持了解**法律要求和行业最佳实践，以确保符合最新的标准。 通过将这些实践嵌入到您的开发和测试工作流中，您可以随时间保持较高水平的无障碍性合规性。 需要注意哪些常见的无障碍问题？ 在测试中要关注的一些常见无障碍性问题包括：\n文本替代：图像缺少alt文本，这对于使用屏幕阅读器的用户至关重要。 键盘导航：无法仅使用键盘导航网站，这会影响运动功能障碍的用户。 颜色对比：文本与背景之间的对比不足，使视觉障碍用户难以阅读内容。 焦点指示器：缺少可见的焦点指示器，这对于依赖键盘导航的用户至关重要。 表单标签：未标记的表单，对于屏幕阅读器用户难以解释。 ARIA 误用：导致屏幕阅读器体验差的错误或缺失的 ARIA 属性。 基于时间的媒体：音频和视频内容缺乏字幕或文本转录。 可调整大小的文本：文本无法调整大小或缩放而不损失内容或功能。 语言标识：缺少语言属性，未告知屏幕阅读器有关文本语言的信息。 错误识别：不足的错误消息，未能引导用户纠正错误。 一致的导航：导航顺序或命名不一致，令依赖模式的用户感到困惑。 动态内容更新：动态内容更新时屏幕阅读器缺少警报。 这些问题可以通过使用自动化工具和手动测试的组合来识别，以确保全面评估无障碍性。\n如何让网站更容易访问？ 为了提升网站的可访问性：\n使用语义化的 HTML 结构化内容，确保正确使用标题 (\u0026lt;h1\u0026gt; 到 \u0026lt;h6\u0026gt;)，列表 (\u0026lt;ul\u0026gt;, \u0026lt;ol\u0026gt;) 和按钮 (\u0026lt;button\u0026gt;) 等元素。 为非文本内容提供文本替代 (alt 属性)，如图像。 确保文本和背景颜色之间有足够的对比度。 通过使用可聚焦的元素和管理焦点顺序，使所有功能可以使用键盘访问。 为交互元素创建标签，使用 \u0026lt;label\u0026gt; 元素或 aria-label 和 aria-labelledby。 避免或提供对引起癫痫的内容的替代方案，例如闪烁的灯光。 提供清晰一致的导航。 包含跳转导航链接，以允许用户跳过重复的内容。 确保表单是可访问的，包括清晰的标签和错误消息。 使用 ARIA landmarks 定义页面的区域 (\u0026lt;nav\u0026gt;, \u0026lt;main\u0026gt;, \u0026lt;aside\u0026gt; 等)。 使用屏幕阅读器和其他辅助技术进行测试，以识别问题。 提供控制或停止动画、视频和音频的选项。 设计响应式布局，适用于各种设备和屏幕大小。 使用可访问的颜色调色板，考虑色盲。 为音频和视频内容提供字幕和文本。 确保将动态内容更新通知给辅助技术，使用 ARIA live regions。 与残障用户一起进行测试，以获取有关您网站可访问性的反馈。 请记住，可访问性是一项持续的承诺，应该融入常规的开发和测试周期中。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-accessibility-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，聚焦于无障碍测试。文章从基础概念、重要性，到流程与技巧、工具与技术，再到挑战与解决方案，全面阐述了无障碍测试在软件开发中的关键角色。读者将深入了解如何确保应用程序对所有用户都具有可访问性，并学到实施无障碍测试的最佳实践。通过这个系列分享，读者将更好地了解无障碍测试的价值，并在实际测试中更全面地考虑用户体验的多样性。","title":"软件测试术语分享:Accessibility Testing 无障碍测试"},{"content":"Acceptance Testing 验收测试 验收测试是由潜在的最终用户或客户进行的，其目的是判断软件是否符合必要的规格并且是否适用于其预定的用途。\n相关术语：\nUAT 用户验收测试 FAT 工厂验收测试 更多信息也可以看看： Wikipedia\n关于验收测试的问题 基础知识和重要性 什么是验收测试？ 验收测试是系统开发生命周期中的一个阶段，主要用于验证系统功能和业务需求是否符合预定的标准，以确保软件已经达到投入生产的标准。通常，这是产品交付给客户或向最终用户提供之前的最后一道关卡。这种测试注重于用户体验和整体系统行为，而非单个组件，通常涉及真实场景和端到端的工作流程。\n要有效进行验收测试，需要考虑以下几点：\n明确定义验收标准：这些标准应由相关利益方共同商定，并构成测试用例的基础。 优先考虑测试用例：集中关注对业务和用户体验至关重要的功能和用户流程，以提供最大价值。 充分利用用户反馈：整合来自测试用户或实际用户的见解，以完善测试。 在适当的情况下进行自动化：尽管自动化可以提高效率，但某些测试可能需要手动进行，以评估可用性和外观。 审查和调整：根据测试结果做出明智的决策，评估产品的准备就绪程度，并找出需要改进的方面。 请谨记，验收测试不仅仅是为了发现缺陷，更是为了确保产品满足业务需求并提供积极的用户体验。保持与相关利益方的沟通渠道畅通，以确保期望与结果一致。\n为什么验收测试很重要？ 验收测试的重要性不可忽视，它充当产品发布市场或交付客户之前的最终验证环节。这确保软件符合业务需求，能够提供期望的用户体验。通过模拟真实的使用场景，验收测试验证了端到端的业务流程，而不仅仅是单个组件或功能。\n这种测试通常是对缺陷和可能严重影响客户满意度和商业成功的问题的最后一道防线。它有助于发现用户期望与实际产品之间的任何差异，使团队能够在对最终用户产生影响之前解决这些问题。\n此外，验收测试为产品验收提供了明确的接受标准的度量标准，确立了“完成”产品的明确标准。它还提供了法律合规性检查，以确保软件符合与行业或市场相关的法规和标准。\n实质上，验收测试是关于增强对产品质量的信心，以及对部署准备就绪的信心。这是审查应用程序的功能、可用性、可访问性和整体性能的机会，这对用户验收至关重要。如果没有这个阶段，团队可能会面临发布产品的风险，这些产品未能完全满足客户的需求或期望，从而导致支持成本增加、声誉受损，甚至可能在市场上失败。\n验收测试有哪些不同类型？ 验收测试可以分为多个类型，每一种都专注于特定的方面和目标：\n用户验收测试 (UAT): 用于确保软件满足用户需求，准备投入实际使用。由用户或利益相关者执行，验证端到端的业务流程。 业务验收测试 (BAT): 专注于验证软件的业务目标。类似于 UAT，但更具战略性，通常涉及高层业务利益相关者。 Alpha 测试: 在软件面向外部用户之前由内部人员执行，旨在尽早发现任何重大问题。 Beta 测试: 由一组外部用户在实际环境中执行，从用户角度识别问题。 合同验收测试: 确保软件符合合同要求，通常根据供应商和客户共同同意的检查清单执行。 法规验收测试 (RAT): 验证软件是否符合行业法规和标准，在金融、医疗保健和航空等领域尤为重要。 运营验收测试 (OAT): 也称为生产验收测试，检查运营方面的事项，如备份、恢复和维护程序。 每种验收测试类型都旨在验证软件在部署和使用方面的准备情况，确保满足所有利益相关者的期望。\n验收测试如何融入软件开发生命周期？ 验收测试在软件开发生命周期（SDLC）中扮演着至关重要的角色，通常在系统测试之后、产品上线之前的发布前阶段进行。它作为最终的验证环节，确保软件满足业务需求，并已准备好投入运营。\n在敏捷方法中，验收测试被整合到迭代中，实现对用户故事的持续验证。这是一个协作的过程，涉及开发人员、测试人员和利益相关者，以确认产品的功能符合业务需求。\n而对于瀑布项目，验收测试则是一个独立的阶段，跟随着详尽的系统测试而呈线性发展。它充当着在软件交付给客户或提供给最终用户之前的关键关卡。\n在这两种情况下，焦点都是验证端到端的业务流程而非个别组件，以确保软件在类似生产环境中的行为符合预期。验收测试是基于所有相关方共同商定的预定义标准。\n验收测试的结果对于启动/暂停决策至关重要。成功通过意味着软件被认为达到预期目标，而任何重大问题都必须在正式启动之前解决。此阶段还是验证法规和合规要求的良机，如果适用的话。\n将验收测试融入 SDLC 确保最终产品不仅在技术层面正常运作，而且能够为业务及其用户提供预期的价值。\n验收测试与其他类型的测试有什么区别？ 验收测试与其他测试类型主要在其范围和涉及的利益相关者方面存在明显差异。而单元测试聚焦于个别组件，集成测试确保系统不同部分的协同工作，验收测试则评估系统对业务需求的符合度，以及是否准备好投入使用。\n功能测试检查代码的具体功能，而验收测试关注的是整个应用程序从最终用户角度的行为。这是一种黑盒测试，内部工作原理不是关注的焦点。\n另一方面，**性能测试**则评估系统在特定工作负载下的响应性和稳定性，这通常不是验收测试的主要目标。\n**可用性测试**关注用户体验，但通常比验收测试更主观，也不太正式，而验收测试则有要满足的具体标准。\n验收测试通常是软件上线前的最后一步，涉及真实场景和与用户需求的验证。通常由与开发或 QA 团队不太深度参与开发流程的利益相关者或业务代表执行。这种外部视角对确保软件满足预期用户的需求和期望至关重要。\n总之，验收测试在其专注于从用户角度验证产品是否准备好投入生产的方面上具有独特性，而不仅仅是验证技术的正确性或性能基准。\n技术和策略 验收测试中有哪些常用技术？ 在验收测试中常用的技术包括：\n行为驱动开发（BDD）：使用 Cucumber、SpecFlow 或 Behat 等框架，以利益相关者理解的自然语言编写测试。测试基于用户故事，确保软件的行为符合预期。 Feature: 用户登录 Scenario: 使用有效凭据成功登录 Given 登录页面已显示 When 用户输入有效凭据 Then 用户被重定向到仪表板 用户验收测试（UAT）：真实用户在模拟生产环境中测试软件，验证端到端的业务流程。 探索性测试：测试人员在没有预定义测试用例的情况下探索软件，发现意外行为或缺陷。 基于会话的测试：具有特定重点或目标以及设定时间框架的结构化探索性测试会话。 基于清单的测试：使用功能或需求列表作为指南，确保验证所有功能。 Alpha/Beta 测试：将软件释放给组织外的有限受众（alpha）或实际用户（beta）以收集反馈。 自动化回归测试：运行自动化测试，确认最近的更改没有对现有功能产生不良影响。 性能测试：评估系统在负载下的性能，确保其满足速度和响应性的验收标准。 合规性测试：验证软件是否符合行业标准、法规或合同协议。 这些技术有助于确保软件在发布前符合业务需求，提供良好的用户体验，并且在关键问题方面没有问题。\n如何制定验收测试策略？ 制定一个验收测试策略包括以下几个关键步骤：\n定义验收标准：与利益相关者合作，为每个功能或用户故事建立清晰且可衡量的验收标准。\n优先考虑测试用例：识别关键业务流程，并相应地优先考虑测试用例。注重用户体验和业务需求。\n选择测试技术：选择适当的测试技术，如行为驱动开发（BDD）或实例规约，以创建可理解且可执行的规范。\n规划测试数据管理：确保不同场景的相关测试数据可用，考虑数据隐私和合规性要求。\n设计测试环境：建立一个尽可能模拟生产环境的稳定测试环境，以发现特定于环境的问题。\n明智地自动化：自动化回归和高-优先级的测试用例，以节省时间和资源。将手动测试保留给探索性、可用性和临时场景。\n与 CI/CD 集成：将验收测试嵌入 CI/CD 流程，以实现对应用程序进行早期和频繁验证。\n监控和度量：实施监控以跟踪测试覆盖率、通过/失败率和缺陷密度。利用这些指标来完善测试流程。\n审查和调整：定期与团队审查测试策略，以适应应用程序或业务优先级的变化。\n利益相关者沟通：通过提供清晰、简洁的报告和仪表板，及时向利益相关者传达测试进展和结果。\n通过遵循这些步骤，您可以创建一个与业务目标一致并确保产品高质量的强大验收测试策略。\n自动化在验收测试中的作用是什么？ 自动化在验收测试中扮演着至关重要的角色，它通过简化软件对业务需求的验证过程，实现了测试用例的重复和一致执行，以确保新功能或更改不会破坏现有功能。验收测试中的自动化具有以下优势：\n通过减少运行测试所需的时间，特别是对于回归测试，提高了效率。 通过在重复性任务中减少人为错误，增强了准确性。 通过在不成比例增加时间或资源的情况下，促进了测试工作的可扩展性，以覆盖更多的功能和场景。 通过允许自动化验收测试成为部署流水线的一部分，支持了持续集成/持续部署（CI/CD），提供了有关应用程序是否准备好投入生产的即时反馈。 向开发人员和利益相关者提供更快的反馈周期，加速了开发过程，提高了产品质量。 通过使人工测试人员专注于探索性测试和其他需要人类判断的领域，改善了资源分配。 自动化验收测试通常是用高级语言编写的，或者通过允许行为驱动开发（BDD）或领域特定语言（DSL）的框架编写，使它们易于理解，适合非技术利益相关者，并确保测试与业务语言和用户期望保持一致。\n// 使用 BDD 框架的自动化验收测试示例 Feature: User login Scenario: Successful login with valid credentials Given the login page is displayed When the user enters valid credentials And the user submits the login form Then the user is redirected to the dashboard 通过将自动化验收测试整合到开发工作流中，团队可以持续验证软件对业务需求的遵循，降低风险，并缩短上市时间。\n验收测试有哪些挑战，如何克服？ 验收测试在面对需求模糊性、环境不匹配和利益相关者沟通等挑战时，需要采取一些对策：\n澄清需求：与利益相关者紧密合作，确保需求清晰且可测试。利用**行为驱动开发（BDD）**等技术，通过实例创建共享理解。 复制生产环境：确保测试环境与生产环境紧密匹配，以避免差异。采用**基础设施即代码（IaC）**自动化环境设置并保持一致性。 改善利益相关者沟通：定期向利益相关者更新测试进展，并让他们参与决策过程。实施演示会话和反馈循环以确保满足他们的期望。 管理测试数据：制定管理和生成测试数据的策略，以准确反映生产场景。利用数据匿名化和合成数据生成工具来维护数据的完整性和隐私性。 明智自动化：将自动化工作重点放在提供最大价值且容易出错的测试上。保持手动测试和自动化测试的平衡，以确保全面覆盖。 处理不稳定性：实施重试机制和根本原因分析以处理不稳定的测试以确保可靠性。使用容器化提供稳定一致的测试环境。 监控并采取行动：设置监控工具以跟踪测试结果和性能。利用这些数据不断完善和改进验收测试流程。 如何将验收测试集成到持续交付流水线中？ 将验收测试整合到持续交付（CD）流水线中，确保新功能符合业务需求且准备好投入生产。为实现这一目标，请按照以下步骤操作：\n自动化验收测试：编写与用户故事或需求相符的自动化验收测试。使用行为驱动开发（BDD）框架如 Cucumber 创建可读的场景。\n版本控制：将验收测试与应用代码一起存储在版本控制系统中，以保持测试用例与其覆盖的功能之间的同步。\n持续集成服务器：配置 CI 服务器（例如 Jenkins、CircleCI），在流水线的一部分触发验收测试。这应该在单元测试和集成测试通过后进行，以确保只有质量良好的代码继续进行。\n测试环境：建立一个专用的测试环境，模拟生产环境。使用基础设施即代码（IaC）工具如 Terraform 或 Ansible 保持一致性和可重复性。\n并行执行：并行运行测试以减少执行时间。使用 Docker 或 Kubernetes 进行容器化可以帮助管理和扩展测试环境。\n门控机制：在流水线中实施门控机制。只有当验收测试通过时，才允许更改进入下一阶段，确保失败的代码不会到达生产环境。\n反馈循环：在测试失败时立即向开发人员提供反馈。将测试报告与 Slack 或电子邮件等通信工具集成。\n持续监控：持续监控测试套件的健康状况。移除不稳定的测试并更新测试以反映用户需求的变化。\n部署决策：使用测试结果做出关于部署的明智决策。自动部署符合验收标准的代码。\n通过将验收测试嵌入到 CD 流水线中，确保每次更改在达到最终用户之前都会根据预期的业务功能进行评估，保持高质量标准，降低生产问题的风险。\n工具和技术 验收测试常用的工具有哪些？ 这些是常用于验收测试的工具：\nCucumber：支持以简单语言规范的方式进行行为驱动开发（BDD）。 Selenium：自动化浏览器，用于进行 Web 应用程序测试。 SpecFlow：通过将可读的业务行为规范与底层实现绑定，弥合领域专家和开发人员之间的沟通鸿沟。 FitNesse：基于 Wiki 的框架，允许用户在表格和可执行规范中定义测试。 Robot Framework：关键字驱动的验收测试方法，非程序员也易于使用。 JBehave：支持 BDD 的框架，允许将故事写入文档的一部分。 TestComplete：提供全面功能的 Web、移动和桌面测试工具。 UFT（Unified Functional Testing）：广泛用于功能和回归测试，支持关键字和脚本接口。 Postman：简化 API 测试，允许用户创建和共享测试套件。 SoapUI：用于测试 SOAP 和 REST Web 服务的工具。 这些工具通过自动化测试用例进行软件验证，这些测试用例模拟用户行为或API调用，以确保系统满足协商一致的标准。它们可以集成到 CI/CD 流水线中，用于持续验证，并支持各种编程语言和平台。每个工具都有其独特的功能，并且选择合适的工具取决于项目的具体需求，例如测试用例的复杂性、技术堆栈和团队的专业知识。\n这些工具如何帮助验收测试？ 测试自动化工具简化了验收测试过程，通过执行测试用例验证软件是否符合业务需求。这些工具不仅减少了进行繁琐的手动测试所需的时间和精力，还确保了验收标准的一致性。\n通过自动化测试用例，团队能够快速发现回归和缺陷，实现及时反馈和纠正。这在敏捷和 DevOps 环境中尤为重要，因为这些环境通常需要频繁的迭代和部署。自动验收测试可以通过持续集成（CI）流水线触发，确保新的更改在部署之前经过用户验收标准的审查。\n此外，自动化工具支持数据驱动测试，允许测试人员使用各种数据集验证应用程序在不同情景下的行为。这提高了测试覆盖率和验收测试的可靠性。\n自动化测试还提供了关于已测试内容的清晰文档，充当验收标准的实时记录。这种透明性有助于保持利益相关方、开发人员和测试人员之间的一致性。\n此外，这些工具通常配备报告功能，提供对测试结果的深入了解，更容易向所有相关方传达产品的状态。\n总的来说，测试自动化工具通过确保测试用例的一致执行，提供软件质量的快速反馈，增强测试覆盖率，并提供清晰的文档和测试结果报告，为验收测试提供了有力支持。\n不同验收测试工具有哪些优缺点？ 验收测试工具在功能、易用性和集成能力上各有千秋。以下是它们的优缺点的简要比较：\nCucumber：\n优势：推动行为驱动开发（BDD），采用简单语言（Gherkin），与多种框架良好整合。 劣势：需要对 BDD 有深入理解，对于复杂测试场景可能需要额外设置。 Selenium：\n优势：支持多种浏览器和语言，拥有庞大用户社区，高度灵活。 劣势：设置较为繁琐，由于浏览器自动化导致执行速度较慢，可能需要额外工具进行 API 测试。 FitNesse：\n优势：结合维基进行文档编制和测试执行，有利于利益相关方协作。 劣势：学习曲线较陡，用户界面相对陈旧，可能在大型项目中扩展性较差。 SpecFlow：\n优势：与.NET 集成，支持 BDD，允许使用自然语言编写测试。 劣势：主要用于.NET 项目，需要理解 BDD 原则。 Robot Framework：\n优势：基于关键词驱动，支持 BDD，拥有多个面向不同应用的库。 劣势：语法可能对开发人员不够直观，可能需要额外的 Python 知识。 TestCafe：\n优势：无需 WebDriver，测试支持所有流行的浏览器，易于设置。 劣势：相较于 Selenium，成熟度较低，可能集成较少。 UFT (Unified Functional Testing)：\n优势：支持多种应用，内置强大的 IDE，具备广泛的对象识别功能。 劣势：昂贵，不太适用于敏捷和持续集成环境。 每个工具都有其长处和不足，最佳选择取决于项目需求、团队专业知识和具体使用的技术。\nAPI 在验收测试中的作用是什么？ APIs在验收测试中扮演着至关重要的角色，充当着与应用逻辑进行交互的接口。它们使测试人员能够在无需用户界面的情况下验证系统在测试中的行为，特别是在后端服务中，用户界面可能不可用或尚未完全开发。\n通过使用APIs，验收测试能够验证：\n系统是否对给定输入正确响应。 是否遵循业务规则。 与其他服务的集成是否按预期运行。 系统的性能是否符合所需的基准。 APIs支持创建可靠、可重复且可以快速执行的自动验收测试。它们有助于在开发周期的早期进行测试，通常作为**持续集成/持续交付（CI/CD）**流程的一部分。\n此外，APIs提供了一层抽象，允许在没有依赖 UI 的情况下测试系统，因为 UI 可能会频繁更改。这导致了更稳定和可维护的验收测试。\n// 伪代码中基于 API 的验收测试示例 const response = await apiClient.createOrder(orderDetails); assert(response.status, 201); assert(response.data.orderId, expectedOrderId); 总的来说，APIs对于验收测试至关重要，通过高效、早期和有针对性的验证实现了系统功能和性能的检验。\n如何在验收测试中利用云技术？ 在验收测试中充分利用云技术带来了多个优势。云平台提供按需的可扩展资源，使团队能够通过动态提供必要的基础架构来模拟真实世界的流量和使用模式。这对于验收测试的**性能和负载测试**方面特别有用。\n利用云服务，可以快速、一致地复制测试环境，确保验收测试在稳定和可控的环境中运行。这对于保持验收测试过程的完整性至关重要。基于云的工具通常具有内置的分析和监控功能，可用于在验收测试期间获取有关应用性能和用户体验的洞察。\n持续集成/持续部署（CI/CD）流水线可以通过云服务实现增强，以自动部署和运行验收测试在各种环境中，包括类似生产的暂存区域。这种集成确保验收测试是交付过程中无缝的一部分。\n此外，云平台通常提供全球数据中心，这意味着验收测试可以更接近最终用户的位置执行，从而在延迟和用户体验方面提供更准确的结果。\n团队还可以从成本节约中受益，因为云服务通常采用按使用量计费的模式，这意味着在测试阶段仅需为所使用的资源付费。\n总的来说，云技术有助于实现更高效、可扩展和真实的验收测试过程，从而可能实现更可靠和用户中心的最终产品。\n最佳实践 验收测试有哪些最佳实践？ 验收测试的最佳实践包括：\n明确定义验收标准：与利益相关者合作，建立明确、可衡量的标准，以便特性能够被接受。 与跨职能团队合作：确保开发人员、测试人员和业务分析师共同努力，理解需求和期望结果。 优先考虑用户体验：关注真实的使用场景，验证端到端的工作流程和用户满意度。 保持测试可维护性：编写易于理解且在应用程序演变时容易更新的测试。 在适当的情况下自动化：使用自动化执行重复且耗时的测试，但请记住，一些探索性测试可能需要手动方法。 使用类似生产的数据进行测试：使用与生产环境紧密模拟的数据，以确保测试是现实的并涵盖边缘情况。 执行回归测试：通过在验收套件中包含回归测试，确保新变更不会破坏现有功能。 监控性能和安全性：将性能和安全性检查作为验收标准的一部分。 为测试工件使用版本控制：将测试用例、脚本和数据存储在版本控制系统中，以跟踪更改并有效地协作。 持续改进流程：定期审查和调整您的测试过程，以解决低效问题并纳入新的最佳实践。 通过遵循这些实践，可以确保验收测试是有效、高效的，并且与利益相关者和最终用户的期望保持一致。\n如何维护和更新验收测试？ 随着时间的推移，保持和更新验收测试需要采取一种有结构的方法，以确保它们保持相关性和有效性：\n定期审查测试用例：定期审查验收测试，使其与新功能、需求和应用程序的变化保持一致。 重构测试：通过对测试进行重构，提高可读性、效率和可维护性，保持测试代码库的清晰性。去除冗余，确保测试是模块化的。 版本控制：使用版本控制系统跟踪测试脚本的变化，以便在必要时回滚到先前的版本。 测试数据管理：有效管理测试数据，确保其保持最新并代表生产数据。 在可能的情况下自动化：对于受到重复更改影响的测试，使用脚本或工具自动化更新过程，以修改测试用例或数据。 与利益相关者合作：与开发人员、业务分析师和产品所有者密切合作，了解变更及其对验收标准的影响。 持续集成：将验收测试集成到 CI/CD 流水线中，以确保它们在每次构建时都得到执行，及早捕获问题。 监控和警报：为测试套件实施监控，检测由于应用程序更改而导致的不稳定性或失败，并设置警报以进行即时处理。 文档撰写：保持测试用例文档的更新，以反映应用程序和测试的当前状态。 反馈循环：与团队建立反馈循环，讨论验收测试的有效性和潜在改进。 通过遵循这些实践，可以有效地保持和更新验收测试，确保它们继续提供价值并满足软件开发生命周期的不断发展需求。\n文档在验收测试中的作用是什么？ 文档在验收测试中扮演着至关重要的角色，作为理解、执行和评估测试标准的基础。这包括验收测试计划（ATP）、测试用例和测试场景，它们勾勒了系统被最终用户或客户视为可接受的条件。\n测试用例源自需求文档，对确保应用程序的所有功能和非功能方面得到验证至关重要。它们提供了测试条件、期望结果和验收标准的逐步描述。\n追踪矩阵将需求与相应的测试联系起来，确保覆盖并有助于识别测试过程中的任何差距。这对于维护验收测试阶段的完整性至关重要。\n**测试报告**记录了验收测试的结果，包括发现的任何缺陷或问题。这些报告对于利益相关者做出关于软件是否准备好投入生产的明智决策至关重要。\n总之，验收测试中的文档确保：\n测试内容和成功标准的清晰性。 测试执行的一致性。 通过将测试与需求进行追踪来确保责任。 将测试结果和发现有效地传达给利益相关者。 适当的文档对于透明、高效和成功的验收测试过程至关重要。\n如何提高验收测试的效率？ 为了提高验收测试的效率：\n根据风险和业务影响，优先考虑测试用例。集中精力测试直接影响用户体验的关键功能。 实施**测试数据管理**实践，确保测试场景可以使用相关且高质量的数据。 利用行为驱动开发 (BDD) 框架，如 Cucumber，创建可读的规范，同时作为自动化测试。 并行化测试以减少执行时间。像 Selenium Grid 这样的工具可以在不同环境中同时运行多个测试。 重复使用测试组件并遵循 DRY（不重复自己）原则以减少维护工作量并提高一致性。 模拟外部依赖以隔离被测试系统并减少外部系统的不可预测性。 使用像 Docker 这样的容器化工具，优化测试环境 设置，以快速启动一致的测试环境。 定期审查和重构测试，去除冗余并确保其与当前需求保持一致。 利用仪表板和报告工具监控和分析测试结果，以快速识别并解决失败。 与利益相关者密切合作，确保验收标准清晰，并收集有关测试覆盖率和结果的反馈。 通过实施这些实践，您可以简化验收测试流程，减少执行时间，并维护高质量的测试套件，为开发生命周期提供有价值的反馈。\n如何有效传达验收测试的结果？ 有效传达验收测试结果涉及清晰、简洁和可操作的报告。使用仪表板提供实时状态更新，突出显示通过/失败率，测试覆盖率和缺陷。利用视觉辅助工具，如图表和图形，以便快速理解。\n整合自动生成的报告，确保其包含必要的细节，如**测试用例描述**，预期结果，**实际结果和测试执行**的证据（截图、日志）。根据不同的利益相关者定制报告——为管理层提供摘要报告，为开发人员提供详细日志。\n利用通知系统在测试失败时立即通知团队。将这些通知整合到已在使用中的工具中，如 Slack 或电子邮件。\n为了透明度和协作，使用像JIRA这样的问题跟踪系统记录缺陷，并将其直接链接到失败的验收测试。这有助于追溯和优先级排序。\n确保测试结果对所有相关方可访问，可能通过共享存储库或基于网络的平台。在团队会议上定期审查测试结果，讨论失败、不稳定的测试和下一步计划。\n最后，保持一个动态的文档或维基，随着项目的发展而不断更新，记录验收测试的见解和决策。这是一个历史记录和未来参考的知识库。\n实时更新的仪表板 包含必要细节的自动化报告 像图表和图形这样的视觉辅助工具 用于即时提醒的通知系统 用于缺陷管理的问题跟踪系统 所有利益相关方都可以访问的可达的测试结果 团队会议中的定期审查 用于历史见解的实时文档 参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-acceptance-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，专注于验收测试。文章从基础概念、重要性，到技术和策略、工具与技术，再到最佳实践，全面解析了 验收测试 在软件开发中的应用。读者将深入了解如何通过验收测试方法更紧密地结合业务需求，提高软件交付的质量和符合性。通过这个系列分享，读者将获得对验收测试的深刻理解，为实际项目中的测试工作提供有力的支持。","title":"软件测试术语分享:Acceptance Testing 验收测试"},{"content":"ATDD 验收测试驱动开发 验收测试驱动开发（ATDD）是一种旨在通过将测试作为开发过程的核心组成部分来减少缺陷的开发方法。这确保应用程序达到高质量标准。\n相关术语：\nTDD 测试驱动开发 UAT 用户验收测试 更多信息也可以看看： Wikipedia\nwikipedia 只有英文版本，没有中文版本。\n关于验收测试驱动开发的问题 基础知识和重要性 什么是验收测试驱动开发（ATDD）？ 验收测试驱动开发（ATDD）是一种开发方法，团队成员（包括开发人员、测试人员和业务客户）在编码开始之前共同编写验收测试，以不同的视角为特色。其主要目标是明确系统功能的详细、以客户为中心的标准，以指导开发并清晰了解所期望的结果。\n在 ATDD 中，验收测试以示例或场景的形式表达，通常采用“Given-When-Then”格式，描述了系统从用户角度的行为。这些测试被自动化，并作为实时文档和回归测试套件的一部分。\nATDD 促进了团队成员之间更好的沟通和理解，确保功能符合业务需求。它使开发工作与客户需求保持一致，有助于防止功能蔓延和缺陷。通过从一开始关注客户需求，团队可以交付更有价值且质量更高的软件。\n在 ATDD 中，测试人员的角色不仅仅局限于传统的测试，还包括参与需求澄清，并确保验收标准是可测试和清晰的。测试人员与开发人员和业务代表密切合作，共同创建和自动化验收测试。\n用于 ATDD 的常用工具包括 Cucumber、SpecFlow 和 FitNesse，它们支持行为驱动开发（BDD）和以实例为基础的规范实践。这些工具允许使用所有利益相关者都能理解的语言编写测试，弥合了技术和非技术团队成员之间的差距。\n有效实施 ATDD 需要转变思维和实践，强调前期规范、持续反馈和迭代开发。它是敏捷和精益开发方法中的关键实践，有助于交付符合用户期望的高质量软件。\n为什么 ATDD 在软件开发中很重要？ 在软件开发中，ATDD 至关重要，因为它确保在编码开始之前，所有利益相关者都对需求有共同的理解。这种方法使开发人员、测试人员和业务代表围绕已达成一致的验收标准进行对齐，促进更好的沟通和协作。通过从一开始关注客户需求，ATDD 最小化了误解的风险，并降低了在开发周期后期进行昂贵的返工的可能性。\n在开发过程的早期引入 ATDD 有助于在问题升级之前识别和解决问题，从而导致更高效和流畅的工作流程。它鼓励使用简单语言进行行为规范，使测试对所有参与方都易于理解。这种明确性有助于在开发之前预防缺陷，这是与传统测试方法相比更为主动的方法。\nATDD 还促进了持续反馈，允许在整个开发生命周期中进行迭代改进。这个迭代的过程有助于完善产品以更好地满足用户期望，最终产生与业务目标密切对齐的高质量软件。\n此外，ATDD 对自动化的强调支持回归测试，实现了一个可处理变化而不需要显著增加工作量的可持续测试过程。这个自动化测试框架对于在快节奏的开发环境中保持高质量尤为重要，特别是在扩大到较大项目时。\n总之，ATDD 之所以重要，是因为它促进了共享理解，减少了返工，确保与业务目标的一致，并支持一个可持续、高质量的开发过程。\nATDD 与传统测试方法有何不同？ ATDD，或验收测试驱动开发，主要在其协作方法和时机方面与传统测试方法不同。传统测试通常发生在开发阶段之后，测试人员根据已经实现的功能创建并执行测试。相比之下，ATDD 涉及到包括开发人员、测试人员和业务代表在内的多个利益相关者，他们在编写任何代码之前定义验收标准并创建验收测试。\nATDD 中的这种前期协作确保所有方对需求和“完成”的定义有共同的理解。它将重点从开发后发现缺陷转移到通过早期澄清期望来预防缺陷。此外，ATDD 鼓励行为驱动开发（BDD），其中测试以所有利益相关者都能理解的语言编写，通常使用 Given-When-Then 格式。\n而传统测试方法可能会严重依赖手动测试或在事后创建自动化测试，ATDD 从一开始就集成了**自动化测试。验收测试被自动化，并成为回归套件**的一部分，提供关于新更改是否符合已达成一致的标准的即时反馈。\n总的来说，ATDD 的积极、协作的方法与传统的被动测试方法形成对比，强调预防而非检测，并在整个团队中促进了对质量的共同责任。\n使用 ATDD 的主要优势有哪些？ ATDD 提供了一些增强软件开发过程的关键优势：\n增强协作：通过在开发周期的早期涉及各种利益相关者（开发人员、测试人员、业务分析师），ATDD 促进了更好的理解和沟通。 清晰需求：验收测试充当具体的需求，减少了歧义，并确保软件满足业务需求。 早期缺陷检测：在验收标准在前期定义时，问题被更早地识别出来，减少了后期修复缺陷的成本和工作量。 客户满意度：关注满足验收标准确保最终产品与客户期望一致。 回归安全：自动化验收测试提供了一个安全网，使得在不破坏现有功能的情况下重构和改进代码更加安全。 持续反馈：定期执行验收测试为产品的状态提供了持续的洞察，允许及时进行调整。 流程化开发：清晰的验收标准指导了开发工作，防止了功能蔓延和过度工程化。 实施 ATDD 可以导致一个更高效、协作和质量导向的开发生命周期，最终交付更好满足用户需求并经受住时间考验的软件。\nATDD 如何提高软件产品的质量？ ATDD 通过确保准确满足**功能需求** 并使产品表现如利益相关者期望的方式，提高了软件质量。通过从一开始关注客户需求，ATDD 促进了清晰且可执行的规范的创建。这些规范指导开发和测试，减少了由于误解或不完整的需求而导致的缺陷的可能性。\n验收测试在编写代码之前就已经定义好，这意味着开发人员有一个明确的目标。这种先测试后编码的方法有助于防止功能蔓延，并确保代码库只包含通过测试所必需的内容，从而使代码库更清晰且更易维护。\n此外，ATDD 鼓励开发人员、测试人员和业务利益相关者之间的协作。这种跨职能的沟通有助于在开发过程的早期识别和解决模糊之处，这可以显著提高产品的质量。\n来自验收测试执行的持续反馈允许早期检测问题，通常比在开发周期后期发现的缺陷更具成本效益。此外，验收测试套件成为可以用于**回归测试**的实时文档，确保新更改不会破坏现有功能。\n总的来说，ATDD 通过澄清需求、促进协作和提供持续反馈，有助于构建与业务需求和用户期望密切一致的产品，从而提高软件质量。\n流程与技巧 ATDD 有哪些关键步骤？ 在 ATDD 中涉及的关键步骤包括：\n协作： 开发人员、测试人员和业务利益相关者之间的协作，共同定义验收标准。 编写验收测试： 在开发开始之前，基于达成一致的标准编写验收测试。 开发： 根据验收测试指导功能或用户故事的开发。 持续集成： 确保代码更改会自动根据验收测试进行测试。 修正： 根据需要对验收测试进行修正，以解决需求或理解的变化。 测试执行：验证软件是否符合达成一致的验收标准。 审查和反馈： 利益相关者审查验收测试，确认其覆盖所需的功能和行为。 迭代：根据需要通过这些步骤进行迭代，直到功能符合验收标准。 验收测试通常是自动化的，以便频繁执行和回归测试。测试以对所有相关方可理解的语言编写，通常使用行为驱动开发（BDD）框架，如 Cucumber 或 SpecFlow。这确保了测试既充当规范又用于验证。\nFeature: User login Scenario: Valid login Given I am on the login page When I enter valid credentials Then I should be redirected to the dashboard 实现有效的 ATDD 需要团队成员之间建立起强烈的协作文化、保持清晰的沟通，以及对质量的共同承诺。\nATDD 如何创建验收测试？ 在 ATDD 中，验收测试是通过团队成员之间的协作创建的，包括开发人员、测试人员和业务利益相关者。该过程始于定义用户故事，描述了用户从其角度期望的功能。每个用户故事都包括验收标准，这些标准构成了验收测试的基础。\n团队讨论验收标准，以确保对需求的共同理解。这种讨论通常涉及示例映射或实例说明，其中使用具体的示例来阐明期望并涵盖不同的场景。\n一旦达成共识，就会编写可执行规范。这些规范通常以Given-When-Then语句的形式结构化，可以直接转化为自动化测试。例如：\nGiven the user is logged in When they attempt to place an order Then the order should be processed 然后，使用 ATDD 框架（如Cucumber或SpecFlow）自动化这些规范，这允许以对非技术利益相关者可访问的领域特定语言编写测试。自动化代码使用框架兼容的语言编写，例如使用 Cucumber 的 Java 或使用 SpecFlow 的 C#。\n@Given(\u0026#34;^the user is logged in$\u0026#34;) public void the_user_is_logged_in() { // Code to ensure user is logged in } @When(\u0026#34;^they attempt to place an order$\u0026#34;) public void they_attempt_to_place_an_order() { // Code to simulate order placement } @Then(\u0026#34;^the order should be processed$\u0026#34;) public void the_order_should_be_processed() { // Assertions to verify order processing } 验收测试在整个开发过程中持续执行，以验证软件是否符合达成一致的标准。这确保了新功能的开发以用户需求为导向，并及早捕捉到回归问题。\nATDD 通常使用哪些技术？ 在 ATDD 中，采用了多种技术来确保满足验收标准并确保软件的行为符合预期：\n行为驱动开发（BDD）：这一技术涉及以自然语言风格编写测试，描述应用程序的行为。通常使用诸如 Cucumber 或 SpecFlow 之类的工具来促进BDD。 实例说明：共同定义说明具体行为或要求的示例。这些示例然后被用作验收测试的基础。 示例映射：一个团队成员使用卡片来代表用户故事（黄色）、规则（蓝色）、示例（绿色）和问题（红色）的研讨会技术。这有助于理解故事并创建验收测试。 可执行规范：以使它们可以直接针对代码执行的方式编写验收测试。这通常涉及使用特定领域语言（DSL）以一种所有利益相关者都能理解的方式来表达测试。 测试先开发：在实际实施开始之前编写验收测试，确保开发集中在通过测试。 协作工具：使用促进业务利益相关者、开发人员和测试人员之间协作的工具，例如共享存储库或像JIRA与 Xray 或 TestRail 这样的协作平台。 持续集成（CI）：将验收测试作为 CI 流水线的一部分自动运行，以获取有关所做更改的即时反馈。 测试工件的版本控制：将验收测试与代码库一起存储在版本控制系统中，以保持测试用例与应用程序代码之间的同步。 这些技术有助于定义清晰的验收标准，促进团队成员之间的协作，并确保在被视为完整之前软件满足业务需求。\nATDD 如何融入软件开发生命周期？ ATDD 通过从一开始就将开发活动与指定的验收标准对齐，融入了软件开发生命周期（SDLC）。在初始阶段，利益相关者共同合作以定义和理解需求，然后将其转化为验收测试。这些测试代表了软件必须展示的行为，以被视为完整。\n在规划和设计阶段，验收测试得到审查和完善，确保它们清晰可测试。开发人员、测试人员和业务代表保持持续沟通，以澄清任何模糊之处。\n随着开发的开始，验收测试引导编码。开发人员编写足够的代码以通过这些测试，确保功能符合达成的标准。这种做法通常被称为测试先开发，促进了渐进式进展并有助于及早发现问题。\n在测试阶段，自动化验收测试经常执行，为软件功能提供即时反馈。这允许快速调整并有助于保持开发的稳定节奏。\n在发布之前，ATDD 确保产品符合业务需求，因为所有功能都是根据预定义的验收测试开发的。代码的持续集成和验收测试的定期执行有助于保持一个为部署准备的稳定构建。\n在部署后，这些验收测试成为回归测试套件的一部分，防范可能破坏现有功能的未来更改。ATDD 融入 SDLC 支持可持续、以质量为中心的开发过程。\n测试人员在 ATDD 中扮演什么角色？ 在 ATDD 中，测试人员的角色是多方面的，侧重于协作、规范和验证。测试人员与开发人员、业务分析师和利益相关者密切合作，澄清需求并确保验收标准定义明确。他们为用户故事和验收测试的创建做出贡献，确保这些测试准确反映业务需求并且可以自动化。\n在开发过程中，测试人员参与验收测试的持续完善，通常与开发人员搭档创建和维护自动化测试。他们确保测试是可执行的规范，指导开发并即时提供有关软件行为是否符合预期结果的反馈。\n测试人员还在维护测试套件方面发挥了关键作用，确保随着代码库的演变它保持可靠和高效。他们还可能负责**测试数据管理和设置必要的测试环境**。\n在 ATDD 循环中，测试人员帮助促进三位好朋友会议，讨论特性实施的问题，并积极参与**迭代计划** 和 回顾以不断改进流程。\n最终，在 ATDD 中，测试人员确保团队交付的产品不仅满足技术需求，而且满足业务需求并为最终用户提供价值。他们在推动 ATDD 中固有的质量为先的方法方面发挥关键作用。\n工具和技术 ATDD 常用的工具有哪些？ 常用的 ATDD 工具包括：\nCucumber：使用 Gherkin 语言编写测试，实现技术和非技术利益相关者之间的协作。 SpecFlow：类似于 Cucumber，专为.NET 框架定制，同样使用 Gherkin 进行测试规范。 FitNesse：结合了文档的 wiki 和自动化测试框架，允许以表格形式编写测试。 Robot Framework：关键字驱动的测试自动化框架，高度可扩展，支持表格数据的测试用例。 Concordion：与 JUnit 集成，允许以 HTML 编写规范，并可链接到用于测试的 Java 代码。 JBehave：Java 中用于行为驱动开发（BDD）的框架，使用自然语言编写的故事推动开发。 Serenity BDD：通过提供先进的报告和实时文档功能，增强了其他 BDD 工具（如 Cucumber 和 JBehave）。 这些工具通过使用所有利益相关者都能理解的语言定义验收标准，支持 ATDD 过程。它们促进了验收测试的自动化，并帮助确保软件特性在被视为完成之前满足预定义的标准。自动化测试工程师使用这些工具来编写、管理和执行验收测试，通常将它们集成到持续集成流水线中以获得持续反馈。熟练掌握编程，理解应用领域，以及熟悉所选工具的语法和最佳实践对有效使用这些工具至关重要。\n这些工具如何支持 ATDD 流程？ 自动化测试工具通过执行以行为驱动格式编写的验收测试，支持ATDD 过程。这些工具通常与Cucumber、SpecFlow或FitNesse等框架集成，这些框架允许使用业务可读语言（如Gherkin）定义测试。\n通过使用这些工具，团队可以自动化验收标准的验证，确保软件符合达成的规范。这种自动化支持持续集成（CI）实践，允许在代码提交时自动运行测试，向开发人员提供即时反馈。\n此外，自动化测试工具通过维护一套测试，可用于验证更改是否破坏了现有功能，从而支持重构。在 ATDD 中，重点是在整个开发过程中满足验收标准，这一点至关重要。\n此外，这些工具通常带有报告功能，使更容易向所有利益相关者传达测试的状态。这种透明度有助于保持对项目进展和质量的共享理解。\n例如，典型的 ATDD 工具链可能如下所示：\nFeature: User login Scenario: Valid user login Given I am on the login page When I enter valid credentials Then I should be redirected to the dashboard 然后，自动化工具将执行此场景，验证所描述的行为。这确保软件符合协同编写的验收测试中业务的期望。\n有效使用这些工具需要哪些技能？ 要有效使用自动化测试工具，需要具备以下几项技能：\n编程知识：熟练掌握与自动化工具相关的编程语言，如 Java、Python 或 C#。 软件开发理解：熟悉软件开发实践和生命周期，以将测试与开发阶段对齐。 测试框架专业知识：具有使用 JUnit、TestNG 或 pytest 等测试框架的经验，并了解其特性和集成。 版本控制系统：能够使用 Git 等版本控制系统管理测试脚本并与开发团队协作。 持续集成/持续部署（CI/CD）：了解 CI/CD 管道和 Jenkins、CircleCI 或 Travis CI 等工具，以将自动化测试集成到构建流程中。 自动化脚本编写：具备脚本编写技能，以创建健壮、可维护和可重用的测试脚本。 理解 ATDD：虽然不需要详细涵盖，但理解 ATDD 原则对创建反映用户需求的验收测试至关重要。 解决问题和分析技能：能够解决测试脚本的问题并适应变化的需求或环境。 注意细节：在编写测试用例时要精确，以覆盖边缘情况，防止误报或漏报。 沟通能力：与利益相关者进行清晰的沟通，了解需求并传达测试结果的重要性。 具体工具知识：熟练掌握特定的 ATDD 工具，如 Cucumber、SpecFlow 或 FitNesse，包括它们的语法和最佳实践。 // 一个使用特定工具语言的简单测试脚本示例 Feature: User login Scenario: Successful login with valid credentials Given the login page is displayed When the user enters valid credentials Then the user is redirected to the dashboard 性能和安全测试：了解性能瓶颈和安全漏洞，将相关测试纳入自动化测试套件。 自动化在 ATDD 中的作用是什么？ 在 ATDD 中，自动化在验证和回归验收标准方面发挥着关键作用，确保一致而高效地执行自动化测试。这些自动化测试源于团队达成的验收标准，以确保软件符合业务需求。在 ATDD 中，自动化具有以下作用：\n促进持续测试，将测试整合到 CI/CD 流水线中，提供对变更的即时反馈。 确保可重复性和验收测试的一致性，减少人为错误和测试执行的差异性。 增加测试覆盖率，在较短的时间内执行更多的测试。 通过提供清晰的、可执行的规范，增强协作，所有团队成员都能够理解并用于验证系统。 通过频繁运行自动化验收测试，缩短反馈周期，迅速了解软件的状态。 通过提供一个安全网，确保新更改不会破坏现有功能，支持重构。 自动验收测试成为系统行为的实时文档，始终保持更新。它们通常以**领域特定语言（DSL）**编写，使非技术利益相关者能够理解。通常使用工具如 Cucumber、SpecFlow 或 FitNesse 来促进这个过程。\nFeature: User login Scenario: Valid user login Given the user has a valid account When the user enters correct credentials Then access is granted 在 ATDD 中的自动化不仅仅是测试，它是关于通过在整个开发生命周期中持续验证软件与业务需求的一致性，构建正确的产品。\n如何在敏捷开发环境中实施 ATDD？ 在敏捷环境中实施 ATDD 涉及开发人员、测试人员和业务利益相关者之间的协作，以在开发开始之前定义验收标准。使用用户故事来捕获需求，并定义反映利益相关者期望行为的验收测试。\n开始时，进行一个规划会议，讨论用户故事并创建验收测试。这确保了对功能及其期望结果的共享理解。使用像 Cucumber 或 SpecFlow 这样的行为驱动开发 (BDD) 工具编写验收测试，以一种对所有相关方都可理解的语言。\n在开发过程中，程序员和测试人员协同工作，测试人员专注于自动化验收测试。这些测试被集成到持续集成 (CI) 流水线中，确保它们经常运行。\n在开发后，执行验收测试。如果它们通过，说明功能符合约定的标准。如果没有，开发人员进行必要的更改。这个循环持续进行，直到功能通过所有验收测试。\n通过定期与团队以及利益相关者一起审查测试及其结果，引入反馈循环。这确保了验收标准与业务目标保持一致，并及时解决任何误解。\n记得要对代码和测试进行重构，以保持简单和可读性。这种做法有助于保持自动化套件的可维护性和可扩展性。\n最后，确保团队是跨职能的，团队成员能够为开发和测试做出贡献。这种方法培养了一个质量和对最终产品的共同责任的文化。\n挑战与解决方案 ATDD 会遇到哪些常见挑战？ ATDD 中常见的挑战包括：\n协作困难：确保开发人员、测试人员和业务利益相关者之间的有效沟通可能是具有挑战性的。误解可能导致不正确的测试标准。 编写清晰的验收标准：制定明确、可测试的验收标准需要技巧和经验。编写不好的标准可能导致测试无效。 维护测试套件：随着应用程序的演变，保持验收测试的最新状态可能会耗费时间。 测试数据管理：生成和管理验收测试所需的数据可能会很复杂，尤其是在处理多个环境时。 在覆盖率和速度之间取得平衡：在保持测试套件对持续集成足够快的同时，实现足够的测试覆盖率可能很困难。 不稳定的测试：间歇性地通过和失败的测试可能会损害对测试套件的信心，并在调查中浪费时间。 与现有流程的整合：将 ATDD 引入到已建立的工作流中可能会遇到阻力，需要谨慎的变更管理。 工具兼容性：确保所选工具与技术栈良好集成并支持 ATDD 方法可能是一项挑战。 技能集：团队成员可能需要培训，以有效参与 ATDD，包括编写验收测试和自动化测试。 克服这些挑战通常涉及改进沟通、投资培训、完善流程，并选择与团队需求和技术栈相符的适当工具。\n如何克服这些挑战？ 在 ATDD 中克服挑战需要战略性的方法：\n协作：培养开发人员、测试人员和业务利益相关者之间协作的文化，以确保对需求有共同的理解。 持续学习：鼓励团队成员不断学习和适应新的工具和技术，以保持与 ATDD 最佳实践的同步。 渐进改进：从小处着手，逐步改进 ATDD 流程，而不是试图进行大规模改革。 熟练掌握工具：投入时间掌握 ATDD 工具，充分利用它们的潜力，并将其无缝集成到开发工作流中。 反馈循环：实施短反馈循环，快速发现和解决问题，提高验收测试的质量。 重构：定期重构测试，保持清晰度，减少维护成本。 模块化设计：设计测试为模块化和可重用的，以最小化重复并简化更新。 清晰文档：保持测试的清晰文档，以确保它们可被所有团队成员理解和维护。 资源分配：分配足够的资源，包括时间和人员，以保持可持续的步伐，避免过度劳累。 度量指标：使用指标跟踪进展并识别改进的领域，但要避免激励错误行为的指标。 风险管理：基于风险和业务价值对测试进行优先排序，确保对关键功能进行全面测试。 通过解决这些方面，团队可以增强他们的 ATDD 实践并克服常见挑战。\n实施 ATDD 有哪些最佳实践？ 实施 ATDD 的最佳实践包括：\n与产品所有者、开发人员和测试人员协作，在编码开始之前定义验收标准。使用用户故事促进这些讨论。 编写清晰简洁的验收测试，反映用户的视角，且能够被所有利益相关者理解。 尽早自动化验收测试并频繁执行，以确保持续反馈。使用像 Gherkin 这样的通用语言编写测试，可以使用 Cucumber 等工具进行自动化。 维护验收标准和测试结果的单一真相来源，确保所有团队成员都能透明且轻松地访问。 定期重构测试，使其能够在应用程序演进时保持可维护性和相关性。 将 ATDD 集成到您的**持续集成/持续交付（CI/CD）**流水线中，以确保每次构建都自动运行测试。 使用**测试数据管理**策略，确保测试具有所需数据且处于正确的状态。 根据风险和业务价值优先考虑测试，首先关注最关键的功能。 培养一个质量文化，使每个人都对产品的质量负责，而不仅仅是测试团队。 定期审查和调整您的 ATDD 流程，以解决任何问题并提高效率。 通过遵循这些实践，您可以增强协作，确保需求的清晰度，并在整个开发生命周期中保持高水平的软件质量。\n如何为大型项目扩展 ATDD？ 在大型项目中扩展 ATDD 需要战略规划和高效的工具。首先，通过构建验收测试来反映项目的模块化架构。这使得可以在不同团队之间并行进行开发和测试。利用版本控制管理测试工件，并确保在团队之间同步。\n利用**测试数据管理**提供一致且隔离的测试环境，避免共享数据时可能出现的冲突和依赖关系。实施 持续集成 CI以自动运行验收测试来验证新的代码提交，提供对集成状态的即时反馈。\n**分布式测试执行**对于处理增加的测试负载至关重要。使用支持在多台机器或容器上并行运行测试的工具。这可以缩短反馈周期，确保更快的周转时间。\n协作工具对于保持开发人员、测试人员和利益相关者之间的沟通至关重要。这些工具应该支持从需求到测试和代码库的追踪，确保所有相关方对验收标准达成一致。\n度量和报告应该定制以提供有关规模进展和质量的见解。自动仪表板可以跟踪测试覆盖率、通过/失败率以及随时间变化的趋势，有助于早期识别潜在问题。\n最后，模块化和重用测试组件是可能的。共享测试步骤或领域特定语言（DSL）定义的库可以减少重复和维护开销。\n通过专注于这些策略，ATDD 可以有效地扩展以适应大型项目的复杂性。\n如何衡量 ATDD 的有效性？ 可以通过几个关键指标来衡量 ATDD 的效果：\n缺陷率的降低：跟踪发布后发现的缺陷数量。较低的数字表明 ATDD 有助于更早地发现和解决问题。 改进的测试覆盖率：使用覆盖工具确保验收测试覆盖了代码库和用户故事的重要部分。 周期时间：监控从功能构思到交付所需的时间。ATDD 应有助于简化流程，缩短周期时间。 反馈循环持续时间：衡量从利益相关者那里获得反馈所需的时间。ATDD 的目标是缩短此循环时间，以便更快地进行调整。 团队协作：评估开发人员、测试人员和业务利益相关者之间的协作水平。有效的 ATDD 实践应该增强沟通和理解。 回归测试套件执行时间：跟踪运行回归套件所需的时间。ATDD 应该导致更有效和有针对性的测试，从而减少执行时间。 验收测试的通过/失败率：记录首次运行验收测试的通过率。较高的通过率表示团队对需求有很好的理解。 客户满意度：向利益相关者和最终用户进行调查，了解他们对已交付功能的满意程度。更高的满意度水平可能表示成功实施了 ATDD。 通过监控这些指标，团队可以评估并不断改进他们的 ATDD 实践。\n参考资料 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-acceptance-test-driven-development/","summary":"这篇博文是软件测试术语分享系列的一部分，专注于 ATDD（验收测试驱动开发）。文章从基础概念、重要性，到流程与技巧、工具与技术，再到挑战与解决方案，全面解析了 ATDD 在软件开发中的应用。读者将深入了解如何通过 ATDD 方法更紧密地结合业务需求，提高软件交付的质量和符合性。通过这个系列分享，读者将获得对 ATDD 的深刻理解，为实际项目中的测试工作提供有力的支持。","title":"软件测试术语分享:ATDD 验收测试驱动开发"},{"content":"A/B 测试 A/B 测试涉及创建一个或多个网页变体，以与当前版本进行比较。其目标是根据特定指标（如每访问者收入或转化率）确定哪个版本的性能最佳。 详见： Wikipedia\n关于 A/B 测试的一些问题 基础知识和重要性 什么是 A/B 测试？ A/B 测试，又称为分割测试，是一种比较网页或应用程序的两个版本以确定哪个性能更好的方法。它涉及在随机向用户展示两个变体（A 和 B），并使用统计分析来确定哪个版本在实现预定义目标方面更有效，比如增加点击率、转化率或其他关键性能指标。\n在软件测试自动化的背景下，A/B 测试可以被自动化以在不需要手动干预的情况下运行对特性或界面的不同变体的测试。自动化的 A/B 测试可以集成到持续集成/持续部署（CI/CD）流水线中，以确保对应用程序所做的任何更改都经过评估，了解其对用户行为和转化率的影响。\n为了自动化 A/B 测试，工程师通常使用特性标志和测试自动化框架的组合。特性标志允许在不同版本的特性之间进行切换，而测试自动化框架执行测试并收集有关用户交互的数据。\n// 代码中的特性标志示例 if (featureFlagService.isFeatureEnabled(\u0026#39;new-checkout-flow\u0026#39;)) { // 变体 B 的代码 } else { // 变体 A 的代码（对照组） } 自动化的 A/B 测试实现了在软件开发中的快速迭代和数据驱动的决策。通过利用自动化，团队可以扩展他们的测试工作，减少人为错误，并加速反馈循环，最终实现更用户中心化和成功的产品。\n为什么 A/B 测试很重要？ A/B 测试的重要性在于，它为我们提供了有关更改对用户行为和转化率影响的实证证据。通过将控制版本（A）与变体（B）进行比较，我们可以做出数据驱动的决策，从而优化性能并提高用户满意度。这种测试方法对于验证关于用户偏好的假设以及确定软件应用中最有效元素（如按钮、图像或工作流程）非常有价值。\n在软件测试自动化的背景下，A/B 测试对于迭代式开发至关重要，使团队能够基于用户反馈逐步改进功能。它还有助于在全面推出新功能之前在较小的受众群体上进行测试，从而减小与其相关的风险。此外，A/B 测试有助于通过确保仅实施最有影响的更改，从而最大化投资回报，节省资源并集中精力于对最终用户真正重要的事物。\n对于测试自动化工程师而言，将 A/B 测试整合到自动化策略中可以产生更强大和以用户为中心的测试用例，确保自动化测试不仅检查功能，还检查真实世界的用户参与和转化。\nA/B 测试的关键组成部分有哪些？ A/B 测试的关键组成部分包括：\n假设（Hypothesis）：对测试结果的清晰预测性陈述。 变量（Variables）：在变体中更改的元素，例如按钮颜色、文本或布局。 测试组（Test Group）：接收变体（B）的受众群体。 对照组（Control Group）：接收原始版本（A）的受众群体。 随机化（Randomization）：确保参与者被随机分配到测试组和对照组，以消除偏见。 成功指标（Success Metrics）：用于确定测试结果的具体可衡量标准，如转化率或点击率。 持续时间（Duration）：测试运行的时间段，确保足够长以收集到重要数据。 数据收集（Data Collection）：跟踪用户互动并根据成功指标衡量性能的机制。 分析（Analysis）：使用统计方法评估数据，并确定性能差异是否显著。 分割（Segmentation）：按用户人口统计信息或行为分解数据，以了解对亚组的不同影响。 在实践中，这些组成部分被整合到一个结构化过程中，以评估变更的影响并做出数据驱动的决策。测试自动化工程师应重点确保测试环境稳定，数据收集准确，并且分析工具正确配置以有效解释结果。\nA/B 测试与用户体验有何关联？ A/B 测试通过允许团队对软件产品的更改做出数据驱动的决策，直接影响用户体验（UX）。通过比较一个功能或界面的两个版本（A 和 B），团队可以衡量每个变体在用户参与、满意度和转化率方面的表现。表现更好的用户体验变体，由增加的页面停留时间、更高的点击率或完成所需操作的改善等指标表示，随后可以为所有用户实施。\n这个过程确保变更不是基于假设或个人偏好，而是基于实际用户行为。它有助于优化用户界面、工作流程和内容，以提高可用性和可访问性。A/B 测试还可以在完全推出之前识别潜在的用户体验问题，减少负面用户反馈的风险以及昂贵的发布后修复的需求。\n通过根据 A/B 测试结果持续迭代和改进产品，公司可以提高用户满意度和忠诚度，这对于长期成功至关重要。本质上，A/B 测试作为用户反馈和产品演进之间的桥梁，促进了以用户为中心的开发方法。\nA/B 测试在产品开发中的角色是什么？ A/B 测试通过使团队能够做出数据驱动的决策，在产品开发中发挥了至关重要的作用。它通过比较产品的两个版本来优化功能，通过特定指标（如转化率或用户参与）确定哪个版本的性能更好。\n在产品开发的背景下，A/B 测试用于验证产品决策并降低与新功能发布相关的风险。通过将新功能（变体）与当前版本（控制）进行测试，开发人员和产品经理可以在将其推向整个用户群之前评估更改的影响。\n这种测试方法还支持迭代式开发，允许根据用户反馈和行为持续改进产品。它可以通过提供用户喜好或拒绝的证据来影响产品路线图，从而指导未来的开发优先级。\n此外，A/B 测试可以集成到敏捷工作流中，其中短周期的开发和频繁的发布很常见。它允许进行快速的实验和适应，这在快节奏的开发环境中至关重要。\n对于测试自动化工程师来说，A/B 测试需要设置对用户交互进行自动跟踪和分析以测量不同变体的性能。工程师必须确保测试环境稳定，并且收集的数据可靠，以进行准确的决策。\n总而言之，A/B 测试是产品开发中的战略性工具，它指导用户体验的增强，验证产品决策，并促进实验性文化以持续改进。\n实施执行 如何设置 A/B 测试？ 设置 A/B 测试涉及以下步骤：\n明确目标： 充分说明您的改进目标（例如，提高转化率、点击率）。\n提出假设： 根据数据，对可能导致改进的变化进行合理猜测。\n创建变体： 在一个或多个变体中实施更改，同时将原始版本作为对照。\n分割受众： 决定如何将用户分组，确保他们被随机分配到对照组或变体组。\n确定度量标准： 选择将衡量变体影响的关键性能指标（KPI）。\n确保正确追踪： 设置追踪工具，收集对照组和变体组用户行为的数据。\n运行测试： 启动实验，允许用户与两个版本互动的足够时间。\n监控测试： 检查任何技术问题，并确保准确收集数据。\n分析结果： 在测试结束后，使用统计方法比较变体与对照的性能。\n做决策： 基于分析结果，决定是否实施更改、进行其他测试或放弃变体。\n这里有一个简单的代码片段，用于说明您可能如何在 Web 应用程序中将用户分配到不同组：\nfunction assignGroup(user) { const randomNumber = Math.random(); return randomNumber \u0026lt; 0.5 ? \u0026#39;control\u0026#39; : \u0026#39;variant\u0026#39;; } 这个函数使用一个随机数将用户分配到\u0026rsquo;对照\u0026rsquo;或\u0026rsquo;变体\u0026rsquo;组，分配比例为 50/50。根据需要调整阈值以更改用户在组之间的分布。\nA/B 测试的进行涉及哪些步骤？ 进行 A/B 测试的步骤：\n定义目标： 清晰地说明您希望通过测试实现的目标，例如提高点击率或改善转化率。\n制定假设： 根据您的目标，创建一个预测测试结果的假设。\n确定变量： 确定您将在变体中更改的元素，与对照组进行比较。\n创建变体： 开发产品的替代版本，其中包括您想要测试的更改。\n选择受众： 选择测试的目标受众，确保其代表您的用户群。\n确定分配： 决定如何在对照组和变体组之间分配受众。\n确保有效性： 检查测试是否没有偏见和可能影响结果的混杂变量。\n运行测试： 部署 A/B 测试给选定的受众，监控每个组的性能。\n收集数据： 收集有关每个组如何与产品的相应版本互动的数据。\n分析结果： 使用统计方法确定对照组和变体之间是否存在显著差异。\n做决策： 基于分析结果，决定是否实施更改、进行其他测试或放弃变体。\n记录发现： 记录测试的结果和见解以供将来参考和组织学习。\n实施更改： 如果变体成功，将更改推广给所有用户。\n请确保运行足够长的测试以收集足够的数据，并避免基于不完整的结果做出决策。\n如何确定 A/B 测试的样本大小？ 确定 A/B 测试的样本大小对确保测试具有足够能力以检测两个变体之间的有意义差异至关重要。以下是一个简明的指南：\n定义基线转化率（BCR）：使用历史数据为控制组建立基线转化率（BCR）。\n确定最小可检测效应（MDE）：确定对您的业务而言在转化率上最小的实质性变化。\n选择显著性水平（alpha）：通常设置为 0.05，这是拒绝零假设为真的概率（第一类错误）。\n设定功效（1 - beta）：通常为 0.80，功效是在零假设为真时正确拒绝零假设的概率（1 - 第二类错误）。\n计算样本大小：使用样本大小计算器或统计软件。输入 BCR、MDE、alpha 和功效，以获取每组所需的样本大小。\n调整实际考虑因素：考虑您可用的流量和测试的持续时间。如果计算得到的样本大小过大，您可能需要增加 MDE 或降低功效，以获得可行的样本大小。\n请记住，样本大小越大，结果越精确，但获取这些结果的时间和成本也会越长。这涉及在特定背景下找到合适平衡的问题。\nA/B 测试中的控制组和变体是什么？ 在 A/B 测试中，控制组是被测试的变量的原始版本，通常代表当前的用户体验或产品功能集。它作为一个基准，用于与新的变体或变体进行比较。变体体现了正在测试的更改，比如调用动作按钮的不同颜色或替代的结账流程。\n有时将控制组称为\u0026rsquo;A\u0026rsquo;版本，而将变体称为\u0026rsquo;B\u0026rsquo;版本。在进行 A/B 测试时，流量或用户会被随机分配到控制组和变体中，确保每个组在统计上是相似的。这种随机化有助于将变量变化的影响与其他外部因素隔离开来。\n然后，根据预定义的指标，如转化率或点击率，监控和测量每个组的性能。通过比较这些指标，测试自动化工程师可以确定变体是否比控制组更有效地影响用户行为。如果变体在统计上显著优于控制组，可能会将其作为所有用户的新默认选项实施。\n分析与解释 如何分析 A/B 测试的结果？ 分析 A/B 测试结果的过程涉及比较控制组（A）和变体组（B）的性能指标，以确定行为或结果是否存在统计学上的显著差异。主要步骤如下：\n数据收集： 在测试期间从两个组中收集数据。 数据清理： 通过去除异常值和离群值来确保数据质量。 计算性能指标： 计算关键指标，如转化率、点击率或其他相关的关键绩效指标，分别应用于两个组。 统计分析： 进行假设检验（例如 t 检验、卡方检验）来比较两组之间的指标。 计算p 值以评估观察到的差异发生的概率。 确定 p 值是否低于预定义的显著水平（通常为 0.05），表明存在统计学上显著的差异。 置信区间： 计算估计效应大小的置信区间，以了解真实效应在一定置信水平下的范围（通常为 95%）。 如果变体在统计学上显著优于控制，表明所做的改变产生了积极影响。然而，还需要考虑实际意义；即使结果在统计学上显著，其影响可能不足以值得实施。此外，审查测试以查看可能影响结果有效性的潜在偏见或错误。经过深入分析后，基于数据做出是否将变体中的更改应用于产品的决策。\nA/B 测试中使用的统计方法有哪些？ 统计方法在A/B 测试中扮演着重要的角色，为制定数据驱动的决策提供了框架。主要的统计方法包括：\n假设检验： 用于确定控制组和变体组之间性能差异是否具有统计学意义。通常包括零假设（无差异）和备择假设（存在差异）。\np 值计算： 用于衡量在零假设为真的情况下观察到结果的概率。较低的 p 值（通常低于 0.05）表示观察到的差异不太可能是偶然发生的，从而导致零假设被拒绝。\n置信区间： 提供了在一定置信水平下真实效应大小可能的范围（通常为 95%）。如果置信区间不包含零，则认为结果在统计学上是显著的。\nt 检验： 用于在正态分布的数据和相似的方差情况下比较两组的均值。在方差不相等的情况下，会使用 Welch\u0026rsquo;s t-test 等变体。\n卡方检验： 用于评估分类数据，以了解变量之间是否存在显著关联。\n贝叶斯方法： 提供了传统频率统计的替代方案，它根据数据给出了假设成立的概率，而不是在给定假设的情况下数据发生的概率。\n功效分析： 用于确定以期望功效（通常为 0.8）和显著水平检测到给定大小效应所需的最小样本量。\n这些方法被应用于从 A/B 测试中收集的数据，以得出关于变体相对于控制的影响的结论。正确的应用确保结果可靠且具有实际指导意义，从而指导产品开发中的明智决策。\n如何解释 A/B 测试的结果？ 解释 A/B 测试的结果涉及比较控制组（A）和变体组（B）的性能指标，以确定是否存在统计学上的显著差异。在测试结束后，您通常会获得一个包含每个组的关键指标（例如转化率、点击率或其他相关 KPI）的数据集。\n首先，计算两组之间的差异。例如，如果您正在测量转化率，请从 A 组的转化率中减去 B 组的转化率。\n接下来，执行统计显著性检验，例如 t 检验或卡方检验，以确定观察到的差异是由偶然发生还是由变体中的更改引起的。您将获得一个 p 值，将其与预先确定的显著性水平（通常为 0.05）进行比较。如果 p 值低于显著性水平，则结果被认为是统计学上显著的。\n此外，计算置信区间，以了解在一定置信水平下两组之间真实差异的范围（通常为 95%）。\n最后，考虑结果的实际意义。即使结果在统计学上显著，也可能不足以证明对产品进行更改。查看效应大小并考虑业务影响，包括潜在的投资回报，然后再做出决策。\n记得考虑可能影响结果的外部因素，并确保测试运行了足够长的时间以捕捉典型用户行为。\n在 A/B 测试的背景下，统计显著性是什么？ 在 A/B 测试的背景下，统计显著性是什么？\n在 A/B 测试的背景下，统计显著性是我们对观察到的测试组（控制组和变体组）之间的差异是否是由于所做的更改而不是由于随机机会而感到有信心的度量。这是用p 值来量化的，它表示在没有实际差异的情况下，获得观察到的结果或更极端结果的概率（零假设）。\n通常，如果p 值低于预定义的阈值，通常为 0.05，结果就被认为具有统计显著性。这意味着观察到的差异由于随机变化的可能性不到 5%。p 值越低，统计显著性就越大。\n为了确定统计显著性，通常会使用统计测试，如t 检验或卡方检验，具体取决于您正在分析的数据类型。这些测试根据 A/B 测试的数据计算 p 值。\n统计显著性有助于做出关于是否实施所测试更改的明智决策。然而，还必须考虑实际显著性或更改对用户行为的实际影响，这可能并不总是仅通过统计显著性来反映。\n在 A/B 测试中如何处理误报或漏报？ 处理 A/B 测试中的误报或漏报涉及到一些关键步骤：\n验证测试设置：确保跟踪代码正确实施，变体组和对照组正确配置。 检查外部因素：识别可能影响测试结果的任何外部事件或更改，例如假期、中断或营销活动。 审核细分：确保受众细分被正确定义，并且组之间没有重叠或污染。 分析数据收集：确认数据在对照组和变体组之间准确且一致地收集。 重新评估样本大小：确保样本大小足够大，能够检测到有意义的差异，并且测试运行时间足够长以达到统计显著性。 使用测试后分析：应用分割分析或队列分析等技术，深入研究结果并了解不同用户组的行为。 进行后续测试：如果结果不明确或存在假阳性或假阴性的怀疑，进行后续测试以验证结果。 通过系统地审查这些领域，您可以识别和纠正误报或漏报，确保您的 A/B 测试结果是可靠且可操作的。\n深层理解 多变量测试是什么，与 A/B 测试有何区别？ 多变量测试（MVT）是一种用于同时测试多个变量以确定如何最好地改善特定结果的技术。与 A/B 测试不同，A/B 测试专注于比较一个变量的两个版本，而 MVT 可以涉及多个变量及其各种排列组合。\n在 MVT 中，您可能会同时测试多个元素的不同变体，例如标题、图像和呼叫到操作按钮。这样就创造了一个可能组合的矩阵，每个组合都会展示给用户的一个子集。其主要优势在于观察不同元素如何相互作用以及对用户行为的综合影响。\n由于 MVT 涉及更多变量，因此为了达到统计显著性，需要更大的样本大小。此外，在设置和分析方面，MVT 也需要更多资源。然而，它可以提供更全面的洞察，了解各种更改如何相互作用，从而潜在地导致更优化的结果。\n相比之下，A/B 测试更简单、更快速实施，重点是一次性进行一个更改的影响。通常用于对单个更改做出决策或者在资源有限的情况下。\n总的来说，虽然 A/B 测试专注于比较一个更改的两个版本，但多变量测试评估多个更改及其相互作用的性能，需要更多资源，但提供对修改的最佳组合更深入的洞察。\n什么是分流 URL 测试？ 分流 URL 测试是 A/B 测试的一种变体，它将流量分配到两个不同的 URL，而不是相同 URL 中的不同版本。这种方法在比较两个不同的页面设计、后端流程或整个网站时特别有用。\n在分流 URL 测试中，用户被随机重定向到其中一个 URL，跟踪他们与页面的互动，以确定哪个版本在预定义的指标（如转化率、停留时间或点击率）方面的表现更好。\n与传统的 A/B 测试相比，主要区别包括：\n独立的 URLs：每个测试版本都存在于自己的 URL 上。 后端更改：它允许测试涉及可能涉及后端修改的重大更改。 复杂更改：适用于测试完全不同的布局或工作流程。 要执行分流 URL 测试，通常会在服务器上使用重定向机制或使用测试工具，根据预定义的规则将流量引导到不同的 URL。重要的是要确保流量的分流是随机的，并且其他因素（如用户的位置、设备等）不会影响结果。\n分析结果涉及比较两个 URL 的性能指标，以确定哪一个更有效地实现了预期的目标。与 A/B 测试一样，统计显著性至关重要，以确保结果不是偶然产生的。\n以下是在 .htaccess 文件中设置分流 URL 测试重定向的基本示例：\nRewriteEngine On RewriteCond %{QUERY_STRING} ^version=a$ RewriteRule ^page$ http://example.com/page-version-a [R=302,L] RewriteCond %{QUERY_STRING} ^version=b$ RewriteRule ^page$ http://example.com/page-version-b [R=302,L] A/B 测试有哪些局限性？ A/B 测试，尽管功能强大，但存在一些限制：\n有限变量：测试通常比较两个版本，只更改一个变量。要同时测试多个变量，需要使用更为复杂的多元测试方法。\n耗时：实现统计显著性可能需要较长时间，尤其是对于流量较低的站点或较小的更改。\n分割挑战：结果可能无法考虑不同用户段的行为，如果样本不具代表性，可能导致误导性的结论。\n外部因素：季节性、市场变化或其他外部因素可能影响测试结果，使得难以将用户行为的变化归因于测试变量本身。\n交互效应：用户体验的一个部分的变化可能会影响另一个部分，如果设计时未考虑这种交互，A/B 测试可能无法检测到。\n资源密集：需要资源来设计、实施、监控和分析，这对于较小的团队或预算较小的项目可能构成制约。\n伦理考虑：未经用户同意或涉及敏感变量的测试可能引发伦理关切。\n局部最大值：A/B 测试对于优化效果很好，但可能导致渐进式改进，可能会忽略创新思想，这些思想可能导致显著更好的结果。\n实施错误：不正确的设置可能导致错误的结果。正确的技术实施至关重要。\n数据解释：数据的错误解释可能发生，特别是如果在统计分析方面缺乏专业知识。\n了解这些限制对于 测试自动化工程师至关重要，以确保有效使用 A/B 测试，并正确解释其结果。\n如何将 A/B 测试与其他测试方法结合使用？ A/B 测试可以与各种测试方法结合，以提升软件质量和用户体验。比如，单元测试 确保各个组件在 A/B 测试比较不同用户流程之前正常运作。集成测试 则检查组合部分是否协同工作，这在 A/B 测试评估更改对集成系统影响之前显得至关重要。\n将 自动化的 回归测试 与 A/B 测试结合使用是很有益的，可以确保新功能或更改不会破坏现有功能。自动化测试可以快速验证控制组和变体版本在暴露给用户之前是否稳定且按预期运行。\n可用性测试 可以与 A/B 测试结合使用，以获得对用户行为和偏好的定性洞察。而 A/B 测试能够量化更改的影响，而 可用性测试可以解释为何某些更改表现更佳。\n在进行 A/B 测试之前，应进行 性能测试 以确保两个变体提供可接受的响应时间并能处理预期负载。这是至关重要的，因为性能可以显著影响用户行为，从而影响 A/B 测试的结果。\n最后，应在 A/B 测试过程中使用 监控和日志工具 来跟踪错误、性能指标和用户交互。这些数据对解释 A/B 测试结果以及诊断可能与正在测试的更改无直接关系的问题非常宝贵。\n通过将 A/B 测试与这些方法结合使用，可以确保对软件更改进行全面评估，从而做出更明智的决策，提供更高质量的产品。\nA/B 测试中 \u0026ldquo;回归均值 \u0026ldquo;的概念是什么？ 在 A/B 测试的情境中，回归到均值指的是极端结果在随后的测量中趋于不那么极端的现象。当一个变体（A 或 B）在初始测试中与控制组显示出显著差异时，这种差异在随后的测试中可能会减小或消失。\n这种效应在分析 A/B 测试结果时尤为重要。如果初始测试显示新功能或设计（变体）表现出色，人们可能会认为这种成功是由于所做的更改。然而，如果初始结果受到不一致的变量的影响，比如临时用户行为、季节效应或其他外部因素，随后的测试可能会显示性能优势并非由于变体本身，而是由于这些外部影响。\n为了减轻由于回归到均值而误解结果的风险，关键是：\n以足够的持续时间运行测试，以平均异常。 当结果异常高或低时，重复测试以确认结果。 使用足够大的样本量，以最小化离群值的影响。 控制尽可能多的外部变量，以确保一致的测试条件。 通过了解回归到均值， 测试自动化工程师可以避免基于初始 A/B 测试结果而做出过早结论，从而更准确地评估更改的有效性。\n参考资料 A/B 测试 Wikipedia https://zh.wikipedia.org/zh-cn/A/B%E6%B8%AC%E8%A9%A6 软件测试术语 Github 仓库 https://github.com/naodeng/QA-Glossary-Wiki QA Glossary Wiki https://ray.run/wiki 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/qa-glossary-wiki/qa-glossary-wiki-a-b-testing/","summary":"这篇博文是软件测试术语分享系列的一部分，专注于 A/B 测试。从基础概念、重要性、实施执行、分析与解释，到深层理解，文章全面介绍了 A/B 测试的各个方面。读者将深入了解这一测试方法如何帮助优化产品和提升用户体验，同时学习在实际项目中如何正确执行、分析和解释 A/B 测试的结果。通过这个系列分享，读者将更全面地理解和应用 A/B 测试在软件开发中的价值。","title":"软件测试术语分享:A/B 测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n真实案例：从难以理解的 React 组件测试到简单愚蠢的测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/real-life-examples/from-unreadable-react-component-tests-to-simple-ones.md\n一段简要说明 测试的代码应该尽量清晰易懂。这样做的好处是在需要理解、更新、重构或修复代码时，能够节省大量时间。相反，如果你连自己写的测试都读不懂，那可就是个糟糕的场景了！\n这里我将分享一下我对一些旧的 React 组件测试进行重构的原因、思考过程和模式。\n问题 在添加了\u0026ldquo;使用 Cypress 和 Storybook 测试虚拟列表组件\u0026rdquo;章节和\u0026ldquo;使用 Cypress 进行 React 组件单元测试\u0026rdquo;章节一年后，我发现我的测试几乎无法阅读。许多抽象层次使我无法仔细理解测试在做什么，导致花费很长时间阅读它们。这是无法接受的阻力。\n如何提高测试的可读性？ TDD 之父 Kent Beck 曾说：\n测试代码不是生产代码。它必须简单且小 1000 倍。\n但是，如何做到呢？是什么导致我的测试如此难以阅读？是什么使可读性变差？\n我将分析一堆我的测试，对它们进行思考，并提出更为直观的方法。被测试的组件是前文提到的 VirtualList。\n测试 1，复杂度低 接下来的测试是最简单的一个：检查当没有传递任何内容时，VirtualList 是否不渲染任何东西。以下是原始测试\nit(\u0026#39;When there are no items, then nothing is showed\u0026#39;, () =\u0026gt; { const itemsAmount = 0 const itemHeight = 30 const listHeight = 300 const items = getStoryItems({ amount: itemsAmount }) mount( \u0026lt;VirtualList items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={createRenderItem({ height: itemHeight })} listHeight={listHeight} /\u0026gt;, ) cy.findByTestId(\u0026#39;VirtualList\u0026#39;) .then($el =\u0026gt; $el.text()) .should(\u0026#39;be.empty\u0026#39;) }) 考虑到测试的简单性，谈论可读性是否有点过于琐碎？不，我已经对此有一些疑问，比如：\ngetStoryItems 是做什么的？ createRenderItem 是做什么的？ 我这里没有贴出 getStoryItems 的代码，但它只是一个生成包含 X 个项目的数组的函数，形式为 [{ id: 1, name: 'Item 1' }, { id: 2, name: 'Item 2' }, /* 等等 */]。它的目的是轻松生成数千个项目，但我编写它的初衷是为了更轻松地编写没有测试意识的 Storybook 故事！然后，我将其重新用于测试，但故事和测试有完全不同的需求和目的！\n与此同时，createRenderItem 是一个工厂，生成列表项（一些 React 组件）。同样，我为 Storybook 设计它是为了使其更具动态性，而测试并不是我最初考虑的。\n这两个函数都很容易阅读，但为什么要强迫读者跟随这些抽象？它们是必需的吗？答案是否定的。\n以下是测试的简化代码，列出了其中的差异。\nit(\u0026#39;When there are no items, then nothing is showed\u0026#39;, () =\u0026gt; { // ------------------------------------------ // Arrange const items = []; mount( \u0026lt;VirtualList items={items} listHeight={90} getItemHeights={() =\u0026gt; 30} RenderItem={RenderItem} /\u0026gt; ); // ------------------------------------------ // Assert cy.findByTestId(\u0026#39;VirtualList\u0026#39;) .then(($el) =\u0026gt; $el.text()) .should(\u0026#39;be.empty\u0026#39;); }); -const itemsAmount = 0 -const itemHeight = 30 -const listHeight = 300 -const items = getStoryItems({ amount: itemsAmount }) +const items = []; mount( \u0026lt;VirtualList items={items} listHeight={listHeight} - getItemHeights={() =\u0026gt; itemHeight} + getItemHeights={() =\u0026gt; 30} - RenderItem={createRenderItem({ height: itemHeight })} + RenderItem={RenderItem} /\u0026gt;, ) 在简化的测试中，最显著的变化有：\n我显式指定了 items，而不是通过 getStoryItems 生成它们。这样做的目标是立即向读者澄清 VirtualList 渲染的是哪些项目。 我移除了“不必要的”常量。如果没有渲染任何项目，项目的高度和列表的高度是无关紧要的。 我取消了 createRenderItem 工厂的必要性。在这里，生成预先设置高度的组件是无用的。 测试 2，中等复杂度 接下来的测试并不复杂。但我实现它的方式在不必要的情况下增加了复杂度\nit(\u0026#39;When the list receives 10000 items, then only the minimum number of them are rendered\u0026#39;, () =\u0026gt; { const itemsAmount = 10000 const itemHeight = 30 const listHeight = 300 const items = getStoryItems({ amount: itemsAmount }) const visibleItemsAmount = listHeight / itemHeight mount( \u0026lt;VirtualList items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={createRenderItem({ height: itemHeight })} listHeight={listHeight} /\u0026gt;, ) const visibleItems = items.slice(0, visibleItemsAmount - 1) itemsShouldBeVisible(visibleItems) // first not-rendered item check cy.findByText(getItemText(items[visibleItemsAmount])).should(\u0026#39;not.exist\u0026#39;) }) 在这里情况变得更加奇怪。再次出现了一些简单的抽象，但读者必须：\n理解 visibleItemsAmount 的值。 通过阅读 items.slice 理解 visibleItems 包含什么。再一次，多了一层复杂性。 猜测 itemsShouldBeVisible 是做什么的，或者阅读它的代码。 猜测 items[visibleItemsAmount] 包含什么。 是的，有一些注释。是的，我尝试创建有意义的名称。但我可以简化它很多。\n还有一件事。想象一下这种情况：测试失败了。不管你做了什么，这个测试都失败了。你开始调试它，但你知道调试一个高度动态的测试（你不知道 items，visibleItemsAmount，visibleItems，items[visibleItemsAmount] 在前期包含什么）是很困难的。你需要在测试代码中添加 console.log/cy.log/debugger/断点，以对测试管理的内容有一个整体的概念，然后才能开始调试 VirtualList。我能避免未来的调试问题吗？我需要测试渲染 10,000 个项目吗？\n以下是我如何改进测试的方式。\nit(\u0026#39;When the list is longer than the available space, then only the minimum number of items are rendered\u0026#39;, () =\u0026gt; { // ------------------------------------------ // Arrange // creating the data const items = [ // visible ones { id: 1, name: \u0026#39;Item 1\u0026#39; }, { id: 2, name: \u0026#39;Item 2\u0026#39; }, { id: 3, name: \u0026#39;Item 3\u0026#39; }, // invisible one { id: 3, name: \u0026#39;Item 4\u0026#39; }, ]; // only 3 items are visible const itemHeight = 30; const listHeight = 90; // mounting the component mount( \u0026lt;VirtualList items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={RenderItem} listHeight={listHeight} /\u0026gt; ); // ------------------------------------------ // Act // ------------------------------------------ // Assert cy.findByText(\u0026#39;Item 1\u0026#39;).should(\u0026#39;be.visible\u0026#39;); cy.findByText(\u0026#39;Item 2\u0026#39;).should(\u0026#39;be.visible\u0026#39;); cy.findByText(\u0026#39;Item 3\u0026#39;).should(\u0026#39;be.visible\u0026#39;); cy.findByText(\u0026#39;Item 4\u0026#39;).should(\u0026#39;not.exist\u0026#39;); }); 同样，在这里，唯一而且关键的改变是为未来的读者/调试者提供了更轻松的体验。你不需要猜测/计算/记录常量的值，也不需要弄清楚抽象的作用。代码就在你眼前，遵循 KISS 原则（保持简单，傻瓜）。\n-const itemsAmount = 10000 -const itemHeight = 30 -const listHeight = 300 -const items = getStoryItems({ amount: itemsAmount }) -const visibleItemsAmount = listHeight / itemHeight +// creating the data +const items = [ + // visible ones + { id: 1, name: \u0026#39;Item 1\u0026#39; }, + { id: 2, name: \u0026#39;Item 2\u0026#39; }, + { id: 3, name: \u0026#39;Item 3\u0026#39; }, + // invisible one + { id: 3, name: \u0026#39;Item 4\u0026#39; }, +]; +// only 3 items are visible +const itemHeight = 30; +const listHeight = 90; /* ... */ -const visibleItems = items.slice(0, visibleItemsAmount - 1) -itemsShouldBeVisible(visibleItems) -cy.findByText(getItemText(items[visibleItemsAmount])).should(\u0026#39;not.exist\u0026#39;) +cy.findByText(\u0026#39;Item 1\u0026#39;).should(\u0026#39;be.visible\u0026#39;); +cy.findByText(\u0026#39;Item 2\u0026#39;).should(\u0026#39;be.visible\u0026#39;); +cy.findByText(\u0026#39;Item 3\u0026#39;).should(\u0026#39;be.visible\u0026#39;); +cy.findByText(\u0026#39;Item 4\u0026#39;).should(\u0026#39;not.exist\u0026#39;); 测试 3，中等复杂度 在下一个测试中，我们的目标是测试 VirtualList 的 buffer 属性，该属性允许在项目尚不可见时渲染一些项目。\nit(\u0026#39;When some items buffered, then they exist in the page\u0026#39;, () =\u0026gt; { const itemsAmount = 1000 const itemHeight = 30 const listHeight = 300 const items = getStoryItems({ amount: itemsAmount }) const visibleItemsAmount = listHeight / itemHeight const bufferedItemsAmount = 5 mount( \u0026lt;VirtualList items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={createRenderItem({ height: itemHeight })} listHeight={listHeight} buffer={bufferedItemsAmount} /\u0026gt;, ) fastScrollVirtualList().then(() =\u0026gt; { const firstRenderedItemIndex = getFirstRenderedItemIndex(items, getItemText) const firstVisibleItemIndex = firstRenderedItemIndex + bufferedItemsAmount const lastVisibleItemIndex = firstVisibleItemIndex + visibleItemsAmount + 1 const lastRenderedItemIndex = lastVisibleItemIndex + bufferedItemsAmount items.slice(firstRenderedItemIndex, firstVisibleItemIndex).forEach(item =\u0026gt; { cy.findByText(getItemText(item)).should(\u0026#39;not.be.visible\u0026#39;) }) items.slice(firstVisibleItemIndex, lastVisibleItemIndex).forEach(item =\u0026gt; { cy.findByText(getItemText(item)).should(\u0026#39;be.visible\u0026#39;) }) items.slice(lastVisibleItemIndex, lastRenderedItemIndex).forEach(item =\u0026gt; { cy.findByText(getItemText(item)).should(\u0026#39;not.be.visible\u0026#39;) }) }) }) 复杂性来自于：\n滚动列表以测试缓冲区在两侧的作用。 当滚动停止时，我无法提前知道哪些项目是可见的，哪些不可见，这就是为什么 fastScrollVirtualList().then(() =\u0026gt; { /* ... */ }) 的内容是动态的。 我稍后会回到第 2 点，但对于这个测试，我切掉了第 1 点的头：为什么我需要通过 Cypress 组件测试在这里测试整个 buffer 行为？我有很多单元测试，检查内部 VirtualList 函数是否正常工作。我不需要再次测试相同的行为。一旦 buffer 生效，它就在两侧都生效了。这个选择使测试受益匪浅；现在它更简单了，包含了许多有助于读者的注释！\nit(\u0026#39;Should render only the visible items and the buffered ones when an item is partially visible\u0026#39;, () =\u0026gt; { // ------------------------------------------ // Arrange // creating the data const items = [ // visible ones { id: 1, name: \u0026#39;Item 1\u0026#39; }, { id: 2, name: \u0026#39;Item 2\u0026#39; }, { id: 3, name: \u0026#39;Item 3\u0026#39; }, // visible ones { id: 4, name: \u0026#39;Item 4\u0026#39; }, // buffered ones { id: 5, name: \u0026#39;Item 5\u0026#39; }, { id: 6, name: \u0026#39;Item 6\u0026#39; }, // non-rendered one { id: 7, name: \u0026#39;Item 7\u0026#39; }, ]; const itemHeight = 30; // 3 items are fully visible, 1 is partially visible const listHeight = 100; // 2 items are buffered const buffer = 2; // mounting the component mount( \u0026lt;VirtualList items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={RenderItem} listHeight={listHeight} buffer={buffer} /\u0026gt; ); // ------------------------------------------ // Act // ------------------------------------------ // Assert cy.findByText(\u0026#39;Item 1\u0026#39;).should(\u0026#39;be.visible\u0026#39;); cy.findByText(\u0026#39;Item 2\u0026#39;).should(\u0026#39;be.visible\u0026#39;); cy.findByText(\u0026#39;Item 3\u0026#39;).should(\u0026#39;be.visible\u0026#39;); cy.findByText(\u0026#39;Item 4\u0026#39;).should(\u0026#39;be.visible\u0026#39;); cy.findByText(\u0026#39;Item 5\u0026#39;).should(\u0026#39;not.be.visible\u0026#39;); cy.findByText(\u0026#39;Item 6\u0026#39;).should(\u0026#39;not.be.visible\u0026#39;); cy.findByText(\u0026#39;Item 7\u0026#39;).should(\u0026#39;not.exist\u0026#39;); }); 测试 4，高复杂度 测试选择是 VirtualList 中最困难的部分，因为：\nVirtualList 管理键盘修饰符，允许简单、累加、减去和范围选择。 VirtualList 是无状态的：我们需要用一个有状态的包装器来包装它，以存储先前的选择，以便测试累加、减去和范围选择。 我的旧测试非常难以阅读，因为：\n有状态的包装器在测试本身的主体中声明，使用测试的范围。 所有的选择都在一个很长的流中被检查。 逐步来，让我们简化它。\n将抽象移到远处 旧测试的第一部分如下：\nit(\u0026#39;When the items are clicked, then they are selected\u0026#39;, () =\u0026gt; { const itemHeight = 30 const listHeight = 300 let testItems const WithSelectionManagement: React.FC\u0026lt;{ testHandleSelect: (newSelectedIds: ItemId[]) =\u0026gt; {} }\u0026gt; = props =\u0026gt; { const { testHandleSelect } = props const items = getStoryItems({ amount: 10000 }) const [selectedItems, setSelectedItems] = React.useState\u0026lt;(string | number)[]\u0026gt;([]) const handleSelect = React.useCallback\u0026lt;(params: OnSelectCallbackParams\u0026lt;StoryItem\u0026gt;) =\u0026gt; void\u0026gt;( ({ newSelectedIds }) =\u0026gt; { setSelectedItems(newSelectedIds) testHandleSelect(newSelectedIds) }, [setSelectedItems, testHandleSelect], ) React.useEffect(() =\u0026gt; { testItems = items }, [items]) return ( \u0026lt;VirtualList items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={createSelectableRenderItem({ height: itemHeight })} listHeight={listHeight} updateScrollModeOnDataChange={{ addedAtTop: true, removedFromTop: true, addedAtBottom: true, removedFromBottom: true, }} selectedItemIds={selectedItems} onSelect={handleSelect} /\u0026gt; ) } WithSelectionManagement.displayName = \u0026#39;WithSelectionManagement\u0026#39; mount(\u0026lt;WithSelectionManagement testHandleSelect={cy.stub().as(\u0026#39;handleSelect\u0026#39;)} /\u0026gt;) /* ... rest of the test ... */ }) 以这样的样板开始阅读测试是相当困难的。你在阅读中迷失了一段时间，失去了测试本身的关键部分。让我们将其从测试中移到远处。\n// wrap the VirtualList to internally manage the selection, passing outside only the new selection function SelectableList(props) { const { onSelect, ...virtualListProps } = props; // store the selection in an internal state const [selectedItems, setSelectedItems] = React.useState([]); const handleSelect = React.useCallback( ({ newSelectedIds }) =\u0026gt; { setSelectedItems(newSelectedIds); // call the passed spy to notify the test about the new selected ids onSelect({ newSelectedIds }); }, [setSelectedItems, onSelect] ); // Transparently renders the VirtualList, apart from: // - storing the selection // - passing the new selection back to the test return ( \u0026lt;VirtualList selectedItemIds={selectedItems} onSelect={handleSelect} // VirtualList props passed from the test {...virtualListProps} /\u0026gt; ); } it(\u0026#39;When two items are clicked pressing the meta button, then they are both selected\u0026#39;, () =\u0026gt; { // ------------------------------------------ // Arrange // creating the data const itemHeight = 30; const listHeight = 90; const items = [ { id: 1, name: \u0026#39;Item 1\u0026#39; }, { id: 2, name: \u0026#39;Item 2\u0026#39; }, { id: 3, name: \u0026#39;Item 3\u0026#39; }, ]; // mounting the component mount( \u0026lt;SelectableList // test-specific props onSelect={cy.spy().as(\u0026#39;onSelect\u0026#39;)} // VirtualList props items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={RenderItem} listHeight={listHeight} /\u0026gt; ); /* ... rest of the test ... */ }) 背景干扰仍然很高，但在阅读测试时你不会遇到它。然后，你是否注意到包装器的调用消耗从\nmount(\u0026lt;WithSelectionManagement testHandleSelect={cy.stub().as(\u0026#39;handleSelect\u0026#39;)} /\u0026gt;) 到\nmount( \u0026lt;SelectableList // test-specific props onSelect={cy.spy().as(\u0026#39;onSelect\u0026#39;)} // VirtualList props items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={RenderItem} listHeight={listHeight} /\u0026gt; ); ？目的是尽可能使代码与之前的更简单的测试相似。SelectableList 现在更透明，因为它只做了一件事情：存储先前的选择。\n拆解长的测试 系好安全带：除了包装器，旧测试如下：\nit(\u0026#39;When the items are clicked, then they are selected\u0026#39;, () =\u0026gt; { /* ... the code of the wrapper ... */ cy.then(() =\u0026gt; expect(testItems).to.have.length.greaterThan(0)) cy.wrap(testItems).then(() =\u0026gt; { cy.findByText(getItemText(testItems[0])).click() cy.get(\u0026#39;@handleSelect\u0026#39;).should(stub =\u0026gt; { expect(stub).to.have.been.calledOnce expect(stub).to.have.been.calledWith([testItems[0].id]) }) cy.findByText(getItemText(testItems[1])).click().window() cy.get(\u0026#39;@handleSelect\u0026#39;).should(stub =\u0026gt; { expect(stub).to.have.been.calledTwice expect(stub).to.have.been.calledWith([testItems[1].id]) }) cy.get(\u0026#39;body\u0026#39;) .type(\u0026#39;{meta}\u0026#39;, { release: false }) .findByText(getItemText(testItems[2])) .click() .get(\u0026#39;@handleSelect\u0026#39;) .should(stub =\u0026gt; { expect(stub).to.have.been.calledThrice expect(stub).to.have.been.calledWith([testItems[1].id, testItems[2].id]) }) .get(\u0026#39;body\u0026#39;) .type(\u0026#39;{meta}\u0026#39;, { release: true }) cy.get(\u0026#39;body\u0026#39;) .type(\u0026#39;{shift}\u0026#39;, { release: false }) .findByText(getItemText(testItems[0])) .click() .get(\u0026#39;@handleSelect\u0026#39;) .should(stub =\u0026gt; { expect(stub).to.have.been.callCount(4) expect(stub).to.have.been.calledWith([testItems[2].id, testItems[1].id, testItems[0].id]) }) .get(\u0026#39;body\u0026#39;) .type(\u0026#39;{shift}\u0026#39;, { release: true }) cy.get(\u0026#39;body\u0026#39;) .type(\u0026#39;{alt}\u0026#39;, { release: false }) .findByText(getItemText(testItems[1])) .click() .get(\u0026#39;@handleSelect\u0026#39;) .should(stub =\u0026gt; { expect(stub).to.have.been.callCount(5) expect(stub).to.have.been.calledWith([testItems[2].id, testItems[0].id]) }) .get(\u0026#39;body\u0026#39;) .type(\u0026#39;{alt}\u0026#39;, { release: true }) fastScrollVirtualList().then(() =\u0026gt; { const firstRenderedItemIndex = getFirstRenderedItemIndex(testItems, getItemText) const firstRenderedItem = testItems[firstRenderedItemIndex] const expectedSelectedItemIds = testItems .slice(0, firstRenderedItemIndex + 1) .map(item =\u0026gt; item.id) cy.get(\u0026#39;body\u0026#39;) .type(\u0026#39;{shift}\u0026#39;, { release: false }) .findByText(getItemText(firstRenderedItem)) .click() .get(\u0026#39;@handleSelect\u0026#39;) .should(stub =\u0026gt; { expect(stub).to.have.been.callCount(6) expect(stub).to.have.been.calledWith(expectedSelectedItemIds) }) .get(\u0026#39;body\u0026#39;) .type(\u0026#39;{shift}\u0026#39;, { release: true }) }) }) }) 现在看来，看起来有点奇怪的地方：\ncy.then(() =\u0026gt; expect(testItems).to.have.length.greaterThan(0))，因为项目是动态生成的，我在外部函数出现问题时中止了测试。 cy.findByText(getItemText(testItems[0])).click() 太过动态，testItems[0] 包含什么？ fastScrollVirtualList().then(() =\u0026gt; { /* ... */ } 的内容 😩 测试本身的长度。 不清楚测试一种选择类型在哪里结束，下一个选择类型在哪里开始。 让我们首先通过将一个包含四种选择的测试拆分为四个测试来消除对这样一个长测试的需求。\n单选 猜猜看？测试简单的选择根本不需要包装器 😊\nit(\u0026#39;When an item is clicked, then it is selected\u0026#39;, () =\u0026gt; { // ------------------------------------------ // Arrange // creating the spy // a spy is needed to intercept the call the VirtualList does const onSelectSpy = cy.spy().as(\u0026#39;onSelect\u0026#39;); // creating the data const items = [ { id: 1, name: \u0026#39;Item 1\u0026#39; }, { id: 2, name: \u0026#39;Item 2\u0026#39; }, { id: 3, name: \u0026#39;Item 3\u0026#39; }, ]; // mounting the component mount( \u0026lt;VirtualList items={items} getItemHeights={() =\u0026gt; 30} RenderItem={RenderItem} listHeight={90} onSelect={onSelectSpy} /\u0026gt; ); // ------------------------------------------ // Act cy.findByText(\u0026#39;Item 1\u0026#39;).click(); // ------------------------------------------ // Assert cy.get(\u0026#39;@onSelect\u0026#39;).should((spy) =\u0026gt; { expect(spy).to.have.been.calledOnce; // Sinon matchers allow to assert about partials of the params // see // https://sinonjs.org/releases/latest/assertions/ // https://sinonjs.org/releases/latest/matchers/ expect(spy).to.have.been.calledWith( Cypress.sinon.match({ newSelectedIds: [1] }) ); expect(spy).to.have.been.calledWith( Cypress.sinon.match({ item: { id: 1, name: \u0026#39;Item 1\u0026#39; } }) ); }); }); 与旧测试的第一部分相比，最显著的变化：\n不再需要包装器。 不再有动态值。 更有表现力的断言。 这是一个单一目的的测试。 累加和减去选择 在这里，我们需要利用包装器。\nit(\u0026#39;When two items are clicked pressing the meta button, then they are both selected\u0026#39;, () =\u0026gt; { // ------------------------------------------ // Arrange // creating the data const itemHeight = 30; const listHeight = 90; const items = [ { id: 1, name: \u0026#39;Item 1\u0026#39; }, { id: 2, name: \u0026#39;Item 2\u0026#39; }, { id: 3, name: \u0026#39;Item 3\u0026#39; }, ]; // mounting the component mount( // mount `SelectableList`instead of `VirtualList` \u0026lt;SelectableList // test-specific props onSelect={cy.spy().as(\u0026#39;onSelect\u0026#39;)} // VirtualList props items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={RenderItem} listHeight={listHeight} /\u0026gt; ); // ------------------------------------------ // click on the first item // Act cy.findByText(\u0026#39;Item 1\u0026#39;) .click() // Assert .get(\u0026#39;@onSelect\u0026#39;) .should((spy) =\u0026gt; { expect(spy).to.have.been.calledOnce; expect(spy).to.have.been.calledWith({ newSelectedIds: [1] }); }); // ------------------------------------------ // click on the second item // Act // keep the meta button pressed cy.get(\u0026#39;body\u0026#39;).type(\u0026#39;{meta}\u0026#39;, { release: false }); cy.findByText(\u0026#39;Item 2\u0026#39;) .click() // Assert .get(\u0026#39;@onSelect\u0026#39;) .should((spy) =\u0026gt; { expect(spy).to.have.been.calledTwice; expect(spy).to.have.been.calledWith({ newSelectedIds: [1, 2] }); }); }); 这里的巨大差异在于避免滚动，因为它不影响累加选择。再次出现显式值，清晰度和简洁性允许进行更直观和更有表现力的测试。\n测试减去选择遵循相同的模式。我在这里不报告它。\n范围选择 与之前的选择相比，我认为范围选择 可能会 受到滚动列表的影响，因为一些将被选择的项目不再呈现。如何使本质上是动态的东西——滚动列表——更加静态？通过手动测试和一些注释。\nit(\u0026#39;When the list is scrolled amd some items are clicked pressing the shift button, then the range selection works\u0026#39;, () =\u0026gt; { // ------------------------------------------ // Arrange // creating the data const items = [ { id: 1, name: \u0026#39;Item 1\u0026#39; }, { id: 2, name: \u0026#39;Item 2\u0026#39; }, { id: 3, name: \u0026#39;Item 3\u0026#39; }, { id: 4, name: \u0026#39;Item 4\u0026#39; }, { id: 5, name: \u0026#39;Item 5\u0026#39; }, { id: 6, name: \u0026#39;Item 6\u0026#39; }, { id: 7, name: \u0026#39;Item 7\u0026#39; }, { id: 8, name: \u0026#39;Item 8\u0026#39; }, { id: 9, name: \u0026#39;Item 9\u0026#39; }, { id: 10, name: \u0026#39;Item 10\u0026#39; }, { id: 11, name: \u0026#39;Item 11\u0026#39; }, { id: 12, name: \u0026#39;Item 12\u0026#39; }, { id: 13, name: \u0026#39;Item 13\u0026#39; }, { id: 14, name: \u0026#39;Item 14\u0026#39; }, { id: 15, name: \u0026#39;Item 15\u0026#39; }, { id: 16, name: \u0026#39;Item 16\u0026#39; }, { id: 17, name: \u0026#39;Item 17\u0026#39; }, { id: 18, name: \u0026#39;Item 18\u0026#39; }, { id: 19, name: \u0026#39;Item 19\u0026#39; }, { id: 20, name: \u0026#39;Item 20\u0026#39; }, ]; // only 3 items are visible const itemHeight = 30; const listHeight = 90; // mounting the component mount( \u0026lt;SelectableList // test-specific props onSelect={cy.spy().as(\u0026#39;onSelect\u0026#39;)} // VirtualList props items={items} getItemHeights={() =\u0026gt; itemHeight} RenderItem={RenderItem} listHeight={listHeight} /\u0026gt; ); // Act // click on the first item cy.findByText(\u0026#39;Item 1\u0026#39;).click(); // scroll the list cy.findAllByTestId(\u0026#39;VirtualList\u0026#39;).first().trigger(\u0026#39;wheel\u0026#39;, { deltaX: 0, deltaY: 200, }); cy.get(\u0026#39;body\u0026#39;).type(\u0026#39;{shift}\u0026#39;, { release: false }); // Item 7, 8, 9, and 10 are going to be visible after the scroll // click on the 10th item. It\u0026#39;s going to be clicked as soon as it\u0026#39;s in the DOM and clickable cy.findByText(\u0026#39;Item 10\u0026#39;) .click() // Assert .get(\u0026#39;@onSelect\u0026#39;) .should((spy) =\u0026gt; { expect(spy).to.have.been.calledTwice; expect(spy).to.have.been.calledWith({ newSelectedIds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] }); }); }); 这里可能发生的最糟糕的事情是，在触发 wheel 事件时，VirtualList 的滚动逻辑滚动得更少或更多。\ncy.findAllByTestId(\u0026#39;VirtualList\u0026#39;).first().trigger(\u0026#39;wheel\u0026#39;, { deltaX: 0, deltaY: 200, }); 但如果发生了，由于有注释，读者会清楚地知道出了什么问题 😊\n相关的文章 🔗 保持低抽象度以便于调试测试 由NoriSte在dev.to进行联合发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-real-life-examples-from-unreadable-react-component-tests-to-simple-ones/","summary":"这篇博文是 UI 测试最佳实践的真实案例篇，第二篇从难以理解的 React 组件测试到简单愚蠢的测试。文章分享了在 React 组件测试中遇到的挑战，并提供了简化和优化测试的实际案例。通过这个真实案例，读者将学到如何通过简单愚蠢的测试方法，更轻松地理解和维护 React 组件的测试代码，提高测试的可读性和可维护性。","title":"UI 测试最佳实践的真实案例篇（二）：从难以理解的 React 组件测试到简单愚蠢的测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n真实案例：用集成测试测试前端，用 E2E 测试测试后端 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/real-life-examples/test-front-end-with-integration-back-end-with-e2e.md\n一段简要说明 使用带有存根服务器的 UI 测试相对于完整的 E2E 测试来说，不仅更加可靠，而且速度更快。\n尽管完整的 E2E 测试仍然提供了最高的信心水平，但代价很高：易碎、潜在不可靠且速度较慢。\n通过使用成本较低的 UI 集成测试，我们仍然可以在前端获得高信心水平，并将成本较高的 E2E 测试留给后端。\n示例测试架构图 这是来自实际的建筑控制云应用程序的高层次架构视图。\nAngular 前端 Node-Express API（后端） 服务（Go lambdas）（后端） 硬件（后端） 根据需求，可以通过纯 API 测试来补充 UI-E2E 测试。一些常用的 API 测试工具包括 Postman，VS Code 的 Rest Client，以及 Cypress。\n请注意：以下所有示例均使用 Cypress，目前它在 XHR 测试支持方面是最优秀的。在现有的测试工具中，完整的 XHR 请求等待和检查并不常见，Cypress 目前提供了最全面的检查支持。\n代码示例：登录测试 以下示例包含两个测试，用于覆盖登录功能。第一个测试使用 UI 集成测试覆盖前端应用程序，第二个测试使用 E2E 测试覆盖后端。\n/** function to fill username, password and Login*/ const fillFormAndClick = ({ username, password }) =\u0026gt; { .. }; // This is an UI integration test with server stubbing. // Remember to write a few E2E tests and a lot of integration ones // @see https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/testing-strategy/component-vs-integration-vs-e2e-testing.zh.md#ui-integration-tests it(\u0026#34;Login: front-end integration tests\u0026#34;, () =\u0026gt; { // A route that intercepts / sniffs every POST request that goes to the authentication URL. // Stubs the response with authentication-success.json fixture. This is called server stubbing cy.intercept({ method: \u0026#34;POST\u0026#34;, fixture: \u0026#34;authentication/authentication-success.json\u0026#34;, // Stubs the response url: `**${AUTHENTICATE_API_URL}` }).as(\u0026#34;auth-xhr\u0026#34;); fillFormAndClick(USERNAME_PLACEHOLDER, PASSWORD_PLACEHOLDER); // wait for the POST XHR cy.wait(\u0026#34;@auth-xhr\u0026#34;).then(interception =\u0026gt; { // assert the payload body that the front end is sending to the back-end expect(interception.request.body).to.have.property(\u0026#34;username\u0026#34;, username); expect(interception.request.body).to.have.property(\u0026#34;password\u0026#34;, password); // assert the request headers in the payload expect(interception.request.headers).to.have.property(\u0026#39;Content-Type\u0026#39;, \u0026#39;application/json;charset=utf-8\u0026#39;); }); // finally, the user must see the feedback cy.getByText(SUCCESS_FEEDBACK).should(\u0026#34;be.visible\u0026#34;); }); // this is a copy of the integration test but without server stubbing. it(\u0026#34;Login: back-end E2E tests\u0026#34;, () =\u0026gt; { // A route that intercepts / sniffs every POST request that goes to the authentication URL. // Distinction: this is NOT stubbed! cy.intercept({ method: \u0026#34;POST\u0026#34;, url: `**${AUTHENTICATE_API_URL}` }).as(\u0026#34;auth-xhr\u0026#34;); fillFormAndClick(USERNAME_PLACEHOLDER, PASSWORD_PLACEHOLDER); cy.wait(\u0026#34;@auth-xhr\u0026#34;).then(interception =\u0026gt; { // since the integration tests already tested the front-end app, we use E2E tests to check the // back-end app. It needs to ensure that the back-end app works and gets the correct response data // response body assertions and status should be in the E2E tests since they rely on the server expect(interception.status).to.equal(200); expect(interception.response.body).to.have.property(\u0026#34;token\u0026#34;); }); // finally, the user must see the feedback cy.getByText(SUCCESS_FEEDBACK).should(\u0026#34;be.visible\u0026#34;); }); 代码示例 2：将 UI 集成测试切换为 UI-E2E 测试 有时候，您可能希望将 UI 集成测试切换为 E2E 测试。\n在较低级别的测试层面，例如仅将测试隔离到 UI 代码时，您可能更愿意使用经济高效的 UI 集成测试。\n而在较高级别的测试层面，例如与中间层服务集成时，您可能需要更高的信心水平，将测试目标定位到后端。\n通过使用条件存根，您可以在 UI 集成测试和 E2E 测试之间切换关注。\n// stub-services.js : a file that only includes a function to stub the back-end services export default function() { // all routes to the specified endpoint will respond with pre-packaged Json data cy.intercept(\u0026#39;/api/../me\u0026#39;, {fixture:\u0026#39;services/me.json\u0026#39;}); cy.intercept(\u0026#39;/api/../permissions\u0026#39;, {fixture:\u0026#39;services/permissions.json\u0026#39;}); // Lots of other fixtures ... } // spec file: import stubServices from \u0026#39;../../support/stub-services\u0026#39;; /** isLocalhost is a function that checks the configuration environment*/ const isLocalHost = () =\u0026gt; Cypress.env(\u0026#39;ENVIRONMENT\u0026#39;) === \u0026#34;localhost\u0026#34;; // ... in your tests, or in before / beforeEach blocks, // stub the services if you are testing front-end (UI integration tests) // do not stub if you are testing the back-end (UI-E2E tests) if (isLocalHost()) { stubServices(); } 参考资料 熟练掌握 UI 测试 - 会议视频 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-real-life-examples-test-front-end-with-integration-back-end-with-e2e/","summary":"这篇博文是 UI 测试最佳实践的真实案例篇，首篇讨论了通过集成测试测试前端，以及利用 E2E 测试测试后端的实际案例。文章深入介绍了在项目中如何结合不同类型的测试来确保整个应用程序的稳定性和功能完整性。通过这个真实案例，读者将了解在实际项目中如何灵活运用 UI 测试最佳实践，提高测试的全面性和质量。","title":"UI 测试最佳实践的真实案例篇（一）：用集成测试测试前端，用 E2E 测试测试后端"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n邮件测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/email-testing.md\n一段简要说明 电子邮件测试对于业务成功至关重要，能够提升电子邮件的表现。在测试 Web 应用时，我们绝不希望忽略这一点，因为现代电子邮件服务使得自动化电子邮件测试变得轻而易举。通常，电子邮件测试包括验证电子邮件字段（发件人、收件人、抄送、密送、主题、附件）、HTML 内容以及电子邮件中的链接。电子邮件服务还支持垃圾邮件检查和视觉检查。\n其核心目标在于实现端到端测试的最后一步，确保典型的 Web 应用能够从头到尾得到全面测试。\n以一个场景为例，用户收到来自组织的电子邮件邀请，可以是通过公司专有服务或第三方平台，比如 LinkedIn 邀请。接着，用户验证电子邮件内容，接受邀请，并加入该组织。随后，用户可以选择离开组织，或者被管理员移除，然后再次收到另一封电子邮件通知。通过电子邮件服务，这一需求的整个过程可以在短短几秒钟内自动完成和执行。\n值得注意的是，电子邮件测试是 SaaS 测试架构的基础，通过允许无状态测试来实现可伸缩性，这些测试能够独立处理其状态，并能够同时由多个实体执行。详细讨论请参阅 测试状态。\n前言 如果你正在使用Gmail 技巧或AWS Simple Email Service，并且这些用例在没有任何副作用的情况下能够满足你的测试需求，那么可能只有topic 1对你感兴趣。\n市面上有很多电子邮件测试解决方案，以及与它们集成的测试框架的组合。在代码片段和实际示例中，我们将使用Cypress和Mailosaur，但这些思想通常适用于任何电子邮件服务和测试自动化框架的组合。\n在使用 Cypress 与 Mailosaur 时，有三种测试开发方法：\n利用 Cypress API 测试功能实现Mailosaur API，使用cy.request()或cy.api()。利用插件和辅助工具构建测试套件。\n利用Mailosaur 的 Node 包并使用cy.task()实现，该方法允许在 Cypress 内运行 Node。\n使用Cypress Mailosaur 插件并将所有复杂性抽象掉！\n请查看cypress-mailosaur-recipe以获取这些方法的实际示例。请注意，你将需要启动一个新的 Mailosaur 试用账户并替换自己的环境变量。\n(1) 解释 \u0026amp; 代码示例 - 启用无状态、可伸缩的测试 在任何现代 Web 应用测试中，能够实现可伸缩的无状态测试是至关重要的。我们追求的是那些能够独立处理其状态，并能够同时由 n 个实体执行的测试。\n在测试 SaaS 应用程序时，通常会涉及订阅、用户、组织等通用概念（例如Slack，Cypress Dashboard Service等），很多端到端工作流可能依赖于拥有唯一用户。否则，一次只能执行一个测试，并且可能与其他同时进行的测试执行发生冲突。这种约束将测试自动化限制在定时作业或手动触发的 CI 中。\n解决唯一用户问题的一些方法包括利用Gmail 技巧或AWS Simple Email Service。如果你只想要唯一的用户而不必检查实际的电子邮件内容（发件人、收件人、抄送、密送、主题、附件等），那么使用无状态测试是正确的路径。\n然而，这些方法仍然可能存在问题；例如，不存在的电子邮件可能导致回送邮件到你的云服务，这可能会让人头疼不已。如果你想要避免这些问题并在自动化中检查实际的电子邮件内容，电子邮件服务提供了有价值的功能。\n电子邮件服务还可以通过更快地接收电子邮件，在流水线中更快地运行测试，消耗更少的 CI 资源以及减少等待测试完成的时间，为测试执行时间提供成本节省。例如，如果你每年运行 1000 个流水线，并每个流水线执行节省 3-4 秒，电子邮件服务可能已经通过提供额外的速度来支付其年度订阅费用。\n实现具有唯一电子邮件的无状态测试 如果每次测试执行都使用一个新的、唯一的用户，并且可以单独验证发送给这个唯一用户的电子邮件，那么就可以实现无状态测试。唯一的副作用将仅影响电子邮件服务的收件箱，但如果测试只通过引用检查电子邮件并在测试结束后进行清理，电子邮件服务的邮箱将不受影响。\n通过 Mailosaur 实现这一点非常容易，以下是两种方法：Mailosaur 的 Node 包或使用faker.js创建我们自己的工具。\n// at cypress/plugins/mailosaur-tasks.js // generates a random email address // sample output: ojh788.\u0026lt;serverId\u0026gt;@mailosaur.io const createEmail = () =\u0026gt; mailosaurClient .servers .generateEmailAddress(envVars.MAILOSAUR_SERVERID); ); // our custom function at a helper file or commands file. The only difference is the defined prefixed name. // sample output: fakerJsName.\u0026lt;serverId\u0026gt;@mailosaur.io const createMailosaurEmail = randomName =\u0026gt; `${randomName}.${Cypress.env(\u0026#39;MAILOSAUR_SERVERID\u0026#39;)}@mailosaur.io`; (2) 解释 - 在电子邮件中进行何种测试以及如何进行测试 首先，让我们详细说明我们需要的设置。\n测试设置和混合方法 Mailosaur Rest API 使用 cy.request() 和 Mailosaur 的 Node 包 使用 cy.task()\nMailosaur 提供了一个npm 包，实际上API 文档中的所有 Node 代码示例都可以转换为cy.task()。另一种方法是使用cy.request()从零开始实现 Mailosaur 的 Rest API。\nMailosaur 在 2020 年中发布了Cypress Mailosaur 插件，它通过这两种方法抽象出所有复杂性。请跳到最后查看代码示例和比较。\n环境变量 我们建议将以下值设置为环境变量。你可以通过使用任何电子邮件地址创建一个免费试用帐户，并从 Mailosaur Web 应用程序中获取这些值。试用帐户的有效期为两周。\n\u0026#34;MAILOSAUR_SERVERID\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;MAILOSAUR_PASSWORD\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;MAILOSAUR_API_KEY\u0026#34;: \u0026#34;*******\u0026#34;, \u0026#34;MAILOSAUR_API\u0026#34;: \u0026#34;https://mailosaur.com/api\u0026#34;, \u0026#34;MAILOSAUR_SERVERNAME\u0026#34;: \u0026#34;user-configurable-server-name\u0026#34; 模块化 cy.task() 你可以将所有实用工具放在cypress/plugins/index.js文件中，就像在此示例中一样。更整洁的方法是将所有与 Mailosaur 相关的任务放在其自己的模块中，并将它们导入到插件文件中。\n// cypress/plugins/index.js const task = require(\u0026#39;some-plugin/task\u0026#39;) const percyHealthCheck = require(\u0026#39;@percy/cypress/task\u0026#39;) // or any other plugin you may need const mailosaurTasks = require(\u0026#39;./mailosaur-tasks\u0026#39;) // our mailosaur module // This is a pattern to merge all Cypress tasks const all = Object.assign({}, percyHealthCheck, task, mailosaurTasks) module.exports = (on, config) =\u0026gt; { on(\u0026#39;task\u0026#39;, all) } //////// // cypress/plugins/mailosaur-tasks.js (this could be anywhere) // the npm package const MailosaurClient = require(\u0026#39;mailosaur\u0026#39;) // we used a static file for envVars. cypress.env.json file can cause issues in CI // There can be other solutions, do your best here. const envVars = require(\u0026#39;../../cypress.json\u0026#39;) const mailosaurClient = new MailosaurClient(envVars.MAILOSAUR_API_KEY) // replicate Mailosaur\u0026#39;s npm code from api docs // https://docs.mailosaur.com/docs/fetching-messages /** finds the most recent email message to the given email*/ const findEmailToUser = async (userEmail) =\u0026gt; { let message = await mailosaurClient.messages.get( envVars.MAILOSAUR_SERVERID, { sentTo: userEmail, }, { timeout: 25000 } ) // time to wait for an email to arrive return message } // other useful utilities can include the below. You can replicate them using the api docs. // checkServerName() // createEmail() // deleteAMessage(messageId) // listAllMessages() module.exports = { checkServerName, createEmail, findEmailToUser, listAllMessages, deleteAMessage } 其他有用的辅助函数，Mailosaur npm 包目前似乎不提供（据我们所知） 我们可以将 Rest API / cy.request()方法与 npm 包 / cy.task()方法协调一致，以构建我们自己的实用程序。\n/** Given user email, returns the id of the email to that user. Good example of hybrid utility functions */ const getEmailId = (email) =\u0026gt; cy.task(\u0026#39;findEmailToUser\u0026#39;, email).its(\u0026#39;id\u0026#39;) /** Deletes 1 email message by message id. Can be useful if you want to delete the message after running the test. */ const deleteEmailById = (id) =\u0026gt; { return cy.request({ method: \u0026#39;DELETE\u0026#39;, url: `${Cypress.env(\u0026#39;MAILOSAUR_API\u0026#39;)}/messages/${id}`, headers: { // important detail authorization: Cypress.env(\u0026#39;MAILOSAUR_PASSWORD\u0026#39;), }, auth: { // important detail user: Cypress.env(\u0026#39;MAILOSAUR_API_KEY\u0026#39;), password: \u0026#39;\u0026#39;, // any pw or empty pw will do }, retryOnStatusCodeFailure: true, // because we can }) } /** Deletes the most recent email sent to the user. Useful for resetting state. */ export const deleteEmail = (email) =\u0026gt; getEmailId(email).then((id) =\u0026gt; deleteEmailById(id)) (3) 代码示例 - 在电子邮件中进行何种测试以及如何进行测试 验证电子邮件字段（发件人、收件人、抄送、密送、主题、附件）、电子邮件中的 HTML 内容和链接。\n// an invite goes out to the recipient from the sender... // in the cypress spec file \u0026gt; it block... cy.task(\u0026#39;findEmailToUser\u0026#39;, recipientEmail).then(emailContent =\u0026gt; { cy.wrap(emailContent).its(\u0026#39;from\u0026#39;)..\u0026lt;chain as needed\u0026gt;.should(\u0026#39;eq\u0026#39;, senderEmail); // from cy.wrap(emailContent).its(\u0026#39;to\u0026#39;)..\u0026lt;chain as needed\u0026gt;.should(..)// to cy.wrap(emailContent).its(\u0026#39;cc\u0026#39;)..\u0026lt;chain as needed\u0026gt;.should(..); // cc cy.wrap(emailContent).its(\u0026#39;subject\u0026#39;)..\u0026lt;chain as needed\u0026gt;.should(..); // subject // similar approach with attachments. // You can always end with ... .then(console.log) to take a look at the content // of you can check out the mailosaur email as JSON content, which makes everything easier! // cy.wrap(emailContent).then(console.log); // sample utilities to check assertions const html = () =\u0026gt; cy.wrap(emailContent).its(\u0026#39;html\u0026#39;); const htmlLinks = () =\u0026gt; html().its(\u0026#39;links\u0026#39;); const images = html().its(\u0026#39;images\u0026#39;); htmlLinks().should(..); // or chain further images().should(..); // note that you can use different styles of api assertions with Cypress // check out api testing examples at // https://github.com/cypress-io/cypress-example-recipes/tree/master/examples/blogs__e2e-api-testing // https://github.com/muratkeremozcan/cypressExamples/blob/master/cypress-api-testing/cypress/integration/firstTest.spec.js }); (4) 这个开销被Cypress Mailosaur 插件抽象掉了 Mailosaur 团队在 2020 年中发布了一个 Cypress 插件。通过使用它，我们无需复制任何复杂的 API 工具，也无需使用 Mailosaur npm 包通过 cy.task 进行操作；在第（3）节中看到的内容都是不必要的。没有必要创建 cy.task 实用程序，甚至不需要混合它们。使用 Cypress Mailosaur 插件，你只需使用 Mailosaur 团队为我们创建的自定义 Cypress 命令。\n我们只需安装npm install cypress-mailosaur --save-dev并在 cypress/support/index.js 中添加以下行： import 'cypress-mailosaur'。\nMailosaur 插件有一些方便的函数，可以帮助你抽象出复杂的需求。 完整列表可以在 https://github.com/mailosaur/cypress-mailosaur 上找到\n以下是上述代码的插件版本。使用方式有些类似，但我们无需实现任何 cy.task() 实用程序、自定义帮助函数或混合帮助程序。我们还获得了新的、易于使用的辅助函数，可以无缝运行。\n你可以在链接中找到这个代码和上面的工作版本。\nit(\u0026#39;uses the plugin to check the email content (no need for creating complex utilities with cy.task) \u0026#39;, function () { const userEmail = createEmail(internet.userName()); cy.task(\u0026#39;sendSimpleEmail\u0026#39;, userEmail); // an npm package to send emails, usually your app would do this // a convenient helper functions to list mesages cy.mailosaurListMessages(Cypress.env(\u0026#39;MAILOSAUR_SERVERID\u0026#39;)).its(\u0026#39;items\u0026#39;).its(\u0026#39;length\u0026#39;).should(\u0026#39;not.eq\u0026#39;, 0); // this helper command replaces the complex cy.task(\u0026#39;findEmailToUser\u0026#39;) utility we had to create cy.mailosaurGetMessage( Cypress.env(\u0026#39;MAILOSAUR_SERVERID\u0026#39;), { sentTo: userEmail }, // note from Jon at Mailosaur: // The get method looks for messages received within the last hour // if looking for emails existing before that, you have to add this. Optional otherwise // { receivedAfter: new Date(\u0026#39;2000-01-01\u0026#39;) } ).then(emailContent =\u0026gt; { // this part is the same cy.wrap(emailContent).its(\u0026#39;from\u0026#39;).its(0).its(\u0026#39;email\u0026#39;).should(\u0026#39;contain\u0026#39;, \u0026#39;test@nodesendmail.com\u0026#39;); cy.wrap(emailContent).its(\u0026#39;to\u0026#39;).its(0).its(\u0026#39;email\u0026#39;).should(\u0026#39;eq\u0026#39;, userEmail); cy.wrap(emailContent).its(\u0026#39;subject\u0026#39;).should(\u0026#39;contain\u0026#39;, \u0026#39;MailComposer sendmail\u0026#39;); }); // alternate approach to getting message by sent to\u0026#39; cy.mailosaurGetMessagesBySentTo(Cypress.env(\u0026#39;MAILOSAUR_SERVERID\u0026#39;), userEmail).then(emailItem =\u0026gt; { // the response is slightly different, but you can modify it to serve the same purpose const emailContent = emailItem.items[0]; cy.wrap(emailContent).its(\u0026#39;from\u0026#39;).its(0).its(\u0026#39;email\u0026#39;).should(\u0026#39;contain\u0026#39;, \u0026#39;test@nodesendmail.com\u0026#39;); cy.wrap(emailContent).its(\u0026#39;to\u0026#39;).its(0).its(\u0026#39;email\u0026#39;).should(\u0026#39;eq\u0026#39;, userEmail); cy.wrap(emailContent).its(\u0026#39;subject\u0026#39;).should(\u0026#39;contain\u0026#39;, \u0026#39;MailComposer sendmail\u0026#39;); }); // an easy to use bonus utility for checking spam score cy.mailosaurGetMessagesBySentTo(Cypress.env(\u0026#39;MAILOSAUR_SERVERID\u0026#39;), userEmail).its(\u0026#39;items\u0026#39;).its(0).its(\u0026#39;id\u0026#39;).then(messageId =\u0026gt; { // does convenient spam analysis cy.mailosaurGetSpamAnalysis(messageId).its(\u0026#39;score\u0026#39;).should(\u0026#39;eq\u0026#39;, 0); // you can observe the console output with a plain \u0026#34;cy.mailosaurGetSpamAnalysis(messageId); \u0026#34; and check for deeper assertions }) }); 参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-advanced-email-testing/","summary":"这篇博文是 UI 测试最佳实践的进阶篇，第三篇介绍邮件测试。文章深入研究了 UI 测试中邮件测试的重要性，以及如何有效地测试与邮件相关的功能。读者将学到如何验证邮件发送、接收和处理等功能，确保系统在邮件通信方面的准确性和可靠性。通过学习这个进阶实践，读者能够更全面地覆盖 UI 测试中与邮件相关的场景，提高测试的全面性和准确性。","title":"UI 测试最佳实践的进阶篇（三）：邮件测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n组合测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/combinatorial-testing.md\n组合测试一段简要说明 组合测试 是一种经过验证的、成本较低的、更为有效的软件测试方法。 这种测试的关键思想是，并非每个参数都对每次故障都有影响，而是大多数故障是由相对较少的参数之间的相互作用引起的。 与传统方法相比，测试参数组合可以更有效地检测故障。 美国国家标准与技术研究院NIST 在 1999 年到 2004 年进行的一系列研究表明，大多数软件缺陷和故障是由一个或两个参数引起的，逐渐减少到由三个或更多参数引起的。这一发现被称为“交互规则”，对软件测试具有重要意义，因为这意味着测试参数组合可以比传统方法更有效地检测故障。NIST 和其他机构收集的数据表明，软件故障仅由少数几个变量的相互作用引发（不超过六个）。有时使用成对（2 路组合）测试可以以较低的成本获得相当不错的结果，通常不低于 60% 的故障覆盖率，但这可能对于关键任务的软件来说可能不足够。\n(1) 代码示例 – 产品负责人问题 一位产品负责人曾提出一个问题：\n\u0026ldquo;从最佳实践或实际角度来看，你是否应该在每种可能的配置下测试系统？ 例如，假设你有 A、B、C、D、E 五个功能，客户 1 拥有 A/B，客户 2 拥有 A/B/C，客户 3 拥有 A/D，客户 4 拥有 B/D，客户 5 拥有 A/B/C/D/E\u0026hellip;. 你是否应该测试每种可能的功能组合，还是测试每个功能单独，如果它们在独立测试中能够正常工作，就相信它们整体上也能正常工作？\u0026rdquo;\n5 个客户和 5 个功能，详尽无遗将需要 25 个测试。 在描述的约束条件下，只需要 14 个测试。 为了提供一个代码示例，我们将使用描述规格的CTWedge脚本化组合模型。还有许多其他列在pairwise.org上的 CT 工具。我们（在西门子）使用过的其他一些工具包括ACTs和CAgen。\nModel POquestion Parameters: features : {A, B, C, D, E} customer: {1, 2, 3, 4, 5} Constraints: # customer = 1 =\u0026gt; features = A || features = B # # customer = 2 =\u0026gt; features = A || features = B || features = C # # customer = 3 =\u0026gt; features = A || features = D # # customer = 4 =\u0026gt; features = B || features = D # # customer = 5 =\u0026gt; features = A || features = B || features = C || features = D || features = E # 在这里粘贴脚本以生成结果 这里。\n测试的目标是检验参数之间的双向（或更多）相互作用。当只有两个参数时，收益并不太明显，因为这是一种穷举的方法。\n如果参数数量超过两个，对它们之间的双向交互进行覆盖将确保找到该领域可能存在的 60-99% 的所有潜在缺陷。三向交互为 90%，四向为 95%，五向为 97%，六向为 100%。\n在这个例子中，通过添加另一个参数，我们称之为 configuration，并假设有 5 种可能的配置 / 参数值。这将生成一个包含 125 个测试的详尽套件。\nModel POquestion Parameters: features : {A, B, C, D, E} customer: {1, 2, 3, 4, 5} configuration: {config1, config2, config3, config4, config5} Constraints: # customer = 1 =\u0026gt; features = A || features = B # # customer = 2 =\u0026gt; features = A || features = B || features = C # # customer = 3 =\u0026gt; features = A || features = D # # customer = 4 =\u0026gt; features = B || features = D # # customer = 5 =\u0026gt; features = A || features = B || features = C || features = D || features = E # 将其粘贴到 CTWedge 上，这将生成一个包含 31 个测试的测试套件。如果添加一些约束，表明某些特性不应该与某些配置一起工作，甚至可以进一步精简。\n请注意，组合测试的建模可以并且确实包含等价分区、边界值分析和其他技术。模型越准确，测试套件的故障检测能力就越强。\n(2) 代码示例 – NASA 的开关板共有 34 个开关 以 NASA 的一个例子为参考，有 34 个开关，每个开关可以处于打开或关闭的状态。要进行详尽的测试，有 170 亿种可能的组合方式。\n不必测试所有的 2^34 种可能性。通过使用组合测试进行建模，你可以根据风险做出经过计算的决策。\nModel NASAswitches Parameters: switch1: Boolean switch2: Boolean switch3: Boolean switch4: Boolean switch5: Boolean switch6: Boolean switch7: Boolean switch8: Boolean switch9: Boolean switch10: Boolean switch11: Boolean switch12: Boolean switch13: Boolean switch14: Boolean switch15: Boolean switch16: Boolean switch17: Boolean switch18: Boolean switch19: Boolean switch20: Boolean switch21: Boolean switch22: Boolean switch23: Boolean switch24: Boolean switch25: Boolean switch26: Boolean switch27: Boolean switch28: Boolean switch29: Boolean switch30: Boolean switch31: Boolean switch32: Boolean switch33: Boolean switch34: Boolean 在 CTWedge 中通过下拉菜单开关测试的相互作用次数。\n14 次测试：通过开关之间的 2 次相互作用引起的故障 - 可根据产品找到 60-99% 的所有潜在故障 33 次测试：通过开关之间的 3 次相互作用引起的故障 - 可根据产品找到 90-99% 的所有潜在故障 85 次测试：通过开关之间的 4 次相互作用引起的故障 - 可根据产品找到 95-99% 的所有潜在故障 220 次测试：通过开关之间的 5 次相互作用引起的故障 - 可找到超过 99% 的所有潜在故障 538 次测试：通过开关之间的 6 次相互作用引起的故障 - 可找到所有潜在故障的 100% (2) 代码示例 - 西门子楼宇操作员 CI 配置 参考上面的幻灯片链接或直播视频以获取有关如何使用CAMetrics测量组合覆盖率的详细说明。基本上，你可以使用任何组合测试工具生成一个 CSV 文件，然后将其拖放到 CAMetrics 中。之后，CAMetrics 可以为你提供各种组合覆盖率报告。\n请注意，将 CSV 转换为 JSON 非常简单，然后可以使用 JSON 文件在所选的任何测试框架中进行数据驱动测试。\nModel CI Parameters: deployment_UI : { branch, development, staging } deployment_API: { development, staging } spec_suite: { ui_services_stubbed, ui_services, ui_services_hardware, spot_check} browser: { chrome, electron, firefox } Constraints: // one extra constraint for firefox spot checks # browser=firefox \u0026lt;=\u0026gt; spec_suite=spot_check # // on staging, run all tests # spec_suite=ui_services_hardware \u0026lt;=\u0026gt; deployment_API=staging # // match dev vs dev, staging vs staging, and when on staging use Chrome # deployment_UI=development =\u0026gt; deployment_API=development # # deployment_UI=staging =\u0026gt; deployment_API=staging # # deployment_UI=staging \u0026amp;\u0026amp; deployment_API=staging =\u0026gt; browser=chrome # // when on branch, stub the services # deployment_UI=branch =\u0026gt; spec_suite=ui_services_stubbed # // do not stub the services when on UI development # deployment_UI=development =\u0026gt; spec_suite!=ui_services_stubbed # 组合测试参考资料和延伸阅读 自动化组合测试软件\n幻灯片 16-50：探讨自动化和组合纪律在辅助探索性测试方面的应用\n西门子工业公司建筑技术部实际组合测试方法的应用\n现代 Web 开发中组合测试的工业研究\n在大型组织中引入组合测试\n组合策略的输入参数建模\n组合模型中的常见模式\n等效类和两层覆盖阵的高效验证和同时测试\n性能测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/performance-testing.md\n性能测试一段简要说明 虽然性能测试是一个庞大的话题，但作为 Web 开发者，我们可以迅速从其核心原则中获益，以提升用户体验、满足功能和非功能需求（NFRs），并检测可能泄漏到生产环境中的不明确系统问题。\n(1) 通过 Lighthouse 确保用户体验 作为 Web 开发者，我们最关心的是用户对性能的感知。谢天谢地，Google 已经让这变得简单，并为我们提供了一个第三方权威评估我们 Web 应用程序的工具 - Lighthouse。\n\u0026ldquo;Lighthouse 是一个用于提高网页质量的开源自动化工具。你可以对任何网页运行它，无论是公开的还是需要身份验证的。它可以进行性能、可访问性、渐进式 Web 应用、SEO 等方面的审计。\u0026rdquo;\n在这个话题中，我们只关注性能，但你也应该考虑从 Lighthouse 的审计中获得关于渐进式 Web 应用、可访问性、搜索引擎优化和最佳实践的评估。\n入门很简单：Chrome \u0026gt; 开发者工具 \u0026gt; 审计 \u0026gt; Lighthouse。然后，生成报告。它会显示如下，并为你提供有关如何改善用户体验的详细指南。\n一旦进行了改进并达成了基线评级，您可以通过将 Lighthouse 纳入您的 CI 来防止回归。\n将 Lighthouse 添加为 node_module；npm i -D lighthouse 或 yarn add --dev lighthouse。 参考 Lighthouse Git 存储库 上的工作流示例。 防止性能评级（和/或其他评级）在开发人员提交代码时出现回归！ 使用 Cypress 集成 Lighthouse 如果你是 Cypress 用户，通过 cypress-audit 插件，你可以在 Cypress 测试中执行 Lighthouse 审计，以及 Pa11y 进行自动化的可访问性测试。\n除了通常的插件设置之外，你可能需要解决你的应用程序的跨域问题，直到 Cypress 官方支持它。\n以下是一个带有内联说明的示例测试。\n// Pass in optional configuration parameters for the Cypress test: // you may need to increase default timeout for the overall task, if you have a slow app. Mind that Lighthouse is only for Chromium based browsers describe(\u0026#39;Lighthouse audit \u0026#39;, { taskTimeout: 90000, browser: \u0026#39;chrome\u0026#39; }, () =\u0026gt; { before(() =\u0026gt; { // if you are using programmatic login, you might not need to use the cy.forceVisit(\u0026#39;/\u0026#39;) workaround for cross-origin (linked above) cy.login(Cypress.env(\u0026#39;USERNAME\u0026#39;), Cypress.env(\u0026#39;PASSWORD\u0026#39;)); }); // thresholds is the first argument to cy.lighthouse(), most of the performance configuration is done here. // a complete list of Lighthouse parameters to use as thresholds can be found at https://github.com/mfrachet/cypress-audit/blob/master/docs/lighthouse.md // for an explanation of the parameters, refer to https://web.dev/lighthouse-performance/ const thresholds = { \u0026#39;first-contentful-paint\u0026#39;: 20000, \u0026#39;largest-contentful-paint\u0026#39;: 35000, \u0026#39;first-meaningful-paint\u0026#39;: 20000, \u0026#39;speed-index\u0026#39;: 25000, interactive: 40000, performance: 5, accessibility: 50, \u0026#39;best-practices\u0026#39;: 50, seo: 50, pwa: 20 }; // the 2nd, and optional argument to cy.lighthouse() replicates Lighthouse CLI commands https://github.com/GoogleChrome/lighthouse#cli-options const desktopConfig = { formFactor: \u0026#39;desktop\u0026#39;, screenEmulation: { disabled: true } }; // your app may need this beforeEach and afterEach workaround for cross-origin (linked above) beforeEach(() =\u0026gt; { cy.restoreLocalStorage(); // Preserve Cookies between tests Cypress.Cookies.defaults({ preserve: /[\\s\\S]*/ }); }); afterEach(() =\u0026gt; { cy.saveLocalStorage(); }); it(\u0026#39;should pass audit for main page \u0026#39;, () =\u0026gt; { cy.lighthouse(thresholds, desktopConfig); }); it(\u0026#39;should pass audit for another page\u0026#39;, () =\u0026gt; { cy.forceVisit(\u0026#39;anotherUrl\u0026#39;); cy.lighthouse(thresholds, desktopConfig); }); }); // Commands for working around cross origin, if needed // -- Save localStorage between tests let LOCAL_STORAGE_MEMORY = {}; Cypress.Commands.add(\u0026#39;saveLocalStorage\u0026#39;, () =\u0026gt; { Object.keys(localStorage).forEach(key =\u0026gt; { LOCAL_STORAGE_MEMORY[key] = localStorage[key]; }); }); Cypress.Commands.add(\u0026#39;restoreLocalStorage\u0026#39;, () =\u0026gt; { Object.keys(LOCAL_STORAGE_MEMORY).forEach(key =\u0026gt; { localStorage.setItem(key, LOCAL_STORAGE_MEMORY[key]); }); }); // -- Visit multiple domains in one test Cypress.Commands.add(\u0026#39;forceVisit\u0026#39;, url =\u0026gt; { cy.window().then(win =\u0026gt; win.open(url, \u0026#39;_self\u0026#39;)); }); (2) 性能作为一种非功能性需求和 Kano 模型 我们可以通过Kano 模型开始建立对性能需求的理解。\n\u0026ldquo;Kano 模型是在 1980 年代由日本学者狩野纪明教授开发的产品开发和客户满意度理论，将客户偏好分为五类。\u0026rdquo;\n从高层次上看，卡诺模型总结了性能特性是标准要求，是任何竞争性产品所期望的。这与我们使用 Lighthouse 的方式重叠；通过它，我们确保满足客户偏好，并确保我们不会回退。\n在这一点上，我们已经满足了明确说明的性能要求。然而，在复杂的应用程序中，我们还需要注意非功能性需求（NFRs）。但是，什么是 NFRs 呢？下面是它们在一瞥之下的高层次视图 - 来自双重标准的ISO/IEC 25010 产品质量模型。\n在下一节中，让我们专注于 NFRs 如何帮助我们进行非功能性能测试的方法。\n(3) 性能测试的类型 为了实际应用，我们可以将非功能性能测试分为 3 个类别\nLoad 负载测试 Spike 尖峰测试 Endurance 耐久测试 这张图总结了它们的上下文：\n关于基准测试和压力测试的额外说明: 本质上，基准测试归结为逐步的步骤，因为我们逐渐了解我们的系统，这成为了初始工作流程的一部分，其中使用自动化工具；\u0026ldquo;我的系统已经崩溃了吗？没有？那我再增加一点\u0026rdquo;。而压力测试，简而言之，就是做得过火了。\n那么可扩展性测试的区别是什么？它是相关的；区别在于系统何时开始以不令人满意的方式不响应的评估。通常情况下，使用自动化工具的方法足够接近，并且可以在负载测试中分析图表时实现。\n这是可扩展性测试意图的高层次图：\n(4) 使用 k6-loadImpact 进行性能测试的实际应用 k6-loadImpact在 Web 开发领域有两个显著的特点。\n使用 JS（ES6） 专为 CI 构建 额外的好处：如果你习惯使用 Postman，你可以轻松地将这些测试转换为 k6。 K6 可以 进行 DOM 测试，但我们认为 Lighthouse 已经处理了这方面的问题。K6 真正强大的地方在于测试 API 时。\n你可以在这里找到使用 k6 的快速入门示例。 这些示例从非常简单的开始，旨在快速建立理解。它们已经准备好直接运行和调整。我们将不会在这里重复这些知识。\n相反，在本节中，我们将概述 k6 测试的概览，并稍后展示一个代码示例，演示如何配置 k6 以适应不同类型的性能测试。\n// k6 lifecycle overview: // 1. init code -\u0026gt; runs once // this is where we configure the type of performance testing (there are also // additional options we do not cover here) export let options = { // there will be 1 virtual user vus: 1, // default function() will execute 1 time. This simple config // is best when trying to get things to work iterations: 1, } // 2. (optional) setup code -\u0026gt; runs once export function setup() { // for example getting a token so you can run API tests in the default // function that comes in (3) virtual user code // what gets returned from this function is passed as an argument to the next // function. For example: `token` return getTokenForUser(); } // 3. virtual user code -\u0026gt; runs once or many times based on // `export let options = { ... } ` export default function(token) { // http.get is a k6 function that hits a URL with optional test parameters // note that we do not need a token for this url http.get(\u0026#34;http://test.loadimpact.com\u0026#34;); } // 4. (optional) teardown code -\u0026gt; runs once export function teardown(data) { // this is in case you need to clean up, for instance if failed test may // leave residue an impact state } 耐久测试配置：\nexport let options = { // endurance test for 30 seconds with 50 virtual users. Adds users immediately vus: 50, duration: \u0026#34;30s\u0026#34;, // alternative to duration, you can specify the exact number of iterations // the test will run // iterations: 500, } 负载测试配置：\nexport let options = { // for 15 seconds ramps up 10 users, adds users gradually // adds a total of 40 users in the next 15 seconds, and up to 50 in the next // 30 seconds.. // lowers down the users to 10 and 5 in the next 15 second iterations stages: [ { duration: \u0026#34;15s\u0026#34;, target: 10 }, { duration: \u0026#34;15s\u0026#34;, target: 40 }, { duration: \u0026#34;30s\u0026#34;, target: 50 }, { duration: \u0026#34;15s\u0026#34;, target: 10 }, { duration: \u0026#34;15s\u0026#34;, target: 5 }, ] } 尖锋测试配置：\nexport let options = { // starts slow and builds up the load rapidly, and then drops the load stages: [ { duration: \u0026#34;5s\u0026#34;, target: 1 }, { duration: \u0026#34;5s\u0026#34;, target: 5 }, { duration: \u0026#34;5s\u0026#34;, target: 25 }, { duration: \u0026#34;3s\u0026#34;, target: 200 }, { duration: \u0026#34;3s\u0026#34;, target: 20 }, { duration: \u0026#34;3s\u0026#34;, target: 10 }, { duration: \u0026#34;3s\u0026#34;, target: 5 }, { duration: \u0026#34;3s\u0026#34;, target: 1 }, ] } 正如你所看到的，stages 是配置性能测试类型的实用工具。\n我们如何分析测试结果？ K6 提供了一个简单的CLI 输出。我们认为这里最重要的两个高级数值是 http_req_duration，它详细说明了响应持续时间，以及 http_req，它显示发送的请求数量。如果这些数值在可接受的范围内，CLI 就达到了其目的。\n如果需要进行更深入的诊断，图形化的insights非常有价值。在这样的图表中，关键是 响应时间 和 请求速率 跟随 虚拟用户 的趋势。任何趋势上的变化都可能提示潜在问题。\n(5) 通过性能测试来防止不稳定的问题进入生产环境 可参考章节 不稳定的测试 \u0026gt; 第三步：识别零星的系统问题 - 不稳定的系统\n性能测试参考资料和延伸阅读 Lighthouse 文档\nLighthouse 代码库\nKano 模型\nISO/IEC 25010 产品质量模型\nk6-loadImpact 文档\n使用 K6 的快速启动示例\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-advanced-combinatorial-testing-and-performance-testing/","summary":"这篇博文是 UI 测试最佳实践的进阶篇，第二篇深入讨论组合测试和性能测试。文章详细介绍了如何有效地进行组合测试，覆盖多个交互元素的不同组合，以提高测试的全面性。此外，博文探讨了 UI 性能测试的重要性，并提供了一些性能测试的最佳实践，确保应用程序在各种负载下的高性能和稳定性。通过学习这些进阶实践，读者将能够更全面地应对复杂的 UI 测试场景，确保系统的质量和性能。","title":"UI 测试最佳实践的进阶篇（二）：组合测试和性能测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n测试状态 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/test-states.md\n一段简要说明 测试应该是可重复的、模块化的，并且应该自己处理状态设置。为了为其他测试实现状态，不应该重复执行 UI 测试。\n我们希望测试是无状态的，具有可扩展性：\n测试应该独立处理其状态。 没有对外部产生不受控制的副作用，或者具有测试自身能够处理的可管理副作用。 测试应该能够被 n 个实体同时执行。 代码示例 – 解释说明 可重复性: 测试必须能够设置状态、执行测试，并在不影响下一个测试执行的前提下使环境保持干净。如果一个测试在每次执行时都使系统混乱，将其留在无法重置的状态，那么这个测试就适合作为手动测试。测试还不能互相冲突：多个测试者和流水线必须能够同时执行相同的测试。如果这不可行，这些测试组应该每天在流水线中执行一次，最好在非工作时间执行 cron 作业。\n每个需要更改环境状态的测试都必须被用作设置 - 状态 - 测试，并确保在下一个测试之前能够清理测试环境。\n最好是 UI 测试不要重复作为设置测试；在必须将 UI 测试用作另一个测试的设置的情况下，应该使用 API 测试、应用程序操作或数据库初始化。\n设置 vs 清理: 设置（之前全部）优于清理（之后全部）。在可能的情况下，测试本身应该负责在一个干净的环境中开始。然而，正如上面强调的，测试不能使得在它们执行后下一个测试无法清理环境。\n登录: UI 登录的各种形式应仅在其各自的测试用例中使用。任何其他需要登录的测试应该使用内部的 API 登录和/或具有预配置的测试用户。\n测试状态设置: 鼓励测试是隔离的，以便它们在执行之前不依赖于整个设置。例如：如果一组测试可能需要创建用户，可以利用一个测试用户在隔离中使用这些测试。另一方面，设置用户的测试应该是独立的和隔离的。\n模块化: 每个测试应该能够独立运行，不依赖于其他测试来为其设置状态。如果需要进行这样的设置，应该在 beforeAll 或 beforeEach 部分进行。测试这一点的一个好方法是在隔离中运行测试：it.only()，fit()，等等。\ndescribe(\u0026#39;..\u0026#39;, function () { // setup (before/beforeEach) is preferred over cleanup (after/afterEach) before(function () { // login with UI once in an isolated test // for login here and all other tests, use a faster login method: use API, App Actions or DB seeding }); beforeEach(function () { // setup additional state... // have one UI test to ensure this state can be achieved // however for the state set up here, utilize API, Application Actions or DB seeding; do not repeat UI tests }); // test each test once with .only to ensure modularity it(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); it.only(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); }); 测试状态参考资料 放弃使用页面对象，转而使用应用动作\nCypress 文档：测试组织、登录、状态控制\n不稳定的测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/advanced/test-flake.md\n一段简要说明 每次测试都必须产生一致的结果，而可重复的流水线执行结果则是至关重要的。如果测试无法产生可靠的结果，将降低对测试的信心，还需要进行维护，这将降低所有价值。在这些情况下，最好进行手动功能测试。\n并请自问以下几个问题：\n如何解决测试波动，通过成长的过程确保测试的可信度？ 如何处理流水线、基础设施、共享资源等方面的假阴性，并在没有控制的情况下解决？ 如何发现零星缺陷？ 第一步：本地识别不稳定的测试 推荐在模拟流水线 CI 机器的操作系统中进行无头模式执行；Linux 和 MacOS 与流水线的行为更为相似，而 Windows 则是个例外，除非你正在使用 Windows Docker 容器。无头执行将更容易暴露测试波动。有多种方法可以重复执行测试规范，Cypress 提供的一个例子是使用 Lodash 库（Cypress 已经内置了）Cypress._.times( \u0026lt;重复次数\u0026gt;, () =\u0026gt; { \u0026lt;你的测试规范代码\u0026gt; })。在提交代码合并请求之前，务必使用此方法。\n第一步的代码示例 // will repeat the full suite 10 times Cypress._.times( 10, function { describe(\u0026#39;..\u0026#39;, function () { before(function () { }); beforeEach(function () { }); // you can place it anywhere to repeat 1 test, or another describe / context block Cypress._.times( 3, function { it(\u0026#39;..\u0026#39;, function () {..}); } it(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); it(\u0026#39;..\u0026#39;, function () {..}); }); }); // this will result in 6 tests per run x 10 runs = 60 executions 第二步：在流水线中识别不稳定的测试并进行重试 在初始的流水线顺利通过并合并代码后，有时测试会出现失败的情况。\n为什么测试在没有可重现的缺陷且测试代码已经完全优化的情况下仍然失败呢？\n为了解决这种零星的失败问题，以及避免测试被忽略或降低团队对其的信心，我们可以采用重试机制：\n用以解决团队无法掌控的不可靠流水线基础设施问题 在开发中遇到的问题，或者依赖于正在开发中的外部服务 最为重要的是，用于锁定零星的系统问题 第二步的代码示例 许多框架都提供了重试实用工具。下面是一个例子来自于 Cypress 文档:\n在一个测试中：\nit(\u0026#39;allows user to login\u0026#39;, { // can also be in a context or describe block retries: { runMode: 2, // for CI usage openMode: 1 // for local usage } }, () =\u0026gt; { // ... }) 在配置文件中，例如 cypress.json:\n{ \u0026#34;retries\u0026#34;: { \u0026#34;runMode\u0026#34;: 1, \u0026#34;openMode\u0026#34;: 3 } } 第三步：识别零星的系统问题 - 不稳定的系统 鉴于以下情况：\n不存在可重现的缺陷 测试代码已经充分优化 已知并通过测试重试有效解决了流水线问题 已知、认可并通过测试重试解决了外部依赖和成长痛苦 \u0026hellip; 我们如何检测系统存在的更深层次问题，这可能表明存在不稳定的系统？以下是团队Cypress 仪表板上的一个示例快照：\n“在周末的 40 次执行中，它以 10% 的错误率失败\u0026hellip; 我们运行了测试套件 40 次，在其中的一次执行中看到该规范重试了 2 次，直到通过\u0026hellip;” 请注意：相机图标表示一些测试失败，因为 Cypress 在失败时会拍摄视频和截图。\n在这些情况下，可以通过每晚或周末的 cron 任务 进行一致性测试，作为更深层次系统问题的初始指标。这些通常是那些容易泄漏到生产环境中、在实际使用中被发现并具有昂贵后果的模糊缺陷。\n代码示例 - cron 任务 at minute 0 at midnight and 2 am, every day-of-week from Monday through Friday: 0 0,2 * * 1-5 At minute 0 past hour 2, 6, 8, 10, 12, 14, 16, 18, and 20 on every day-of-week from Saturday through Sunday: 0 2,6,8,10,12,14,16,18,20 * * 6-7 一旦排除了所有其他因素，并且在管道中使用 cron 任务自动化测试初步指示了“系统波动”，这些问题就是性能测试的理想候选项，因为这种测试方法可以直接指出可能导致“不稳定的系统”的系统缺陷。\n性能测试的要点如下： 有许多性能测试工具，其中一个我们认为比较易于使用的是 k6-loadImpact，因为它采用了 ES6 语法，并且与流水线兼容。 你可以在 这里 找到一个包含代码示例的简单教程。\n不稳定的测试参考资料 Google 测试博客：我们的测试中哪些是不稳定的，是从哪些方面产生的\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-advanced-test-states-and-test-flake/","summary":"这篇博文是 UI 测试最佳实践的进阶篇，首篇介绍测试状态和处理不稳定测试的方法。文章深入探讨了在 UI 测试中如何有效处理测试状态，以及应对测试不稳定性的最佳实践。读者将学到确保测试脚本可靠性的策略，包括等待机制、测试数据管理等方面的技巧。通过这个进阶篇的指南，读者能够更灵活地应对复杂的 UI 测试场景，确保测试结果的一致性和可信度。","title":"UI 测试最佳实践的进阶篇（一）：测试状态和不稳定的测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n视觉回归测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/tools/visual-regression-testing.md\n一段简要说明 视觉回归测试是通过比较代码更改后用户将看到的屏幕截图来验证 CSS 中的回归问题的一种方法。这主要用于覆盖 CSS 的回归问题，但也适用于涵盖窗口、跨浏览器/设备组合以及本地化问题。可以将其类比为 Jest 快照，但与将 DOM 作为文本进行比较不同，它实际上是通过实际屏幕截图的比较来实现的。\n视觉回归测试的过程包括：\n记录基准快照（初始执行）。\n再次执行视觉测试，并将其与基准快照进行比较（后续执行）。\n如果新的快照与基准快照匹配，则接受。\n否则，设置新的基准快照，或者这是一个视觉回归缺陷。\n视觉回归工具会找到任何像素差异。随着快照的增加和数量的增多，这可能变得复杂。视觉快照服务的一个主要优势是其具有 AI 功能；AI 可以随着时间的推移进行训练，我们可以训练它忽略我们可能不关心的微小快照差异。需要注意的是，通过给定快照名称，我们可以训练 AI 变得非常宽松，接受任何差异\n。因此，我们需要谨慎处理，以免误将有效的失败结果标记为通过。我们可以通过更改快照名称、窗口或代码的任何部分来重置训练。\n如果没有 AI，我们将不得不手动处理每一个微小的误差，接受或拒绝每一个不必要的负面结果。如果没有内置的跨浏览器和跨窗口测试，我们的测试套件将在本地或 CI 中呈指数增长。可以观看 Gil Tayar 的演讲为 CSS 编写测试以获取更多信息。\n服务的第二大优势在于它们可以通过单个测试解决跨窗口和浏览器的问题，因此我们无需在 CI 中重复执行相同的测试以涵盖不同的变体。\n使用 Percy 和 Applitools 的 Cypress 示例 所有的代码示例都可以在这个仓库中找到，里面包含一个带有 Percy 以及 Applitools 镜像的 ReactJS 应用程序，用于视觉测试。\n我们将深入了解两个流行的服务，Percy 和 Applitools，并演示这些服务如何通过维护视觉快照来节省带宽。我们还将讨论它们在涉及跨浏览器和窗口组合时如何成为一种增强力。\n使用服务进行视觉回归测试有一个共同的流程：\n记录默认快照并将其与后续测试执行中的新快照进行比较。我们必须首次接受初始快照。\n从那时起，与默认匹配的新快照将自动被接受。\n不匹配的新快照会在 Web 界面上触发通知；我们要么拒绝，要么接受这个新的基线。如果我们拒绝，那就是一个缺陷。如果我们接受，就有了一个新的基线，循环继续。\n假设我们想要验证用户的头像。\nPercy 流程 一个简单的测试，用于验证用户的头像。 // cypress/e2e/ui-integration/user-context-retainment.spec.js describe(\u0026#34;User selection retainment between routes\u0026#34;, () =\u0026gt; { before(() =\u0026gt; { cy.stubNetwork(); cy.visit(\u0026#34;/\u0026#34;); }); it(\u0026#34;Should keep the user context between routes - full snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // the visual test - full snapshot cy.percySnapshot(\u0026#34;User selection retainment between routes\u0026#34;); // \u0026lt;-- }); }); it(\u0026#34;Should keep the user context between routes - css-focused snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // the visual test - using custom command for css selector focus // \u0026lt;-- cy.get(\u0026#39;[data-cy=\u0026#34;user-details\u0026#34;]\u0026#39;).percySnapshotElement( \u0026#34;user details with custom selector\u0026#34; ); }); }); }); 在第一个测试中，我们看到了第一行代码，它截取了整个屏幕的截图。在后续的测试中，我们看到了 user-details 选择器的快照。由于 Percy 不支持直接的选择器快照，因此使用了自定义命令 percySnapshotElement。\n为了执行视觉差异测试，我们需要一个 Percy 账户和令牌。只有连接到该账户并通过 cy run 执行时，视觉测试才会运行。这主要用于 CI。详细信息请查看注册部分。\n一旦我们执行测试，Percy 界面中的初始快照如下。我们引入了一行测试代码，它在 4 个浏览器和 2 个窗口上运行；这是 8 个组合，在 CI 中我们无需担心。请注意，每个分辨率 x 浏览器都会消耗配额；如果我们测试了 2 个窗口和 4 个浏览器，这个一行测试代码将消耗 8 个配额。\n在后续的测试中，如果存在视觉差异（例如，如果我们关闭后端并且无法渲染图像），我们将在 Percy 界面中看到视觉差异的指示器。在这里，我们还可以验证不同浏览器和窗口之间的差异。\n到了这一步，我们可以训练 AI 不太聪明，自动接受将来可能出现的损坏的头像图像。然而，你可以想象到一些微不足道的像素差异，而我们并不关心这些。这就是视觉回归服务节省带宽的地方；维护视觉快照。\nPercy 的优势在于保持事情简单。然而，CI 设置是我们必须处理的额外工作。请参考博文指南获取有关设置 Percy 的所有详细信息。\nApplitools 流程 这是 使用 Applitools 编写的相同测试.\n// Applitools version of the visual test // cypress/e2e/ui-integration/user-context-retainment-applitools.spec.js describe(\u0026#34;User selection retainment between routes\u0026#34;, () =\u0026gt; { before(() =\u0026gt; { // Each test should open its own Eyes for its own snapshots cy.eyesOpen({ appName: \u0026#34;hooks-in-action\u0026#34;, testName: Cypress.currentTest.title, }); cy.stubNetwork(); cy.visit(\u0026#34;/\u0026#34;); }); it(\u0026#34;Should keep the user context between routes - full snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // full page test // \u0026lt;-- cy.eyesCheckWindow({ tag: \u0026#34;User selection retainment between routes\u0026#34;, target: \u0026#34;window\u0026#34;, matchLevel: \u0026#34;Layout\u0026#34;, }); }); }); it(\u0026#34;Should keep the user context between routes - css focused snapshot\u0026#34;, () =\u0026gt; { cy.fixture(\u0026#34;users\u0026#34;).then((users) =\u0026gt; { cy.get(\u0026#34;.user-picker\u0026#34;).select(users[3].name); cy.contains(\u0026#34;Users\u0026#34;).click(); cy.wait(\u0026#34;@userStub\u0026#34;); cy.url().should(\u0026#34;contain\u0026#34;, \u0026#34;/users\u0026#34;); cy.get(\u0026#34;.item-header\u0026#34;).contains(users[3].name); // partial page test // \u0026lt;-- cy.eyesCheckWindow({ tag: \u0026#34;user details with custom selector\u0026#34;, target: \u0026#34;region\u0026#34;, selector: \u0026#39;[data-cy=\u0026#34;user-details\u0026#34;]\u0026#39;, // if fully is true (default) then the snapshot is of the entire page, // if fully is false then snapshot is of the viewport. fully: false, }); }); }); afterEach(() =\u0026gt; { cy.eyesClose(); }); }); 我们注意到在测试开始和结束时需要执行的额外命令 cy.eyesOpen 和 cy.eyesClose。此外，我们还看到 cy.eyesCheckWindow 是非常可定制的，不像 Percy 中那样需要自定义命令。\n有关设置 Applitools 的详细信息以及与 Percy 的比较，请查看这篇博客文章。\n与 Percy 类似，使用 Applitools，我们的测试在不同的浏览器和窗口中执行，并记录基准快照。\n如果存在视觉差异，Web 界面上会有清晰的指示器。\n下面是 Percy 与 Applitools 代码的对比。\n总的来说，Applitools 在可配置性方面更强大，而 Percy 更注重简单性。Percy 的用户界面更为精简，更易于使用，而 Applitools 的用户界面相对较为繁忙，但经过多年的改进已经有了很大的提升。从代码数量的角度来看，Percy 显然更为简洁，因为它不需要执行 \u0026ldquo;打开\u0026rdquo; 和 \u0026ldquo;关闭\u0026rdquo; 操作，而是可以直接执行主要命令。对于本地开发体验而言，Applitools 更胜一筹；能够在 Cypress 的开放模式下执行测试，而不是通过繁琐的命令行命令，是一个很大的优势。在测试运行器中直接显示实际的视觉差异，相对于 Percy 的情况，Percy 中的视觉失败只在 Web 用户界面上显示，这也是 Applitools 的一个优势。在 CI 环境中，不需要配置任何 yml 文件，这也使 Applitools 更具竞争力。另一个优势是能够通过选择器拍摄 UI 的子部分的快照；这个功能在 Applitools 中是内置的，而在 Percy 中则需要使用自定义命令，而且不能确保在实际环境中的普适性。\n| | Percy | Applitools |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; |\n| 代码 | 代码量较少 | 更具配置性 |\n| 用户体验 | 精简易用 | 较为繁琐，但有较大改善 |\n| 本地开发 | 仅支持无头模式 | 同时支持 Cypress 开放模式 |\n| CI | 需要 yml 文件 | 无需 yml 文件 |\n| 配置 | 主要在 Web 应用上，视口配置为本地文件 | 本地文件 |\n| 子部分快照 | 需要使用自定义命令，可能不适用于所有场景 | 内置支持 |\n| 视觉差异 AI | 需要更多时间形成观点 | 需要更多时间形成观点 |\n视觉测试并非无成本；在没有服务的情况下，执行视觉测试需要持续的工程师资源。在 CI 中，服务为我们在不同视口和浏览器组合上节省了成本，我们测试的所有服务在这方面都表现得很一致。视觉服务之间的最大区别在于 AI 在多大程度上帮助我们省去视觉测试的维护成本。我们认为最关键的决策因素是在内部应用中长期使用这两个工具（4-8 周），并进行并行比较。这将有助于评估哪个工具的 AI 更好，能够降低视觉测试的维护工作，而这正是对技术娴熟的团队将该测试策略纳入其组合中的最大挑战。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-tools-visual-regression-testing/","summary":"这篇博文聚焦于 UI 测试最佳实践的工具，第二篇介绍了视觉回归测试。文章详细解释了视觉回归测试在 UI 开发中的重要性，以及如何利用相关工具进行自动化视觉测试。读者将了解如何捕捉和比较页面截图，以确保界面在开发过程中的变化不影响现有的设计。通过视觉回归测试，读者能够更全面地验证 UI 的外观和布局，提高测试的全面性和准确性。","title":"UI 测试最佳实践的工具篇（二）：视觉回归测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n一些 UI 测试问题及 Cypress 的解决方案 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/tools/ui-testing-problems-cypress.md\n招募贡献者：你是否是 TestCafé 专家？我希望将“问题”部分与“Cypress 如何解决它们”部分分开，并添加一个专门介绍 TestCafé 如何解决问题的章节！\n在测试前端应用程序时会面临一些“传统”测试不具备的挑战：你需要协调一个真实的浏览器。浏览器本质上是庞大的应用程序，你需要启动它们，通过专门的库进行管理，利用一些 API 来模拟用户可能执行的相同类型的交互，然后检查前端应用程序的状态（基本上是显示的内容）是否符合你的期望。\n这个过程及其涉及的步骤是使 UI 测试变得困难的原因。主要问题包括：\n一切都是异步的：用户模拟的交互是异步的，UI 异步响应，浏览器异步响应，你用于协调和与浏览器通信的工具也是异步的。 await page.goto(url); await page.click(\u0026#39;[data-test=\u0026#34;contact-us-button\u0026#34;]\u0026#39;); await expect(page).toMatch(\u0026#34;Contact Us\u0026#34;); 而一旦你需要处理更加复杂的情况，等待所有事情就会导致你深陷于管理承诺和递归承诺之中。\n你要自动化用户流程：因此，你需要复制用户流程，检查自动用户流程，调试失败的（还有自动的、超级快的）用户流程。 想象一下，你与同事并排工作，他遇到了问题，你要求他执行某个操作，以便你可以直接使用他的浏览器 DevTools 检查问题，但是当你需要检查问题时，他却不停地点击/输入。这就是在 UI 测试中遇到问题时需要面对的情况。暂停/停止正在运行的流程很困难，你需要多次重新运行相同的测试。\n在 Web 应用程序中，有很多情况可能会干扰元素的交互性：它的内部状态、标记属性、视觉外观、其他元素的外观等。其中一些很容易发现（例如，“禁用”属性），但有些则不是（具有更高 z-index 值的另一个元素）。总的来说，很难调试问题的原因，因为你需要仔细检查元素本身、整个页面、自动化交互的工具等。\n自动化和测试前端应用程序确实很有挑战，但有一些工具不能减轻痛苦，还有一些工具能为你赋予超能力，继续前进吧！\n常用工具 要自动化和测试前端应用程序，你需要两种不同的工具：\n一个测试运行器：负责执行测试本身的工具\n一个浏览器自动化工具：提供一些 API 与专门启动的浏览器进行交互的工具\n这两个工具是独立的，你选择的测试运行器（例如 Jest）在终端中运行（并提供所有测试反馈），而第二个工具（如 Selenium 或 Puppeteer）则打开一个浏览器，执行测试中编写的命令，并返回结果。\n基于终端的测试运行程序和浏览器自动化工具之间可以进行双向通信。\n这两个工具是相互独立的，这使得很多事情变得复杂！在浏览器中执行的操作非常快速！你可以减缓它们的速度，但无法暂停或停止它们！或者更确切地说，至少不能通过交互方式实现\u0026hellip; 因为你显然可以在代码编辑器中来回跳转，在你想要检查的步骤之后注释掉所有内容，重新运行测试并检查发生了什么。但这并不是一个理想的流程。而且由于测试是一个小程序，你知道你需要重复这个步骤很多次……\n在以上描述的方式中运行测试时，另一个问题出现了：通常你在终端登录（测试运行器工作的地方），而操作则发生在浏览器中。**你如何将它们连接起来？**你是否在终端和浏览器控制台中都添加时间戳记录？是否在你的前端应用程序上方添加一个固定的 DIV，显示正在运行的测试名称？在终端中发生的事情与通过终端执行（或记录）的事情之间的连接也很困难。\n最后但同样重要的是：在终端中调试测试时，你并不是在调试真实的 DOM 元素，而是在调试序列化/引用的元素。终端和浏览器之间没有任何双向交互性，因此你不能像你习惯的那样充分利用浏览器的 DevTools。\n相信我，以这种方式理解为什么测试失败或为什么浏览器不如你期望的那样工作真的很困难。但你必须在测试消耗过程的所有三个不同阶段面对这个问题：\n1：当你最初编写测试时\n2：当测试失败时，你不能将任何东西发送到生产环境\n3：当你需要更新它们因为规格发生了变化\n步骤 #1 和 #3 相当相似，#3 可能更快，但 #1 可能会令人筋疲力尽。如果你使用的工具不帮助你，#2 将使你对 UI 测试产生厌恶…\n测试运行器的用途 停下来，思考一下所提到的工具试图达到的目标，从测试运行器开始。\n测试运行器用于管理单元测试。当然，你可以按照自己的方式使用/插入它们，但它们基本上是为了超快速（并行化）的小型功能调用而设计的。它们没有类似浏览器 DevTools 的功能，但主要问题是测试超时。每个测试都有一个超时，这是完全合理的。由于超时，如果一个测试运行时间太长，测试运行器会将其终止。\n但是当你将测试超时与 UI 测试的需求结合在一起时，会发生什么呢？正如你所知，用户流程可能会非常漫长。有很多原因：\n交互本身可能会非常漫长，并涉及大量的点击、输入、计算、等待等。\n有很多东西根本无法（从时间角度）受控制，尤其是 XHR 请求！你无法知道 Docker 容器（或者暂存服务器）响应需要多长时间。如果后端没有使用 Docker，你还必须面对网络缓慢的问题。\n这些例子展示了 UI 测试可能会有多么不可预测。解决方案似乎很方便：增加测试超时时间！但这是最糟糕的解决方案，因为：\n测试超时是在出现问题时可以节省大量时间的“绞刑”。如果将超时设置为一分钟，如果单个测试未按预期工作，你将等待一分钟（60 秒！！！）。测试持续时间过长是开发人员讨厌测试的主要原因之一，因为流水线永远无法结束。尽管如此：在某些特定场景中，你无法确定 60 秒是否足够…… 想想 AWS Lambda 在慢服务器唤醒时所需的时间，再加上网络问题……\n调试过程怎么办？请记住，当由于超时而终止测试时，自动化浏览器会被自动关闭……\n最后但同样重要的是，记住你需要进行与 DOM 相关的断言。在 UI 测试中，你不处理对象、数组和基元，而是基本上处理 DOM 元素。像“我期望元素等于…”这样的断言是无效的，尽管对于单元测试而言是有效的，当然，这个问题通常通过外部插件来解决。\n浏览器自动化工具的用途 Selenium 和 Puppeteer 旨在提供一种简单、不依赖于魔法的 UI 自动化体验。它们并不是用于测试 UI，而只是为了自动执行用户交互。自动化和测试在某些方面有重叠，但它们并不相同。两者都试图理解按钮是否可点击，并尝试点击它，但前者在失败时会失败，而后者会尝试告诉你为什么失败。前者告诉你一个元素不在页面上，而后者告诉你它不在页面上是因为先前的 XHR 请求失败了。\n我们习惯于将测试运行器与浏览器自动化工具组合在一起，并尝试充分利用它们，但由于两个非集成且不同的工具无法提供的问题而感到困扰。\n再谈论测试（和待测试的应用程序）的可调试性：为了减速/调试/暂停/停止/使它们工作等等，你需要经常“休眠”测试。这是一种常见的实践，既因为它在短期内解决了问题，有时因为你没有其他选择（请阅读 等待，不要休眠 部分）。不幸的是，添加一些**“休眠”步骤会使测试变得越来越糟糕**，越来越慢。正如我之前所写的：测试的缓慢是导致开发人员讨厌 UI 测试的最常见缺陷之一。\n此外：**测试失败时会发生什么？**在理解如何修复错误之前，你可以采取什么措施了解问题？如果你足够幸运地在本地发现了有问题的测试，那么你的痛苦是有限的。但如果测试在流水线中失败，如果你没有界面，你怎么知道发生了什么？你是否添加了一些自动截图的保险伞？有什么比截图更直观的吗？不幸的是……\n你甚至需要利用第三方调试工具（React DevTools、Vue DevTools 等），但将它们安装到受控浏览器上的过程并不是世界上最方便的。\n最后但同样重要的是：对服务器进行存根化并断言关于 XHR 请求的内容可能被视为测试实现细节… 但我不这么认为，有两个原因：\n在谈到黑盒测试时，我们提到了（好的）实践，即避免测试某些东西的工作方式，只集中在它做了什么上。应用于前端应用程序时，意味着只测试应用程序向用户公开的功能，而不是它是如何公开的（它是否使用 React 或 Vue.js、是否将数据保存到 localStorage 或 sessionStorage 并不重要）。相同的原则也可以应用于客户端/服务器通信，但了解某事之所以没有发生是因为错误的 XHR 请求可能很困难（特别是当你以无头模式运行自动化浏览器时）。而通过断言请求负载、响应负载、响应状态等，你得到的帮助是无价的（始终关注测试在失败情况下如何引导你识别问题）。\n如果你使用 Pact 或类似的工具测试客户端/服务器合同，那么你就不需要这样做，但在你的工作流中是否有这类测试？\n如果你是前端开发人员，你知道你不能总是在后端工作完成后才开始工作。但如果他们为你提供了完整的 JSON 响应，存根化后端可以让你完成所有前端编码工作，只需在集成前端与后端时检查一切是否按预期工作。这涉及到生产力问题。\n隐性测试挑战 上述考虑带来了另一个问题：测试代码应该尽可能简单。测试允许你检查一切是否按预期工作，但它们毕竟是小型程序。因此，你需要随着时间来维护它们。由于你需要在一段时间后理解它们（如果你需要花费数小时来理解为什么和如何测试工作，那是不可行的，测试应该帮助你，而不是像糟糕的代码那样使你的生活变得复杂），因此它们的代码不应该很复杂（请阅读 将软件测试视为文档工具 部分）。\n然而，并非为像 UI 测试这样困难的任务而创建的工具并不帮助你编写简单的测试代码。因此，你的测试生活再次变得更加困难…… 因此，你注定要花费大量时间调试失败的测试，而不是理解前端应用程序中到底发生了什么问题（假设确实出现了问题……）。结果是测试的可信度降低……\nCypress 助力解决 别担心，我并不是为了让你感到悲伤而描述这种戏剧性的情况😉，而只是为了让你意识到你不需要混合使用通用工具，你需要一些专门设计的工具！我想到了两个工具：Cypress 和 TestCafé。两者都非常出色，因为它们只有一个目标：重新发明（或修复？）UI 测试领域。\n我将专注于 Cypress，并稍后将它们进行比较。 Cypress 是如何解决上述所有问题的？首先…\nCCypress 拥有用户界面 是的，你通过终端启动 Cypress，但是你是通过它的用户界面 来使用它的！而且该用户界面是与你的应用程序并排的！请看这个预览\n命令日志用户界面（左侧）与你的前端应用程序（右侧）并排运行。\n这是什么意思？命令日志用户界面 的主要特点有哪些？\n你直接获得 Cypress 正在执行的反馈。每次通过其命令（cy.click、cy.type 等）要求 Cypress 与页面交互时，Cypress 都会向测试运行器添加一个日志。这种冗长的自动日志记录在编写测试和调试测试时非常有帮助。它极大地提高了你的生产力，既因为它是自动的，又因为它与你的应用程序并排。 但是，正如我告诉过你的，当编写 UI 测试时，缺少追溯性的调试性是一个很大的缺陷…让我向你介绍…\n交互式时间旅行：不确定应用程序是如何达到特定命令或测试失败的？你想查看一下前一个步骤的 UI 吗？这就是命令日志是交互式的原因！你可以悬停在各个记录的步骤上，看看应用程序在特定步骤的外观！或者，显然，你可以固定一个步骤并检查 DOM，检查应用程序在该步骤之前/之后的外观等。这是另一个拯救生命的功能，无论是在初次接触时（在你不了解测试工具的情况下调试测试可能是一场噩梦）还是在日常测试工作中。它使测试检查变得如此方便，以至于你完全忘记了没有它是如何进行测试的。在 此视频 中查看其实际效果。 其他命令日志实用工具包括：\n命令详细日志：单击命令会在浏览器 DevTools 中显示更详细的日志\n断言检查：单击断言会在浏览器 DevTools 中显示预期值和结果。你无需以更详细的日志记录重新启动测试\n如果你监视 XHR 调用，则命令日志会显示受监视/存根调用的摘要以及它们被调用的次数\n… 还有更多，详见 Cypress 官方文档中的其功能。\nCypress 命令行 默认情况下，命令是异步的，请看下面的片段\ncy.visit(url); cy.click(\u0026#39;[data-test=\u0026#34;contact-us-button\u0026#34;]\u0026#39;); cy.contains(\u0026#34;Contact Us\u0026#34;).should(\u0026#34;be.visible\u0026#34;); 你注意到有 await 吗？没有，原因很简单：在 UI 中的所有事物都需要等待，为什么你要管理 await 呢？Cypress 会为你“等待”，这意味着如果一个 DOM 元素在你尝试与之交互时还没有准备好，没问题！Cypress 会重试（默认为 4 秒），直到可以与元素交互（用户的方式，因此仅当元素可见时，不被禁用，没有被覆盖等）。因此，你可以完全避免面对前端固有的异步性！\n上述功能还有一个效果：你还记得那个不太好的测试超时吗？好吧，把它忘掉吧！在 Cypress 中，测试没有超时！你无需猜测（并根据需要不断调整）测试的持续时间，每个命令都有自己的超时时间！如果出了什么问题，测试很快就会失败！而且如果测试顺利进行，就不会面临测试超时的问题！\n最后但并非最不重要的：与 DOM 相关的命令报告与 DOM 相关的错误，你需要的方式。看下面的例子：\nCypress 清晰地从用户/DOM 视角报告问题。\n很明显用户为什么无法在输入框中输入文字。Cypress 不是唯一一个具有像用户一样执行命令的工具，但其清晰的错误报告相当不同寻常。\n测试质量 在测试中，开发人员可能会犯很多常见的错误。有些错误可能微不足道，但有些则相当严重。Cypress 强制你避免一些错误，具体如何呢？\n通过 AAA-质量的文档：快来看一下，它包含了很多最佳实践和反模式。所有人都对文档的质量给予了高度评价。\n重置状态：测试不会共享状态，因为每个测试运行之前都会重置 cookies、localStorage 等。你当然可以创建智能命令，以保持测试的独立性（共享状态的真正问题在于测试的独立性，可以看一下我课程中的一个例子），但你无法跳过重置。这是个优势，相信我 😉\n移除了在断言失败时恢复测试的可能性，如果测试失败，你就无法继续进行。确实需要使测试更加稳定，即使有时可能看起来有些困难。这是一个明智的选择，否则你可能会被允许编写糟糕的测试。\n通过许多等待助手：重试能力 和 自动等待 是救命稻草，它们让你关心你的应用程序和测试，而不是等待元素等。Cypress 允许你等待 DOM 元素、XHR 请求、页面加载，并且它根据需要调整超时（XHR 请求或页面加载可能需要的时间比输入元素出现要长），而无需使用固定时间的等待（再次强调，请阅读等待，不要休眠部分\n生产力 Cypress 在另一个非常重要的方面获胜：提高生产力。请在专门的章节中详细了解：将你的测试工具用作主要的开发工具.\n调试 如上所述，没有一些专门功能的情况下，调试测试可能会成为一场噩梦。调试失败的测试有两种情况：\n在编写测试时\n在 CI/CD 流水线中测试失败时\nCypress 提供了两个令人惊叹的解决方案：\n播放/暂停 功能**：通过编程或通过 UI，你都可以暂停测试然后恢复。是的，它甚至提供逐步导航，就像你习惯于在代码中设置断点并逐步进行一样。使用播放/暂停两次后，你就再也离不开它了 😊 播放/暂停和时光旅行提供了令人惊叹的体验，让你完全忘记常见的费时调试困扰。\n自动截图和视频：如果测试失败，Cypress 会保存测试的最后一步的截图。有时，最后一步可以帮助你理解发生了什么（特别是如果你添加了很多表达明确意图的断言，在这里你可以阅读没有良好的逐步断言，你会面临什么风险），但如果截图不能帮助你太多\u0026hellip; Cypress 还会录制整个测试的视频，包括测试运行器 UI。有时，自动记录帮助我以最简单的方式发现与 CI 相关的问题。\n常见问题 我刚刚将 Cypress 介绍为一个完美的工具，现在我预先回答一些经常问我的常见问题：\nCypress 是否免费？是的，它是免费、开源、采用 MIT 许可。只有当你想要利用其 Dashboard 服务 时，才需要付费。简单来说：你希望 Cypress 托管你测试的视频吗？那就需要付费，否则一切都是免费的。\nCypress 是否支持除 Chrome 之外的其他浏览器？在我写作的时候（2020 年 1 月 21 日），Firefox 和 Edge 的支持正处于 beta 测试阶段。\n我提到了 TestCafé，它们之间的主要区别是什么？\nTestCafé 没有类似于 Test Runner UI 的功能，在我看来是一个很大的缺失。 TestCafé 在 DOM 元素超时到期时等待，而 Cypress 最多等待相同的超时时间。因此，使用 TestCafé 时，你必须手动校准等待时间，以避免测试运行时间过长，而使用 Cypress 则无需关心这个问题。 TestCafé 没有完整的 XHR 请求检查，这是一个有争议的问题，但我认为这是一个重要的功能，可以使测试更加可靠，并提供有用的错误报告。 TestCafé 支持所有现有的浏览器！这是一个独特的特点，而 Cypress 不支持所有浏览器，也不支持移动浏览器。请注意，跨浏览器的需求可能被高估，但如果你确实需要，TestCafé 是完美的工具。 Cypress 有缺点吗？当然有！它存在一个 与 window.fetch 相关的历史问题，这迫使你使用 Axios 或者 添加一个变通方法，而且你可能需要一些额外的步骤来处理 OAuth，因为你的应用运行在 iframe 中。但尽管如此，它仍然是最受欢迎的 UI 测试工具之一。\n更一般地说：请记住，我们正在讨论 UI 测试，Cypress 在这方面表现得特别出色。如果你只是需要自动化浏览器（用于数据抓取或其他用途），请不要使用它！\n结论 总的来说，上述问题和解决方案可以归纳如下：\n前端测试中存在异步问题，Cypress 几乎可以完全透明地处理这些问题。\n逐步调试：Cypress 的时光旅行和播放/暂停功能是你的得力助手。\nCypress 在测试失败时提供清晰的错误信息。\n调试变得非常方便，多亏了并排运行测试和应用程序。\n在测试失败时，自动截图和录像功能为诊断问题提供了帮助。\nCypress 测试本身没有超时限制，但 Cypress 命令有超时设置。\nCypress 允许你在没有后端的情况下轻松进行工作。\nCypress 具备许多提高生产力的功能。\nCypress 设计的唯一目标是使 UI 测试变得简单易行。\n参考资料 掌握 UI 测试 - 会议视频 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-tools-ui-testing-problems-cypress/","summary":"这篇博文聚焦于 UI 测试最佳实践的工具，首篇介绍一些 UI 测试问题及 Cypress 的解决方案。文章探讨了常见 UI 测试难题，详细介绍了 Cypress 框架如何提供强大的解决方案，包括实时查看、可靠性、速度等方面的优势。通过这些解决方案，读者能够更好地应对 UI 测试中的挑战，提高测试效率和可靠性。","title":"UI 测试最佳实践的工具篇（一）：一些 UI 测试问题及 Cypress 的解决方案"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n将测试视为文档工具 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/testing-perks/tests-as-documentation.md\n文档编写通常很困难，需要精确而细致的工作，并要求整个团队理解并重视撰写良好的文档。文档编写是一种无私的行为，对其他开发人员和未来的你都有帮助。\n测试方法不仅是确保我们编写的代码符合项目需求、防止引入回归的绝佳方式，还是对代码和用户流程进行文档编写的利器。\n通过将测试用例作为文档工具的好处包括：\n文档与代码紧密关联：所有 UI 测试都应该从用户的角度出发编写，它们的描述也应如此。观察用户在项目中能够完成的操作是了解项目功能的有效途径。\n每个代码库都由成千上万个小代码片段组成，有时可能很难将所有要点联系在一起。测试有助于对项目有一个总体了解，甚至包括很多技术细节。\n你不依赖于某些员工的历史记忆：很多时候，你最终会向一些了解项目并记得某些特定边缘案例的员工请教。一个良好的测试套件可以大大减少对这种知识的需求，并避免每个新开发人员通过几行代码引入回归问题。\n同时，交接和入职阶段变得相当容易。\n额外的一点是：如果你利用 Gherkin 语法，甚至对一些不太懂技术的人，比如 QA 团队来说，文档的效果都会提高。\n请记住：\n测试描述必须对于不了解项目背景的开发人员来说也必须清晰。\n重复使用的测试函数、固定装置等必须有有意义的名称。一个用于注册和登录测试的 registration-success.json 固定装置可能会误导未来的读者，并使历史知识变得必要。请记住，依赖历史知识总是对必须经受开发人员更替的代码库不利。\n总的来说，UI 测试在前端应用中起着基础作用，它们是唯一记录用户预期能够完成的真实目标的手段。\n测试的代码必须尽可能简单。易于阅读，无条件，抽象级别低，具有良好的日志级别等。永远记住测试必须减轻阅读和理解代码的认知负担，因此它们的复杂性应该比待理解的代码低一个数量级。这提高了开发人员在自动化浏览器中查看测试之后必\n须经历的深入过程。\n\u0026ldquo;连接\u0026quot;代码和测试：如果用户流程相当长，将一些“步骤”（带有一些注释）在源代码和测试代码之间共享可能是有用的。类似于 /** #1 \\*/、/** #2 \\*/ 等。\nUI 测试并不是唯一的测试类型：为代码的某些可能难以理解的部分编写更多的低级测试是描述代码期望行为的好方法。\n在测试中添加注释可以极大地帮助读者，参见\u0026ldquo;匹配测试代码和测试运行命令\u0026quot;章节中的“保持抽象水平以便于调试测试”一章。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-testing-perks-tests-as-documentation/","summary":"这篇博文强调了 UI 测试最佳实践中通用测试的好处，特别是将测试视为文档工具的优势。文章解释了通过编写清晰、可读的测试代码，测试不仅仅是验证功能的手段，还是项目文档的一部分。这种做法有助于项目团队更好地理解系统，提高协作效率，并为后续开发和维护工作提供有价值的参考。通过将测试视为文档工具，项目团队能够更好地利用测试来传递信息，确保系统的可靠性和可维护性。","title":"UI 测试最佳实践的通用测试的好处篇：将测试视为文档工具"},{"content":"写在前面 为什么不用 postman 和 insomnia 关于 Postman：Postman 于 2023 年 5 月宣布将逐步淘汰具有离线功能的 Scratch Pad 模型，大部分功能将转移到云端，这意味着用户必须登录才能使用 Postman。（不登录的情况下可使用的功能有限，登录的话不确认是否会向云端上传我们测试使用的接口信息，安全性不可预估） 关于 Insomnia：Insomnia 在 2023 年 9 月 28 日发布的 8.0 版本中开始加重了对云端的依赖，用户必须登录才能使用全功能的 Insomnia。现有的 Scratch Pad 功能有限（不登录的情况下可使用的功能有限，登录的话不确认是否会向云端上传我们测试使用的接口信息，安全性不可预估） 所以需要一个将 API 工作区数据与第三方服务器隔离的替代方案，Bruno 就是可行的替代方案之一。\n为什么选择 Bruno 官方说明：https://github.com/usebruno/bruno/discussions/269\n与 postman 的对比：https://www.usebruno.com/compare/bruno-vs-postman\n开源，MIT License\n客户端全平台支持 (Mac/linux/Windows)\n离线客户端，无云同步功能计划\n支持 Postman/insomina 脚本导入（只能导入 API 请求脚本，无法导入测试脚本）\n社区相对活跃，产品开发路线图清晰\n从 0 到 1 搭建 Bruno 接口自动化测试项目 这篇文章会更聚焦如何使用 Bruno 提供的功能，从零开始搭建一个接口自动化测试项目。\nBruno 程序的安装和基本使用请参考：postman 替换工具 bruno 使用介绍\n项目结构 Bruno 接口自动化测试项目的基础结构如下：\nBruno-demo ├── README.md // 项目说明文件 ├── package.json ├── package-lock.json ├── Testcase // 测试用例文件夹 │ └── APITestDemo1.bru // 测试用例文件 1 │ └── APITestDemo2.bru // 测试用例文件 2 │ └── bruno.json // bruno COLLECTION 配置文件 │ └── environments // 不同测试环境文件夹 │ └── dev.bru // 测试环境配置文件 │ └── Report // 测试报告文件 │ └── report.json //json 格式报告文件 ├── .gitignore └── node_modules // 项目依赖 项目搭建准备 新建项目文件夹 mkdir Bruno-demo 项目初始化 // 进入项目文件夹下 cd Bruno-demo // nodejs 项目初始化 npm init -y 安装 Bruno CLI 依赖 // 安装 Bruno CLI npm install @usebruno/cli --save-dev Bruno CLI 是 Bruno 官方提供的命令行工具，可以通过简单的命令行命令轻松运行 API 集合。我们可以更轻松地在不同环境中测试 API、自动化测试流程，并将 API 测试与持续集成和部署工作流程集成。\n使用 Bruno 编写接口测试用例 新建测试用例目录 运行 Bruno app 到首页 新建名称为 Testcase 的 COLLECTION，且选择 COLLECTION 的目录为上面创建的项目文件夹 新建 Get 请求测试用例 点击 Testcase 的 COLLECTION 下的 ADD REQUEST 按钮，新建一个 GET 请求 输入请求名称为 GetDemo，输入请求地址为 https://jsonplaceholder.typicode.com/posts/1 给 Get 请求添加测试断言 使用 Bruno 自带的 Assert 编写测试断言 点击 GetDemo 请求下的 Assert 按钮，进入测试断言编辑页面\n输入断言 1：响应状态码等于 200.断言 2：响应体中的 title 包含 provident 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 使用 JavaScript 编写测试断言 点击 GetDemo 请求下的 Tests 按钮，进入测试断言脚本编辑页面 输入脚本代码，断言 1：响应状态码等于 200.断言 2：响应体中的 title 包含 provident test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 新建 Post 请求测试用例 点击 Testcase 的 COLLECTION 下的 ADD REQUEST 按钮，新建一个 POST 请求\n输入请求名称为 PostDemo，输入请求地址为 https://jsonplaceholder.typicode.com/posts 点击新建的 PostDemo 请求下的 Body 按钮，进入请求体编辑页面\n选择 Body 类型为 JSON，输入请求体内容为\n{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 给 Post 请求添加测试断言 使用 Bruno 自带的 Assert 编写 Post 请求测试断言 点击 PostDemo 请求下的 Assert 按钮，进入测试断言编辑页面\n输入断言 1：响应状态码等于 201.断言 2：响应体中的 title 等于 foo 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 使用 JavaScript 编写 Post 请求测试断言 点击 PostDemo 请求下的 Tests 按钮，进入测试断言脚本编辑页面 输入脚本代码，断言 1：响应状态码等于 201.断言 2：响应体中的 title 等于 foo test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(201); }); test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 调试断言：点击右上角的 Run 按钮，运行断言，查看断言结果是否符合预期 本地运行两个测试用例 点击 Testcase 的 COLLECTION 下的 Run 按钮，运行所有测试用例 确认运行结果是否符合预期 至此，两个接口的测试用例和断言已经编写完成\n环境变量配置 通过查看上面两个测试用例的运行结果，我们发现两个测试用例的请求地址都是 https://jsonplaceholder.typicode.com，如果我们需要在不同的测试环境中运行这两个测试用例，那么我们需要修改两个测试用例的请求地址，这样的话，如果测试用例很多，那么修改起来就很麻烦。Bruno 提供了环境变量的功能，我们可以将测试用例中的请求地址配置为环境变量，这样的话，我们只需要在不同的测试环境中配置不同的环境变量，就可以实现在不同的测试环境中运行测试用例。\n新建环境变量配置文件 点击 Testcase 的 COLLECTION 下的 Environments 按钮，进入环境变量配置页面 点击右上角的 ADD ENVIRONMENT 按钮，新建一个环境变量配置文件，输入名称为 dev，点击右上角的 SAVE 按钮保存配置文件 点击新建的 dev 环境变量配置文件，进入环境变量配置页面 点击右上角的 ADD VARIABLE 按钮，新建一个环境变量，输入名称为 host，输入值为 https://jsonplaceholder.typicode.com，点击右上角的 SAVE 按钮保存环境变量 在测试用例中使用环境变量 点击 Testcase 的 COLLECTION 下的 GetDemo 请求，进入 GetDemo 请求编辑页面 将 GetDemo 请求的请求地址修改为 {{host}}/posts/1，点击右上角的 SAVE 按钮保存 GetDemo 请求 点击 Testcase 的 COLLECTION 下的 PostDemo 请求，进入 PostDemo 请求编辑页面 将 PostDemo 请求的请求地址修改为 {{host}}/posts，点击右上角的 SAVE 按钮保存 PostDemo 请求 调试环境变量 点击 Testcase 的 COLLECTION 下的 Environments 按钮，选择 dev 环境变量 点击右上角的 RUN 按钮，运行所有测试用例，确认运行结果是否符合预期 至此，环境变量配置和调试已经完成\n命令行运行测试用例 前置检查 刚才我们已经测试用例的存储目录设置为了之前创建的项目文件夹，所以我们需要在项目文件夹下检查用例文件和环境变量配置文件是否已经创建成功。\n目前我们的项目文件夹目录结构如下：\nBruno-demo ├── package.json ├── package-lock.json ├── Testcase // 测试用例文件夹 │ └── APITestDemo1.bru // 测试用例文件 1 │ └── APITestDemo2.bru // 测试用例文件 2 │ └── bruno.json // bruno COLLECTION 配置文件 │ └── environments // 不同测试环境文件夹 │ └── dev.bru // 测试环境配置文件 └── node_modules // 项目依赖 命令行调试运行测试用例 在项目文件下的 Testcase 文件夹，运行命令行命令 bru run --env dev，运行所有测试用例\n确认运行结果是否符合预期\n输出 json 格式报告 在项目文件下的 Testcase 文件夹下新建 Report 文件夹，用于存放测试报告文件\n在项目文件下的 Testcase 文件夹，运行命令行命令 bru run --env dev --output Report/results.json，运行所有测试用例\n确认测试报告文件正常输出 至此，Bruno 接口自动化测试项目的搭建已经完成。\n集成到 CI/CD 流程 Bruno 程序的安装和基本使用请参考：postman 替换工具 bruno 使用介绍#接入 CI\n参考资料 Bruno 官方文档 https://docs.usebruno.com/ postman 替换工具 bruno 使用介绍 https://naodeng.com.cn/zh/posts/api-automation-testing/introduction_of_bruno/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/bruno-tutorial-building-your-own-project-from-0-to-1/","summary":"这篇博文是 Bruno 接口自动化测试教程，从零开始搭建 Bruno 接口自动化测试项目。文章详细指导读者如何建立测试项目的基础结构，配置环境，以及编写第一个接口测试用例。通过这个教程，读者能够逐步了解 Bruno 框架的使用方法，从零到一地构建起完整的接口自动化测试项目，提高测试效率和可维护性。","title":"Bruno 接口自动化测试教程：从 0 到 1 搭建 Bruno 接口自动化测试项目"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n从金字塔顶层入手测试 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/beginners/top-to-bottom-approach.md\n一段简要说明 当你是一位经验丰富的测试员时，处理测试套件是一件轻松的事情。但学习如何正确地测试，要测试什么、避免什么，选择哪种类型的测试等等，并不那么容易。\n测试在一开始是昂贵的。一切都是新的，你尝试实现的例子不起作用，你不清楚为什么测试失败，它与你的代码有什么关系，等等。\n我们都熟知测试金字塔，通常，我们从底部开始构建。\n标准测试金字塔方法：从下到上。\n从底部开始构建金字塔是有道理的。从单元测试入手更容易，因为它们运行快速，不需要复杂的上下文或工具。一个“单元”（无论你用“单元”表示什么：一个函数、一个组件等）仅包含几行代码，通常几乎没有依赖项（或根本没有依赖项）等等。\n这种方法的最大缺陷是什么？基本上是信心。\n测试关乎信心，以及在高信心但较慢的测试与低信心但较快的测试之间的权衡。\n如果你是测试领域的新手，术语“信心”可能不太清晰，那么你如何确保你正在开发的应用程序在测试通过时是有效的？这就是测试信心。\n为什么单元测试提供的信心如此之少？一些例子：\n如果isValidEmail函数通过了测试，你能确定你的前端应用程序的注册表单有效吗？ 如果Input React 组件通过了测试，你能确定注册表单也有效吗？ 如果整个RegisterForm组件通过了测试，你能确定用户可以注册吗？ 答案是否定的。整个应用程序由许多单元相互集成而成，还不包括一些呈现（CSS）问题，这可能会因为一个 z-index 较高的图像遮挡了提交按钮而阻止用户注册。\n再次谈论测试新手的经验缺失（就像我两年前一样）：每一项新事物都需要大量认知负担，而你不能同时面对太多的新事物。同时处理应用程序的常规开发、新的测试主题、单元测试世界和 UI 测试（后两者需要不同的工具和努力）是很困难的。\n看看这张详尽的图片，它来自 JavaScript 和 Node.js 测试最佳实践 项目：\n由 Yoni Goldberg 提供，请访问 testjavascript.com，并在 JavaScript 和 Node.js 测试最佳实践 资源库。\n对于经验丰富的开发人员来说是如此，而当你第一次接触测试领域时，情况更糟。\n自底向上的方法的结果 你不可避免地将大部分注意力放在金字塔的基础——单元测试上。你即将编写的一堆测试让你熟悉了测试的世界，但缺乏信心。你可能会发现自己在问：\n\u0026ldquo;我写的测试有什么好处呢？\u0026rdquo; \u0026ldquo;我花了一些时间与单元测试战斗，但应用程序仍然像以前一样崩溃，测试是否只是自娱自乐？\u0026rdquo; \u0026ldquo;老实说，我现在比开始测试之前更加疑惑了…\u0026rdquo; 从下到上的方法不可避免地会让你把精力集中在单元测试上。\n问题并不出在你身上，而是在于对于初学者来说，采用了错误的测试方法！\n那么，我的建议是什么呢？从金字塔的顶部开始，首先关注 UI 测试！\n首先，什么是 UI 测试（也称为功能测试、端到端测试等）？本质上，它是一种打开真实浏览器并与 DOM 元素交互的脚本，与真实最终用户的操作方式相同。有时候视频能够更生动地说明问题：看一看对 Conduit - RealWorld 项目运行的端到端测试和Conio 后台的一些 UI 测试。\n在上述视频中，你会看到一个真实的浏览器加载整个前端应用并与其进行交互。这种方法的优点包括：\n你的应用在与最终用户相同的环境（即浏览器）中进行测试，这意味着更高的信心。即使只编写一个 UI 测试，它也比一百个单元测试给你更多的信心。 受测路径（用户执行的步骤，如“注册”、“创建新 帖”等）与最终用户执行的路径相同，这意味着（对你而言）更低的认知负担，以了解你真正在测试什么。\n老实说，与自动化终端相比，自动化浏览器更有趣 😁 UI 测试最适用于你日常工作中大多数项目的小到中等规模。从落地页到小型 CMS：所有这些都至少需要一些 UI 测试，然而基于测试信心和你必须遵守的交付要求，你可能会对基于单元测试的测试信心和交付要求有所超越。只有少数人在 Facebook、Spotify、Netflix 等公司工作，这些公司需要严格的测试策略、代码覆盖要求等。总的来说：如果你为中型到大型产品公司工作，你可能不需要这篇文章，因为测试已经成为公司文化的核心🎉。 当然，这种方法也有一些缺点，但我稍后会列举出来。下面是我建议的方法：\n自上而下的方法\n从上到下的方法是否强制执行测试的不良实践？ 本文不讨论最佳实践或不良实践（请查看文章末尾的一长串资源），而是关注如何让新的前端开发人员在测试领域有益地参与。我的目标是提供一种更实际的方法，一种使开发人员能够享受测试的优势而不至于留下比以前更多的疑问的方法。\n如果 UI 测试如此神奇，为什么还有其他类型的测试存在？ 这正是关键！请注意，我并不反对单元测试！每种测试都很重要，不同的测试提供不同的反馈！从上到下的方法足够让开发人员喜欢整个测试世界。\n然后，你将发现高级别 UI 测试 的局限性：\n它们很慢：我知道上面的视频让你觉得它们运行得很快，但实际上并非如此。当你有五、十、二十个时，它们很快，但是当你有数百个 UI 测试并且它们需要几分钟时，你会开始思考如何改善情况 它们主要提供高层次的反馈：如果表单的提交按钮不起作用，那么问题是什么？有大量可能的原因，但是 UI 测试不能排除其中一些原因 它们呈现整个应用程序，如果你只想测试一些较小的东西，这可能会很麻烦。通过整个应用程序无法复制一些你需要测试的边缘情况 解决上述所有问题的方法是：降低测试金字塔！如果你需要更低级别的测试，那么做得好！这是本文的目标。\n考虑两种方法的结果：\n从下到上：对于你编写的单元测试的效用存在疑虑，并且你不理解这些测试如何帮助你提高测试信心 从上到下：你拥有一些有信心的测试，并最终需要深入测试金字塔。如果你不需要深入，这意味着你的项目很小，不需要更多的测试 然后，请从该项目的根目录开始，探索各种最佳实践，以便从一开始就成功地进行 UI 测试。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-beginners-top-to-botton-approach/","summary":"这篇博文是 UI 测试最佳实践初学者篇，建议从金字塔的顶层入手测试。文章解释了在 UI 测试金字塔的顶部，即端到端测试，开始学习的优势。通过此方法，初学者能够更容易理解应用程序的整体行为，快速验证关键路径，并逐步深入学习更底层的单元测试和集成测试。这种渐进的学习方式有助于建立坚实的 UI 测试基础，提高测试覆盖率和质量。","title":"UI 测试最佳实践的初学者篇：从金字塔顶层入手测试"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n检验请求和响应负载 原文链接:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/server-communication-testing/test-request-and-response-payload.md\n一段简要说明 前端应用因与后端通信不协调而导致停止工作的频率有多高？\n前端应用和后端应用之间存在一份合同，你始终需要测试合同是否得到遵守。每一次前后端应用之间的通信都由以下几个方面定义：\n请求的 URL 所使用的 HTTP 动词（GET、POST 等） 请求的有效负载和标头：前端应用发送给后端应用的数据 响应的有效负载、标头和状态：后端应用发送回前端应用的数据 你需要对所有这些方面进行测试，更广义地说，你需要等待每个相关的 AJAX 请求，为什么呢？\n相关的 XHR 请求是你正在测试的应用程序流程的一部分 即使 XHR 请求不是你正在测试的流程的一部分，它对达到期望的 UI 状态也可能是相关的 等待 XHR 请求可以使你的测试更为健壮，参见等待，不要休眠章节及其XHR 请求等待部分 在现有的测试工具中，完全等待和检查 XHR 请求并不那么常见，目前 Cypress 提供了最全面的检查支持。\n请注意：以下所有示例均基于 Cypress，它目前提供了最佳的 XHR 测试支持。\n对 XHR 请求进行断言的完整示例 // ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(interception =\u0026gt; { // request headers assertion expect(interception.request.headers).to.have.property(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); // request payload assertions expect(interception.request.body).to.have.property(\u0026#34;username\u0026#34;, \u0026#34;admin\u0026#34;); expect(interception.request.body).to.have.property(\u0026#34;password\u0026#34;, \u0026#34;asupersecretpassword\u0026#34;); // status assertion expect(interception.response.statusCode).to.equal(200); // response headers assertions expect(interception.response.body).to.have.property(\u0026#34;access-control-allow-origin\u0026#34;, \u0026#34;*\u0026#34;); // response payload assertions expect(interception.response.body).to.have.property(\u0026#34;token\u0026#34;); }); 在下面的章节中，我们将详细讨论 XHR 请求的不同特征。\n验证 XHR 请求的 URL 在 Cypress 中，用于请求的 URL 是通过cy.intercept调用定义的。你可能需要检查 URL 的查询字符串。\n// ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;**/authentication**\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(interception =\u0026gt; { // query string assertion expect(interception.request.url).to.contain(\u0026#34;username=admin\u0026#34;); expect(interception.request.url).to.contain(\u0026#34;password=asupersecretpassword\u0026#34;); }); 请注意，当你需要对多个主题进行断言时，Cypress 的then =\u0026gt; expect语法非常有帮助（例如，URL 和状态）。如果你只需要对单个主题进行断言，可以使用更具表现力的should语法。\ncy.wait(\u0026#34;@authentication-xhr\u0026#34;) .its(\u0026#34;url\u0026#34;) .should(\u0026#34;contain\u0026#34;, \u0026#34;username=admin\u0026#34;) .and(\u0026#34;contain\u0026#34;, \u0026#34;password=asupersecretpassword\u0026#34;); XHR 请求的方法 在 Cypress 中，请求使用cy.intercept函数定义。你可以通过指定它来定义要拦截的请求类型。\n// the most compact `cy.intercept` call, the GET method is implied cy.intercept(\u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // method can be explicitly defined cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // the extended `cy.intercept` call is available too cy.intercept({ method: \u0026#34;POST\u0026#34;, url: \u0026#34;**/authentication\u0026#34; }).as(\u0026#34;authentication-xhr\u0026#34;); 验证 XHR 请求的 payload 和 headers 对 XHR 请求的 payload 和 headers 进行断言允许你立即获得有关糟糕的 XHR 请求原因的详细反馈。必须在每个 XHR 请求上进行检查，以确保一切都正确地表示了测试执行的 UI 操作。\n// ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(interception =\u0026gt; { // request headers assertion expect(interception.request.headers).to.have.property(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); // request payload assertions expect(interception.request.body).to.have.property(\u0026#34;username\u0026#34;, \u0026#34;admin\u0026#34;); expect(interception.request.body).to.have.property(\u0026#34;password\u0026#34;, \u0026#34;asupersecretpassword\u0026#34;); }); 验证 XHR 请求响应的 payload, headers 和 status 响应必须百分之百符合前端应用的预期，否则可能向用户展示意料之外的状态。响应断言在完整的端到端测试中很有用，但在 UI 集成测试中则无关紧要（TODO：链接到集成测试页面）。\n// ask Cypress to intercept every XHR request made to a URL ending with `/authentication` cy.intercept(\u0026#34;POST\u0026#34;, \u0026#34;**/authentication\u0026#34;).as(\u0026#34;authentication-xhr\u0026#34;); // ... your test actions... cy.wait(\u0026#34;@authentication-xhr\u0026#34;).then(intercept =\u0026gt; { // status assertions expect(intercept.response.statusCode).to.equal(200); // response headers assertions expect(intercept.response.body).to.have.property(\u0026#34;access-control-allow-origin\u0026#34;, \u0026#34;*\u0026#34;); // response payload assertions expect(intercept.response.body).to.have.property(\u0026#34;token\u0026#34;); }); 测试监控 原文链接：:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/server-communication-testing/monitoring-tests.md\n一段简要说明 随着前端期望的提高，服务器和服务的复杂性也在增加。前端应用需要变得越来越快：代码拆分、懒加载、Brotli 压缩等性能优化解决方案已成为标准。还有一些令人惊叹的解决方案，如基于机器学习和分析数据的代码拆分和资源预加载。此外，JAMstack 站点生成器可用于避免手动管理许多性能优化，但它们的配置和构建过程可能会破坏已经测试过的功能。\n有很多我们一旦测试过就认为理所当然的功能，但它们并非无法回归，可能会导致灾难。例如：\nsitemap.xml 和 robots.txt 的爬行配置（通常每个环境都不同） 使用 Brotli/gzip 提供的资产：错误的内容编码可能会破坏站点的所有功能 针对静态或动态资产的不同配置的缓存管理 这些问题可能看起来很明显，但比你想象的更微妙。如果你关心用户体验，就应该保持监控，因为通常在发现问题时已经为时过晚。我知道不能监控所有事物，但是测试应用的次数越多，测试就越能成为首要的质量检查工具。\n监控测试也可以与 E2E 测试集成（毕竟，它们只是简单的 E2E 测试），但将它们保持分开可以帮助你在需要时运行它们。上述大多数事项与 DevOps 相关，有了超快的监控测试，您可以获得即时而专注的反馈。\nCypress 示例 缓存监控测试示例 const urls = { staging: \u0026#34;https://staging.example.com\u0026#34;, production: \u0026#34;https://example.com\u0026#34;, } const shouldNotBeCached = (xhr) =\u0026gt; cy.wrap(xhr).its(\u0026#34;headers.cache-control\u0026#34;).should(\u0026#34;equal\u0026#34;, \u0026#34;public,max-age=0,must-revalidate\u0026#34;) const shouldBeCached = (xhr) =\u0026gt; cy.wrap(xhr).its(\u0026#34;headers.cache-control\u0026#34;).should(\u0026#34;equal\u0026#34;, \u0026#34;public,max-age=31536000,immutable\u0026#34;) // extract the main JS file from the source code of the page const getMainJsUrl = pageSource =\u0026gt; \u0026#34;/app-56a3f6cb9e6156c82be6.js\u0026#34; context(\u0026#39;Site monitoring\u0026#39;, () =\u0026gt; { context(\u0026#39;The HTML should not be cached\u0026#39;, () =\u0026gt; { const test = url =\u0026gt; cy.request(url) .then(shouldNotBeCached) it(\u0026#34;staging\u0026#34;, () =\u0026gt; test(urls.staging)) it(\u0026#34;production\u0026#34;, () =\u0026gt; test(urls.production)) }) context(\u0026#39;The static assets should be cached\u0026#39;, () =\u0026gt; { const test = url =\u0026gt; cy.request(url) .its(\u0026#34;body\u0026#34;) .then(getMainJsUrl) .then(appUrl =\u0026gt; url+appUrl) .then(cy.request) .then(shouldBeCached) it(\u0026#39;staging\u0026#39;, () =\u0026gt; test(urls.staging)) it(\u0026#39;production\u0026#39;, () =\u0026gt; test(urls.production)) }) }) 内容编码监控测试示例 context(\u0026#39;The Brotli-compressed assets should be served with the correct content encoding\u0026#39;, () =\u0026gt; { const test = url =\u0026gt; { cy.request(url) .its(\u0026#34;body\u0026#34;) .then(getMainJsUrl) .then(appUrl =\u0026gt; cy.request({url: url + appUrl, headers: {\u0026#34;Accept-Encoding\u0026#34;: \u0026#34;br\u0026#34;}}) .its(\u0026#34;headers.content-encoding\u0026#34;) .should(\u0026#34;equal\u0026#34;, \u0026#34;br\u0026#34;)) } it(\u0026#39;staging\u0026#39;, () =\u0026gt; test(urls.staging)) it(\u0026#39;production\u0026#39;, () =\u0026gt; test(urls.production)) }) 抓取监测测试示例 context(\u0026#39;The robots.txt file should disallow the crawling of the staging site and allow the production one\u0026#39;, () =\u0026gt; { const test = (url, content) =\u0026gt; cy.request(`${url}/robots.txt`) .its(\u0026#34;body\u0026#34;) .should(\u0026#34;contain\u0026#34;, content) it(\u0026#39;staging\u0026#39;, () =\u0026gt; test(urls.staging, \u0026#34;Disallow: /\u0026#34;)) it(\u0026#39;production\u0026#39;, () =\u0026gt; test(urls.production, \u0026#34;Allow: /\u0026#34;)) }) 由NoriSte 在 dev.to 和 Medium进行联合发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-server-communication-testing-test-the-request-and-response-payloads-and-monitoring-tests/","summary":"这篇博文深入探讨了 UI 测试最佳实践中的服务通信测试，重点关注请求和响应负载的验证以及测试监控。读者将学到如何有效检验 UI 与服务之间的请求和响应负载，以确保系统交互的正确性和可靠性。博文还介绍了在 UI 测试中如何进行监控，以及监测服务通信过程中的性能和可用性。通过这些实践，读者能够更全面地覆盖 UI 测试中的服务通信方面，提高测试的全面性和准确性，确保系统的正常运行。","title":"UI 测试最佳实践的服务通信测试：检验请求和响应负载，测试监控"},{"content":"输出 html 报告 通过之前的 K6 的默认测试报告来看，K6 本身只能输出命令行的报告，没有图形化界面的测试报告。\n如果我们想要生成图形化界面的测试报告，可以使用第三方提供的 K6 HTML Report Exporter v2 插件来生成 html 报告。\n下面是使用 K6 HTML Report Exporter v2 插件来生成 html 报告的步骤：\n在测试脚本中引入 K6 HTML Report Exporter v2 插件 import { htmlReport } from \u0026#34;https://raw.githubusercontent.com/benc-uk/k6-reporter/main/dist/bundle.js\u0026#34;; 在测试脚本中配置 K6 HTML Report Exporter v2 插件 export function handleSummary(data) { return { \u0026#34;summary.html\u0026#34;: htmlReport(data), }; } 完整的测试脚本示例 import { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; import { htmlReport } from \u0026#34;https://raw.githubusercontent.com/benc-uk/k6-reporter/main/dist/bundle.js\u0026#34;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, }); } export function handleSummary(data) { return { \u0026#34;summary.html\u0026#34;: htmlReport(data), }; } 使用 k6 运行测试脚本即可在项目根目录生成名称为 summary.html 的 html 报告 打开 summary.html 报告即可查看 html 报告。 更多关于 K6 HTML Report Exporter v2 插件的用法，请参考官方文档 https://github.com/benc-uk/k6-reporter[https://github.com/benc-uk/k6-reporter]\n持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 k6.yml。\n编辑 k6.yml 文件：将以下内容复制到文件中\nname: K6 Performance Test on: [push] jobs: build: name: Run k6 test runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 - name: Run k6 local test uses: grafana/k6-action@v0.3.1 with: filename: demo.js flags: --vus 50 --duration 10s 提交代码：将 k6.yml 文件添加到仓库中并提交。\n查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 K6 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 我们也通过 github action 输出 html 报告，先调整一下 k6.yml 文件\nname: K6 Performance Test on: [push] jobs: build: name: Run k6 performance test runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v4 - name: Run k6 local test uses: grafana/k6-action@v0.3.1 with: filename: demo.js flags: --vus 50 --duration 10s - name: Archive K6 performance test report uses: actions/upload-artifact@v3 with: name: K6-performance-test-report path: summary.html - name: Upload K6 performance test report to GitHub uses: actions/upload-artifact@v3 with: name: K6-performance-test-report path: summary.html 提交代码：将 k6.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 K6 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果和测试报告附件。 参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-advanced-usage-output-html-report-and-ci-cd-integration/","summary":"这篇博文深入探讨了 K6 性能测试的进阶用法，集中介绍了输出 HTML 报告和在 CI/CD 中集成 K6 的实践，特别以 GitHub Actions 为例。读者将学到如何生成详细的 HTML 测试报告，以及如何通过 GitHub Actions 集成 K6 到 CI/CD 流程中，实现自动化性能测试。这种高级用法不仅提供了更直观的性能测试结果展示，还确保了性能测试的及时执行，有助于在开发过程中发现和解决潜在的性能问题。","title":"K6 性能测试教程 - 进阶用法：输出 html 报告和 CI/CD 集成"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n将您的测试工具用作主要的开发工具 原文链接:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/use-your-testing-tool-as-your-primary-development-tool.md\n一段简要说明 一个实例展示出问题的本质。比如说，你正在开发一个身份验证表单，可能的步骤是：\n编写用户名输入字段的代码 在浏览器中手动测试它 编写密码输入字段的代码 在浏览器中手动测试它 编写提交按钮的代码 编写 XHR 请求的处理代码 然后，你遇到了一个问题，因为在不修改源代码的情况下，你需要一个虚拟的或模拟的服务器来响应应用程序的 XHR 请求。于是，你开始编写一个集成测试：\n填写用户名输入字段 填写密码输入字段 点击提交按钮 检查 XHR 请求 模拟 XHR 的响应 检查反馈 对每个错误流程进行相同的测试步骤 编写处理错误流程的代码 重新检查测试结果 看一下第一个测试步骤，它们与我们在编写身份验证表单时手动执行的步骤相同。然后，我们为服务器的响应创建了存根，并检查表单的最终行为（包括成功或失败的响应）。\n这个工作流程可以很容易地得到改进，如果我们在编写表单的同时编写测试（TDD 开发者已经训练成这样）：\n编写用户名输入字段的代码 * 编写填充用户名输入字段的测试* 编写密码输入字段的代码 更新测试以填充密码输入字段 编写提交按钮的代码 更新测试以点击提交按钮 在测试中创建 XHR 的响应存根 编写 XHR 请求的管理代码 检查反馈 编写错误流程的管理代码 更新测试以检查错误流程 对于每个错误流程，重复以上步骤 * 请注意，如果要采用严格的 TDD 方法，可以颠倒第一步和第二步的顺序。\n这样做的最重要的好处是什么？\n你几乎完全避免手动测试应用程序 充分利用测试工具的速度，它以惊人的速度填充表单，让你节省大量时间 无需在编写表单后再编写测试（TDD 开发者已经避免这样做），尽管最初可能看起来有点烦人 完全避免在源代码中引入一些临时状态（例如输入字段的默认值、虚假的 XHR 响应） 直接用真实的网络响应测试你的应用程序（请记住，应用程序不知道网络请求是由测试工具存根的） 每次保存测试文件时都重新启动测试 可以充分利用 Chrome DevTools 和框架特定的开发工具 如何充分利用现有的开发工具？\n嗯，几乎每个测试工具都可以做到这一点，但 Cypress 在这方面脱颖而出。Cypress 拥有一个专门的 Chrome 用户，该用户在所有你的测试和所有你的项目中都是持久存在的。通过这样做，Cypress 允许你拥有一个真正专为测试而设的浏览器，其中包含你喜欢的扩展，即使你使用的是与浏览相同的 Chrome 版本。\n将其与出色的用户界面结合起来，你就可以准备好直接使用 Cypress 开发应用程序。下面你可以看到 Cypress 用户界面的一些截图，展示了将其作为主要开发工具使用的简便性。\n浏览器选择 Cypress 控制的浏览器开发者工具 Cypress Skip 和 Only UI 插件 这个工具让你可以直接在 Cypress UI 中为测试添加.only或.skip。 Cypress 观察和重新加载插件 此功能使您能够在每次源代码编译时重新运行 Cypress 测试。\n如果您想在 Cypress 控制的浏览器中查看 React/Redux 开发工具的实际效果，可以使用 cypress-react-devtools 存储库。\n此文由 NoriSte 在 dev.to 和 Medium上进行联合发表。\n保持低抽象度以便于调试测试 原文链接:https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/ui-tests-debugging-best-practices.md\n一段简要说明 UI 测试涉及许多步骤，主要有三个关键目标，但其中两个往往被低估：\n测试一个功能（显而易见） 帮助读者理解代码的作用（通常被低估） 简化调试（被低估，同时需要经验） 下面让我们一起了解编写 UI 测试时要记住的一些简单但有效的技巧。\n可读性 关于测试中抽象的问题是一个有争议的话题（Page-Object Model 的粉丝可能会对此有异议）。\n让我们看一个我不得不修复的真实测试的例子。\n// spec.ts file it(\u0026#39;Create Query Action\u0026#39;, createQueryAction); // test.ts file (simplified version) export const createMutationAction = () =\u0026gt; { // ... clearActionDef(); typeIntoActionDef(statements.createMutationActionText); clearActionTypes(); // ... }; // test.ts file contains the clearActionDef, typeIntoActionDef, etc. const clearActionDef = () =\u0026gt; { cy.get(\u0026#39;textarea\u0026#39;).first().type(\u0026#39;{selectall}\u0026#39;, { force: true }); cy.get(\u0026#39;textarea\u0026#39;).first().trigger(\u0026#39;keydown\u0026#39;, { keyCode: 46, which: 46, force: true, }); }; // test.ts file contains also the statements const statements = { createMutationActionText: `type Mutation { login (username: String!, password: String!): LoginResponse }`, createMutationCustomType: `type LoginResponse { accessToken: String! } `, createMutationHandler: \u0026#39;https://hasura-actions-demo.glitch.me/login\u0026#39;, // ... } 短函数的背后思路是创建小而可重复使用的代码片段，以帮助其他需要在页面上执行类似操作的测试。\n我认为这不太好，因为很难建立对测试的执行过程的心智模型！所有测试部分都被分割成小函数和实用程序，而测试的代码必须尽可能地直截了当。\n你还记得章节开头提到的两个被低估的点吗？这个想法是测试应该实现三个主要目标：\n帮助读者理解代码的作用 以便轻松进行调试 前者要求测试的代码尽可能简单，而在测试的代码中使用抽象并没有好处，因为这会导致花费更多时间调试和维护测试，而不是应用程序。\n后者与测试的错误部分有关：调试/修复它们。调试 UI 测试很困难，因为你需要处理以下元素：\n你的前端应用程序 浏览器 控制浏览器的工具 你提供给控制浏览器的工具的指令 上述每个元素都可能出现问题，即使是经验丰富的开发人员也可能在理解测试失败的原因时感到困扰。\n因此，端到端测试是复杂的。Cypress 提高了开发人员的生活质量（在 一些 UI 测试问题和 Cypress 方法 章节中了解更多），但直截了当的代码会极大地帮助。\n不使用任何抽象 我建议根本不使用抽象（稍后，我将讨论一些例外情况以及哪种抽象是好的）！我将上述例子改写为如下形式：\nit(\u0026#39;Test the feature\u0026#39;, () =\u0026gt; { cy.get(\u0026#39;textarea\u0026#39;).eq(0).as(\u0026#39;actionDefinitionTextarea\u0026#39;); cy.get(\u0026#39;textarea\u0026#39;).eq(1).as(\u0026#39;typeConfigurationTextarea\u0026#39;); cy.get(\u0026#39;@actionDefinitionTextarea\u0026#39;).clearConsoleTextarea().type( `type Mutation { login (username: String!, password: String!): LoginResponse }`, { force: true, delay: 0 } ); cy.get(\u0026#39;@typeConfigurationTextarea\u0026#39;).clearConsoleTextarea().type( `type LoginResponse { accessToken: String! } `, { force: true, delay: 0 } ); // ... }) 重写后的测试与原始测试执行相同的操作，但当你查看测试代码时，无需来回跳转来在脑中建立连接。\n想知道在文本区域中输入了什么吗？毫不费力，就在那里！ 想知道文本使用的是哪个文本区域吗？毫不费力，就在那里！ 在测试中什么时候使用抽象化是好的呢？ 在我看来：\n当我想隐藏一些可能没有价值但可能分散读者注意力的测试怪癖时 当它们是软的，几乎不带参数，只有一层深度 当存在相当数量的重复（确切的数量是主观的） 一个测试怪癖的例子是下面这个\n/** * Clear a Console\u0026#39;s textarea. * Work around cy.clear sometimes not working in the Console\u0026#39;s textareas. */ Cypress.Commands.add(\u0026#39;clearConsoleTextarea\u0026#39;, { prevSubject: \u0026#39;element\u0026#39; }, el =\u0026gt; { cy.wrap(el).type(\u0026#39;{selectall}\u0026#39;, { force: true }).trigger(\u0026#39;keydown\u0026#39;, { keyCode: 46, which: 46, force: true, }); }); 我创建了中心的 cy.clearConsoleTextarea，原因如下：\n这是一种权宜之计 😊 对于新手来说，阅读 trigger('keydown') 而不是使用更符合习惯的 cy.clear 是有点奇怪的，我不想在每个地方都留下解释的注释。 该命令由 5 行代码组成，将使测试代码变得过长而毫无必要。 以下内容是软抽象的一个例子：\nfunction expectSuccessNotification = (title: string) { cy.get(\u0026#39;.notification-success\u0026#39;) .should(\u0026#39;be.visible\u0026#39;) .should(\u0026#39;contain\u0026#39;, title) } 我喜欢它的原因是\n它不依赖其他抽象代码：如果我的测试在 expectSuccessNotification('Table created!') 失败，我不必陷入深奥的代码中，理解 expectSuccessNotification 背后发生了什么。 它只接受一个变量，而不是很多选项；也没有包含那些在理解代码最终执行内容时变得复杂的条件。 它专注于特定用例。它不试图一次性涵盖所有通知类型、内容等。其他专注于特定用例的函数会处理。 如果你重构通知系统，你有一个中心点进行重构，以适应新的通知系统。 相反，这是我不希望拥有的（在谈论通知工具时）。\nexport const expectNotification = ( { type, title, message, }: { type: \u0026#39;success\u0026#39; | \u0026#39;error\u0026#39;; title: string; message?: string; }, timeout = 10000 ) =\u0026gt; { const el = cy.get( type === \u0026#39;success\u0026#39; ? \u0026#39;.notification-success\u0026#39; : \u0026#39;.notification-error\u0026#39;, { timeout } ); el.should(\u0026#39;be.visible\u0026#39;); el.should(\u0026#39;contain\u0026#39;, title); if (message) el.should(\u0026#39;contain\u0026#39;, message); }; 我对上面的例子不太喜欢，原因有两点：\n它试图一次性涵盖太多用例。 如果测试失败，你必须处理让整个体验变成噩梦的各种条件。 在Hasura 控制台 UI 编码模式：测试文章中，你可以找到我们在内部遵循的更多最佳实践。\n匹配测试代码和测试运行器命令 Cypress 测试运行器有助于理解应用程序中发生了什么以及执行了哪些命令，但在调试测试时，很难立即在测试运行器和代码之间建立关联。而且，日志无法帮助理解测试从功能角度正在做什么（例如，日志说“在文本区域中键入”，但没有说明“在类型配置文本区域中键入”）。因此，查找失败的根本原因是困难的。Cypress 会为失败的测试记录视频，但如果阅读者/调试者不能在日志和测试在普通英语中所做的事情之间建立直接关联，则视频就毫无用处。\n请看下面的内容 我添加了一个日志，报告测试正在进行的操作，使测试代码与测试运行程序之间能够直接对应。 (cy.log('**--- Type in the Webhook Handler field**');).\n请注意，你可以向 \u0026lsquo;cy.log\u0026rsquo; 传递更多参数，这些参数将在单击记录的命令时直接显示在开发工具的控制台中。\nStorybook 和 Playwright 已经引入了step实用工具的概念，可以用英语解释测试中的步骤。Cypress 没有相同的选项，因此我认为我提出的cy.log是很有价值的。\n这里需要注意：不要将cy.log链在一起，因为它不是一个查询命令，不会对链进行重试。\n截至 Cypress V12 版本，cy.log在函数级别不进行重试。\n例如：\ncy.log(\u0026#39;foo\u0026#39;).get(\u0026#39;bar\u0026#39;).should(\u0026#39;baz\u0026#39;) // does not retry cy.get(\u0026#39;bar\u0026#39;).should(\u0026#39;baz\u0026#39;) // retries the whole chain until the assertion passes (you have 10 sec timeout set) 值得注意的是，即使 Cypress 没有 step，Filip Hric 的 cypress-plugin-steps 也是一个有效的替代选择。\n使用清晰的选择器 看一下这段代码\ncy.get(\u0026#39;textarea\u0026#39;) .eq(0) .type(`{enter}{uparrow}${statements.createMutationGQLQuery}`, { force: true, }); cy.get('textarea').eq(0) 是什么？在没有更好的选择器的情况下，我建议将它们放在 Cypress 的别名下，比如\n// Assign an alias to the most unclear selectors for future references cy.get(\u0026#39;textarea\u0026#39;).eq(0).as(\u0026#39;actionDefinitionTextarea\u0026#39;); cy.get(\u0026#39;textarea\u0026#39;).eq(1).as(\u0026#39;typeConfigurationTextarea\u0026#39;); 然后通过这种方式来引用它们\ncy.get(\u0026#39;@actionDefinitionTextarea\u0026#39;).clearConsoleTextarea().type(/* ... */); 以提高读者的体验。\n减少 data-testid 属性 我不想讨论测试本身及其对测试结果可信度的价值，只想谈谈 data-testid 属性在调试阶段的影响。\n如果无法从页面中检索带有 data-testid 属性的元素，可能的问题有：\n元素不存在。 元素存在，但它没有该属性。 元素存在，具有该属性，但值不符合预期。 上述所有问题都会导致开发人员重新启动测试、检查元素、查找与测试相关的属性等。相反，如果测试基于文本内容，仅通过截图就足以了解测试搜索的文本是否不存在或错误。\n此外，对于那些必须处理 data-testid 的工程师来说，还有一些不足之处：\n在重构期间必须维护与测试相关的属性，但在有数百个属性时并不容易。 如果测试相关的属性在页面上是唯一的，那么它们会很有帮助。然而，当你有数百个这样的属性时，很难保证它们是唯一的。 我的建议是仅在以下情况使用 data-testid 属性：\n用于节，而不是元素（例如 Header、Footer 等），以减小基于文本搜索的范围。以下是一个示例： cy.get(\u0026#39;[data-test=\u0026#34;Actions list\u0026#34;]\u0026#39;).within(() =\u0026gt; { // \u0026lt;-- reduce the scope cy.contains(\u0026#39;login\u0026#39;) // \u0026lt;-- the \u0026#34;login\u0026#34; text could exist more times in the page }) 非文本元素，如图标、图片等。 最后但同样重要的是：我建议为它们赋予用户友好的值，而不是采用程序员的命名风格（例如，“操作列表”而不是“actionsList”），尤其是当该部分显示相同文本时。这样可以直接关联测试代码、Cypress 的测试运行器和页面的文本内容。\n将相关操作分组 通常来说，阅读一系列平面的交互并不能帮助理解测试运行的页面结构。\n例如：\n获取 1 并点击 获取 2 并点击 获取 3 并点击 获取 4 并点击 获取 5 并点击 获取 6 并点击 获取 7 并点击 获取 8 并点击 然而，将列表展开可以帮助读者构建一个有关所涉及部分位置的心理模型\n在块 1 内 获取 1 并点击 获取 2 并点击 获取 3 并点击 在块 2 内 获取 4 并点击 获取 5 并点击 获取 6 并点击 获取 7 并点击 获取 8 并点击 再强调一下：Storybook 和 Playwright 已经引入了“步骤（step）”实用程序的概念，该实用程序可以将操作进行分组，而上述建议在 Cypress 中非常实用。\n相关章节 🔗 从晦涩难懂的 React 组件测试到简单、易读的版本 由 NoriSte 在 dev.to进行发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-best-practices-3-use-your-testing-tool-as-your-primary-development-tool-and-keep-abstraction-low-to-ease--debugging-the-tests/","summary":"这篇博文深入研究 UI 测试的通用最佳实践之三：将测试工具作为主要开发工具，并保持低抽象度以便于调试。文章强调将测试工具纳入主要开发过程，加强测试与开发的协同，提高代码质量。另外，博文建议保持测试脚本的低抽象度，以便更容易调试和理解。这种做法有助于加速问题排查和测试脚本的维护，从而提高 UI 测试的效率和可靠性。通过采用这些通用最佳实践，读者将能够更好地整合 UI 测试到开发流程中，实现更高效的软件开发。","title":"UI 测试最佳实践的通用最佳实践（三）：将你的测试工具用作主要的开发工具和保持低抽象度以便于调试测试"},{"content":"如何快速编写 K6 性能测试脚本 我们除了可以使用 JavaScript 编写 K6 性能测试脚本外，K6 还提供了多种快捷的方式来编写性能测试脚本。\n1.使用 K6 提供的 Test builder 测试生成器工具来编写脚本 2.使用 K6 Recorder 录制器录制脚本 3.使用 浏览器开发者工具获取 HAR 文件后使用 har-to-k6 工具将 HAR 文件转换为 K6 脚本 下面将分别介绍这三种方式。\n使用 K6 提供的 Test builder 测试生成器工具来编写脚本 k6 的 Test builder 测试生成器提供了一个图形界面，可根据您的输入生成 k6 测试脚本。然后，您可以复制测试脚本并从 CLI 运行测试。\nTest builder 测试生成器目前还是一个实验性的功能，可能会在未来的版本中发生变化。大家可以查看官方文档：https://k6.io/docs/using-k6/test-builder/获取更多信息\n安装 Test builder 测试生成器 Test builder 不需要安装，它是 Grafana Cloud k6 提供的一个功能，可以在浏览器中使用。\n需要注册一个 Grafana Cloud k6 账号，然后登录 Grafana Cloud。\n如何进入 Test builder 测试生成器界面：\n登录进入 Grafana Cloud 首页 依次点击左侧菜单栏上的 Testing \u0026amp; synthetics\u0026mdash;\u0026gt;Performance\u0026mdash;\u0026gt;Projects 然后选择 default project 或者新建一个 project，进入到项目的详情页面 点击页面上的 Start testing 按钮，然后再选择页面下的 Test builder，进入到 Test builder 测试生成器界面 提醒：由于 Test builder 测试生成器是 Grafana Cloud 上登录进行使用，可能 Grafana Cloud 存储一些敏感数据，所以建议大家不要在生产环境中使用 Test builder 测试生成器。\n如何使用 Test builder 测试生成器 1.在 Test builder 测试生成器界面，点击 Scenario_1 下的 Options 按钮进入到配置页面，配置测试场景的基本信息，如下图所示： 可以看到场景配置页面提供了多种配置选项，可以根据自己的需求进行配置场景名称，执行器类型和不同的 UV 配置。\n2.在 Test builder 测试生成器界面，点击 Scenario_1 下的 Requests 按钮进入到 Requests 管理页面，如下图所示： 3.点击页面下的 Request 按钮进入添加请求页面，如下图所示： 4.在添加请求页面，输入请求的 URL 地址，再根据实际情况添加请求的 headers 或请求的 body 或检查点等参数，然后点击页面上的 Create 按钮，完成性能场景的配置，如下图所示： 获取 Test builder 测试生成器生成的脚本 在 Test builder 测试生成器界面，点击页面上的 Script 按钮，页面就会展示出 Test builder 测试生成器生成的脚本，如下图所示：\n可以看到 Test builder 测试生成器生成的脚本，是一个完整的 K6 测试脚本，可以直接复制到本地，然后使用 k6 运行该脚本。\n运行 Test builder 测试生成器生成的脚本 在 Test builder 测试生成器界面，点击页面上的 Run Test 按钮，页面就会展示出 Test builder 测试生成器生成的脚本的运行结果，如下图所示：\n可以看到 Test builder 测试生成器生成的脚本运行的很详细的测试结果信息。\n其他 Test builder 测试生成器的功能 也支持导入 HAR 文件生成测试脚本 也支持多个 scenario 场景的配置和一个 scenario 场景的多个请求的配置 更多关于 Test builder 测试生成器的内容，请参考官方文档：https://grafana.com/docs/grafana-cloud/k6/author-run/test-builder/\n使用 K6 Recorder 录制器录制脚本 K6 Recorder 录制器是 K6 提供的一个浏览器扩展程序，可以在浏览器中录制用户与 Web 应用程序的交互，并将其转换为 k6 测试脚本。\n安装 K6 Recorder 录制器 K6 Recorder 录制器是一个浏览器扩展程序，可以在 Chrome 或 Firefox 中使用。您可以从 Chrome Web Store 或 Firefox Add-ons 页面安装它。\nChrome Web Store 安装地址：https://chrome.google.com/webstore/detail/grafana-k6-browser-record/fbanjfonbcedhifbgikmjelkkckhhidl\nFirefox Add-ons 安装地址：https://addons.mozilla.org/en-US/firefox/addon/grafana-k6-browser-recorder/\n安装完成后，就可以在浏览器中使用 K6 Recorder 录制器了。\n如何使用 K6 Recorder 录制器 在浏览器上点击打开 k6 Recorder 录制器扩展。 选择保存自动生成的脚本的位置。 要将其保存在本地计算机上，请选择\u0026quot;我不想在云中保存测试\u0026quot;(后面的例子我选择的这个选项)。 要将其保存到任何 Grafana Cloud k6 项目中，请选择“登录”。 选择保存脚本位置后，在当前浏览器选项卡输入测试网站地址，点击选择开始录制按钮以开始录制当前浏览器选项卡。 图中我打开了谷歌的首页并点击了搜索框，输入了 123，然后点击了搜索按钮，\n点击了 k6 Recorder 录制器的停止录制按钮停止录制。 将录制的文件取名保存在本地（我这里取名为 record-demo.har）。 使用 har-to-k6 工具将 HAR 文件转换为 K6 脚本。 har-to-k6 工具是一个命令行工具，可以将 HAR 文件转换为 k6 脚本。需要先通过 npm install -g har-to-k6安装 har-to-k6 工具，然后通过 har-to-k6 record-demo.har -O record-demo.js命令将 HAR 文件转换为 K6 脚本。\n转换后的 K6 脚本部分截图如下所示： 大家可以根据自己的需求对转换后的 K6 脚本进行修改，然后使用 k6 运行该脚本。 使用 k6 运行转换后的 K6 脚本，查看运行结果。 更多关于 K6 Recorder 录制器的内容，请参考官方文档：https://grafana.com/docs/k6/latest/using-k6/test-authoring/create-tests-from-recordings/using-the-browser-recorder/\n使用浏览器开发者工具和 har-to-k6 工具生成 K6 脚本 除了我们可以使用 K6 Recorder 录制器来录制脚本外，我们还可以使用浏览器开发者工具获取测试请求的 HAR 文件，然后使用 har-to-k6 工具转换 HAR 文件来生成 K6 脚本。\n可以获取 HAR 文件的浏览器和工具 我们可以根据实际情况选择一个工具来记录 HAR 文件。市面上的很多浏览器和工具可以以 HAR 格式导出 HTTP 流量。大家常用的是：\nChrome 浏览器 Firefox 浏览器 Microsoft Edge 浏览器 Charles 代理抓包工具 (HTTP proxy/recorder) Fiddler 代理抓包工具 (HTTP proxy/recorder) 如何使用浏览器开发者工具获取 HAR 文件 下面是使用 Chrome 浏览器开发者工具获取测试请求 HAR 文件例子：\n在 Chrome 中打开新的隐身窗口。 （可以排除登录 cookies 等干扰信息）。\n打开 Chrome 开发者工具（按 F12）。\n选择网络选项卡 Network。\n检查和确认录音按钮（圆形按钮）是否已激活（红色）。\n如果想要记录多个连续的页面加载，请选中“保留日志”复选框。 输入测试网站的 URL（如 https://www.google.com/），然后开始执行和后续模拟用户执行的操作（如输入 123 进行搜索）。\n完成后，在 Chrome 开发人员工具中，右键单击 URL 并选择“将内容另存为 HAR”。 选择保存 HAR 文件的位置并重命名（如 har-demo），然后点击保存按钮，完成 HAR 文件的保存。\n使用 har-to-k6 进行转换 HAR 文件 安装 har-to-k6 工具 通过 npm install -g har-to-k6命令安装 har-to-k6 工具。 使用 har-to-k6 工具将 HAR 文件转换为 K6 脚本 通过 har-to-k6 har-demo.har -O har-demo.js命令将 HAR 文件转换为 K6 脚本。 转换后的 K6 脚本部分截图如下所示： 大家可以根据自己的需求对转换后的 K6 脚本进行修改，然后使用 k6 运行该脚本。 使用 k6 运行转换后的 K6 脚本，查看运行结果。 更多关于 HAR 文件的内容，请参考官方文档：https://grafana.com/docs/k6/latest/using-k6/test-authoring/create-tests-from-recordings/using-the-har-converter/\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-advanced-usage-how-to-quickly-writing-k6-performance-test-script/","summary":"这篇博文深入介绍了在进行 K6 性能测试时，除了传统的 JavaScript 编写脚本方式外，还介绍了 K6 提供的多种快捷方式。首先，通过 K6 提供的 Test Builder 测试生成器工具，读者能够轻松快捷地生成性能测试脚本，简化了脚本编写过程。其次，博文介绍了使用 K6 Recorder 录制器的方法，通过录制操作生成脚本，省去手动编写的步骤。最后，读者还能了解到使用浏览器开发者工具获取 HAR 文件，并通过 har-to-k6 工具将其转换为 K6 脚本的技巧。通过本文，读者将更全面地了解 K6 性能测试工具的灵活性和多样化的脚本编写方式。","title":"K6 性能测试教程 - 进阶用法：如何快速编写 K6 性能测试脚本"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\nUI 测试调试最佳实践 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/ui-tests-debugging-best-practices.md\n在转向 Cypress 之前，我通常使用 Puppeteer 编写 UI 测试。理解浏览器中发生的事情、了解正在运行的测试以及调试测试都不是简单的任务，因此我开始采取一系列解决方案来帮助我应对整个流程。\n诸如 Cypress 和 TestCafé 的工具几乎使下面列出的最佳实践变得无关紧要，但除非你之前使用过 Selenium 或 Puppeteer 等工具进行测试，否则你不会意识到专为测试而设计的工具对简化生活有多么重要。\n第零步是以非无头模式启动浏览器，然后\u0026hellip;\n在 console.log 中记录/显示测试的描述 由于在浏览器内部无法获得有关正在运行的测试的视觉反馈，请务必在浏览器控制台中记录测试的名称。在测试速度很快的情况下（少于 1 秒），这可能没有太多用处，但在测试时间较长或在使用 test.skip 和 test.only 进行测试时，这是有帮助的，可以对正在运行的测试进行双重检查。\n在 Puppeteer 中，可以通过以下方式实现：\ntest(\u0026#39;Test description\u0026#39;, async () =\u0026gt; { await page.evaluate(() =\u0026gt; console.log(\u0026#39;Test description\u0026#39;)); // ... the test code... }) 如果你需要更为显眼的反馈，甚至可以考虑在页面的左上角添加一个固定的 div，每个测试都会用自己的描述填充\u0026hellip;\n将浏览器的 console.log 转发到 Node.js 使用 Puppeteer 的一个简单例子：\npage.on(\u0026#39;console\u0026#39;, msg =\u0026gt; console.log(\u0026#39;BROWSER LOG:\u0026#39;, msg.text())); 允许你在同一终端窗口中查看测试日志和浏览器日志。简单而有效。\n启动浏览器时已经打开开发者工具 就像在经典的前端开发中一样，在页面加载已经开始后再打开开发者工具可能会导致你错过重要的信息，特别是在网络选项卡中。在调试测试时，启动浏览器时已经打开开发者工具可以节省宝贵的时间和信息。\nconst browser = await puppeteer.launch({ headless: false, devtools: true }); 减缓模拟用户操作速度 浏览器自动化工具速度非常快，这使得我们能在几秒钟内运行大量测试。然而，在调试过程中，这可能是一个劣势，因为你需要用眼睛跟踪页面上发生的情况。减缓每个动作可能会适得其反——因为整个测试变得很慢——但通常这是执行一些快速检查的最简单方法。在 Puppeteer 中，有一个全局设置可以实现这一点。\nconst browser = await puppeteer.launch({ headless: false, slowMo: 250, // slow down every action by 250ms }); 一些动作，比如输入，允许你添加更具体的延迟（这会叠加在全局 slowMo 设置之上）\nawait page.type(\u0026#39;.username\u0026#39;, \u0026#39;admin\u0026#39;, {delay: 10}); 使用调试器语句暂停测试 另一方面，就像在标准的 Web 开发中一样，你可以在运行在页面上的代码中添加一个调试器语句来“暂停”JavaScript 执行。请注意：该语句仅在已打开控制浏览器的开发者工具时有效。\nawait page.evaluate(() =\u0026gt; {debugger;}); 通过点击“继续执行脚本”或按下 F8 键（调试器是一个“飞行”断点），将恢复测试的执行。\n延长测试超时时间 类似 Jest、Jasmine 等的测试运行器都设有测试超时时间。这个超时时间的作用在于，在测试中发生问题导致测试无法正常结束时，及时终止测试。在 UI 测试中，这种行为相对繁琐，因为你需要在测试开始时打开浏览器，在测试结束时关闭浏览器。在正常的测试生命周期中，设定过高的超时时间并不实际，因为一旦测试失败就会导致大量时间的浪费，而过低的超时时间可能在测试完成之前就提前“截断”了测试。\n相反，你需要设定较长的超时时间，因为你不希望测试结束的时候在你检查浏览器时关闭它。这就是为什么在调试受控浏览器时，设定为 10 分钟的超时时间可能会很有帮助。\n当然，也可以\u0026hellip;\n避免在测试结束时关闭浏览器 测试开始时，打开浏览器，而在测试结束时不关闭它。避免关闭浏览器可让你自由地检查前端应用，而无需担心测试超时。这仅在本地运行测试时有效，但在运行测试于 CI 管道之前，必须还原自动关闭以避免由于未关闭的浏览器实例导致内存不足。\n使用截图 在以无头模式运行测试时，这在测试稳定且仅在出现回归时才失败的阶段尤其有帮助。如果测试失败，很多时候截图能让你了解你正在开发的功能是如何影响之前正常工作的功能的。最有效的解决方案是在测试失败时截图，否则，你可以在 UI 测试中确定一些检查点，并在这些步骤中截图。\n频繁使用断言 一个经验法则：如果测试失败，它必须直接带你理解出了什么问题，而不是重新启动测试并手动调试。尝试在你的代码库中手动引入一些错误（改变请求有效载荷，移除元素等），并查看测试报告。错误是否与你引入的错误相关联？阅读失败报告的人是否能够理解需要修复什么？\n你需要在测试中添加很多断言，这是完全可以的！单元测试通常只包含一个步骤和一个或两个断言，但 UI 测试不同，它们有很多步骤，因此你需要很多断言。将它们视为一系列单元测试，其中前一个测试对第二个测试的创建是必要的，以此类推。\n使用 test.skip 和 test.only 这是每个测试运行器的基础之一，但你可能不知道：如果你不习惯使用 skip 和 only，请从现在开始吧！否则，你将浪费很多时间，即使你的测试文件只包含两三个测试。始终仅运行你正在工作或需要调试的最小数量的测试！\n串行运行测试 如果你正在使用 Puppeteer 结合 Jest，请记住 Jest 有一个专门的 runInBand 选项，它防止测试的执行在你的 CPU 核心上分散。将测试并行化可以加快执行速度，但在你需要用眼睛跟踪测试操作时可能会让人感到烦扰。runInBand 选项使测试串行运行。将它与 test.skip、test.only 以及 jest-watch-typeahead 结合使用可以避免很多调试的麻烦。\n保持测试代码简单 宁愿有些重复，也不要过度抽象。努力让测试代码简单易读。你调试 UI 测试越多，就越能体会到其中的困难。当你需要理解底层发生了什么，以及哪一步不按预期工作时，你那超度抽象、完全符合 DRY 原则（不重复自己）的测试代码就会变得令人头痛。\n更一般而言，测试是小型脚本，它们必须比它们测试的代码简单两个数量级，将其视为一个盟友，而不是更复杂的程序。\n选择专门设计的工具 上述提到的解决方案都是有效的，但它们有一个共同点：它们都是变通方法。这是因为我在示例中使用的工具 Puppeteer 并非为 UI 测试而创建的，而是为通用浏览器自动化而设计的，然后，通过一些外部工具的帮助，并在测试中使用 Puppeteer，使其可以用于 UI 测试。测试 Web 应用有不同的需求，需要不同的工具，而不仅仅是自动化操作。\n如果你需要编写 UI 测试，你应该考虑切换到 Cypress 或 TestCafé，因为它们已经被设计成简化你的测试工作。如何实现的呢？通过一系列实用工具和默认行为，以及一系列一流的解决方案，使你能够理解并调试浏览器中发生的情况。请注意，本章中提到的所有 Puppeteer 最佳实践\u0026hellip; 在 Cypress 或 TestCafé 中完全无用 😉\n一些 UI 测试问题及 Cypress 方法 和 前端生产力提升：将 Cypress 作为你的主要开发浏览器 这两章包括了 Cypress 一流工具的概述。\n由NoriSte 在 dev.to 和 Medium上进行联合发表._\n在测试中达到 UI 状态而无需使用 UI 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/reaching-ui-state.md\n一段简要说明 在 UI 场景中覆盖一次是有价值的，而在其他测试中复制其中任何部分提供的价值很小；这些测试可能需要系统的相关状态。假设在一个新测试中，你需要一种状态，而那种状态 - 部分或全部 - 与 UI 测试中的某些部分重复。在这种情况下，可以考虑以下几种技术：\n直接导航 网络存根记录和播放 应用程序动作 数据库种子 免责声明：整个技术包的应用仅在 Cypress 中可能（据我们所知），因此以下代码示例是在 Cypress 上下文中。\n直接导航 这是最简单的技术，适用于任何框架。假设测试的意图与你的应用程序中的某个页面有关。与其进行点击导航，直接访问 URL。一旦到达，你可以等待 UI 元素（任何测试框架）或网络调用（一些测试框架），或两者兼而有之。\n// Test A covers click-navigation to a certain page. // This is Test B, and navigating to that page is the prerequisite step. // assuming baseUrl is set in cypress.json or config file // directly navigate to the page. cy.visit(\u0026#39;/endpoint\u0026#39;); // to ensure stability, wait for network (preferred), ui elements, or both // note: checking the endpoint you are at is entirely optional, only for sanity that you are at the right page cy.url().should(\u0026#39;contain\u0026#39;, \u0026#39;endpoint\u0026#39;); // cy.url().should(\u0026#39;match\u0026#39;, /endpoint/); // there are many, some more complex, ways of doing it // network wait: this is in addition to the sanity url check, and it is more important // because you want the page to \u0026#34;settle\u0026#34; before you start running assertions on it // usually a GET request. Is aliased so we can wait for it. cy.intercept(\u0026#39;some-xhr-call-that-happens-upon-landing\u0026#39;).as(\u0026#39;crutcXHR\u0026#39;); // The default Cypress timeout is 4 seconds. 15 seconds here is arbitrary. // Most pages load faster, but if you need more time then increase the timeout. // The only caveat to increasing timeout is that the tests will take longer to fail, but still run as fast as possible when things work. cy.wait(\u0026#39;@crutchXHR\u0026#39;, {timeout: 15000}); // ui-element wait is straightforward, and may be optional, as well as less stable) cy.get(\u0026#39;element-on-page\u0026#39;).should(\u0026#39;exist\u0026#39;).and(\u0026#39;be.visible\u0026#39;); 直接导航的优缺点 优点：不进行点击导航可以节省测试时间，并减少测试维护的工作量。\n缺点：这种技术忽略了用户通过应用程序的端到端点击方式。确保在其他测试中至少有一个工作流程覆盖与点击导航相同的工作流程，以确保点击导航功能不会出现回归问题。通常，点击导航可以成为一个独立的测试；在设置其他测试的状态时，不要重复已经在其他地方覆盖的 UI 测试。思考模式类似于登录；如果在一个测试中进行 UI 登录，在其他测试中可以实现程序化登录，这既快速又经济。\n应用程序操作 Cypress 为你提供了对应用程序的完全控制权。你可以绕过页面对象的抽象层（与你的应用程序分离），通过 cy.get() 直接访问 UI，还可以访问 API、数据库，甚至可以访问源代码。\n应用程序操作是一种快捷方式，允许你访问内部工具以节省时间。一个简单的例子可以是一个 cy.signup() 自定义命令，该命令进入注册表单并调用注册表单的回调，而不是填写表单并点击注册按钮。\n以下是一个快速示例，演示了在 Angular 应用程序中如何允许 Cypress 访问源代码。\n// Angular Component file example /* setup: 1. Identify the component in the DOM; inspect and find the corresponding \u0026lt;app.. tag, 2. Right in the constructor of your component, insert conditional */ constructor( /* ... */ ) { /* if running inside Cypress tests, set the component may need // @ts-ignore initially */ if (window.Cypress) { window.yourComponent = this; } } // at https://github.com/naodeng/ui-testing-best-practices/blob/master/https://github.com/naodeng/ui-testing-best-practices/blob/master/support/app-actions.ts helper file: /** yields window.yourComponent */ export const yourComponent = () =\u0026gt; cy.window().should(\u0026#39;have.property\u0026#39;, \u0026#39;yourComponent\u0026#39;); /** yields the data property on your component */ export const getSomeListData = () =\u0026gt; yourComponent().should(\u0026#39;have.property\u0026#39;, \u0026#39;data\u0026#39;); 在这之后，在 DevTools 中查看该组件允许的属性，或者在组件代码中查看你可以使用 .invoke() 进行的函数。\n可以查看 演示幻灯片 获取一个使用应用程序操作进行视觉测试的代码示例。\n另一个应用程序操作的示例，利用状态，使用 Siemens 的 Building Operator Siemens 的建筑控制产品 在下面的状态图中有 3 个状态。我们从左右两个窗格都存在的地方开始。如果删除右窗格（删除点/红色流），则只剩下左窗格。如果删除左窗格（删除设备 - 蓝色流），两个窗格都消失，并且 UI 被重定向。\n在测试 UI 时，你可能选择删除右窗格（红色流），然后在另一个测试中，你可能选择删除左窗格（蓝色流）。这遗漏了通过状态图的最后一条路径，其中右窗格和左窗格被逐一删除。\n我们已经在一个 UI 测试中涵盖了删除右窗格（红色路径）。为什么不避免重复进行此测试，利用应用程序操作，获取源代码中的删除函数，并使用 cy.invoke() 调用它呢？\nit(\u0026#39;Component test: delete right pane and then left\u0026#39;, () =\u0026gt; { /* tests a SEQUENCE not covered with UI tests * tests a COMBINATION of components */ appAction.deleteRightPane(); cy.window().should(\u0026#39;not.have.property\u0026#39;, \u0026#39;rightPaneComponent\u0026#39;); cy.window().should(\u0026#39;have.property\u0026#39;, \u0026#39;leftPaneComponent\u0026#39;); appAction.deleteLeftPane(); cy.window().should(\u0026#39;not.have.property\u0026#39;, \u0026#39;leftPaneComponent\u0026#39;); cy.window().should(\u0026#39;not.have.property\u0026#39;, \u0026#39;rightPaneComponent\u0026#39;); cy.url().should(\u0026#39;match\u0026#39;, redirectRoute); }); 应用程序操作的优缺点 使用应用程序操作/拥有组件访问速度很快！测试不太容易受到变化的影响。一般来说，这是在较低级别进行测试的好处。然而，对于工程师而言，这可能会变得让人上瘾，开始忽视对用户界面的测试；优势可能变成劣势。\n有一些反对应用程序的论点。开发人员可能认为 Cypress 对源代码的访问不理想。在 Cypress 具有官方组件测试支持之前，这没有反驳的理由。\n应用程序操作的真正威力在于将应用程序操作与其他技术结合使用时显现出来；不重复 UI 工作流程来设置状态，将组件测试与视觉测试结合使用，将组件测试与网络操作结合使用，这些都是这种方法的亮点所在。\n网络存根记录和回放 这是一种与 UI 集成测试密切相关的高级技术。回顾 UI 集成参考 1, 2。\nCypress 允许你对所有网络流量进行存根。我们可以记录来自一个端点的网络数据，并在 UI 每次调用任意服务器时存根该响应。\n首先，从开发者工具复制网络数据到一个 json 文件中。将其放置在 cypress/fixtures 文件夹中。这个文件夹专为此目的而创建，对它的任何引用都将默认指向文件夹的根目录。\n// prerequisite: the data has been copied to a file `cypress/fixtures/agents.json` // this is a shorthand for cy.fixture(). More at https://docs.cypress.io/api/commands/fixture.html#Accessing-Fixture-Data cy.intercept(\u0026#39;some-xhr-call-that-happens-upon-landing\u0026#39;, { fixture: \u0026#39;agents.json\u0026#39;} ).as(\u0026#39;crutcXHR\u0026#39;); // all calls to the network route will be stubbed by the data in agents.json file 如果有很多网络请求发生怎么办？ 我们从哪里获取所有的模拟数据？我们不想手动复制和保存它们。我们希望在测试运行时记录它们，以便与真实的 API 进行比对。\n至少有两个 Cypress 插件可以用于这个目的 1 和 2。\n如果这些插件不适用于你，你可以轻松使用以下三个函数创建自己的记录和回放工具。\nfunction stubRecorder(pathToJson) { const xhrData = []; // an empty array to hold the data cy.server({ // if recording, save the response data in the array onResponse: (response) =\u0026gt; { const url = response.url; const method = response.method; const data = response.response.body; // We push a new entry into the xhrData array xhrData.push({ url, method, data }); } }); // cy.intercept() specification below is used as a selector for the data you want to record. // In this example, all GET requests from any url will be selected // You can specify the methods and routes that are recorded cy.log(\u0026#39;recording!\u0026#39;); cy.intercept({ method: \u0026#39;GET\u0026#39;, url: \u0026#39;*\u0026#39;, }); // if recording, after the test runs, create a fixture file with the recorded data after(function () { cy.writeFile(`./cypress/fixtures/${pathToJson}.json`, xhrData); cy.log(`Wrote ${xhrData.length} XHR responses to local file ${pathToJson}.json`); }); } /** Plays recorded fixture with all required network data as json*/ function playStubbedFixture(stateFixture) { cy.log(`playing fixture from ${stateFixture}`); cy.fixture(stateFixture, { timeout: 15000 }) // the fixture file may be large and take time in CI .each(({method, url, data}) =\u0026gt; { cy.intercept(method, url, data); }).as(`stateFixture_stub`); } /** Visits the stubbed state */ function visitStubbedState(stubFile, url, wait: boolean = true) { playStubbedFixture(stubFile); cy.visit(url); if (wait) { // sometimes you do not want to wait for network, this gives you the option cy.wait(\u0026#39;@stateFixture_stub\u0026#39;, { timeout: 15000 }); } } ////////// // usage // recording network it(\u0026#39;should run your test\u0026#39;, function () { stubrecorder(\u0026#39;jsonfileNameForNetworkData\u0026#39;); // your original test cy.wait(5000); // one-time wait so that the after() step records all the network without missing anything // the rest of your original test }); // playing the stubbed network it(\u0026#39;should run your test\u0026#39;, function () { // every time we visit this endpoint, all network will be stubbed // double check this by observing (XHR stubbed) network responses in the test runner visitStubbedState(\u0026#39;jsonfileNameForNetworkData\u0026#39;, \u0026#39;/endpoint\u0026#39;); // the rest of your original test }); 网络存根记录和回放的优缺点 UI 集成测试是 UI 测试的核心。它们在真实浏览器中运行整个应用程序，而不连接真实服务器。它们运行速度极快，对网络中的随机故障或错误负面影响较小。\n工程师们必须认识到，这种优势如果被滥用可能成为一种诅咒。UI 应用程序是隔离的，但如果有网络故障，它们会被忽略。这对于功能分支测试非常有用，但在进一步的部署中，应确保后端也正常运行。请参阅 使用集成测试前端，同时使用 E2E 测试后端 了解何时使用哪种技术。\n填充数据库 Cypress cy.task() 功能非常强大。实际上，它允许你在 Cypress 上下文中使用 Node.js。这可以是任何内容，从 Node.js 代码到使用 npm 包来操纵数据库。如果你的应用程序使用 Node.js，你可以重用应用程序代码来帮助设置和操纵测试数据。\n关于这个主题有一个 Cypress 示例，我们将以此作为参考结束。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-best-practices-2-ui-tests-debugging-best-practices-and-reaching-ui-state/","summary":"这篇博文探讨了 UI 测试的通用最佳实践之二：UI 测试调试和无需使用 UI 达到 UI 状态。博文详细介绍了在 UI 测试中的调试技巧，包括使用断点、日志和交互式调试工具等方法，提高测试脚本的调试效率。此外，文章强调了通过直接设置应用程序状态而无需依赖 UI 元素来达到 UI 状态的方法，以提高测试速度和稳定性。通过这些实践，读者能够更好地应对 UI 测试中的调试挑战，同时优化测试脚本的执行效率。","title":"UI 测试最佳实践的通用最佳实践（二）：UI 测试调试最佳实践和在测试中达到 UI 状态而无需使用 UI"},{"content":"K6 常用功能 上一篇博文介绍了K6 性能测试教程：常用功能（1）- HTTP 请求，指标和检查 这一篇文章主要聚焦在阈值设置、测试生命周期和场景设计方面。阐述了如何利用 K6 在性能测试中设定合理的阈值，以便有效监测系统的性能表现。同时，探讨了测试生命周期的重要性，以及如何在不同阶段进行有针对性的性能测试。\nThresholds 阈值 什么是阈值 阈值一般是我们为测试指标定义的通过/失败标准。对于 K6 来说，如果被测系统的性能不满足阈值条件，测试将以失败状态结束。\n前面提到的检查（check）是用来验证测试结果是否符合预期，check 不通过，测试还会继续，而阈值（threshold）是用来验证测试结果是否符合性能要求。如果不符合，测试将以失败状态结束。\n通常情况下，我们进行性能测试时会使用阈值来编写不同服务或接口的 SLOs(服务级别目标 Service Level Objectives)。\n下面为一些阈值的例子：\n不到 1% 的请求返回错误。 95% 的请求响应时间低于 200 毫秒。 99% 的请求响应时间低于 400 毫秒。 特定端点始终在 300 毫秒内响应。 自定义指标（等待时间趋势）的任何条件（大于 300 毫秒）。 如果后续会写性能自动化测试脚本，那么阈值就是必不可少的。\n给你的测试一个阈值。 自动化执行 设置测试失败警报。 HTTP 错误和响应持续时间的阈值示例 以下示例演示如何使用阈值来设置并评估 HTTP 错误率（http_req_failed 指标）和评估 95% 的请求响应是否在特定持续时间内发生（http_req_duration 指标）：\nimport http from \u0026#39;k6/http\u0026#39;; export const options = { thresholds: { http_req_failed: [\u0026#39;rate\u0026lt;0.01\u0026#39;], // HTTP 错误率应该低于 1% http_req_duration: [\u0026#39;p(95)\u0026lt;200\u0026#39;], // 95% 的请求响应应该低于 200ms }, }; export default function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); } 上述的示例中，我们设置了两个阈值：\nHTTP 错误率应该低于 1%。（用到了 http_req_failed 指标） 95% 的请求响应应该低于 200ms。（用到了 http_req_duration 指标） 对于上面代码设置的阈值，如果运行的时候，HTTP 错误率低于 1% 和 95% 的请求响应低于 200ms，那么测试就会以成功状态结束，否则任一阈值不满足，测试就将以失败状态结束。\n运行该脚本，可以看到如下结果：\n结果中显示，http_req_failed 阈值通过了，http_req_duration 阈值没有通过，整体测试以失败状态结束。\n如果任何阈值失败，则阈值名称（http_req_failed、http_req_duration）旁边的绿色小复选标记 ✓ 将是 ✗ 并且 k6 将以非零值退出退出代码。\n阈值语法 阈值语法是一个字符串，由以下部分组成：\n指标名称（例如 http_req_duration）。 一个或多个条件，用逗号分隔。 每个条件都由一个运算符和一个值组成。 运算符可以是以下之一：\u0026gt;、\u0026gt;=、\u0026lt;、\u0026lt;=、==、!=、=~、!~。 值可以是数字或百分比。 百分比值必须在 0 到 100 之间。 想要在测试脚本中使用阈值，步骤如下：\n1.在 options 对象中添加 thresholds 属性，如下所示：\nexport const options = { thresholds: { /* ... */ }, }; 2.在 thresholds 对象中定义阈值表达式（至少一个，可以多个），如下所示：\nexport const options = { thresholds: { //短格式 METRIC_NAME1: [\u0026#39;THRESHOLD_EXPRESSION\u0026#39;, `...`], //长格式 METRIC_NAME2: [ { threshold: \u0026#39;THRESHOLD_EXPRESSION\u0026#39;, abortOnFail: true, // boolean delayAbortEval: \u0026#39;10s\u0026#39;, // string }, ], // full format }, }; 阈值表达式支持短格式和长格式，短格式将所有阈值表达式作为字符串放入数组中。长格式将每个阈值放入一个对象中，并具有在失败时中止的额外属性。 上面示例代码中的 METRIC_NAME1 和 THRESHOLD_EXPRESSION 是占位符。正常情况下必须是指标名称和阈值表达式。 示例代码声明配置指标 metric_name1 和 metric_name2 的两个阈值。通过评估阈值后的\u0026rsquo;threshold_expression\u0026rsquo;来确定阈值是通过还是失败，. 阈值表达式语法 阈值表达式的计算结果为 true 或 false 。阈值表达式必须采用以下格式：\n\u0026lt;aggregation_method\u0026gt; \u0026lt;operator\u0026gt; \u0026lt;value\u0026gt; \u0026lt;aggregation_method\u0026gt;：聚合方法，用于计算指标的值。例如，p(95) 表示 95% 百分位数，而 avg 表示平均值。 \u0026lt;operator\u0026gt;：运算符，用于比较指标的值与阈值表达式中的值。例如，\u0026gt; 表示大于，\u0026lt; 表示小于，== 表示等于。 \u0026lt;value\u0026gt;：阈值表达式中的值。例如，200 表示 200 毫秒，95 表示 95%。 阈值表达式的一些示例如下：\navg \u0026lt; 200 // 平均持续时间必须小于 200 毫秒 count \u0026gt;= 500 // 计数必须大于或等于 500 p(90) \u0026lt; 300 // 90% 的样本必须低于 300 按类型划分的聚合方法 k6 根据类型聚合指标。这些聚合方法构成阈值表达式的一部分。\n以下是按类型划分的聚合方法列表：\n指标类型 聚合方法 ｜Counter count 计数 和 rate 比率 ｜Gauge value 具体的值 ｜Rate rate 比率 ｜Trend avg 平均值、min 最小值、max 最大值、med 和 p(N) 其中 N 指定阈值百分位值，表示为 0.0 到 100 之间的数字。p(99.99) 表示第 99.99 个百分位。这些值以毫秒为单位。｜ 一个复杂的聚合方法示例：\nimport http from \u0026#39;k6/http\u0026#39;; import { Trend, Rate, Counter, Gauge } from \u0026#39;k6/metrics\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const TrendRTT = new Trend(\u0026#39;RTT\u0026#39;); export const RateContentOK = new Rate(\u0026#39;Content OK\u0026#39;); export const GaugeContentSize = new Gauge(\u0026#39;ContentSize\u0026#39;); export const CounterErrors = new Counter(\u0026#39;Errors\u0026#39;); export const options = { thresholds: { // 计数：不允许超过 99 次返回错误的内容。 \u0026#39;Errors\u0026#39;: [\u0026#39;count\u0026lt;100\u0026#39;], // 计量：返回的内容必须控制在 4000 字节以下。 \u0026#39;ContentSize\u0026#39;: [\u0026#39;value\u0026lt;4000\u0026#39;], // 比率：内容必须在 95 次以上达到“OK”。 \u0026#39;Content OK\u0026#39;: [\u0026#39;rate\u0026gt;0.95\u0026#39;], // 趋势：百分位数、平均值、中位数和最小值必须保持在指定的毫秒范围内。 \u0026#39;RTT\u0026#39;: [\u0026#39;p(99)\u0026lt;300\u0026#39;, \u0026#39;p(70)\u0026lt;250\u0026#39;, \u0026#39;avg\u0026lt;200\u0026#39;, \u0026#39;med\u0026lt;150\u0026#39;, \u0026#39;min\u0026lt;100\u0026#39;], }, }; export default function () { const res = http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); const contentOK = res.json(\u0026#39;name\u0026#39;) === \u0026#39;Bert\u0026#39;; TrendRTT.add(res.timings.duration); RateContentOK.add(contentOK); GaugeContentSize.add(res.body.length); CounterErrors.add(!contentOK); sleep(1); } 注意：不要通过重复相同的对象键来为同一指标指定多个阈值。\n由于阈值被定义为 JavaScript 对象的属性，因此您不能指定多个具有相同属性名称的阈值。如果要为一个指标设置多个阈值，请使用同一键的数组指定它们。\n常用的阈值示例 使用阈值的最快方法是先使用内置指标。以下是一些常用的复制示例\n1.在指定持续时间内完成的请求百分比 import http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { // 90% 的请求必须在 400 毫秒内完成。 http_req_duration: [\u0026#39;p(90) \u0026lt; 400\u0026#39;], }, }; export default function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); sleep(1); } 2.错误率低于 1% import http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { // 在整个测试执行过程中，错误率必须低于 1％。 http_req_failed: [\u0026#39;rate\u0026lt;0.01\u0026#39;], }, }; export default function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); sleep(1); } 3.单个指标的多个阈值 我们也可以为一项指标应用多个阈值。该阈值对于不同的请求百分位数有不同的持续时间要求。\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { // 90％的请求必须在 400 毫秒内完成，95％在 800 毫秒内完成，99.9％在 2 秒内完成。 http_req_duration: [\u0026#39;p(90) \u0026lt; 400\u0026#39;, \u0026#39;p(95) \u0026lt; 800\u0026#39;, \u0026#39;p(99.9) \u0026lt; 2000\u0026#39;], }, }; export default function () { const res1 = http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); sleep(1); } 4.持续时间组的阈值 我们也可以为每个组设置阈值。此代码具有针对单独请求和批量请求的组。对于每个组，都有不同的阈值。\nimport http from \u0026#39;k6/http\u0026#39;; import { group, sleep } from \u0026#39;k6\u0026#39;; export const options = { thresholds: { \u0026#39;group_duration{group:::individualRequests}\u0026#39;: [\u0026#39;avg \u0026lt; 400\u0026#39;], \u0026#39;group_duration{group:::batchRequests}\u0026#39;: [\u0026#39;avg \u0026lt; 200\u0026#39;], }, vus: 1, duration: \u0026#39;10s\u0026#39;, }; export default function () { group(\u0026#39;individualRequests\u0026#39;, function () { http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/1/\u0026#39;); http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/2/\u0026#39;); http.get(\u0026#39;https://test-api.k6.io/public/crocodiles/3/\u0026#39;); }); group(\u0026#39;batchRequests\u0026#39;, function () { http.batch([ [\u0026#39;GET\u0026#39;, `https://test-api.k6.io/public/crocodiles/1/`], [\u0026#39;GET\u0026#39;, `https://test-api.k6.io/public/crocodiles/2/`], [\u0026#39;GET\u0026#39;, `https://test-api.k6.io/public/crocodiles/3/`], ]); }); sleep(1); } 超过阈值时中止测试 如果在测试过程中，我们想要在阈值不满足时中止测试，那么可以使用 abortOnFail 属性。\n将 abortOnFail 属性设置为 true。当您设置 abortOnFail 时，一旦阈值失败，测试运行就会停止。\n这里也会有一种特殊情况，测试可能会因为这个阈值的设定导致在测试生成重要数据之前中止。为了防止这些情况，我们可以使用 delayAbortEval 延迟 abortOnFail。在此脚本中，abortOnFail 延迟了十秒。十秒后，如果未达到 p(99) \u0026lt; 10 阈值，测试将中止。\nexport const options = { thresholds: { metric_name: [ { threshold: \u0026#39;p(99) \u0026lt; 10\u0026#39;, // string abortOnFail: true, // boolean delayAbortEval: \u0026#39;10s\u0026#39;, // string /*...*/ }, ], }, }; 更多阈值的内容，请参考官方文档：https://k6.io/docs/using-k6/thresholds/\nTest lifecycle 测试生命周期 K6 框架中的测试的生命周期，测试脚本始终都以下面的相同顺序进行执行：\ninit 初始化阶段：上下文中的代码准备脚本、加载文件、导入模块并定义测试生命周期函数。必需的。 setup 前置准备设置阶段：设置测试环境并生成数据。可选的。 VU UV 阶段：代码在 default 或场景函数中运行，运行时间和次数与 options 定义的一样长。必需的。 teardown 后置测试退出阶段：对数据进行后处理并关闭测试环境。可选的。 生命周期函数：除了初始化代码之外，每个阶段都在生命周期函数中发生，这是在 k6 运行时按照特定顺序调用的函数。\n下面是一个完整的测试生命周期示例：\n// 1. 配置 init 阶段（必需的） export function setup() { // 2. 配置 setup 阶段（可选的） } export default function (data) { // 3. 配置 VU 阶段（必需的） } export function teardown(data) { // 4. 配置 teardown 阶段（可选的） } 生命周期阶段概述 测试阶段 目的 示例 请求次数 init 初始化阶段 加载本地文件、导入模块、声明生命周期函数 打开 JSON 文件，导入模块 每个 VU 一次* Setup 前置准备配置阶段 设置要处理的数据，在 VU 之间共享数据 调用 API 启动测试环境 一次 VU code VU 代码阶段 运行测试函数，通常是 default 发出 https 请求，验证响应 每次迭代一次，根据测试选项的需要进行多次 Teardown 测试后置退出阶段 设置代码的处理结果，停止测试环境 验证设置是否有一定的结果，发送 webhook 通知测试已完成 一次 ** * 在云脚本中，init 代码可能会被更频繁地调用。** 如果 Setup 函数异常结束（例如抛出错误），则不会调用 teardown() 函数。考虑向 setup() 函数添加逻辑以处理错误并确保正确清理。\ninit 初始化阶段 K6 测试的必要阶段。这个阶段用来在测试之前准备测试环境和初始化测试条件\ninit 上下文中的代码每个 VU 都会运行一次。\n一般在init 阶段可能会做的事情：\n导入模块 从本地文件系统加载文件 为所有 options 配置测试 为 VU、setup 和 teardown 阶段（以及自定义或 handleSummary() 函数）定义生命周期函数。 init 上下文中的代码始终首先执行\nVU 阶段 VU 阶段是测试的核心。在这个阶段，代码在 default 或场景函数中运行，运行时间和次数与 options 定义的一样长。\n关于 UV 阶段的 Q\u0026amp;A：\n1.为什么有 VU 阶段？\nVU 阶段是测试的核心，脚本必须至少包含一个定义 VU 逻辑的场景函数。该函数内部的代码是 VU 代码。 VU 阶段是真正的测试代码，所以 VU 阶段的代码会被多次执行，执行次数由 options 定义的一样长。 2.为什么把 init 阶段和 VU 阶段分开\n将 init 阶段与 VU 阶段分离，可以消除 VU 代码中不相关的计算，从而提高 k6 性能并使测试结果更加可靠。init 代码的一个限制是它无法发出 HTTP 请求。此限制确保 init 阶段在测试中可重现（协议请求的响应是动态且不可预测的） 将 init 阶段与 VU 阶段分离，可以使 VU 阶段的代码更加简洁，更加专注于测试逻辑。 3.UV 阶段的默认函数生命周期的理解\nVU 从头到尾依次执行 default() 函数。一旦 VU 到达函数末尾，它就会循环回到开头并重新执行代码 作为此“重新启动”过程的一部分，k6 会重置 VU。Cookie 被清除，TCP 连接可能被断开（取决于我们的测试配置选项）。 Setup 测试前置准备配置阶段 和 teardown 测试后置退出阶段 Setup 和 teardown 阶段是可选的。这两个阶段都是在 VU 阶段之前和之后运行的。\n与 default 一样，setup 和 teardown 函数必须是导出函数。但与 default 函数不同，k6 每次测试仅调用 setup 和 teardown 一次。\nsetup 在测试开始时调用，在 init 阶段之后但在 VU 阶段之前。 teardown 在测试结束时、VU 阶段（default 函数）之后调用。 与 init 阶段不同，您可以在设置和拆卸阶段调用完整的 k6 API 更多 K6 测试生命周期的内容，请参考官方文档：https://k6.io/docs/using-k6/test-life-cycle/\nScenarios 测试场景 在 K6 的测试脚本中，可以定义多个测试场景，每个场景都可以有自己的配置项，例如 VU 数量、持续时间等。\n测试场景可以详细配置 VU 和迭代计划的方式。通过测试场景配置，我们可以在性能测试中对不同的工作负载或流量模式进行更好的根据业务进行自定义。\n使用测试场景配置的好处：\n更简便、更灵活的测试组织方式。您可以在同一个脚本中定义多个测试场景，每个场景可以独立执行不同的 JavaScript 函数。 模拟更真实的流量情况。每个测试场景都可以使用不同的虚拟用户（VU）和迭代调度模式，由专门设计的执行器提供支持。 并行或顺序工作负载。各个场景相互独立并行运行，尽管可以通过仔细设置每个场景的 startTime 属性使它们看起来像是按顺序运行的。 细致入微的结果分析。可以为每个场景设置不同的环境变量和指标标签。 测试场景配置 我们可以使用代码中的 options 对象中的 scenarios 键值来配置具体场景方案。也可以为场景指定任意名称，只要脚本中的每个场景名称都是唯一的即可。\n场景配置示例：\nexport const options = { scenarios: { example_scenario: { // 使用的执行器名称 executor: \u0026#39;shared-iterations\u0026#39;, // 常规的场景配置 startTime: \u0026#39;10s\u0026#39;, gracefulStop: \u0026#39;5s\u0026#39;, env: { EXAMPLEVAR: \u0026#39;testing\u0026#39; }, tags: { example_tag: \u0026#39;testing\u0026#39; }, // 与执行器相关的特殊配置 vus: 10, iterations: 200, maxDuration: \u0026#39;10s\u0026#39;, }, another_scenario: { /*...*/ }, }, }; 测试场景执行器 对于每个 k6 场景，VU（虚拟用户）的工作负载由执行器进行调度。执行器配置测试运行的持续时间、流量是否保持恒定或变化，以及工作负载是由 VU 还是到达率（即开放或关闭模型）建模的。\n我们设置的测试场景对象必须定义 executor 属性，并选择其中一个预定义的执行器名称。您选择的执行器将决定 k6 如何对负载进行建模。可选项包括：\n按迭代次数。\nshared-iterations 在 VU 之间共享迭代。 per-vu-iterations 让每个 VU 运行配置的迭代。 按 VU 数量。\nconstant-VUs 以恒定数量发送 VU。 ramping-vus 根据您配置的阶段增加 VU 数量。 按迭代率。\nconstant-arrival-rate 以恒定速率开始迭代。 ramping-arrival-rate 根据您配置的阶段提高迭代率。 除了这些通用场景选项之外，每个执行程序对象还具有特定于其工作负载的其他选项，可以点击执行者获取更多\n测试场景配置选项 选项名称 类型 描述 默认值 executor(必填) string 唯一的执行者名称 - startTime string 自测试开始以来的时间偏移，此时该场景应开始执行。 \u0026ldquo;0s\u0026rdquo; gracefulStop string 在强行停止迭代之前等待迭代完成执行的时间。要了解更多信息，请阅读优雅停止。 \u0026ldquo;30s\u0026rdquo; exec string 要执行的导出 JS 函数的名称。 \u0026ldquo;default\u0026rdquo; env object 此场景特定的环境变量。 {} tags object 特定于此场景的标签。 {} 测试场景示例 测试场景的 demo 脚本 会结合两种场景并按顺序执行：\nshared_iter_scenario 立即启动。10 个 VU 尝试尽快使用 100 次迭代（某些 VU 可能比其他 VU 使用更多迭代）。 per_vu_scenario 在 10 秒后开始。在这种情况下，十个 VU 每个运行十次迭代。 示例代码如下：\nimport http from \u0026#39;k6/http\u0026#39;; export const options = { scenarios: { shared_iter_scenario: { executor: \u0026#39;shared-iterations\u0026#39;, vus: 10, iterations: 100, startTime: \u0026#39;0s\u0026#39;, }, per_vu_scenario: { executor: \u0026#39;per-vu-iterations\u0026#39;, vus: 10, iterations: 10, startTime: \u0026#39;10s\u0026#39;, }, }, }; export default function () { http.get(\u0026#39;https://test.k6.io/\u0026#39;); } 运行场景 demo 脚本，可以看到如下结果：\n观看测试结果，你会发现配置了场景的测试结果中，除了常规的测试结果外，k6 输出将包含有关 demo 场景的 详细结果信息 (shared_iter_scenario 场景和 per_vu_scenario 场景的很详细的指标信息)。\n更多关于测试场景的内容，请参考官方文档：https://k6.io/docs/using-k6/scenarios/\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ K6 性能测试教程：常用功能（1）- HTTP 请求，指标和检查:https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-common-functions-1-http-request-metrics-and-checks/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-common-functions-2-thresholds-test-lifecycle-and-scenarios/","summary":"这篇博文深入介绍了 K6 性能测试工具的常用功能，主要聚焦在阈值设置、测试生命周期和场景设计方面。阐述了如何利用 K6 在性能测试中设定合理的阈值，以便有效监测系统的性能表现。同时，探讨了测试生命周期的重要性，以及如何在不同阶段进行有针对性的性能测试。此外，博文还详细解释了 K6 中场景的概念，以及如何根据实际需求设计和配置场景，确保测试全面覆盖各种使用情景。通过本文，读者能够更深入地了解 K6 性能测试工具在项目中的实际应用，提高性能测试的效果和准确性。","title":"K6 性能测试教程：常用功能（2）- 阈值，测试生命周期和场景"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n等待，不要休眠 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/await-dont-sleep.md\n一段简要说明 在测试 UI 时，您需要定义应用程序必须经过的关键点。到达这些关键点是一个异步过程，因为几乎 100% 的情况下，UI 不会同步更新。\n这些关键点称为确定性事件，即您知道必须发生的事件。\n具体取决于您定义的事件以及 UI 达到这些事件的方式，但通常会存在一些“长时间”等待，例如 XHR 请求，以及一些更快的等待，例如重新渲染更新。\n解决异步更新的方法似乎很简单：休眠/暂停测试一段时间，几毫秒、几分之一秒，甚至几秒钟。这可以使测试正常工作，因为它给应用程序足够的时间来更新自身并移动到下一个要测试的确定性事件。\n请注意，除了特定和已知的等待（例如使用 setInterval 或 setTimeout 时），完全无法预测休眠时间应该是多久，因为它可能取决于：\n网络状态（对于 XHR 请求） 可用机器资源的总量（CPU、RAM 等） 例如，CI 流水线可能会对其进行限制 在本地机器上，其他应用程序也可能会消耗这些资源 其他资源消耗更新的并发情况（canvas 等） 一系列不可预测的因素，如 Service Workers、缓存管理等，可能加快或减缓 UI 更新过程 每个固定的延迟都会使测试变得更加脆弱，并增加其持续时间。您需要在虚假负面和夸张的测试持续时间之间找到平衡。\n等待可分为四个主要类别：\n页面加载等待：测试应用程序时需要处理的第一个等待，等待一个允许您了解页面是否可交互的事件 内容等待：等待匹配选择器的 DOM 元素 XHR 请求等待：等待 XHR 请求开始或相应接收到 以下所有示例都基于 Cypress。\n页面加载等待 // Cypress code cy.visit(\u0026#39;http://localhost:3000\u0026#39;) 内容等待 请看以下示例，了解如何在可用工具中实现等待 DOM 元素。\n内容等待代码示例 等待元素 // Cypress code // it waits up to 4 seconds by default cy.get(\u0026#39;#form-feedback\u0026#39;) // the timeout can be customized cy.get(\u0026#39;#form-feedback\u0026#39;, { timeout: 5000 }) 等待具有特定内容的元素 // Cypress code cy.get(\u0026#39;#form-feedback\u0026#39;).contains(\u0026#39;Success\u0026#39;) XHR-请求等待 XHR-请求等待代码示例 等待 XHR 请求/响应 // Cypress code cy.intercept(\u0026#39;http://dummy.restapiexample.com/api/v1/employees\u0026#39;).as(\u0026#39;employees\u0026#39;) cy.wait(\u0026#39;@employees\u0026#39;) .its(\u0026#39;response.body\u0026#39;) .then((body) =\u0026gt; { /* ... */ }) 由 NoriSte 在 dev.to 和 Medium上进行联合发表.\n明智地为测试文件命名 原文链接：https://github.com/NoriSte/ui-testing-best-practices/blob/master/sections/generic-best-practices/name-test-files-wisely.md\n一段简要说明 编写各种不同的 UI 测试是一种好习惯，而采用一种常见的测试文件命名方式更是有益的。\n这很有用，因为通常情况下，你需要仅运行某一类测试，可能的情况包括：\n在开发过程中，你只需要运行其中一些测试 你正在更改一些相关组件，并需要检查生成的标记是否发生了变化 你正在更改全局 CSS 规则，只需运行视觉测试 你正在更改应用程序流程，需要运行整个应用程序集成测试 你的 DevOps 同事需要确保一切正常运行，最简单的方法就是只运行端对端测试 你的构建流水线需要运行集成测试和端对端测试 你的监控流水线需要一个脚本来运行端对端测试和监控测试 如果你为测试取一个明智的命名，将会非常容易只运行其中的某些类型。\nCypress:\ncypress run --spec \\\u0026#34;cypress/integration/**/*.e2e.*\\\u0026#34; Jest:\njest --testPathPattern=e2e\\\\.*$ 没有一种全局的命名测试文件的方式，一个建议是使用以下方式命名：\n正在测试的主题 测试的类型（integration、e2e、monitoring、component等） 选择的测试后缀（test、spec等） 文件扩展名（.js、.ts、.jsx、.tsx等） 它们之间用句点分隔。\n以下是一些例子：\nauthentication.e2e.test.ts authentication.integration.test.ts site.monitoring.test.js login.component.test.tsx 等等。 参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-generic-best-practices-1-await-dont-sleep-and-name-test-files-wisely/","summary":"这篇博文探讨了 UI 测试的通用最佳实践之一：等待策略。强调了在 UI 测试中避免使用休眠（sleep）方法，而是采用等待机制来确保测试脚本与应用程序的同步。此外，博文提倡为测试文件采用明智的命名规范，以提高代码可维护性和可读性。通过这些最佳实践，读者将更有效地编写稳健的 UI 测试脚本，确保测试的准确性和可靠性，提升整个软件开发过程的质量。","title":"UI 测试最佳实践的通用最佳实践（一）：等待，不要休眠和明智地为测试文件命名"},{"content":"K6 常用功能 HTTP Requests 使用 K6 进行性能测试的第一步就是定义要测试的 HTTP 请求。\nGET 请求例子 使用 k6 new 命令创建的 demo 测试脚本中，已经包含了一个简单的 GET 方法 HTTP 请求：\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export default function() { http.get(\u0026#39;https://test.k6.io\u0026#39;); sleep(1); } POST 请求例子 这个 POST 请求例子展示一些复杂的场景的应用（带有电子邮件/密码身份验证负载的 POST 请求）\nimport http from \u0026#39;k6/http\u0026#39;; export default function () { const url = \u0026#39;http://test.k6.io/login\u0026#39;; const payload = JSON.stringify({ email: \u0026#39;aaa\u0026#39;, password: \u0026#39;bbb\u0026#39;, }); const params = { headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, }; http.post(url, payload, params); } 以上内容参考自 K6 官方文档\n支持的 HTTP 方法 K6 提供的 HTTP 模块能处理各种 HTTP 请求和方法。以下是支持的 HTTP 方法列表：\n方法 作用 batch() 并行发出多个 HTTP 请求（例如浏览器往往会这样做）。 del() 发出 HTTP DELETE 请求。 get() 发出 HTTP GET 请求。 head() 发出 HTTP HEAD 请求。 options() 发出 HTTP OPTIONS 请求。 patch() 发出 HTTP PATCH 请求。 post() 发出 HTTP POST 请求。 put() 发出 HTTP PUT 请求。 request() 发出任何类型的 HTTP 请求。 HTTP 请求标签 K6 允许为每个 HTTP 请求添加标签，结合标签和分组，可以很方便的在测试结果中更好地组织，分组请求和过滤结果组织分析。\n以下为支持的标签列表：\n标签 作用 name 请求名称。默认为请求的 URL method 请求方法（GET、POST、PUT 等） url 默认为请求的 URL。 expected_response 默认情况下，200 到 399 之间的响应状态为 true。使用 setResponseCallback 更改默认行为。 group 当请求在组内运行时，标记值是组名称。默认为空。 scenario 当请求在场景内运行时，标记值是场景名称。默认为 default。 status 响应状态 HTTP 请求使用 tag 和 group 标签的例子会在后续的 demo 中展示。\n大家也可以参考官方的例子：https://grafana.com/docs/k6/latest/using-k6/http-requests/\nMetrics 指标 指标用于衡量系统在测试条件下的性能。默认情况下，k6 会自动收集内置指标。除了内置指标，您还可以创建自定义指标。\n指标一般分为四大类：\n计数器（Counters）：对值求和。 计量器（Gauges）：跟踪最小、最大和最新的值。 比率（Rates）：跟踪非零值发生的频率。 趋势（Trends）：计算多个值的统计信息（如均值、模式或百分位数）。 要使测试断言符合需求标准，可以根据性能测试要求的指标条件编写阈值（表达式的具体内容取决于指标类型）。\n为了后续进行筛选指标，可以使用标签和分组，这样可以更好地组织测试结果。\n测试结果输出文件可以以各种摘要和细粒度格式导出指标，具体信息请参阅结果输出文档。（后面测试结果输出文档会详细介绍这一部分）\nK6 内置指标 每个 k6 测试执行都会发出内置和自定义指标。每个支持的协议也有其特定的指标。\n标准内置指标 无论测试使用什么协议，k6 始终收集以下指标：\n指标名称 指标分类 指标描述 vus Gauge 当前活跃虚拟用户数 vus_max Gauge 最大可能虚拟用户数（VU 资源已预先分配，以避免扩大负载时影响性能） iterations 迭代 Counter VU 执行 JS 脚本（default 函数）的总次数。 iteration_duration Trend 完成一次完整迭代的时间，包括在 setup 和 teardown 中花费的时间。要计算特定场景的迭代函数的持续时间，请尝试此解决方法 dropped_iterations Counter 由于缺少 VU（对于到达率执行程序）或时间不足（基于迭代的执行程序中的 maxDuration 已过期）而未启动的迭代次数。关于删除迭代 data_received Counter 接收到的数据量。此示例介绍如何跟踪单个 URL 的数据。 data_sent Counter 发送的数据量。跟踪单个 URL 的数据以跟踪单个 URL 的数据。 checks Rate 设置的检查成功率。 指标分类分别为：计数器（Counter）、计量器（Gauges）、比率（Rates）、趋势（Trends）\nHTTP 特定的内置指标 HTTP 特定的内置指标是仅在 HTTP 请求期间才会生成和收集的指标。其他类型的请求（例如 WebSocket）不会生成这些指标。\n注意：对于所有 http_req_* 指标，时间戳在请求结束时发出。换句话说，时间戳发生在 k6 收到响应正文末尾或请求超时时。\n下表列出了 HTTP 特定的内置指标：\n指标名称 指标分类 指标描述 http_reqs Counter k6 总共生成了多少个 HTTP 请求。 http_req_blocked Trend 在发起请求之前阻塞（等待空闲 TCP 连接槽）所花费的时间。float类型 http_req_connecting Trend 与远程主机建立 TCP 连接所花费的时间。float类型 http_req_tls_handshaking Trend 与远程主机握手 TLS 会话所花费的时间 http_req_sending Trend 向远程主机发送数据所花费的时间。float类型 http_req_waiting Trend 等待远程主机响应所花费的时间（也称为“第一个字节的时间”或“TTFB”）。float类型 http_req_receiving Trend 从远程主机接收响应数据所花费的时间。float类型 http_req_duration Trend 请求的总时间。它等于 http_req_sending + http_req_waiting + http_req_receiving（即远程服务器处理请求和响应所需的时间，没有初始 DNS 查找/连接时间）。float类型 http_req_failed Rate 根据 setResponseCallback 的失败请求率。 指标分类分别为：计数器（Counter）、计量器（Gauges）、比率（Rates）、趋势（Trends）\n其他内置指标 K6 内置指标除了标准内置指标和 HTTP 特定的内置指标外，还有其他内置指标：\nBrowser metrics 浏览器指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#browser Built-in WebSocket metrics 内置 WebSocket 指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#websockets Built-in gRPC metrics 内置 gRPC 指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#grpc 自定义指标 除了系统内建的指标之外，您还可以创建自定义指标。例如，您可以计算与业务逻辑相关的指标，或者利用 Response.timings 对象为特定的一组端点创建指标。\n每种指标类型都有一个构造函数，用于生成自定义指标。该构造函数会生成一个声明类型的指标对象。每种类型都有一个 add 方法，用于记录指标测量值。\n注意：必须在 init 上下文中创建自定义指标。这会限制内存并确保 K6 可以验证所有阈值是否评估了定义的指标。\n自定义指标 demo 示例 以下示例演示如何创建等待时间的自定义趋势指标：\n项目文件中的 demo_custom_metrics.js 文件已经包含了这个 demo 示例，可以直接运行查看结果。\n1.从导入 k6/metrics 模块引入 Trend 构造函数 import { Trend } from \u0026#39;k6/metrics\u0026#39;; 等待时间趋势指标属于趋势（Trends）指标，所以需要从 k6/metrics 模块引入 Trend 构造函数。\n2.在 init 上下文中构造一个新的自定义度量 Trend 对象 const myTrend = new Trend(\u0026#39;waiting_time\u0026#39;); 在 init 上下文中构造一个新的自定义度量 Trend 对象，脚本中的对象为 myTrend，其指标在结果输出中显示为 waiting_time。\n3.在脚本中使用 add 方法记录指标测量值 export default function() { const res = http.get(\u0026#39;https://test.k6.io\u0026#39;); myTrend.add(res.timings.waiting); } 在脚本中使用 add 方法记录指标测量值，这里使用了 res.timings.waiting，即等待时间。\n4.demo_custom_metrics.js 自定义指标完整代码 import http from \u0026#39;k6/http\u0026#39;; import { Trend } from \u0026#39;k6/metrics\u0026#39;; const myTrend = new Trend(\u0026#39;waiting_time\u0026#39;); export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); myTrend.add(res.timings.waiting); console.log(myTrend.name); // waiting_time } 5.运行 demo_custom_metrics.js 并查看自动化趋势指标 k6 run demo_custom_metrics.js 运行结果如下：\n可以看到，自定义指标 waiting_time 已经在结果输出中显示出来了。\n更多关于自定义指标的内容，请参考官方文档：https://k6.io/docs/using-k6/metrics/#custom-metrics\nChecks 检查 这里也可以理解为断言，即对测试结果进行验证。\n检查用来检验不同测试中的具体测试条件是否正确相应，和我们常规在做其他类型测试时也会对测试结果进行验证，以确保系统是否以期望的内容作出响应。\n例如，一个验证可以确保 POST 请求的响应状态为 201，或者响应体的大小是否符合预期。\n检查类似于许多测试框架中称为断言的概念，但是K6 在验证失败并不会中止测试或以失败状态结束。相反，k6 会在测试继续运行时追踪失败验证的比率。\n每个检查都创建一个速率指标。要使检查中止或导致测试失败，可以将其与阈值结合使用。\n下面会介绍如何使用不同类型的检查，以及如何在测试结果中查看检查结果。\n1.检查 HTTP 响应状态 K6 的检查非常适用于与 HTTP 请求相关的响应断言。\n示例，以下代码片段来检查 HTTP 响应代码为 200：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, }); } 运行该脚本，可以看到如下结果：\n当脚本包含检查时，摘要报告会显示通过了多少测试检查。\n在此示例中，请注意检查“HTTP response code is status 200”在调用时是 100% 成功的。\n2.检查 HTTP 响应体 除了检查 HTTP 响应状态外，还可以检查 HTTP 响应体。\n示例，以下代码片段来检查 HTTP 响应体大小为 9591 bytes：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response body size is 9591 bytes\u0026#39;: (r) =\u0026gt; r.body.length == 9591, }); } 运行该脚本，可以看到如下结果：\n当脚本包含检查时，摘要报告会显示通过了多少测试检查。\n在此示例中，请注意检查“HTTP response body size is 9591 bytes”在调用时是 100% 成功的。\n3.添加多个检查 有时候我们在一个测试脚本中需要添加多个检查，那可以直接在单​​个 check() 语句中添加多个检查，如下面脚本所示：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, \u0026#39;HTTP response body size is 9591 bytes\u0026#39;: (r) =\u0026gt; r.body.length == 9591, }); } 运行该脚本，可以看到如下结果：\n在此示例中，两个检查都是正常通过的（调用是 100% 成功的）。\n注意：当检查失败时，脚本将继续成功执行，并且不会返回“失败”退出状态。如果您需要根据检查结果使整个测试失败，则必须将检查与阈值结合起来。这在特定环境中特别有用，例如将 k6 集成到 CI 管道中或在安排性能测试时接收警报。\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-common-functions-1-http-request-metrics-and-checks/","summary":"这篇文章详细介绍了 K6 中的 HTTP 请求（http request）功能，解析了常用的性能指标和检查功能。学会如何使用 K6 进行强大的性能测试，通过 HTTP 请求模拟用户行为，了解性能指标以评估系统响应。文章还深入讲解了如何配置和执行检查，确保性能符合预期标准。无论您是初学者还是经验丰富的性能测试专业人员，这篇教程将为您提供实用知识，助您充分发挥 K6 的性能测试潜力。点击链接，开启高效性能测试之旅！","title":"K6 性能测试教程：常用功能（1）- HTTP 请求，指标和检查"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n什么样的测试策略才更合理 上一篇文章讲到了不同的测试类型，以及它们的优缺点。在这篇文章中，我们将深入探讨什么样的测试策略才更为合理。 会从在开始阶段，避免追求完美主义，选择一个参考浏览器，发现了 bug？先编写测试，然后再着手修复，和单个长的端到端测试还是多个小的独立测试？等方面阐述了什么样的测试策略才更合理\n在开始阶段，避免追求完美主义 测试真的改变了你的工作方式，但就像所有事情一样，需要一些经验才能真正发挥其威力。在一开始，务必避免完美主义的陷阱。为什么呢？\n测试本质上就是小程序。完美主义可能会导致你在了解如何处理不同的测试上下文之前编写非常复杂的测试。\n复杂的测试是个大敌人，因为调试失败的测试比调试失败的应用程序更加困难。而且复杂的测试让你失去了测试实践本身的优势，浪费了很多时间，最终不可避免地会让你放弃。如果你有这样的经历，不要气馁，对很多测试初学者来说都是一样的（对我来说也是，这就是我开始写这个 repo 的原因 😊），不要害怕向同事或其他开发人员寻求帮助。\n误报：完美主义导致很多误报。误报是指应用程序按预期工作，但测试失败的情况。\n误报在一开始确实让人泄气，因为你开始写测试是为了有一个盟友来检查应用程序状态\u0026hellip; 但最终你却得到了另一个需要维护的应用程序，而测试并没有提供任何帮助。如果你发现自己在与误报作斗争，请停下来，重新学习，并寻求帮助！\n测试的实用性：成功的测试在失败时直接指向问题。正确的断言和确定性事件使你的测试强大而且非常重要的是，它们在失败时是有用的。相反，过多的断言和检查可能会使你的测试因为无用而变得脆弱。\n所谓完美主义是指检查每一个前端细节。在开始时，你的有限的测试经验不允许你有针对性地测试所有的交互。开始时，测试一些简单的事情，比如\n页面是否正确加载？ 菜单按钮是否正常工作？ 用户是否能够填写表单并成功跳转到感谢页面？ 而在开始阶段，不要过于关注测试一些诸如\n条件数据加载 复杂的表单规则 无控制的（第三方）集成 元素选择器 等复杂的交互。 为了避免陷入完美主义的陷阱，初学者的待办事项清单可以是：\n选择最简单的测试对象（对用户有用的东西）。 从用户的角度考虑。记住用户关心内容和功能，而不关心选择器和内部应用程序状态。 编写你的测试。 运行测试多次以确保它的稳定性。 当测试成功时，在前端应用程序中插入一个导致它失败的错误，然后检查测试是否失败。然后移除你故意插入的错误。 以无头和非无头模式运行测试。 根据你的经验（也问问同事），思考从你测试的内容的角度看，可能导致前端应用程序失败的原因是什么。 模拟不同的前端故障（关闭服务器、插入其他错误）并检查测试是否提供足够的反馈，以了解哪里失败了。 仅对两三种故障进行测试，记住你有限的经验可能导致你测试错误的东西。 然后，转移到另一个测试对象并重复所有先前的步骤。 软件测试是一场奇妙的旅程，这个 repo 的目标是帮助你避免最常见的陷阱。\n建议的流程只是可能方法之一。我知道一切都是主观的，请为每个建议提出请求以进行改进！\n选择一个参考浏览器 每个人都关心跨浏览器测试。我们通常习惯在每个浏览器上手动测试所有内容，因为我们知道，不同浏览器之间存在许多差异。当我们开始评估合适的测试工具时，跨浏览器测试是一个重要的话题，也是你在考虑时可能首先想到的。但是不要担心：首先从功能测试和视觉测试分离开始，这是正确评估跨浏览器支持需求（也是选择正确测试工具的第一步）。视觉测试可以集成到每个测试工具中，感谢诸如 Applitools 和 Percy 这样的服务。\n换句话说，不要仅仅基于跨浏览器支持来选择测试工具。以下是一些建议：\nSelenium 和 Puppeteer 是通用的自动化工具。它们可以用作测试工具（有许多插件和模块可帮助你实现），但它们并非专为测试而设计，因此它们缺少一些集成实用工具，这可能使测试编写更加简便。\n只考虑 Cypress、Playwright 和 TestCafé，因为它们是专为简化 UI 测试过程而创建的工具。这些工具自动处理一半的最佳实践，而在测试中的一些方面，它们可能更符合你的需求。在 UI 测试方面，由于其\n困难性，花些时间试验这些工具是值得的。\n仔细思考你需要测试什么。如果你需要测试特定的移动能力，请选择 TestCafé，但如果你只需要测试表单和按钮是否正常工作，你在选择上就更加灵活。\n查看 Cypress Test Runner，这是使 Cypress 异于常人的工具，对于测试开发过程中非常有帮助。\n研究 Playwright 在调试方面的优势。Playwright 非常快速稳定，最近其开发体验有了很大改进。\n跨浏览器测试通常涉及到视觉测试（CSS 浏览器差异），但这与功能测试不同。视觉测试得益于许多专用插件和工具的支持。详细了解 视觉测试对应的章节 Applitools，其中我们讨论了一些专用产品，这些产品可以与几乎所有测试工具集成，通过将被测试页面的快照上传到其服务器并进行呈现来进行工作。\n你还可以在 等待，不是休眠 章节中了解各种测试工具之间的一些差异。\n发现了 bug？先编写测试，然后再着手修复 所以，当你在前端应用程序中发现错误并已经进行了调试时，你可以系统地复现它，准备好修复它。以测试为导向的思维必须经历以下步骤：\n确定预期的行为。 编写一个测试，旨在以正确的方式使用前端应用程序。 测试必须失败，因为错误不允许用户完成任务。 修复错误。 检查测试现在是否通过。 为什么要采用这种方法？为什么要编写测试呢？我知道直接修复错误可能看起来更快，但请考虑以下几点：\n通常情况下，你的测试工具比你更快地达到显示错误的应用程序状态（参见使用测试工具作为主要开发工具 章节）。\n有时你认为你能够系统地复现错误，但这并不总是正确的。编写一个揭示错误的测试可以确保你百分之百确定错误是可重现的，排除了许多偏差变量，如现有的会话、缓存、服务工作者、浏览器扩展、浏览器版本等，这些可能会影响你的信心。有时你可能会发现你并没有完全正确地识别错误。\n与此同时，当测试通过了你的修复时，你确实知道你的解决方\n案按预期工作。可能影响错误识别过程的相同变量可能会影响工作效果的虚假感觉。\n有了测试，错误就可以永远修复了！ 测试将被执行成千上万次，让你对错误修复感到百分之百的信心。\n成功的测试可以作为你所做工作的验证轨迹。\n最后但同样重要的是：确保你编写的测试一开始是失败的！而且它之所以失败是因为有错误！\n测试不仅仅是为了重现错误并在视觉上检查它，而是必须在修复错误后获得积极的反馈。与错误相关的测试如果一开始就没有失败，那真的非常危险，因为你可能认为你做得很好，而实际上你从一开始就没有完全正确地重现错误。\n作为一般规则：破碎的流程必须有一个破碎的测试，一个成功的测试必须与一个正常工作的应用程序相关联。\n单个长的端到端测试还是多个小的独立测试？ 在讨论对 CRUD 应用进行测试时，我们应该如何组织“创建”、“修改”和“删除”端到端（E2E）测试呢？\n完整的选项列表如下：\n有三个小的 E2E 测试，依赖于执行顺序（测试 B 假设测试 A 已运行）- 这是唯一的不良解决方案，我将解释原因。 有三个小的 E2E 测试，独立于执行顺序（测试 B 不受测试 A 是否运行的影响）- 从理论上讲，是最好的解决方案。但仍然需要大量样板代码，而且为了快速执行。 有一个执行所有操作的扩展 E2E 测试 - 对于本文介绍的案例来说，这是一个很好的折中方案。 这取决于情况，我提到的大多数问题与 E2E 测试的隐含问题有关，这是我们应该尽量减少这类测试的强烈信号。作为前端工程师，我更喜欢投资时间编写无需服务器的测试，而不是 E2E 测试。继续阅读，你将了解原因。\n1 - 有三个小的 E2E 测试，依赖于执行顺序（测试 B 假设测试 A 已运行） 测试流程如下：\n开始（应用程序状态为空） 测试 1: 创建实体 测试 2: 修改实体 测试 3: 删除实体 结束（应用程序状态为空） 在这种情况下，这些测试不是独立的，而是依赖于执行顺序。为了测试 CRUD 流程，有三个主要测试：\u0026ldquo;创建实体\u0026rdquo;、\u0026ldquo;修改实体\u0026rdquo;、\u0026ldquo;删除实体\u0026rdquo;。第二个测试（\u0026ldquo;修改实体\u0026rdquo;）假设在其启动时应用程序状态是正确的，因为它在 \u0026ldquo;创建实体\u0026rdquo; 之后运行。\u0026ldquo;删除实体\u0026rdquo; 也必须在 \u0026ldquo;修改实体\u0026rdquo; 之后运行，依此类推。\n将多个测试耦合在一起是一种反模式，原因如下：\n误报：一旦一个测试失败，后续测试会连续失败。 难以调试：由于不确定性较高，理解失败的根本原因更加复杂。测试失败是因为代码本身失败？还是因为先前测试的状态发生了变化？然后，当一个测试失败时，你必须调试两个测试。 难以调试（再次）：开发人员会浪费大量时间，因为他们无法运行单个测试，也无法使用 skip 和 only 仅运行其中一部分测试。 难以重构：测试无法移动到其他位置。如果测试代码变得太长、太复杂等，你无法将其移动到专用文件/目录中，因为它依赖于先前的测试。 难以阅读：读者无法知道一个测试的作用，因为他们还必须了解先前的测试。你必须阅读两个测试，而不是一个，这是不好的。 我不建议以这种方式编写耦合的测试，但我想包含它们以确保您明白原因。\n2 - 设计三个小型端到端（E2E）测试，使其独立于执行顺序 为了确保每个测试的独立性，每个测试在运行前都应该创建所需的应用程序状态，然后在完成后进行清理。相较于原有的顺序（创建-\u0026gt;修改-\u0026gt;删除），前文提到的流程应该调整如下（斜体 表示与原有流程相比的新步骤）：\n开始（应用程序状态为空） 测试 1：创建实体 之前：加载页面（应用程序状态为空） 创建实体 之后：删除实体（应用程序状态为空） 测试 2：修改实体 之前：通过 API 创建实体 之前：加载页面（应用程序状态为空） 修改实体 之后：通过 API 删除实体（应用程序状态为空） 测试 3：删除实体 之前：通过 API 创建实体 之前：加载页面（应用程序状态为空） 删除实体 之后：删除操作（应用程序状态为空） 结束（应用程序状态为空） 通过这种方式，每个测试都是相互独立的。需要注意的是，之前和之后的操作直接通过调用服务器 API 完成，因为通过 UI 完成这些操作将会很慢。然而，这种方法的问题在于测试变得更加耗时，因为每个测试都需要创建实体，并且每个测试都需要访问页面。当应用程序加载需要花费 10 秒钟时（Hasura 的控制台最初的情况），重新加载应用程序将成为一个问题。\n为了确保测试既独立又高效，我们需要进一步改进上述流程：\n充分利用前一个测试的应用状态。 同时，如果尚未运行测试，还需要创建所需的应用状态。 具体来说，流程如下（与前一章节相比，斜体表示新步骤）：\n开始（应用状态为空）\n测试 1： 创建实体\n之前：实体 是否存在？ 否：没问题！ 是：通过 API 删除实体 之前：加载页面（应用状态为空） 创建实体 测试 2： 修改实体\n之前：实体 是否存在？ 是：没问题！ 否：通过 API 创建实体 之前：实体 是否已包含测试即将进行的更改？ 是：没问题！ 否：通过 API 修改实体 之前：我们是否已经在正确的页面上？ 是：没问题！ 否：加载页面 修改实体 测试 3： 删除实体\n之前：实体是否存在？ 是：没问题！ 否：通过 API 创建实体 之前：我们是否已经在正确的页面上？ 是：没问题！ 否：加载页面 删除实体\n结束（应用状态为空）\n现在，如果你一次运行所有测试，每个测试都会利用之前测试的应用状态。如果只运行“修改实体”测试，它会创建所需的一切，然后运行测试本身。\n现在我们既有测试的独立性又有测试的性能！很不错！\n嗯\u0026hellip; 你是否注意到我们需要编写大量代码？cypress-data-session 插件很方便，但存在两个问题：\n有很多与 cypress-data-session 相关的样板代码 在 E2E 测试中，必须维护许多可能与主应用程序中使用的 API 调用不同步的 API 调用。 这是一个与 cypress-data-session 相关的样板代码示例（来自 Hasura Console 代码库）。\nimport { readMetadata } from \u0026#39;../services/readMetadata\u0026#39;; import { deleteHakunaMatataPermission } from \u0026#39;../services/deleteHakunaMatataPermission\u0026#39;; /** * Ensure the Action does not have the Permission. * * ATTENTION: if you get the \u0026#34;setup function changed for session...\u0026#34; error, simply close the * Cypress-controlled browser and re-launch the test file. */ export function hakunaMatataPermissionMustNotExist( settingUpApplicationState = true ) { cy.dataSession({ name: \u0026#39;hakunaMatataPermissionMustNotExist\u0026#39;, // Without it, cy.dataSession run the setup function also the very first time, trying to // delete a Permission that does not exist init: () =\u0026gt; true, // Check if the Permission exists validate: () =\u0026gt; { Cypress.log({ message: \u0026#39;**--- Action check: start**\u0026#39; }); return readMetadata().then(response =\u0026gt; { const loginAction = response.body.actions?.find( action =\u0026gt; action.name === \u0026#39;login\u0026#39; ); if (!loginAction || !loginAction.permissions) return true; const permission = loginAction.permissions.find( permission =\u0026gt; permission.role === \u0026#39;hakuna_matata\u0026#39; ); // Returns true if the permission does not exist return !permission; }); }, preSetup: () =\u0026gt; Cypress.log({ message: \u0026#39;**--- The permission must be deleted**\u0026#39; }), // Delete the Permission setup: () =\u0026gt; { deleteHakunaMatataPermission(); if (settingUpApplicationState) { // Ensure the UI read the latest data if it were previously loaded cy.reload(); } }, }); } 以下是用于创建实体的 API 调用示例（来自 Hasura Console 代码库）。\n/** * Create the Action straight on the server. */ export function createLoginAction() { Cypress.log({ message: \u0026#39;**--- Action creation: start**\u0026#39; }); cy.request(\u0026#39;POST\u0026#39;, \u0026#39;http://localhost:8080/v1/metadata\u0026#39;, { type: \u0026#39;bulk\u0026#39;, source: \u0026#39;default\u0026#39;, args: [ { type: \u0026#39;set_custom_types\u0026#39;, args: { scalars: [], input_objects: [ { name: \u0026#39;SampleInput\u0026#39;, fields: [ { name: \u0026#39;username\u0026#39;, type: \u0026#39;String!\u0026#39; }, { name: \u0026#39;password\u0026#39;, type: \u0026#39;String!\u0026#39; }, ], }, ], objects: [ { name: \u0026#39;SampleOutput\u0026#39;, fields: [{ name: \u0026#39;accessToken\u0026#39;, type: \u0026#39;String!\u0026#39; }], }, { name: \u0026#39;LoginResponse\u0026#39;, description: null, fields: [ { name: \u0026#39;accessToken\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, ], }, { name: \u0026#39;AddResult\u0026#39;, fields: [{ name: \u0026#39;sum\u0026#39;, type: \u0026#39;Int\u0026#39; }], }, ], enums: [], }, }, { type: \u0026#39;create_action\u0026#39;, args: { name: \u0026#39;login\u0026#39;, definition: { arguments: [ { name: \u0026#39;username\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, { name: \u0026#39;password\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, ], kind: \u0026#39;synchronous\u0026#39;, output_type: \u0026#39;LoginResponse\u0026#39;, handler: \u0026#39;https://hasura-actions-demo.glitch.me/login\u0026#39;, type: \u0026#39;mutation\u0026#39;, headers: [], timeout: 25, request_transform: null, }, comment: null, }, }, ], }).then(() =\u0026gt; Cypress.log({ message: \u0026#39;**--- Action creation: end**\u0026#39; })); } 因此，拥有独立的测试是至关重要的，但也伴随着一些成本。\n这就是为什么，针对这个具体问题，我选择了最后一种选择\u0026hellip;\n3 - 进行一次全面的端到端测试 优点：可以减少很多样板文件。\n缺点：与测试一起工作变得更慢了（你不能再仅运行第三个测试了）\n与我们需要编写的样板和需要维护的代码相比，将它们统一起来是值得的。毕竟，我正在处理的特定 CRUD 流程大约需要 20 秒。\n开始 (应用程序状态为空) 测试：CRUD 之前*：如果存在实体，则删除它（应用程序状态为空）* 之前*：加载页面* 创建实体 修改实体 删除实体 之后*：如果存在实体，则删除它（应用程序状态为空）* 结束 (应用程序状态为空) 同时，这也使得 cypress-data-session 变得无用。因此，少了一个需要保持更新的依赖。\n结论 处理端到端测试很困难。处理真实数据、清除真实应用程序状态等都是有成本的。我知道端到端测试是唯一能够提供完整信心的测试，但作为一名前端工程师（请记住，我不是 QA 工程师），我更愿意使用无需服务器的测试。\n相关章节 🔗 从金字塔的顶端着手构建测试！ 🔗 把你的测试工具当作主要的开发工具来使用 由 NoriSte 在 dev.to上进行了跨发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-testing-strategy-2-more-reasonable-testing-strategy-for-ui-testing/","summary":"这篇博文深入探讨 UI 测试最佳实践的测试策略（二），着重介绍了更为合理的测试策略。从避免追求完美主义、选择参考浏览器、发现 Bug 时的处理方式，到在修复之前编写测试、单个长的端到端测试与多个小的独立测试的选择，全面阐述了什么样的测试策略更为合理。无论是初学者还是经验丰富的测试专业人员，这篇博文都将为您提供实用的指导，帮助您制定更明智、高效的 UI 测试策略。点击链接，探索更合理的 UI 测试方法！","title":"UI 测试最佳实践的测试策略（二）：什么样的测试策略才更合理"},{"content":"一段简要说明 在谈论 UI 测试时（请记住我们只谈论 UI，而不是底层 JavaScript 代码），有三种主要的测试类型：\n组件测试：UI 的单元测试，它们在隔离的环境中测试每个单独的组件。\n在隔离中开发组件很重要，因为它允许你将它们与相应的容器/用途隔离开来。组件存在是为了隔离单一的行为/内容（单一职责原则），因此，在隔离中编码是有益的。\n有许多在隔离中开发组件的方法和工具，但由于其效果和生态系统，Storybook 成为了标准选择。\n组件有三种类型的契约：生成的输出（HTML），它们的视觉方面（CSS）和外部 API（props 和回调）。测试每个方面可能很繁琐，这就是 Storyshots 可以派上用场的地方。它允许你自动化：\n快照测试：快照是组件生成的输出，一个包含所有呈现 HTML 的字符串。如果生成的 HTML 更改，无论是意外还是非意外，快照测试都会失败，你可以选择这些更改是有意还是无意。\n视觉回归测试：与先前的组件相比，组件的视觉方面逐像素比较，同样，你被提示选择是否接受更改。\n这些测试由 Storyshots 在每个 Storybook 页面（又名“故事”）上自动启动。\n回调测试：一个小的 React 容器应用呈现组件并传递一些回调。然后，模拟用户交互并传递期望调用的回调。React Testing Library 是这类测试的标准库。\n交互/状态测试：与组件的一些交互期望正确的状态管理。这种类型的测试必须从消费者的角度编写，而不是从内部的角度（例如，用户填写输入字段时的输入字段值，而不是内部组件状态）。交互/状态测试应在触发键盘事件后断言输入字段的值。\n或者，Cypress 推出了自己的解决方案，以便在其中启动组件测试，请查看 使用 Cypress 进行 React 组件单元测试 章节。\nUI 集成测试：它们在真实浏览器中运行整个应用 而不连接真实服务器。这些测试是每个前端开发人员的王牌。它们运行速度快，不容易出现随机失败或假阴性。\n前端应用程序并不知道没有真实服务器：每个 AJAX 调用都会被测试工具在瞬间解决。静态 JSON 响应（称为“fixtures”）用于模拟服务器响应。Fixtures 允许我们测试前端状态，模拟每种可能的后端状态。\n另一个有趣的效果是：Fixtures 允许您在没有工作的后端 应用程序的情况下工作。您可以将 UI 集成测试视为“仅前端”测试。\n在最成功的测试套件的核心，有很多 UI 集成测试，考虑到对前端应用程序的最佳测试类型。\n端到端（E2E）测试：它们与真实服务器进行交互，运行整个应用程序。从用户交互（其中之一是“端”）到业务数据（另一个“端”）：一切都必须按设计工作。E2E 测试通常很慢，因为\n它们需要一个 工作的后端 应用程序，通常在前端应用程序旁边启动。没有服务器，你不能启动它们，所以你依赖于后端开发人员的工作 它们需要 可靠的数据，在每次测试之前进行种植和清理 这就是为什么 E2E 测试不可行作为唯一/主要测试类型的原因。它们非常重要，因为它们测试所有内容（前端 + 后端），但必须小心使用，以避免脆弱且持续时间长的测试套件。\n在具有许多 UI 集成测试的完整套件中，您可以将 E2E 测试视为“后端测试”。通过它们，您应该测试哪些流程？\n快乐路径流程：您需要确保至少用户能够完成基本操作 对您的业务有价值 在具有许多 UI 集成测试的完整套件中，您可以将 E2E 测试视为“后端测试”。通过它们，您应该测试哪些流程？\n快乐路径流程：您需要确保至少用户能够完成基本操作 对您的业务有价值的一切：无论是快乐路径还是其他，都要测试您的业务关心的任何内容（明显是优先考虑它们） 经常中断的一切：系统的薄弱区域也必须受到监视 识别/定义测试类型对于对它们进行分组、合理命名测试文件、限制它们的\n范围以及选择是否在整个应用程序和部署流水线中运行它们很有用。\n由NoriSte在dev.to和Medium上进行了跨发表。\n翻译自：Component vs (UI) Integration vs E2E Tests*\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/ui-automation-testing/ui-testing-best-practice-testing-strategy--1-component-tests-vs-ui-integration-tests-vs-e2e-tests/","summary":"这篇博文深入研究 UI 测试最佳实践，首篇聚焦于测试策略的选择：组件测试、UI 集成测试和端到端（E2E）测试的区别。了解每种测试类型的优缺点，帮助您在 UI 测试中做出明智的选择。不论您是开发者还是测试专业人员，这篇文章将为您提供深入洞察，助力您设计出更可靠、高效的 UI 测试策略。点击链接，探索 UI 测试的最佳实践，提升您的测试流程质量。","title":"UI 测试最佳实践的测试策略（一）：组件测试 vs（UI）集成测试 vs E2E 测试"},{"content":"什么是 K6 k6 是一款用于性能测试和负载测试的开源工具，主要用于评估和验证应用程序的性能和稳定性。以下是关于 k6 的一些主要特点和信息：\n开源性： k6 是一款完全开源的性能测试工具，代码存储在 GitHub 上。这意味着用户可以自由访问、使用和修改工具的源代码。\nJavaScript 编写脚本： k6 使用 JavaScript 语言编写测试脚本，这使得编写测试用例相对简单，并且对于开发人员而言更加友好。脚本可以包含 HTTP 请求、WebSocket 连接、脚本执行逻辑等。\n支持多种协议： k6 支持多种常见的协议，包括 HTTP、WebSocket、Socket.IO、gRPC 等，使其可以广泛应用于各种类型的应用程序。\n分布式测试： k6 具有分布式测试的能力，允许在多个节点上运行测试，从而模拟更真实的生产环境负载。\n实时结果和报告： k6 提供实时结果，包括请求响应时间、吞吐量等，并能够生成详细的 HTML 报告，帮助用户更好地理解应用程序的性能状况。\n容器化支持： k6 适应容器化环境，可以轻松集成到 CI/CD 流水线中，并与常见的容器编排工具（如 Kubernetes）配合使用。\n插件生态系统： k6 支持插件，用户可以通过插件扩展其功能，满足特定需求。\n活跃的社区： 由于 k6 是一个开源项目，拥有一个积极的社区，提供支持、文档和示例，使用户更容易上手和解决问题。\n总体而言，k6 是一个灵活、强大且易于使用的性能测试工具，适用于各种规模的应用程序和系统。\n官方网站及文档 官方网站 官方文档 安装 Mac 系统安装 Mac 系统可以通过 Homebrew 安装 k6：\nbrew install k6 Windows 系统安装 Windows 系统可以通过 Chocolatey 安装 k6：\nchoco install k6 或者通过 winget 安装 k6：\nwinget install k6 Docker 安装 k6 也可以通过 Docker 安装：\ndocker pull grafana/k6 其他系统安装 K6 除了支持上述系统外，还支持 Linux（Debian/Ubuntu/Fedora/CentOS），也支持下载 K6 二进制文件和 K6 扩展进行安装，具体安装方式请参考官方文档。\n确认 K6 安装成功 安装完成后，可以通过以下命令确认 k6 是否安装成功：\nk6 version 如果安装成功，会显示 k6 的版本信息：\n第一个 K6 测试脚本 编写第一个测试脚本 新建一个 K6 性能测试项目目录并进入 mkdir k6-demo cd k6-demo 创建一个名为 demo.js 的文件，用于编写测试脚本 可以通过 k6 new 命令创建一个测试脚本文件： k6 new demo.js 也可以直接创建一个名为 demo.js 的测试脚本文件 touch demo.js 编辑测试脚本 如果是通过 k6 new 命令创建的测试脚本文件，会自动生成一个简单的测试脚本，如下所示：\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { // A number specifying the number of VUs to run concurrently. vus: 10, // A string specifying the total duration of the test run. duration: \u0026#39;30s\u0026#39;, // The following section contains configuration options for execution of this // test script in Grafana Cloud. // // See https://grafana.com/docs/grafana-cloud/k6/get-started/run-cloud-tests-from-the-cli/ // to learn about authoring and running k6 test scripts in Grafana k6 Cloud. // // ext: { // loadimpact: { // // The ID of the project to which the test is assigned in the k6 Cloud UI. // // By default tests are executed in default project. // projectID: \u0026#34;\u0026#34;, // // The name of the test in the k6 Cloud UI. // // Test runs with the same name will be grouped. // name: \u0026#34;demo.js\u0026#34; // } // }, // Uncomment this section to enable the use of Browser API in your tests. // // See https://grafana.com/docs/k6/latest/using-k6-browser/running-browser-tests/ to learn more // about using Browser API in your test scripts. // // scenarios: { // // The scenario name appears in the result summary, tags, and so on. // // You can give the scenario any name, as long as each name in the script is unique. // ui: { // // Executor is a mandatory parameter for browser-based tests. // // Shared iterations in this case tells k6 to reuse VUs to execute iterations. // // // // See https://grafana.com/docs/k6/latest/using-k6/scenarios/executors/ for other executor types. // executor: \u0026#39;shared-iterations\u0026#39;, // options: { // browser: { // // This is a mandatory parameter that instructs k6 to launch and // // connect to a chromium-based browser, and use it to run UI-based // // tests. // type: \u0026#39;chromium\u0026#39;, // }, // }, // }, // } }; // The function that defines VU logic. // // See https://grafana.com/docs/k6/latest/examples/get-started-with-k6/ to learn more // about authoring k6 scripts. // export default function() { http.get(\u0026#39;https://test.k6.io\u0026#39;); sleep(1); } 如果是直接创建的测试脚本文件，可以将上述内容复制到 demo.js 文件中。\n运行测试脚本 在 demo.js 文件所在目录下，运行以下命令：\nk6 run demo.js 查看测试结果 如果一切正常，会看到类似如下的输出：\n包含以下信息：\nexecution: 执行信息，包括开始时间、结束时间、持续时间、VU 数量、迭代次数等。 scenarios: 场景信息，包括场景名称、VU 数量、迭代次数、持续时间、平均响应时间、吞吐量等。 http_reqs: HTTP 请求信息，包括请求名称、请求数量、失败数量、平均响应时间、吞吐量等。 解析 demo 测试脚本 import http from 'k6/http';：导入 k6 的 HTTP 模块，用于发送 HTTP 请求。\nimport { sleep } from 'k6';：导入 k6 的 sleep 方法，用于执行脚本等待。\nexport const options = { ... }：定义测试脚本的配置项，包括 VU 数量、持续时间等。\nvus: 10,：定义 VU 数量为 10（指定并发运行的 VU 数量）。\nduration: '30s',：定义持续时间为 30 秒（指定测试运行总持续时间）。\nexport default function() { ... }：定义测试脚本的逻辑，包括发送 HTTP 请求、执行等待等。\nhttp.get('https://test.k6.io');：发送一个 GET 请求到 https://test.k6.io。\nsleep(1);：执行等待 1 秒。\n其他注释内容可以忽略，这些内容是关于 k6 的一些高级功能，后续会介绍。\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/k6-tutorial-getting-started-and-your-first-k6-test-script/","summary":"这篇文章将带您进入 K6 性能测试的世界。博文内容涵盖了 K6 性能测试的入门知识、环境搭建步骤，以及如何编写您的第一个测试脚本。无论您是初学者还是有经验的性能测试专业人员，这篇教程都将为您提供清晰的指导，帮助您快速上手 K6，并开始构建高效的性能测试脚本","title":"K6 性能测试教程：入门介绍，环境搭建和编写第一个 K6 测试脚本"},{"content":"亲爱的读者们，\n最近，在搜索引擎上检查个人博客文章的收录情况时，我不得不向大家通报一件令人痛心的事情。我发现我的博客文章竟然被一位 CSDN 博主原封不动地抄袭复制到他的博客上，而且更令人遗憾的是，他并未注明出处。\n对于这种不道德的行为，我感到愤怒和失望。我一直努力为大家提供原创、有价值的内容，而这样的抄袭行为是对我的辛勤努力和付出的严重不尊重。为了捍卫自己的权益，我认为有必要发布这篇声明，让大家了解事实真相。\n首先，我要明确表示，我坚决反对一切形式的抄袭和侵权行为。我运营的博客是我的个人创作空间，我希望它能成为分享和交流的平台，而不是被他人肆意剽窃的对象。\n在确认了 CSDN 博主的行为后，我深感遗憾，也决定采取一切必要的法律手段来维护自己的合法权益。同时，我呼吁所有博主和创作者共同努力，维护良好的创作环境，杜绝抄袭现象。\n最后，我要感谢一直以来支持我的读者们。你们的支持是我创作的动力，也是我战胜困难的力量。我会继续为大家带来真实、有价值的内容。\n抄袭博客链接：https://blog.csdn.net/2301_76387166?type=blog\n我已经联系 CSDN 下架。\n再次感谢大家的关注和支持。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/article-plagiarism-statement/","summary":"这篇博文是关于我的文章被抄袭的声明。","title":"关于我的文章被抄袭的声明"},{"content":"Java 和 REST Assured 框架实现接口自动化项目 REST Assured 框架教程目录 目录不可点击，仅为展示目录结构\nRestAssured 接口自动化测试快速启动项目 RestAssured 介绍 项目结构 Gradle 构建的版本 Maven 构建的版本 项目依赖 从 0 到 1 搭建 REST Assured 接口测试项目 Gradle 版本 Maven 版本 进阶用法 验证响应数据 文件上传 Logging 日志 Filters 过滤器 持续集成 接入 github action 集成 allure 测试报告 数据驱动 多环境支持 REST Assured 框架教程对应文章 REST Assured 接口自动化测试教程：进阶用法 - 集成 CI/CD 和集成 allure 测试报告:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-integration-ci-cd-and-allure-report/\nREST Assured 接口自动化测试教程：进阶用法 - 验证响应和日志记录，过滤器，文件上传:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-verifying-response-and-logging/\nREST Assured 接口自动化测试教程：从 0 到 1 搭建 REST Assured 接口自动化测试项目:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-building-your-own-project-from-0-to-1/\nREST Assured 接口自动化测试教程：入门介绍和环境搭建准备:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-and-environment-preparation/\nREST Assured 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/RestAssured-API-Test-Starter/ Rest assured 官方文档：https://rest-assured.io/ Rest assured 官方 github：https://github.com/rest-assured/rest-assured Rest assured 官方文档中文翻译：https://github.com/RookieTester/rest-assured-doc Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions JavaScript 和 SuperTest 框架实现接口自动化项目 SuperTest 框架教程目录 目录不可点击，仅为展示目录结构\nSuperTest 接口自动化测试快速启动项目 介绍 项目依赖 项目文件结构 从 0 到 1 搭建 SuperTest 接口自动化测试项目 Mocha 版本 Jest 版本 进阶用法 持续集成 接入 github action 常用断言 SuperTest 的内置断言 CHAI 的常用断言 Jest 的常用断言 数据驱动 多环境支持 SuperTest 框架教程对应文章 SuperTest 接口自动化测试教程：进阶用法 - 多环境支持：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-multiple-environment-support/ SuperTest 接口自动化测试教程：进阶用法 - 数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-data-driven/ SuperTest 接口自动化测试教程：进阶用法 - 常用断言：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-common-assertions/ SuperTest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action:https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-integration-ci-cd-and-github-action/ SuperTest 接口自动化测试教程：从 0 到 1 搭建 Supertest 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-building-your-own-project-from-0-to-1/ SuperTest 接口自动化测试教程：入门介绍和环境搭建准备：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-getting-started-and-own-environment-preparation/ SuperTest 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/SuperTest-API-Test-Starter SuperTest 文档：https://github.com/ladjs/supertest Jest 文档：https://jestjs.io/docs/en/getting-started Mocha 文档：https://mochajs.org/ Chai 文档：https://www.chaijs.com/ Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions Python 和 Pytest 框架实现接口自动化项目 Pytest 框架教程目录 目录不可点击，仅为展示目录结构\nPytest 接口自动化测试快速启动项目 介绍 Pytest 介绍 python 虚拟环境介绍 项目依赖 项目目录结构 从 0 到 1 搭建 Pytest 接口自动化测试项目 进阶用法 持续集成 接入 github action 常用断言 数据驱动 多环境支持 集成 allure 报告 并发测试和分布式测试 筛选用例执行 Pytest 框架教程对应文章 Pytest 接口自动化测试教程：进阶用法 - 筛选测试用例执行，并发测试和分布式测试：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-filter-testcase-and-concurrent-testing-distributed-testing/ Pytest 接口自动化测试教程：进阶用法 - 多环境支持 和 集成 allure 报告：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-multiple-environment-support-and-integration-allure-report/ Pytest 接口自动化测试教程：进阶用法 - 常用断言和数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-common-assertions-and-data-driven/ Pytest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-integration-ci-cd-and-github-action/ Pytest 接口自动化测试教程：从 0 到 1 搭建 Pytest 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-building-your-own-project-from-0-to-1/ Pytest 接口自动化测试教程：入门介绍和环境搭建准备：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-getting-started-and-own-environment-preparation/ Pytest 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Pytest-API-Test-Starter Pytest 文档：https://docs.pytest.org/en/stable/ Pytest-html 文档：https://pypi.org/project/pytest-html/ Pytest-xdist 文档：https://pypi.org/project/pytest-xdist/ Allure-pytest 文档：https://pypi.org/project/allure-pytest/ Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions 测试工具实现接口自动化测试 Postman 接口自动化测试 Postman 框架教程目录 目录不可点击，仅为展示目录结构\nPostman-API-Test-Starter 介绍 接口测试简介 Postman 与 newman 介绍 项目依赖 项目文件结构 从 0 到 1 搭建 Postman 接口自动化测试项目 进阶用法 输出 html 测试报告 CI/CD 持续集成 接入 github action 集成 allure 测试报告 常用测试脚本 响应测试脚本 请求前脚本 测试脚本中可用的第三方库 chai.js 断言库方法 使用 cheerio 操作 HTML 文件 使用 tv4 来验证 JSON Schema 生成 uuid 使用 xml2js 将 XML 转换为 JavaScript 对象 常用工具函数 util stream 流操作 定时器 timers 时间处理 events 数据驱动 使用环境变量 使用数据文件 文件上传 并发测试 Postman 框架教程对应文章 Postman 接口自动化测试教程：进阶用法 - 常用命令行选项，文件上传场景和 SSL 证书场景：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-command-line-options-and-file-upload/ Postman 接口自动化测试教程：进阶用法 - 数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-data-driven-and-environment-data-driven/ Postman 接口自动化测试教程：进阶用法 - 常用的测试脚本和常用的第三方包用法示例：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-test-scripts-and-commonly-used-third-party-packages/ Postman 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action，接入 allure 测试报告：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-integration-html-report-and-allure-report-integration-github-action/ Postman 接口自动化测试教程：入门介绍和从 0 到 1 搭建 Postman 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-getting-started-and-building-your-own-project-from-0-to-1/ Postman 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Postman-API-Test-Starter Postman 官方文档:https://learning.postman.com/docs/getting-started/introduction/ Newman 官方文档:https://github.com/postmanlabs/newman gitHub action 文档：https://docs.github.com/en/actions allure 文档：https://docs.qameta.io/allure/ Bruno 接口自动化测试 Bruno 框架教程目录 目录不可点击，仅为展示目录结构\nbruno-user-guide 为什么选择 bruno 安装 bruno 客户端使用入门 默认主界面 API 请求集 API 请求 编写 API 请求测试脚本 环境变量 测试脚本接口自动化 前置条件 接口自动化项目 demo 接入 CI 接入 github action Postman 脚本迁移 API 请求集迁移 环境变量迁移 测试脚本迁移参考 Bruno 框架教程对应文章 postman 替换工具 bruno 使用介绍:https://naodeng.tech/zh/posts/api-automation-testing/introduction_of_bruno/ Bruno 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Bruno-API-Test-Starter Bruno 文档：https://docs.usebruno.com/ gitHub action 文档：https://docs.github.com/en/actions 推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/a-collection-of-tutorials-on-api-automation-testing-for-different-frameworks-and-different-development-languages/","summary":"这篇博文汇总了关于不同框架和开发语言的接口自动化测试教程，为读者提供全面的学习资源。涵盖了各种流行测试框架和编程语言，让您能够选择适合自己项目的最佳方案。无论您是 Python、Java、JavaScript 还是其他语言的开发者，无论您偏好使用的是 REST Assured、SuperTest 还是其他框架，这个合集都将为您提供深入的学习指南，帮助您在接口自动化测试领域更加游刃有余。不容错过的资源，助您全面掌握接口自动化测试的各种工具和技术。","title":"接口测试新手入门教程：不同框架和不同开发语言"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括常用命令行选项、文件上传场景和 SSL 证书场景。\n文件上传场景 在 postman 和 newman 做接口自动化时，文件上传可以通过 form-data 的方式来实现。\n文件必须存在于当前工作目录中。请求的 \u0026ldquo;src \u0026ldquo;属性中也必须包含文件名。\n在此集合中，当前工作目录中应包含名为 \u0026ldquo;demo.txt\u0026rdquo; 的文件。\n{ \u0026#34;info\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;file-upload\u0026#34; }, \u0026#34;item\u0026#34;: [ { \u0026#34;request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://postman-echo.com/post\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;formdata\u0026#34;, \u0026#34;formdata\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;enabled\u0026#34;: true, \u0026#34;src\u0026#34;: \u0026#34;demo.txt\u0026#34; } ] } } } ] } 注意：调整文件上传的路径，确保文件存在路径在项目根目录下存在或者使用绝对路径\nNewman 常用命令行选项 newman 是一个命令行工具，可以使用它来运行 postman 集合。newman 提供了许多选项，可以在运行集合时使用这些选项。\n以下是一些常用的 newman 命令行选项的介绍和示例：\n基本命令 newman run \u0026lt;collection\u0026gt;： 用于运行 Postman 集合。\nnewman run collection.json -e, --environment \u0026lt;environment\u0026gt;： 指定环境文件。\nnewman run collection.json -e environment.json -g, --globals \u0026lt;globals\u0026gt;： 指定全局变量文件。\nnewman run collection.json -g globals.json -d, --iteration-data \u0026lt;data\u0026gt;： 指定数据文件，用于数据驱动测试。\nnewman run collection.json -d data-file.csv 输出和报告 -r, --reporters \u0026lt;reporters\u0026gt;： 指定报告器，可以生成多个报告，如 cli、json、html 等。\nnewman run collection.json -r cli,json --reporter-json-export \u0026lt;file\u0026gt;： 将测试结果导出为 JSON 文件。\nnewman run collection.json --reporters json --reporter-json-export output.json --reporter-html-export \u0026lt;file\u0026gt;： 将测试结果导出为 HTML 文件。\nnewman run collection.json --reporters html --reporter-html-export output.html --reporter-html-template \u0026lt;file\u0026gt;： 使用自定义 HTML 模板生成 HTML 报告。\nnewman run collection.json --reporters html --reporter-html-template custom-template.hbs 其他选项 -h, --help： 显示帮助信息，列出所有命令行选项。\nnewman run --help -v, --version： 显示 Newman 版本信息。\nnewman --version -x, --suppress-exit-code： 在运行失败时，不返回非零的退出代码。\nnewman run collection.json -x --delay-request \u0026lt;ms\u0026gt;： 设置请求之间的延迟时间，以模拟实际场景。\nnewman run collection.json --delay-request 1000 --timeout \u0026lt;ms\u0026gt;： 设置请求的超时时间。\nnewman run collection.json --timeout 5000 --no-color： 禁用控制台输出的颜色。\nnewman run collection.json --no-color --bail： 在第一个失败的测试时停止运行。\nnewman run collection.json --bail 这只是一些常见的 Newman 命令行选项。你可以通过运行 newman run --help 查看所有可用选项以及它们的描述。根据你的测试需求，你可能需要调整和组合这些选项。\nSSL 证书配置 客户端证书是传统身份验证机制的替代方案。这些允许用户使用公共证书和验证证书所有权的可选私钥向服务器发出经过身份验证的请求。在某些情况下，私钥也可能受到秘密密码的保护，从而提供额外的身份验证安全层。\nNewman 通过以下 CLI 选项支持 SSL 客户端证书：\n使用单个 SSL 客户端证书 直接在 newman 命令后面根据证书的实际情况添加以下选项即可\n--ssl-client-cert 参数后跟着公共客户端证书文件的路径。\n--ssl-client-key 参数后跟着客户端私钥的路径（可选）。\n--ssl-client-passphrase 参数后跟着用于保护私有客户端密钥的秘密密码（可选）。\n使用多个 SSL 客户端证书 适用于每次运行需要支持多个证书的情况\n--ssl-client-cert-list SSL 客户端证书列表配置文件（JSON 格式）的路径。 参考示例/ssl-client-cert-list.json。\n[ { \u0026#34;name\u0026#34;: \u0026#34;domain1\u0026#34;, \u0026#34;matches\u0026#34;: [\u0026#34;https://test.domain1.com/*\u0026#34;, \u0026#34;https://www.domain1/*\u0026#34;], \u0026#34;key\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain1.key\u0026#34;}, \u0026#34;cert\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain1.crt\u0026#34;}, \u0026#34;passphrase\u0026#34;: \u0026#34;changeme\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;domain2\u0026#34;, \u0026#34;matches\u0026#34;: [\u0026#34;https://domain2.com/*\u0026#34;], \u0026#34;key\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain2.key\u0026#34;}, \u0026#34;cert\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain2.crt\u0026#34;}, \u0026#34;passphrase\u0026#34;: \u0026#34;changeme\u0026#34; } ] 另外这种 json 配置也适用于不同证书不同环境的情况，根据 matches 匹配不同的环境和域名。\n备注：此选项允许根据 URL 或主机名设置不同的 SSL 客户端证书。此选项优先于 \u0026ndash;ssl-client-cert、 \u0026ndash;ssl-client-key 和 \u0026ndash;ssl-client-passphrase 选项。如果列表中没有匹配的 URL，这些选项将用作后备选项。\nTrusted CA 证书 适用于需要信任自定义 CA 证书的情况\n如果不想使用 \u0026ndash;insecure 选项，可以像这样提供额外的可信 CA 证书：\n--ssl-extra-ca-certs 参数后跟着保存一个或多个 PEM 格式可信 CA 证书的文件路径的列表。 参考文档 Postman 官方文档:https://learning.postman.com/docs/getting-started/introduction/ Newman 官方文档:https://github.com/postmanlabs/newman?tab=readme-ov-file#command-line-options 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-command-line-options-and-file-upload/","summary":"这篇博文深度挖掘 Postman 接口自动化测试的进阶用法，集中讨论常用命令行选项、文件上传场景和 SSL 证书场景。学会如何运用常用命令行选项优化测试流程，解决文件上传和 SSL 证书等特殊场景的测试挑战","title":"Postman 接口自动化测试教程：进阶用法 - 常用命令行选项，文件上传场景和 SSL 证书场景"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括数据文件驱动和环境变量数据驱动。\n数据驱动 在 API 自动化测试的过程中。使用数据驱动是一种常规测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。\n测试数据可以很容易地修改，而不需要修改测试用例代码。\n数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\n可参考 demo：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n在 Postman 中进行数据驱动测试，特别是使用 JSON 数据作为测试数据，可以通过环境变量和数据文件配合 Postman 提供的测试脚本来实现，以下会分别以简单的示例来介绍环境变量和数据文件的使用。\n使用环境变量 大致的步骤是：将测试数据存储在环境变量中，然后在测试脚本中读取环境变量中的数据，进行测试。\n1. 创建环境变量 在 Postman 中，你可以在 \u0026ldquo;Manage Environments\u0026rdquo; 窗口中创建环境变量。在 \u0026ldquo;Manage Environments\u0026rdquo; 窗口中，你可以创建多个环境，每个环境都有一组环境变量。\n之前在 demo 中创建了一个环境变量，名为 DemoEnv，其中包含了一个环境变量 baseURL，用于存储 API 的基本 URL。 这一次我们在 DemoEnv 环境中添加多个环境变量，用于存储 get-demo 接口和 post-demo 接口的各类测试数据。\n点击编辑DemoEnv环境，添加以下环境变量：\nKey Value getAPI posts/1 getAPIResponseStatus 200 getAPIResponseData {\u0026ldquo;userId\u0026rdquo;:1,\u0026ldquo;id\u0026rdquo;:1,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026rdquo;,\u0026ldquo;body\u0026rdquo;:\u0026ldquo;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026rdquo;} postAPI posts postAPIResponseStatus 201 postAPIResponseData {\u0026ldquo;title\u0026rdquo;:\u0026ldquo;foo\u0026rdquo;,\u0026ldquo;body\u0026rdquo;:\u0026ldquo;bar\u0026rdquo;,\u0026ldquo;userId\u0026rdquo;:1,\u0026ldquo;id\u0026rdquo;:101} 2. 使用环境变量 在 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用环境变量来存储和获取数据。在请求 Body 中，你可以通过 pm.environment.get 获取环境变量的值。\n注意：在 JavaScript 中，环境变量获取的值是字符串\n编辑 get-demo 接口 将 URL 修改为 {{baseURL}}/{{getAPI}}， 编辑 Tests 脚本用来验证响应数据： // 获取环境变量中的数据 const getAPIResponseStatus = parseInt(pm.environment.get(\u0026#34;getAPIResponseStatus\u0026#34;)); const getAPIResponseData = JSON.parse(pm.environment.get(\u0026#39;getAPIResponseData\u0026#39;)); pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(getAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(getAPIResponseData.id); pm.expect(data.userId).to.equal(getAPIResponseData.userId); pm.expect(data.title).to.equal(getAPIResponseData.title); pm.expect(data.body).to.equal(getAPIResponseData.body); }); 点击保存，然后点击发送，可以看到测试通过。 编辑 post-demo 接口 将 URL 修改为 {{baseURL}}/{{postAPI}}， 编辑 Tests 脚本用来验证响应数据： // 获取环境变量中的数据 const postAPIResponseStatus = parseInt(pm.environment.get(\u0026#34;postAPIResponseStatus\u0026#34;)); const postAPIResponseData = JSON.parse(pm.environment.get(\u0026#39;postAPIResponseData\u0026#39;)); pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(postAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(postAPIResponseData.id); pm.expect(data.userId).to.equal(postAPIResponseData.userId); pm.expect(data.title).to.equal(postAPIResponseData.title); pm.expect(data.body).to.equal(postAPIResponseData.body); }); 点击保存，然后点击发送，可以看到测试通过。 3. 调试环境变量数据驱动脚本 选择对应的环境变量和更新后的测试用例，运行整个 demo collection，确认测试通过\n4.自动化运行环境变量数据驱动脚本 将更新后的测试用例导出到自动化测试项目测试用例文件夹下 调整 package.json 在 package.json 文件中，更新测试脚本，用于运行环境变量数据驱动测试用例：\ndemo 项目为了区分不同场景，新增了测试命令为 environment-driven-test\n\u0026#34;environment-driven-test\u0026#34;: \u0026#34;newman run Testcase/Environment-Driven.postman_collection.json -e Env/Environment-Driven-DemoEnv.postman_environment.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34;, 运行测试 npm run environment-driven-test 使用数据文件 大致的步骤是：将测试数据存放在数据文件中，然后在测试脚本中读取数据文件中的数据，进行测试。\npostman 的数据文件支持 json，csv 和 txt 等多种格式，以下示例会以 json 格式 进行\n1.创建数据文件 在 postma 接口自动化测试项目下新建 Data 文件夹 mkdir Data 在 Data 文件夹下新建 json 格式数据文件 testdata.json cd Data touch testdata.json 更新测试数据文件 testdata.json [ { \u0026#34;getAPI\u0026#34;: \u0026#34;posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;: \u0026#34;posts\u0026#34;, \u0026#34;getAPIResponseStatus\u0026#34;: 200, \u0026#34;getAPIResponseData\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPIResponseStatus\u0026#34;: 201, \u0026#34;postAPIResponseData\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } ] 2.更新测试用例 更新 get-demo 接口 编辑 Pre-request Script 脚本来从测试数据文件中获取 请求 url const getAPI = pm.iterationData.get(\u0026#39;getAPI\u0026#39;); 将 URL 修改为 {{baseURL}}/{{getAPI}}，\n编辑 test 脚本来从测试数据文件中获取测试数据\nconst getAPIResponseStatus = pm.iterationData.get(\u0026#39;getAPIResponseStatus\u0026#39;); const getAPIResponseData = pm.iterationData.get(\u0026#39;getAPIResponseData\u0026#39;); pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(getAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(getAPIResponseData.id); pm.expect(data.userId).to.equal(getAPIResponseData.userId); pm.expect(data.title).to.equal(getAPIResponseData.title); pm.expect(data.body).to.equal(getAPIResponseData.body); }); 更新 post-demo 接口 编辑 Pre-request Script 脚本来从测试数据文件中获取 请求 url const postAPI = pm.iterationData.get(\u0026#39;postAPI\u0026#39;); 将 URL 修改为 {{baseURL}}/{{postAPI}}，\n编辑 test 脚本来从测试数据文件中获取测试数据\n// 从数据文件获取测试数据 const postAPIResponseStatus = pm.iterationData.get(\u0026#39;postAPIResponseStatus\u0026#39;); const postAPIResponseData = pm.iterationData.get(\u0026#39;postAPIResponseData\u0026#39;); pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(postAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(postAPIResponseData.id); pm.expect(data.userId).to.equal(postAPIResponseData.userId); pm.expect(data.title).to.equal(postAPIResponseData.title); pm.expect(data.body).to.equal(postAPIResponseData.body); }); 3.调试 在 postman 页面选择 get-demo request 和 post-demo request 所在的 demo Collection，点击右上角的三个点，选择 Run Collection 在 runner 准备页面右侧区域点击 Data 的 Select File 按钮，选择之前的测试数据文件 testdata.json 然后点击 Run demo，确认运行通过即可导出测试用例文件 4.自动化运行数据驱动脚本 将更新后的测试用例导出到自动化测试项目测试用例文件夹下 调整 package.json 在 package.json 文件中，更新测试测试脚本，用于运行数据驱动测试用例：\ndemo 项目为了区分不同场景，新增了测试命令为 data-driven-test，且命令后加了-d 参数 用于指定测试数据文件路径\n\u0026#34;data-driven-test\u0026#34;: \u0026#34;newman run Testcase/Data-Driven.postman_collection.json -e Env/DemoEnv.postman_environment.json -d Data/testdata.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34; 运行测试 npm run data-driven-test 参考文档 Postman 官方文档 newman 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-data-driven-and-environment-data-driven/","summary":"这篇博文深入研究 Postman 接口自动化测试的高级技巧，专注于数据文件驱动和环境变量数据驱动。学习如何通过外部数据文件和灵活的环境变量，优雅地进行测试数据的驱动，提高测试覆盖率。博文将为您展示如何以更智能的方式管理和利用数据，使测试用例更具可扩展性和灵活性。","title":"Postman 接口自动化测试教程：进阶用法 - 数据驱动"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括常用测试响应测试脚本，测试前置脚本和常用的测试脚本可用的第三方包等。\n常用测试脚本 Postman 提供了测试脚本功能，可以使用 JavaScript 编写脚本来验证 API 的响应和行为。这些脚本可以在请求的“Tests”标签下添加，分为请求前脚本（Pre-request Script）和响应后脚本（Tests）两个部分。下面是一些常用的 Postman 和 Newman 测试脚本：\n响应测试脚本 状态码检查：\npm.test(\u0026#34;Status code is 200\u0026#34;, function () { pm.response.to.have.status(200); }); 响应时间检查：\npm.test(\u0026#34;Response time is less than 200ms\u0026#34;, function () { pm.expect(pm.response.responseTime).to.be.below(200); }); 响应体 JSON 格式检查：\npm.test(\u0026#34;Response body is a valid JSON\u0026#34;, function () { pm.response.to.be.json; }); 响应体字段值检查：\npm.test(\u0026#34;Response body contains expected value\u0026#34;, function () { pm.expect(pm.response.json().key).to.eql(\u0026#34;expectedValue\u0026#34;); }); 响应体数组长度检查：\npm.test(\u0026#34;Response body array has correct length\u0026#34;, function () { pm.expect(pm.response.json().arrayKey).to.have.lengthOf(3); }); 响应体属性存在性检查：\npm.test(\u0026#34;Response body has required properties\u0026#34;, function () { pm.expect(pm.response.json()).to.have.property(\u0026#34;key\u0026#34;); }); 请求前脚本 动态设置请求参数：\npm.variables.set(\u0026#34;dynamicVariable\u0026#34;, \u0026#34;dynamicValue\u0026#34;); 使用全局变量设置请求头：\npm.request.headers.add({ key: \u0026#39;Authorization\u0026#39;, value: pm.globals.get(\u0026#39;authToken\u0026#39;) }); 生成随机数并设置为变量：\nconst randomNumber = Math.floor(Math.random() * 1000); pm.variables.set(\u0026#34;randomNumber\u0026#34;, randomNumber); 签名生成或加密等操作：\n// 示例：使用 CryptoJS 进行 HMAC SHA256 签名 const CryptoJS = require(\u0026#39;crypto-js\u0026#39;); const secretKey = \u0026#39;yourSecretKey\u0026#39;; const message = \u0026#39;dataToSign\u0026#39;; const signature = CryptoJS.HmacSHA256(message, secretKey).toString(CryptoJS.enc.Base64); pm.variables.set(\u0026#34;signature\u0026#34;, signature); 测试脚本中可用的第三方库 提供的 require 方法允许您使用沙箱内置库模块。下面列出了个人常用的可用库和示例 更多可用的库可以在这里找到\nchai.js 断言库方法 在 Postman 的测试脚本中，你可以使用 Chai 断言库来编写断言，以验证你的 API 响应是否符合预期。Chai 提供了多种断言风格，包括 BDD（Behavior Driven Development）、TDD（Test Driven Development）等。以下是一些基本的 Chai 使用方法：\n1. 安装 Chai 在 Postman 的脚本环境中，你无需单独安装 Chai，因为 Postman 默认已经内置了 Chai。\n2. 使用 BDD 风格断言 在 Postman 的 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用 Chai 的 BDD 风格断言，例如：\n// 引入 Chai 库 const chai = require(\u0026#39;chai\u0026#39;); // 使用 BDD 风格断言 const expect = chai.expect; // 示例：验证响应状态码为 200 pm.test(\u0026#39;Status code is 200\u0026#39;, function() { expect(pm.response.code).to.equal(200); }); // 示例：验证响应体是 JSON pm.test(\u0026#39;Response body is JSON\u0026#39;, function() { expect(pm.response.headers.get(\u0026#39;Content-Type\u0026#39;)).to.include(\u0026#39;application/json\u0026#39;); }); 3. 使用 TDD 风格断言 // 引入 Chai 库 const chai = require(\u0026#39;chai\u0026#39;); // 使用 TDD 风格断言 const assert = chai.assert; // 示例：使用 assert 断言响应状态码为 200 assert.equal(pm.response.code, 200, \u0026#39;Status code should be 200\u0026#39;); 4. Chai 支持的一些常用断言 相等性：\nexpect(actual).to.equal(expected); 包含：\nexpect(actual).to.include(expected); 类型检查：\nexpect(actual).to.be.a(\u0026#39;string\u0026#39;); 大于/小于：\nexpect(actual).to.be.above(expected); expect(actual).to.be.below(expected); 空/非空：\nexpect(actual).to.be.null; expect(actual).to.not.be.null; 深度相等性：\nexpect(actual).to.deep.equal(expected); 以上只是 Chai 断言库的一些基本用法，你可以根据需要使用更多的断言方法和组合。Chai 提供了丰富的断言功能，可以满足各种测试需求。更多详细信息，请查阅 Chai 的官方文档：Chai Documentation。\n使用 cheerio 操作 HTML 文件 在 Postman 中，Cheerio 是一个基于 jQuery 的库，用于在服务器端操作 HTML 文档。它允许你使用类似于 jQuery 的语法来选择和操作 HTML 元素，非常适用于解析和提取 HTML 页面中的信息。在 Postman 中，你可以使用 Cheerio 库进行 HTML 响应的解析。以下是 Cheerio 在 Postman 中的基本用法：\n安装 Cheerio：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 Cheerio 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，可以使用以下方式安装 Cheerio： // 安装 Cheerio const cheerio = require(\u0026#39;cheerio\u0026#39;); 使用 Cheerio 解析 HTML：\n在请求的 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用 Cheerio 解析 HTML。以下是一个简单的例子： // 从响应中获取 HTML 内容 const htmlContent = pm.response.text(); // 使用 Cheerio 解析 HTML const $ = cheerio.load(htmlContent); // 示例：从 HTML 中提取标题文本 const titleText = $(\u0026#39;title\u0026#39;).text(); console.log(\u0026#39;Title:\u0026#39;, titleText); // 示例：从 HTML 中提取所有链接的 href 属性 const links = []; $(\u0026#39;a\u0026#39;).each(function () { const link = $(this).attr(\u0026#39;href\u0026#39;); links.push(link); }); console.log(\u0026#39;Links:\u0026#39;, links); 在上述例子中，cheerio.load(htmlContent) 用于加载 HTML 内容，并使用类似于 jQuery 的语法来选择和操作元素。\n注意事项：\nCheerio 主要用于解析静态 HTML，对于使用 JavaScript 动态生成的内容，可能无法正常获取。在这种情况下，你可能需要考虑使用 Puppeteer 或其他支持 JavaScript 执行的工具。 这只是 Cheerio 在 Postman 中的基本用法。你可以根据具体的需求使用 Cheerio 提供的各种选择器和方法。请查阅 Cheerio 的官方文档以获取更详细的信息：Cheerio Documentation。\n使用 tv4 来验证 JSON Schema 在 Postman 中，tv4 是一个 JSON Schema 验证库，用于验证 JSON 数据是否符合给定的 JSON Schema。JSON Schema 是一种描述 JSON 数据结构的规范，它定义了 JSON 对象的属性、类型和其他约束。\n以下是在 Postman 中使用 tv4 进行 JSON Schema 验证的基本步骤：\n安装 tv4 库：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 tv4 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 tv4： // 安装 tv4 const tv4 = require(\u0026#39;tv4\u0026#39;); 定义 JSON Schema：\n在 Postman 中，你可以在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分定义 JSON Schema。JSON Schema 可以作为一个 JavaScript 对象进行定义。以下是一个简单的例子： // 定义 JSON Schema const jsonSchema = { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;number\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;] }; 使用 tv4 进行验证：\n在请求的 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用 tv4 对 JSON 数据进行验证。以下是一个简单的例子： // 获取响应的 JSON 数据 const jsonResponse = pm.response.json(); // 使用 tv4 进行 JSON Schema 验证 const isValid = tv4.validate(jsonResponse, jsonSchema); // 检查验证结果 pm.test(\u0026#39;JSON is valid according to the schema\u0026#39;, function() { pm.expect(isValid).to.be.true; }); 在上述例子中，tv4.validate(jsonResponse, jsonSchema) 用于验证 jsonResponse 是否符合 jsonSchema 定义的规范。验证结果存储在 isValid 变量中，然后使用 pm.test 来检查验证结果。\n这只是 tv4 在 Postman 中的基本用法。你可以根据实际需求，定义更复杂的 JSON Schema，并使用 tv4 的其他功能进行更灵活的验证。请查阅 tv4 的官方文档以获取更详细的信息：tv4 Documentation。\n生成 uuid 在 Postman 中，你可以使用 uuid 模块来生成 UUID（Universally Unique Identifier），也被称为 GUID。以下是在 Postman 中使用 uuid 模块的基本用法：\n1. 安装 uuid 模块 在 Postman 的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 uuid 模块：\n// 安装 uuid 模块 const uuid = require(\u0026#39;uuid\u0026#39;); 2. 生成 UUID // 生成 UUID const generatedUUID = uuid.v4(); console.log(\u0026#39;Generated UUID:\u0026#39;, generatedUUID); 在上述例子中，uuid.v4() 用于生成一个基于随机数的 UUID。你可以在 Postman 脚本中使用生成的 UUID，例如将其设置为请求头或参数的值。\n示例 以下是一个在 Postman \u0026ldquo;Pre-request Script\u0026rdquo; 中生成 UUID 并设置为请求头的示例：\n// 安装 uuid 模块 const uuid = require(\u0026#39;uuid\u0026#39;); // 生成 UUID const generatedUUID = uuid.v4(); // 设置请求头 pm.request.headers.add({ key: \u0026#39;X-Request-ID\u0026#39;, value: generatedUUID }); 在上述例子中，X-Request-ID 是一个常见的请求头，用于标识请求的唯一性。生成的 UUID 被设置为这个请求头的值，以确保每个请求都有唯一的标识。\n请注意，Postman 在运行脚本时会自动执行安装依赖项的步骤，无需手动安装 uuid 模块。\n使用 xml2js 将 XML 转换为 JavaScript 对象 在 Postman 中，xml2js 是一个用于将 XML 转换为 JavaScript 对象的库。在 Postman 的脚本中，你可以使用 xml2js 来处理 XML 响应并将其转换为易于处理的 JavaScript 对象。以下是在 Postman 中使用 xml2js 的基本步骤：\n安装 xml2js 库：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 xml2js 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 xml2js： // 安装 xml2js const xml2js = require(\u0026#39;xml2js\u0026#39;); 解析 XML 响应：\n获取 XML 响应后，你可以使用 xml2js 将其解析为 JavaScript 对象。以下是一个简单的例子： // 获取响应的 XML 内容 const xmlContent = pm.response.text(); // 使用 xml2js 解析 XML xml2js.parseString(xmlContent, function (err, result) { if (err) { console.error(\u0026#39;Error parsing XML:\u0026#39;, err); return; } // result 是解析后的 JavaScript 对象 console.log(\u0026#39;Parsed XML:\u0026#39;, result); }); 在上述例子中，xml2js.parseString(xmlContent, function (err, result) {...} 用于异步地解析 XML 内容。解析后的 JavaScript 对象存储在 result 中。\n处理解析后的 JavaScript 对象：\n一旦你获得了解析后的 JavaScript 对象，你就可以按照普通的 JavaScript 对象处理方式访问和操作它的属性。 // 示例：访问解析后的 JavaScript 对象的属性 const value = result.root.element[0].subelement[0]._; console.log(\u0026#39;Value from parsed XML:\u0026#39;, value); 在上述例子中，result.root.element[0].subelement[0]._ 是一个访问解析后对象属性的示例。具体的结构取决于你的 XML 结构。\n这只是 xml2js 在 Postman 中的基本用法。你可以根据实际需求使用 xml2js 的其他功能，例如设置解析选项，处理命名空间等。请查阅 xml2js 的官方文档以获取更详细的信息：xml2js Documentation。\n常用工具函数 util 在 Postman 中，util 是一个全局对象，提供了一些常用的实用工具函数，可以在 Postman 脚本中使用。以下是一些常见的 util 对象的用法：\n1. util.guid() - 生成全局唯一标识符（GUID） // 生成一个全局唯一标识符 const uniqueId = util.guid(); console.log(\u0026#39;Unique ID:\u0026#39;, uniqueId); 2. util.timestamp() - 获取当前时间戳 // 获取当前时间戳（毫秒） const timestamp = util.timestamp(); console.log(\u0026#39;Timestamp:\u0026#39;, timestamp); 3. util.randomInt(min, max) - 生成指定范围内的随机整数 // 生成 1 到 100 之间的随机整数 const randomInt = util.randomInt(1, 100); console.log(\u0026#39;Random Integer:\u0026#39;, randomInt); 4. util.unixTimestamp() - 获取当前时间戳（Unix 时间戳，秒） // 获取当前时间戳（秒） const unixTimestamp = util.unixTimestamp(); console.log(\u0026#39;Unix Timestamp:\u0026#39;, unixTimestamp); 5. util.encodeBase64(str) 和 util.decodeBase64(base64Str) - Base64 编码和解码 // Base64 编码 const encodedString = util.encodeBase64(\u0026#39;Hello, World!\u0026#39;); console.log(\u0026#39;Encoded String:\u0026#39;, encodedString); // Base64 解码 const decodedString = util.decodeBase64(encodedString); console.log(\u0026#39;Decoded String:\u0026#39;, decodedString); 6. util.each(obj, callback) - 遍历对象或数组 // 遍历数组 const array = [1, 2, 3, 4]; util.each(array, function (value, index) { console.log(`Index ${index}: ${value}`); }); // 遍历对象 const obj = { a: 1, b: 2, c: 3 }; util.each(obj, function (value, key) { console.log(`Key ${key}: ${value}`); }); 注意事项 在 Postman 脚本中，可以通过 util 对象直接调用这些实用工具函数。 util 对象提供的这些方法能够简化在 Postman 脚本中的一些常见任务，如生成随机数、处理时间戳等。 请注意查阅 Postman 的官方文档，因为 Postman 会不断更新和改进其脚本环境，可能会引入新的实用工具函数。 stream 流操作 在 Node.js 中使用流（Streams）通常用于处理大量的数据，可以有效地降低内存占用并提高性能。以下是一些在 Node.js 中使用流的基本用法，可以参考这些方法来处理数据或文件。\n1. 读取流（Readable Streams）： const fs = require(\u0026#39;fs\u0026#39;); // 创建可读流 const readableStream = fs.createReadStream(\u0026#39;input.txt\u0026#39;); // 设置编码（如果是文本文件） readableStream.setEncoding(\u0026#39;utf-8\u0026#39;); // 处理数据 readableStream.on(\u0026#39;data\u0026#39;, function(chunk) { console.log(\u0026#39;Received chunk:\u0026#39;, chunk); }); // 处理结束 readableStream.on(\u0026#39;end\u0026#39;, function() { console.log(\u0026#39;Stream ended.\u0026#39;); }); // 处理错误 readableStream.on(\u0026#39;error\u0026#39;, function(err) { console.error(\u0026#39;Error:\u0026#39;, err); }); 2. 写入流（Writable Streams）： const fs = require(\u0026#39;fs\u0026#39;); // 创建可写流 const writableStream = fs.createWriteStream(\u0026#39;output.txt\u0026#39;); // 写入数据 writableStream.write(\u0026#39;Hello, World!\\n\u0026#39;); writableStream.write(\u0026#39;Another line.\u0026#39;); // 结束写入 writableStream.end(); // 处理结束 writableStream.on(\u0026#39;finish\u0026#39;, function() { console.log(\u0026#39;Write completed.\u0026#39;); }); // 处理错误 writableStream.on(\u0026#39;error\u0026#39;, function(err) { console.error(\u0026#39;Error:\u0026#39;, err); }); 3. 转换流（Transform Streams）： const { Transform } = require(\u0026#39;stream\u0026#39;); // 创建转换流 const myTransform = new Transform({ transform(chunk, encoding, callback) { // 转换数据 const transformedData = chunk.toString().toUpperCase(); this.push(transformedData); callback(); } }); // 管道连接读取流、转换流和写入流 readableStream.pipe(myTransform).pipe(writableStream); 这只是 Node.js 中使用流的一些基本用法。在 Postman 中，你可以在请求的脚本中使用这些方法，例如 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，通过 Node.js 运行环境来执行这些脚本。请注意，Node.js 中的流 API 可以更复杂，例如通过使用 pipeline 函数来处理多个流的连接。\n定时器 timers 在 Postman 中，你可以使用 Node.js 的定时器功能来处理定时任务或延时执行的操作。以下是一些基本的 Node.js 定时器的用法，这些用法可以在 Postman 的脚本中使用。\n1. setTimeout - 延时执行 // 延时执行操作 setTimeout(function() { console.log(\u0026#39;Delayed operation.\u0026#39;); }, 2000); // 2000 毫秒（2 秒） 2. setInterval - 定时执行重复操作 // 定时执行重复操作 const intervalId = setInterval(function() { console.log(\u0026#39;Repeated operation.\u0026#39;); }, 3000); // 3000 毫秒（3 秒） // 取消定时执行 // clearInterval(intervalId); 3. 在 Postman 中使用 在 Postman 中，你可以在 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分中使用这些定时器。例如，在 \u0026ldquo;Tests\u0026rdquo; 部分中延时执行操作：\n// 在 \u0026#34;Tests\u0026#34; 部分延时执行操作 setTimeout(function() { console.log(\u0026#39;Delayed operation in Tests.\u0026#39;); }, 2000); // 2000 毫秒（2 秒） 请注意，在 Postman 的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分执行的代码是在 Node.js 环境中运行的，因此你可以使用 Node.js 支持的大多数功能，包括定时器。\n在以上例子中，setTimeout 会在指定的延时后执行一次操作，而 setInterval 会在每隔指定的时间间隔后执行一次操作。在 Postman 中，你可以根据实际需求使用这些定时器功能。\n时间处理 events 在 Postman 的脚本环境中，你可以使用 Node.js 的 events 模块来处理事件。events 模块提供了 EventEmitter 类，该类可以用于定义和触发事件。以下是在 Postman 中使用 Node.js 的 events 模块的一些基本用法：\n1. 创建事件发射器 const EventEmitter = require(\u0026#39;events\u0026#39;); const myEmitter = new EventEmitter(); 2. 定义事件处理函数 // 定义事件处理函数 function myEventHandler() { console.log(\u0026#39;Event handled.\u0026#39;); } 3. 注册事件处理函数 // 注册事件处理函数 myEmitter.on(\u0026#39;myEvent\u0026#39;, myEventHandler); 4. 触发事件 // 触发事件 myEmitter.emit(\u0026#39;myEvent\u0026#39;); 示例 在 Postman 的脚本环境中，你可以使用事件来实现异步操作的回调或处理。以下是一个简单的例子，演示如何在异步操作完成后触发事件：\nconst EventEmitter = require(\u0026#39;events\u0026#39;); const myEmitter = new EventEmitter(); // 模拟异步操作 function performAsyncOperation() { setTimeout(function() { console.log(\u0026#39;Async operation completed.\u0026#39;); // 触发事件 myEmitter.emit(\u0026#39;asyncOperationComplete\u0026#39;); }, 2000); } // 注册事件处理函数 myEmitter.on(\u0026#39;asyncOperationComplete\u0026#39;, function() { console.log(\u0026#39;Handling async operation completion.\u0026#39;); // 这里可以执行异步操作完成后的处理逻辑 }); // 执行异步操作 performAsyncOperation(); 在上述例子中，performAsyncOperation 函数模拟了一个异步操作，当该操作完成时，通过 myEmitter.emit 触发了 asyncOperationComplete 事件。在事件处理函数中，你可以编写处理异步操作完成后的逻辑。\n请注意，在 Postman 的脚本中，异步操作的执行方式可能受到限制，因此在实际使用中需要谨慎考虑。\n参考文档 Postman 官方文档 newman 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-test-scripts-and-commonly-used-third-party-packages/","summary":"深入研究 Postman 接口自动化测试的高级用法，专注于常用的测试脚本和第三方包示例。探讨如何编写强大的测试脚本，涵盖各种测试场景，并介绍一些常用的第三方包，优化测试流程。","title":"Postman 接口自动化测试教程：进阶用法 - 常用的测试脚本和常用的第三方包用法示例"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括测试数据、测试脚本、测试报告和测试报告集成等。 也会介绍如何将 Postman 和 Newman 集成到 CI/CD 流程中，以实现自动化测试。\n输出 html 测试报告 demo 会以集成newman-reporter-htmlextra为例，介绍如何输出 html 测试报告。\n安装 newman-reporter-htmlextra 依赖包 npm install newman-reporter-htmlextra --save-dev 注意：目前 newman 最新 V6 版本在 html 测试报告的一些包兼容性上有问题，所以这里使用 5.1.2 版本\n调整 package.json 在 package.json 文件中，更新测试测试脚本，用于运行测试用例并输出 html 测试报告：\n\u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r htmlextra --reporter-htmlextra-export ./Report/Postman-newman-demo-api-testing-report.html\u0026#34; 指定输出 html 测试报告的路径为 Report/Postman-newman-demo-api-testing-report.html\n运行测试用例输出 html 报告 运行测试用例 npm run test 检查报告文件 浏览器打开报告文件 输出多种格式的测试报告 前面的配置是输出 html 格式的测试报告，如果想要输出多种格式的测试报告，如命令行 cli 的报告，可以在 package.json 文件中添加以下脚本：\n\u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r cli,htmlextra --reporter-htmlextra-export ./Report/Postman-newman-demo-api-testing-report.html\u0026#34; 再次运行测试用例，可以看到在 Report 文件夹下，除了 html 格式的测试报告，还有 cli 格式的测试报告。\nCI/CD 持续集成 将接口自动化测试的代码集成到 CI/CD 流程中，可以实现自动化测试，提高测试效率。\n接入 github action 以 github action 为例，其他 CI 工具类似\n可参考 demo：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 postman.yml。\n编辑 postman.yml 文件：将以下内容复制到文件中\nname: RUN Postman API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-Postman-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive Postman test report uses: actions/upload-artifact@v3 with: name: Postman-test-report path: Report - name: Upload Postman report to GitHub uses: actions/upload-artifact@v3 with: name: Postman-test-report path: Report 提交代码：将 postman.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN-Postman-API-Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 集成 allure 测试报告 allure 是一个轻量级的、灵活的、多语言支持的测试报告工具，可以生成各种各样的测试报告，包括饼图、柱状图、曲线图等，可以方便地查看测试结果。\n安装 allure 测试报告依赖 npm install newman-reporter-allure --save-dev 调整 package.json 中输出 allure 测试报告的脚本 \u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34; 调整 Postman 测试用例 调整 get-demo 的 Tests 脚本，添加以下脚本，用于生成 allure 测试报告： // @allure.label.suite=postman-new-api-testing-demo // @allure.label.story=\u0026#34;Verify-the-get-api-return-correct-data\u0026#34; // @allure.label.owner=\u0026#34;naodeng\u0026#34; // @allure.label.tag=\u0026#34;GETAPI\u0026#34; pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调整 post-demo 的 Tests 脚本，添加以下脚本，用于生成 allure 测试报告： // @allure.label.suite=postman-new-api-testing-demo // @allure.label.story=\u0026#34;Verify-the-post-api-return-correct-data\u0026#34; // @allure.label.owner=\u0026#34;naodeng\u0026#34; // @allure.label.tag=\u0026#34;POSTAPI\u0026#34; pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(201); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(101); pm.expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 保存更改后的 postman 测试用例，重新导出测试用例文件并替换原来的测试用例文件。 运行测试用例输出 allure 报告 运行测试用例 npm run test 会在项目文件夹下生成 allure-results 文件夹，里面包含了测试用例的执行结果。\n预览 allure 测试报告 allure serve 参考文档 Postman 官方文档 newman 官方文档 newman-reporter-htmlextra newman-reporter-allure github action 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-advance-usage-integration-html-report-and-allure-report-integration-github-action/","summary":"Postman 接口自动化测试的进阶应用，专注于 CI/CD 和 GitHub Actions 的集成，以及 Allure 测试报告的接入。学习如何将 Postman 测试无缝整合到 CI/CD 流程中，通过 GitHub Actions 实现自动化测试。此外，了解如何集成 Allure 测试报告框架，生成详尽的测试结果报告","title":"Postman 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action，接入 allure 测试报告"},{"content":"介绍 接口测试简介 什么是 API? API:应用程序接口（全称：application programming interface），缩写为 API，是一种计算接口，它定义多个软件中介之间的交互，以及可以进行的调用（call）或请求（request）的种类，如何进行调用或发出请求，应使用的数据格式，应遵循的惯例等。它还可以提供扩展机制，以便用户可以通过各种方式对现有功能进行不同程度的扩展。一个 API 可以是完全定制的，针对某个组件的，也可以是基于行业标准设计的以确保互操作性。通过信息隐藏，API 实现了模块化编程，从而允许用户实现独立地使用接口。\n什么是 API 测试？ 接口测试是软件测试的一种，它包括两种测试类型：狭义上指的是直接针对应用程序接口（下面使用缩写 API 指代，其中文简称为接口）的功能进行的测试；广义上指集成测试中，通过调用 API 测试整体的功能完成度、可靠性、安全性与性能等指标。\nAPI Best Practice:\nAPI 定义遵循 RESTFUL API 风格，语意化的 URI 定义，准确的 HTTP 状态码，通过 API 的定义就可以知道资源间的关系 配有详细且准确的 API 文档（如 Swagger 文档） 对外的 API 可以包含版本号以快速迭代（如 https://thoughtworks.com/v1/users/） 测试四象限中不同象限的测试，其测试目的跟测试策略也不同，API 测试主要位于第二、第四象限\nAPI 测试在测试金子塔中处于一个相对靠上的位置，主要站在系统、服务边界来测试功能和业务逻辑，执行时机是在服务完成构建、部署到测试环境之后再执行、验证。\nAPI 测试类型 功能测试\n正确性测试 异常处理 内部逻辑 …… 非功能测试\n性能 安全 …… API 测试步骤 发送请求 得到响应 验证响应结果 Postman 与 newman 介绍 Postman 是一个流行的 API 开发工具，它提供了一个易于使用的图形界面，可用于创建，测试和调试 API。Postman 还提供了一个可以轻松编写和共享测试脚本的功能。它支持多种 HTTP 请求方法，包括 GET，POST，PUT，DELETE 等，并且可以使用各种身份验证和授权方式来测试 API。\nNewman 是 Postman 的命令行工具，可用于在不使用 Postman GUI 的情况下运行测试集。使用 Newman，用户可以轻松地将 Postman 集合导出为一个可执行文件，并在任何环境中运行它。此外，Newman 还支持生成 HTML 或 Junit 格式的测试报告，以及集成到 CI/CD 管道中以实现自动化测试。\n总的来说，Postman 是一个强大的 API 开发和测试工具，而 Newman 则是一个方便的命令行工具，用于在不使用 Postman GUI 的情况下运行测试集。它们的结合使用可以提高 API 测试和开发的效率和准确性。\n除了基本功能，Postman 还具有以下特性：\n环境和变量管理：Postman 支持在不同环境之间切换，例如在开发、测试和生产环境之间切换。同时，它还支持变量管理，可以轻松地为不同的测试用例和请求设置变量。 自动化测试：用户可以使用 Postman 创建和运行自动化测试，以便在持续集成或部署流程中集成。这使得测试变得更加准确和高效。 协作和共享：Postman 支持将集合和环境与团队共享，方便团队成员之间的协作。 监控：Postman 还提供 API 监控功能，可以实时监控 API 的可用性和性能。 而 Newman 则主要有以下特点：\n命令行接口：Newman 可以在命令行中运行，因此可以方便地自动化测试和集成到 CI/CD 流程中。 支持多种输出格式：Newman 支持多种输出格式，包括 HTML、JSON 和 JUnit 格式，方便用户在不同场景下使用。 并发执行：Newman 支持并发执行测试，从而提高了测试的效率。 轻量级：与 Postman GUI 相比，Newman 是一个轻量级的工具，因此在运行测试时需要更少的资源。 总之，Postman 和 Newman 是现代 API 测试的重要工具，它们提供了强大的功能，可以使 API 测试变得更加高效、准确和自动化。\n除了上述提到的功能和特点，Postman 和 Newman 还有其他一些重要的功能和优势：\n集成：Postman 和 Newman 可以与许多其他工具和服务进行集成，例如 GitHub、Jenkins、Slack 等。这使得它们可以轻松地集成到开发和部署流程中，以实现更高效的 API 开发和测试。 文档生成：Postman 可以使用 API 的请求和响应来生成 API 文档。这可以使 API 文档更加准确和及时。 测试脚本：Postman 可以使用 JavaScript 编写测试脚本，这可以使测试变得更加灵活和自定义。用户可以轻松地编写自定义测试脚本，以确保 API 的行为符合预期。 历史记录：Postman 可以存储 API 请求的历史记录，这可以方便用户查看和管理以前的请求和响应。这对于调试和问题排查非常有用。 多平台支持：Postman 和 Newman 可以在多种平台上运行，包括 Windows、MacOS 和 Linux 等。 总之，Postman 和 Newman 是现代 API 测试和开发的强大工具。它们提供了丰富的功能和灵活的测试脚本，可以帮助开发人员和测试人员更快、更准确地构建和测试 API。\n项目依赖 需提前安装好以下环境\nnodejs, demo 版本为 v21.1.0 Postman 安装完成，可通过官方网站下载安装包进行安装 项目文件结构 以下是一个 Postman 和 Newman 的接口自动化测试项目的文件结构，其中包含了测试配置文件、测试用例文件、测试工具文件和测试报告文件。可进行参考。\nPostman-Newman-demo ├── README.md ├── package.json ├── package-lock.json ├── Data // 测试配置文件 │ └── testdata.csv // 测试数据 ├── Testcase // 测试用例文件夹 │ └── APITestDemo.postman_collection.json // 测试用例文件 ├── Env // 不同测试环境文件夹 │ └── DemoEnv.postman_environment.json // 测试环境配置文件 ├── Report // 测试报告文件 │ └── report.html ├── .gitignore └── node_modules // 项目依赖 从 0 到 1 搭建 Postman 接口自动化测试项目 下面会介绍从 0 到 1 搭建一个 Postman 和 Newman 的接口自动化测试项目，包括测试配置、测试用例、测试环境、测试工具和测试报告等。\n可参考 demo 项目：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n新建项目文件夹 mkdir Postman-Newman-demo 项目初始化 // 进入项目文件夹下 cd Postman-Newman-demo // nodejs 项目初始化 npm init -y 安装依赖 目前 newman 最新版本在 html 测试报告的一些包兼容性上有问题，所以这里使用 4.2.3 版本\n// 安装 newman npm install newman@4.2.3 --save-dev Postman 编写接口测试用例 新建 Collection 和 Request 打开 Postman，点击左上角的 New 按钮，选择 Collection，输入 Collection 的名称，点击 Create Collection 按钮，创建一个名称为 demo 的 Collection。 在 Collection 中，点击右上角的三个点，选择 Add Request，输入 Request 的名称，点击 Save 按钮，创建一个 Request 命名为 get-demo。再添加一个 Request 命名为 post-demo。 编辑 Request 和编写测试用例 可根据项目文件下的 demoAPI.md 文件中的接口文档，获取 demo 使用的 Request 的 URL、请求方法、请求头、请求体等信息。\nget-demo 在 get-demo 的 Request 中，选择 GET 请求方法，输入 URL 为https://jsonplaceholder.typicode.com/posts/1 在 Headers 中，添加一个 Key 为 Content-Type，Value 为 application/json; 的请求头。 在 Tests 下，添加以下脚本，用于验证响应结果： pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 点击 Send 按钮，发送请求，验证响应结果。 确认响应结果正确后，点击 Save 按钮，保存 Request。\npost-demo 在 post-demo 的 Request 中，选择 POST 请求方法，输入 URL 为https://jsonplaceholder.typicode.com/posts 在 Headers 中，添加一个 Key 为 Content-Type，Value 为 application/json; 的请求头。 在 Body 中，选择 raw，选择 JSON 格式，输入以下请求体： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 在 Tests 下，添加以下脚本，用于验证响应结果： pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(201); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(101); pm.expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 确认响应结果正确后，点击 Save 按钮，保存 Request。\nPostman 编写测试环境配置文件 下面会取接口请求的 host 为环境变量来进行 demo\n添加环境变量 在 Postman 的右上角，点击齿轮图标，选择 Manage Environments，点击 Add 按钮，输入环境名称为 DemoEnv，点击 Add 按钮，创建一个名称为 DemoEnv 的环境。 编辑环境变量，添加一个 Key 为 host，Value 为https://jsonplaceholder.typicode.com的环境变量。 点击 Add 按钮，保存环境变量。 更新 Request 在 get-demo 的 Request 中，更新 URL 为{{host}}/posts/1 在 post-demo 的 Request 中，更新 URL 为{{host}}/posts 验证环境变量 在 Postman 的右上角，点击齿轮图标，选择 DemoEnv，切换环境变量为 DemoEnv。 选择 get-demo 的 Request，点击 Send 按钮，发送请求，验证响应结果。确认响应结果正确后，点击 Save 按钮，保存 Request。 选择 post-demo 的 Request，点击 Send 按钮，发送请求，验证响应结果。确认响应结果正确后，点击 Save 按钮，保存 Request。 导出环境变量和测试用例文件 在 Postman 的右上角，点击齿轮图标，选择 Export，选择 DemoEnv，点击 Export 按钮，导出环境变量。 选择 get-demo request 和 post-demo request 所在的 demo Collection，点击右上角的三个点，选择 Export，选择 Collection v2.1，点击 Export 按钮，导出测试用例文件。 调整项目文件结构 新建 Env 和 Testcase 文件夹 在项目文件夹下，新建一个名为 Env 的文件夹，用于存放环境变量文件。 // 新建 Env 文件夹 mkdir Env 在项目文件夹下，新建一个名为 Testcase 的文件夹，用于存放测试用例文件。 // 新建 Testcase 文件夹 mkdir Testcase 调整用例文件和环境变量文件 将导出的环境变量文件和测试用例文件放到项目文件夹下的 Env 和 Testcase 文件夹下。\n调整 package.json 文件 在 package.json 文件中，添加以下脚本，用于运行测试用例： \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json\u0026#34; } 运行测试用例 npm run test 参考文档 Postman 官方文档 newman 官方文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/postman-tutorial-getting-started-and-building-your-own-project-from-0-to-1/","summary":"关于 Postman 接口自动化测试的导引，全面介绍入门基础和从零开始搭建项目的步骤。学习如何有效地使用 Postman 进行 API 测试，了解项目搭建的基础结构、环境设置和测试用例的编写","title":"Postman 接口自动化测试教程：入门介绍和从 0 到 1 搭建 Postman 接口自动化测试项目"},{"content":"进阶用法 并发测试和分布式测试 在日常的接口自动化测试过程中，需要并发执行测试用例，以提高测试效率。\n有时候也需要引入分布式测试，以便在多台机器上同时运行测试用例，也能更好的提升测试效率。\npytest-xdist 是 Pytest 的一个插件，能提供了一些对应的功能，主要用于支持并发测试和分布式测试。\npytest-xdist 功能介绍 并发执行测试：\n使用 -n 选项：pytest -n NUM 允许并发运行测试，其中 NUM 是并发 worker 的数量。这可以加速测试执行，特别是在拥有多个 CPU 内核的计算机上。 pytest -n 3 # 启动 3 个并发 worker 执行测试 分布式测试：\n使用 pytest --dist=loadscope：允许在多个节点上执行测试，通过分布式测试可以更快地完成测试运行。 pytest --dist=loadscope 使用 pytest --dist=each：每个节点运行一组测试，适用于分布式测试。 pytest --dist=each 参数化测试和并发：\n使用 pytest.mark.run：结合 pytest.mark.run 标记，可以选择在不同的进程或节点上运行具有不同标记的测试。 @pytest.mark.run(processes=2) def test_example(): pass 分布式环境设置：\n使用 pytest_configure_node：可以在节点上运行测试之前进行配置。 def pytest_configure_node(node): node.slaveinput[\u0026#39;my_option\u0026#39;] = \u0026#39;some value\u0026#39; 使用 pytest_configure_node：可以在节点上运行测试之前进行配置。 def pytest_configure_node(node): node.slaveinput[\u0026#39;my_option\u0026#39;] = \u0026#39;some value\u0026#39; 分布式测试环境销毁：\n使用 pytest_configure_node：可以在节点上运行测试之后进行清理。 def pytest_configure_node(node): # 配置节点 yield # 在节点上运行测试后执行清理 print(\u0026#34;Cleaning up after test run on node %s\u0026#34; % node.gateway.id) 这些是 pytest-xdist 提供的一些功能，可以帮助您更有效地执行并发测试和分布式测试，以加速测试执行并提高效率。确保在使用前查阅 pytest-xdist 的文档以获取更详细的信息和用法示例。\n安装 pytest-xdist 依赖 pip install pytest-xdist 并发运行测试用例示例 并发 3 个 worker 执行测试用例 分别运行以下命令，查看测试用例的执行时长\n并发执行 pytest -n 3 默认串行执行 pytest 串行执行耗时 9.81s，而并发执行耗时 1.63s，可以看到并发执行测试用例可以大大提高测试效率。\n并发 3 个 worker 执行测试用例，并且每个 worker 都会打印测试用例的进度 pytest -n 3 -v 测试结果中会打印测试进度，可以更好的了解测试用例的执行情况。\n分布式测试示例 分布式测试，每个节点运行一组测试 pytest --dist=each 分布式测试可以更快地完成测试运行。\n分布式测试，每个节点运行一组测试，并且每个 worker 都会打印测试用例的进度 pytest --dist=each -v 测试结果中会打印测试进度，可以更好的了解测试用例的执行情况。\n分布式测试，每个节点运行一组测试，并且每个 worker 都会打印测试用例的进度，同时打印测试日志的输出 pytest --dist=each -v --capture=no 测试结果中会打印测试日志的输出，可以更好的了解测试用例的执行情况。\n筛选用例执行 在日常的接口测试过程中，我们需要根据实际情况来选择性地执行测试用例，以提高测试效率。\n一般我们使用 allure 测试报告的时候，可以使用 Allure 标签特性来进行筛选对应标签的的用例来执行测试，但 Pytest 框架不直接支持运行基于 Allure 标签的测试。所以可以使用 Pytest 标记来实现这一点。\nPytest 提供 marks标记功能可以用来标记不同类型的测试用例，然后进行筛选对应类型的测试用例进行执行。\n大致流程为你可以用自定义标记（如 Regression/Smoke）来标记测试，然后使用 pytest 的 -m 选项只运行这些测试。\n定义 Pytest 标记 编辑 pytest.ini 文件，添加以下内容：自定义标记的类型\nRegression:标记为回归测试的用例 Smoke:标记为冒烟测试的用例 markers = Regression: marks tests as Regression Smoke: marks tests as Smoke 标记用例 操作步骤为：\n引入 pytest 使用 @pytest.mark 标记测试用例 为做区分，这里新建测试用例文件，文件名为 test_demo_filter.py\nimport pytest import requests import json class TestPytestMultiEnvDemo: @pytest.mark.Regression # mark the test case as regression def test_get_demo_filter(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send request response = requests.get(host+get_api) # assert assert response.status_code == 200 assert response.json() == get_api_response_data @pytest.mark.Smoke # mark the test case as smoke def test_post_demo_filter(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] print(\u0026#34;make the request\u0026#34;) post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # Your test code here response = requests.post(host + post_api, json=post_api_request_data) print(\u0026#34;verify the response status code\u0026#34;) assert response.status_code == 201 print(\u0026#34;verify the response data\u0026#34;) assert response.json() == post_api_response_data 筛选测试用例执行 运行 Regression 标记的测试用例 pytest -m Regression 这条命令告诉 pytest 只运行标有 Regression 的测试。\n运行 Smoke 标记的测试用例 pytest -m Smoke 这条命令告诉 pytest 只运行标有 Smoke 的测试。\n参考资料 pytest-xdist 文档:https://pytest-xdist.readthedocs.io/en/stable/ pytest makers 文档:https://docs.pytest.org/en/6.2.x/example/markers.html pytest 文档:https://docs.pytest.org/en/6.2.x/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-filter-testcase-and-concurrent-testing-distributed-testing/","summary":"聚焦于测试用例筛选、并发测试和分布式测试。学会如何有针对性地执行测试用例，提高测试效率。探索 Pytest 的并发测试特性，了解如何同时执行多个测试用例，缩短测试时间。","title":"Pytest 接口自动化测试教程：进阶用法 - 筛选测试用例执行，并发测试和分布式测试"},{"content":"进阶用法 多环境支持 在实际的 API 自动化测试过程中，我们需要在不同的环境中运行测试用例，以确保 API 在各个环境中都能正常运行。\n通过使用 Pytest 的 fixture 功能，我们可以轻松地实现多环境支持。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n新建不同环境测试配置文件 配置文件会以 json 格式存储为例，其他格式如 YAML、CSV 等类似，均可参考\n// 新建测试配置文件夹 mkdir config // 进入测试配置文件夹 cd config // 新建开发环境测试配置文件 touch dev_config.json // 新建生产环境测试配置文件 touch prod_config.json 编写不同环境测试配置文件 编写开发环境测试配置文件 根据实际情况配置开发环境测试配置文件\n{ \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 编写生产环境测试配置文件 根据实际情况配置生产环境测试配置文件\n{ \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 新建不同环境测试数据文件 不同环境请求数据文件和响应数据文件分别存储测试用例的不同环境请求数据和不同环境预期响应数据。\n// 新建测试数据文件夹 mkdir data // 进入测试数据文件夹 cd data // 新建开发环境请求数据文件 touch dev_request_data.json // 新建开发环境响应数据文件 touch dev_response_data.json // 新建生产环境请求数据文件 touch prod_request_data.json // 新建生产环境响应数据文件 touch prod_response_data.json 编写不同环境测试数据文件 编写开发环境请求数据文件 开发环境请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写开发环境响应数据文件 开发环境响应数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 编写生产环境请求数据文件 生产环境请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写生产环境响应数据文件 生产环境响应数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 配置支持多环境的 fixture fixture 会以 conftest.py 文件存储为例，其他格式如 YAML、CSV 等类似，均可参考\n项目根目录新建 conftest.py 文件 mkdrir conftest.py 编写 conftest.py 文件 import pytest import json import json import os @pytest.fixture(scope=\u0026#34;session\u0026#34;) def env_config(request): # get config file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;config/{env}_config.json\u0026#39;, \u0026#39;r\u0026#39;) as config_file: config = json.load(config_file) return config @pytest.fixture(scope=\u0026#34;session\u0026#34;) def env_request_data(request): # get request data file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;data/{env}_request_data.json\u0026#39;, \u0026#39;r\u0026#39;) as request_data_file: request_data = json.load(request_data_file) return request_data @pytest.fixture (scope=\u0026#34;session\u0026#34;) def env_response_data(request): # get response data file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;data/{env}_response_data.json\u0026#39;, \u0026#39;r\u0026#39;) as response_data_file: response_data = json.load(response_data_file) return response_data 更新测试用例来支持多环境 为做区分，这里新建测试用例文件，文件名为 test_demo_multi_environment.py\nimport requests import json class TestPytestMultiEnvDemo: def test_get_demo_multi_env(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send request response = requests.get(host+get_api) # assert assert response.status_code == 200 assert response.json() == get_api_response_data def test_post_demo_multi_env(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # send request response = requests.post(host + post_api, post_api_request_data) # assert assert response.status_code == 201 assert response.json() == post_api_response_data 运行该测试用例确认多环境支持是否生效 运行开发环境测试用例 ENV=dev pytest test_case/test_demo_multi_environment.py 运行生产环境测试用例 ENV=prod pytest test_case/test_demo_multi_environment.py 集成 allure 报告 allure 是一个轻量级的、灵活的、易于扩展的测试报告工具，它提供了丰富的报告类型和功能，可以帮助您更好地可视化测试结果。\nallure 报告可以与 Pytest 集成，以生成详细的测试报告。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n安装 allure-pytest 依赖 pip install allure-pytest 避免之前安装的 pytest-html-reporter 与 allure-pytest 冲突，建议先卸载 pytest-html-reporter\npip uninstall pytest-html-reporter 配置 allure-pytest 更新 pytest.ini 文件来指定 allure 报告的存储位置\n[pytest] # allure addopts = --alluredir ./allure-results 调整测试用例来支持 allure 报告 为做区分，这里新建测试用例文件，文件名为 test_demo_allure.py\nimport allure import requests @allure.feature(\u0026#34;Test example API\u0026#34;) class TestPytestAllureDemo: @allure.story(\u0026#34;Test example get endpoint\u0026#34;) @allure.title(\u0026#34;Verify the get API\u0026#34;) @allure.description(\u0026#34;verify the get API response status code and data\u0026#34;) @allure.severity(\u0026#34;blocker\u0026#34;) def test_get_example_endpoint_allure(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_request_data = env_request_data[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send get request response = requests.get(host + get_api) # assert print(\u0026#34;response status code is\u0026#34; + str(response.status_code)) assert response.status_code == 200 print(\u0026#34;response data is\u0026#34; + str(response.json())) assert response.json() == get_api_response_data @allure.story(\u0026#34;Test example POST API\u0026#34;) @allure.title(\u0026#34;Verify the POST API\u0026#34;) @allure.description(\u0026#34;verify the POST API response status code and data\u0026#34;) @allure.severity(\u0026#34;Critical\u0026#34;) def test_post_example_endpoint_allure(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # send request response = requests.post(host + post_api, json=post_api_request_data) # assert print(\u0026#34;response status code is\u0026#34; + str(response.status_code)) assert response.status_code == 201 print(\u0026#34;response data is\u0026#34; + str(response.json())) assert response.json() == post_api_response_data 运行测试用例生成 allure 报告 ENV=dev pytest test_case/test_demo_allure.py 查看 allure 报告 输入以下命令来启动 allure 服务并浏览器中查看 allure 报告\nallure serve allure-results 调整 CI/CD 流程来支持 allure 报告 以 github action 为例，其他 CI 工具类似\n更新.github/workflows/pytest.yml 文件内容来上传 allure 报告到 GitHub\nname: Pytest API Testing on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] permissions: contents: read jobs: Pytes-API-Testing: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python 3.10 uses: actions/setup-python@v3 with: python-version: \u0026#34;3.10\u0026#34; - name: Install dependencies run: | python -m pip install --upgrade pip pip install -r requirements.txt - name: Test with pytest run: | ENV=dev pytest - name: Archive Pytest allure test report uses: actions/upload-artifact@v3 with: name: Pytest-allure-report path: allure-results - name: Upload Pytest allure report to GitHub uses: actions/upload-artifact@v3 with: name: Pytest-allure-report path: allure-results 查看 github action allure 报告 在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Pytest API Testing 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。\n参考 Pytest 文档 Allure 文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-multiple-environment-support-and-integration-allure-report/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 如何支持不同环境测试用例执行，以及如何集成 allure 报告来实现测试报告多样化。","title":"Pytest 接口自动化测试教程：进阶用法 - 多环境支持 和 集成 allure 报告"},{"content":"进阶用法 常用断言 使用 Pytest 在接口自动化测试用例编写过程中，我们需要使用各种断言来验证测试的预期结果。\nPytest 提供了更多的断言和灵活的断言库，以满足各种测试需求。\n以下是一些常用的 Pytest 接口自动化测试断言：\n相等性断言：检查两个值是否相等。\nassert actual_value == expected_value 不相等性断言：检查两个值是否不相等。\nassert actual_value != expected_value 包含断言：检查一个值是否包含在另一个值中，通常用于检查字符串是否包含子字符串。\nassert substring in full_string 成员资格断言：检查一个值是否在集合、列表或其他可迭代对象中。\nassert item in iterable 真值断言：检查一个表达式或变量是否为真。\nassert expression 或\nassert variable 假值断言：检查一个表达式或变量是否为假。\nassert not expression 或\nassert not variable 大于、小于、大于等于、小于等于断言：检查一个值是否大于、小于、大于等于或小于等于另一个值。\nassert value \u0026gt; other_value assert value \u0026lt; other_value assert value \u0026gt;= other_value assert value \u0026lt;= other_value 类型断言：检查一个值的类型是否符合预期。\nassert isinstance(value, expected_type) 例如，检查一个值是否是字符串：\nassert isinstance(my_string, str) 异常断言：检查在代码块中是否引发了特定类型的异常。\nwith pytest.raises(ExpectedException): # 代码块，期望引发 ExpectedException 异常 近似相等断言：检查两个浮点数是否在某个误差范围内相等。\nassert math.isclose(actual_value, expected_value, rel_tol=1e-9) 列表相等断言：检查两个列表是否相等。\nassert actual_list == expected_list 字典相等断言：检查两个字典是否相等。\nassert actual_dict == expected_dict 正则表达式匹配断言：检查一个字符串是否匹配给定的正则表达式。\nimport re assert re.match(pattern, string) 空值断言：检查一个值是否为 None。\nassert value is None 非空值断言：检查一个值是否不为 None。\nassert value is not None 布尔值断言：检查一个值是否为 True 或 False。\nassert boolean_expression 空容器断言：检查一个列表、集合或字典是否为空。\nassert not container # 检查容器是否为空 包含子集断言：检查一个集合是否包含另一个集合作为子集。\nassert subset \u0026lt;= full_set 字符串开头或结尾断言：检查一个字符串是否以指定的前缀或后缀开头或结尾。\nassert string.startswith(prefix) assert string.endswith(suffix) 数量断言：检查一个列表、集合或其他可迭代对象的元素数量。\nassert len(iterable) == expected_length 范围断言：检查一个值是否在指定的范围内。\nassert lower_bound \u0026lt;= value \u0026lt;= upper_bound 文件存在断言：检查文件是否存在。\nimport os assert os.path.exists(file_path) 以上是一些 Pytest 常用的断言，但根据具体的测试需求，您可能会使用其他断言或结合多个断言来更全面地验证测试结果。 详细的断言文档可以在 Pytest 官方网站找到：Pytest - Built-in fixtures, marks, and nodes\n数据驱动 在 API 自动化测试的过程中。使用数据驱动是一种常规测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。\n测试数据可以很容易地修改，而不需要修改测试用例代码。\n数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n新建测试配置文件 配置文件会以 json 格式存储为例，其他格式如 YAML、CSV 等类似，均可参考\n// 新建测试配置文件夹 mkdir config // 新建测试配置文件 cd config touch config.json 编写测试配置文件 配置文件存储测试环境的配置信息，如测试环境的 URL、数据库连接信息等。\ndemo 中的测试配置文件内容如下：\n配置 host 信息 配置 getAPI 接口信息 配置 postAPI 接口信息 { \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 新建测试数据文件 请求数据文件和响应数据文件分别存储测试用例的请求数据和预期响应数据。\n// 新建测试数据文件夹 mkdir data // 进入测试数据文件夹 cd data // 新建请求数据文件 touch request_data.json // 新建响应数据文件 touch response_data.json 编写测试数据文件 编写请求数据文件 请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写响应数据文件 请求数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 更新测试用例来支持数据驱动 为做区分，这里新建测试用例文件，文件名为 test_demo_data_driving.py\nimport requests import json # 从配置文件夹获取测试配置 with open(\u0026#34;config/config.json\u0026#34;, \u0026#34;r\u0026#34;) as json_file: config = json.load(json_file) # 从测试数据文件夹获取接口请求数据 with open(\u0026#39;data/request_data.json\u0026#39;, \u0026#39;r\u0026#39;) as json_file: request_data = json.load(json_file) # 从测试数据文件夹获取接口响应数据 with open(\u0026#39;data/response_data.json\u0026#39;, \u0026#39;r\u0026#39;) as json_file: response_data = json.load(json_file) class TestPytestDemo: def test_get_demo(self): host = config.get(\u0026#34;host\u0026#34;) get_api = config.get(\u0026#34;getAPI\u0026#34;) get_api_response_data = response_data.get(\u0026#34;getAPI\u0026#34;) # 发起请求 response = requests.get(host+get_api) # 断言 assert response.status_code == 200 assert response.json() == get_api_response_data def test_post_demo(self): host = config.get(\u0026#34;host\u0026#34;) post_api = config.get(\u0026#34;postAPI\u0026#34;) post_api_request_data = request_data.get(\u0026#34;postAPI\u0026#34;) post_api_response_data = response_data.get(\u0026#34;postAPI\u0026#34;) # 发起请求 response = requests.post(host + post_api, post_api_request_data) # 断言 assert response.status_code == 201 assert response.json() == post_api_response_data 运行该测试用例确认数据驱动是否生效 若用 demo 项目运行数据驱动支持测试用例：test_demo_data_driving.py，建议先屏蔽掉其他测试用例，否则可能会报错\n参考 pytest 文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-common-assertions-and-data-driven/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 常用断言和数据驱动。","title":"Pytest 接口自动化测试教程：进阶用法 - 常用断言和数据驱动"},{"content":"进阶用法 持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 pytest.yml。\n编辑 pytest.yml 文件：将以下内容复制到文件中\n# This workflow will install Python dependencies, run tests and lint with a single version of Python # For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python name: Pytest API Testing on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] permissions: contents: read jobs: Pytes-API-Testing: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python 3.10 uses: actions/setup-python@v3 with: python-version: \u0026#34;3.10\u0026#34; - name: Install dependencies run: | python -m pip install --upgrade pip pip install -r requirements.txt - name: Test with pytest run: | pytest - name: Archive Pytest test report uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: report - name: Upload Pytest report to GitHub uses: actions/upload-artifact@v3 with: name: Pytest-test-report path: report 提交代码：将 pytest.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Pytest API Testing 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 参考 pytest 文档 gitHub action 文档 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-integration-ci-cd-and-github-action/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 集成到 CI/CD 流程中，以及如何使用 GitHub Actions 实现自动化测试。","title":"Pytest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action"},{"content":"从 0 到 1 搭建 Pytest 接口自动化测试项目 1.创建项目目录 mkdir Pytest-API-Testing-Demo 2.项目初始化 // 进入项目文件夹下 cd Pytest-API-Testing-Demo // 创建项目 python 项目虚拟环境 python -m venv .env // 启用项目 python 项目虚拟环境 source .env/bin/activate 3.安装项目依赖 // 安装 requests 包 pip install requests // 安装pytest 包 pip install pytest // 将项目依赖项保存到 requirements.txt 文件中 pip freeze \u0026gt; requirements.txt 4.新建测试文件及测试用例 // 新建测试文件夹 mkdir tests // 新建测试用例文件 cd tests touch test_demo.py 5.编写测试用例 测试接口可参考项目中 demoAPI.md 文件\nimport requests class TestPytestDemo: def test_get_demo(self): base_url = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34; # 发起请求 response = requests.get(f\u0026#34;{base_url}/posts/1\u0026#34;) # 断言 assert response.status_code == 200 assert response.json()[\u0026#39;userId\u0026#39;] == 1 assert response.json()[\u0026#39;id\u0026#39;] == 1 def test_post_demo(self): base_url = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34; requests_data = { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } # 发起请求 response = requests.post(f\u0026#34;{base_url}/posts\u0026#34;, requests_data) # 断言 assert response.status_code == 201 print(response.json()) assert response.json()[\u0026#39;userId\u0026#39;] == \u0026#39;1\u0026#39; assert response.json()[\u0026#39;id\u0026#39;] == 101 6.运行测试用例 pytest 7.查看测试报告 8.接入 pytest-html-reporter 测试报告 https://github.com/prashanth-sams/pytest-html-reporter\n安装 pytest-html-reporter 依赖 pip install pytest-html-reporter 配置测试报告参数 项目根目录下新建 pytest.ini 文件 添加以下内容 [pytest] addopts = -vs -rf --html-report=./report --title=\u0026#39;PYTEST REPORT\u0026#39; --self-contained-html 运行测试用例 pytest 查看测试报告 报告在项目根目录下的 report 目录下，使用浏览器打开 pytest_html_report.html 文件即可查看\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-building-your-own-project-from-0-to-1/","summary":"将从零开始教您如何建立 Pytest 接口自动化测试项目。您将学习如何创建项目的基础结构，设置环境，编写测试用例，以及执行自动化测试。","title":"Pytest 接口自动化测试教程：从 0 到 1 搭建 Pytest 接口自动化测试项目"},{"content":"介绍 Pytest 介绍 Pytest 是一个流行的 Python 测试框架，用于编写、组织和运行各种类型的自动化测试。它提供了丰富的功能，使您能够轻松编写和管理测试用例，以及生成详细的测试报告。以下是 Pytest 的一些主要特点和优势：\n简单和易用：Pytest 的设计使得编写测试用例变得简单且易于理解。您可以使用 Python 的标准 assert 语句来编写测试断言，而不需要学习新的断言语法。\n自动发现测试用例：Pytest 可以自动发现和运行项目中的测试用例，而不需要显式配置测试套件。测试用例文件可以命名为 test_*.py 或 *_test.py，或使用特定的测试函数命名规范。\n丰富的插件生态系统：Pytest 可以通过插件扩展其功能。有许多第三方插件可用，以满足不同测试需求，如 Allure 报告、参数化、覆盖率分析等。\n参数化测试：Pytest 支持参数化测试，允许您运行相同的测试用例多次，但使用不同的参数。这可以减少代码重复，提高测试覆盖率。\n异常和故障定位：Pytest 提供详细的错误和异常信息，有助于您更容易地定位和解决问题。它还提供详细的回溯（traceback）信息。\n并行测试执行：Pytest 支持并行执行测试用例，提高了测试执行的速度，特别是在大型项目中。\n多种报告格式：Pytest 支持多种测试报告格式，包括终端输出、JUnit XML、HTML 报告和 Allure 报告等。这些报告可以帮助您可视化测试结果。\n命令行选项：Pytest 提供了丰富的命令行选项，以定制测试运行的行为，包括过滤、重试、覆盖率分析等。\n集成性：Pytest 可以与其他测试框架和工具（如 Selenium、Django、Flask 等）以及持续集成系统（如 Jenkins、Travis CI 等）轻松集成。\n活跃的社区：Pytest 拥有一个活跃的社区，有广泛的文档和教程可供学习和参考。您还可以在社区中获得支持和解决问题。\n总之，Pytest 是一个强大且灵活的测试框架，适用于各种规模和类型的项目。它的易用性、自动化能力以及丰富的插件使它成为 Python 测试领域的首选工具之一。\n官方网站：https://docs.pytest.org/en/latest/\npython 虚拟环境介绍 Python 虚拟环境（Virtual Environment）是一种机制，用于在单个 Python 安装中创建和管理多个隔离的开发环境。虚拟环境有助于解决不同项目之间的依赖冲突问题，确保每个项目都能够使用其独立的 Python 包和库，而不会相互干扰。以下是如何创建和使用 Python 虚拟环境的步骤：\n安装虚拟环境工具: 在开始之前，确保您已安装 Python 的虚拟环境工具。在 Python 3.3 及更高版本中，venv 模块已经内置，可以使用它来创建虚拟环境。如果您使用较旧版本的 Python，您可以安装 virtualenv 工具。\n对于 Python 3.3+，venv 工具已内置，无需额外安装。\n对于 Python 2.x，可以使用以下命令安装 virtualenv 工具：\npip install virtualenv 创建虚拟环境: 打开终端，移动到您希望创建虚拟环境的目录，并运行以下命令以创建虚拟环境：\n使用 venv（适用于 Python 3.3+）：\npython -m venv myenv 使用 virtualenv（适用于 Python 2.x）：\nvirtualenv myenv 在上述命令中，myenv 是虚拟环境的名称，您可以自定义名称。\n激活虚拟环境: 要开始使用虚拟环境，需要激活它。在不同的操作系统中，激活命令略有不同：\n在 macOS 和 Linux 上：\nsource myenv/bin/activate 在 Windows 上（使用 Command Prompt）：\nmyenv\\Scripts\\activate 在 Windows 上（使用 PowerShell）：\n.\\myenv\\Scripts\\Activate.ps1 一旦虚拟环境激活，您会在终端提示符前看到虚拟环境的名称，表示您已进入虚拟环境。\n在虚拟环境中安装依赖: 在虚拟环境中，您可以使用 pip 安装项目所需的任何 Python 包和库，这些依赖将与该虚拟环境关联。例如：\npip install requests 使用虚拟环境: 在虚拟环境中工作时，您可以运行 Python 脚本和使用安装在虚拟环境中的包。这确保了您的项目在独立的环境中运行，不会与全局 Python 安装产生冲突。\n退出虚拟环境: 要退出虚拟环境，只需在终端中运行以下命令：\ndeactivate 这将使您返回到全局 Python 环境。\n通过使用虚拟环境，您可以在不同项目之间维护干净的依赖关系，并确保项目的稳定性和隔离性。这是 Python 开发中的一个良好实践。\n项目依赖 需提前安装好以下环境\npython, demo 版本为 v3.11.6 大家安装 python3.x 以上的版本即可\n项目目录结构 以下为一个 Pytest 接口自动化测试项目的目录结构示例：\n后续 demo 项目会引入 allure 报告，所以会多出一个 allure-report 目录\nPytest-allure-demo/ ├── tests/ # 存放测试用例文件 │ ├── test_login.py # 示例测试用例文件 │ ├── test_order.py # 示例测试用例文件 │ └── ... ├── data/ # 存放测试数据文件（如 JSON、CSV 等） │ ├── dev_test_data.json # 开发环境测试数据文件 │ ├── prod_test_data.json # 生产环境测试数据文件 │ ├── ... ├── config/ │ ├── dev_config.json # 开发环境配置文件 │ ├── prod_config.json # 生产环境配置文件 │ ├── ... ├── conftest.py # Pytest 的全局配置文件 ├── pytest.ini # Pytest 配置文件 ├── requirements.txt # 项目依赖项文件 └── allure-report/ # 存放 Allure 报告 参考 Pytest: https://docs.pytest.org/en/latest/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/pytest-tutorial-getting-started-and-own-environment-preparation/","summary":"包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 Pytest 以及如何开始使用它来进行 API 测试。","title":"Pytest 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"多环境支持 在使用 Jest 或 Mocha 进行 API 测试时，你可能需要支持测试不同的环境，例如开发环境、测试环境和生产环境。这可以通过配置不同的测试脚本和环境变量来实现。\n下面会简单描述一下如何在 Jest 和 Mocha 中配置多环境支持，会以支持两个环境来进行 demo 演示。\nMocha 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\nJest 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\nmocha 版本和 Jest 版本类似，这里以 Mocha 版本为例\n新建多环境测试配置文件 // 新建测试配置文件夹 若已有则不用新建 mkdir Config // 新建测试环境测试配置文件 cd Config touch testConfig-test.js // 新建开发环境测试配置文件 touch testConfig-dev.js 编写多环境测试配置文件 编写测试环境测试配置文件 根据实际情况编写测试环境测试配置文件\n// Test config file for test environment module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 编写开发环境测试配置文件 根据实际情况编写开发环境测试配置文件\n// Test config file for dev environment module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 新建多环境测试数据文件 // 新建测试数据文件夹 若已有则不用新建 mkdir testData // 进入测试数据文件夹 cd testData // 新建测试环境请求数据文件 touch requestData-test.js // 新建测试环境响应数据文件 touch responseData-test.js // 新建开发环境请求数据文件 touch requestData-dev.js // 新建开发环境响应数据文件 touch responseData-dev.js 编写多环境测试数据文件 编写测试环境请求数据文件 根据实际情况编写测试环境请求数据文件\n// Test request data file for test environment module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写测试环境响应数据文件 根据实际情况编写测试环境响应数据文件\n// Test response data file for test environment module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 编写开发环境请求数据文件 根据实际情况编写开发环境请求数据文件\n// Test request data file for dev environment module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写开发环境响应数据文件 根据实际情况编写开发环境响应数据文件\n// Test response data file for dev environment module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 更新测试用例来支持多环境 为做区分，这里新建测试用例文件，文件名为 multiEnvTest.spec.js\n// Test: multiEnvTest.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect const config = process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../Config/testConfig-test\u0026#39;) : require(\u0026#39;../Config/testConfig-dev\u0026#39;); // import test config const requestData = process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../TestData/requestData-test\u0026#39;) : require(\u0026#39;../TestData/requestData-dev\u0026#39;); // import request data const responseData= process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../TestData/responseData-test\u0026#39;) : require(\u0026#39;../TestData/responseData-dev\u0026#39;); // import response data // Test Suite describe(\u0026#39;multiEnv-Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;multiEnv-Verify that the GET API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .get(config.getAPI) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.getAPI.id) expect(res.body.userId).to.equal(responseData.getAPI.userId) expect(res.body.title).to.equal(responseData.getAPI.title) expect(res.body.body).to.equal(responseData.getAPI.body) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;multiEnv-Verify that the POST API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .post(config.postAPI) // API endpoint .send(requestData.postAPI) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.postAPI.id ) expect(res.body.userId).to.equal(responseData.postAPI.userId ) expect(res.body.title).to.equal(responseData.postAPI.title ) expect(res.body.body).to.equal(responseData.postAPI.body ) }) // expected response body .end(done) // end the test case }); }); 更新测试脚本来支持多环境 \u0026lsquo;\u0026lsquo;\u0026lsquo;json // package.json \u0026ldquo;scripts\u0026rdquo;: { \u0026ldquo;test\u0026rdquo;: \u0026ldquo;NODE_ENV=test mocha\u0026rdquo; // 运行测试环境测试脚本 \u0026ldquo;dev\u0026rdquo;: \u0026ldquo;NODE_ENV=dev mocha\u0026rdquo; // 运行 dev 环境测试脚本 }, \u0026rsquo;\u0026rsquo;\u0026rsquo;\n运行该测试用例确认多环境支持是否生效 若用 demo 项目运行多环境支持测试用例：multiEnvTest.spec.js，建议先屏蔽掉 dataDrivingTest.spec.js 和 test.spec.js 测试用例，否则会报错\n运行测试环境测试脚本 npm run test 运行开发环境测试脚本 npm run dev 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-multiple-environment-support/","summary":"专注于 SuperTest 的高级用法，着重介绍多环境支持。您将学习如何配置和管理多个测试环境，以适应不同开发和部署阶段。","title":"SuperTest 接口自动化测试教程：进阶用法 - 多环境支持"},{"content":"数据驱动 API 测试的数据驱动是一种测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\nMocha 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\nJest 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\nmocha 版本和 Jest 版本类似，这里以 Mocha 版本为例\n新建测试配置文件 // 新建测试配置文件夹 mkdir Config // 新建测试配置文件 cd Config touch config.js 编写测试配置文件 // Test config file module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 新建测试数据文件 // 新建测试数据文件夹 mkdir testData // 进入测试数据文件夹 cd testData // 新建请求数据文件 touch requestData.js // 新建响应数据文件 touch responseData.js 编写测试数据文件 编写请求数据文件 // Test request data file module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写响应数据文件 // Test response data file module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 更新测试用例来支持数据驱动 为做区分，这里新建测试用例文件，文件名为 dataDrivingTest.spec.js\n// Test: dataDrivingTest.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect const config = require(\u0026#39;../Config/testConfig\u0026#39;); // import test config const requestData = require(\u0026#39;../TestData/requestData\u0026#39;); // import request data const responseData = require(\u0026#39;../TestData/responseData\u0026#39;); // import response data // Test Suite describe(\u0026#39;Data Driving-Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;Data Driving-Verify that the GET API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .get(config.getAPI) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.getAPI.id) expect(res.body.userId).to.equal(responseData.getAPI.userId) expect(res.body.title).to.equal(responseData.getAPI.title) expect(res.body.body).to.equal(responseData.getAPI.body) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;Data Driving-Verify that the POST API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .post(config.postAPI) // API endpoint .send(requestData.postAPI) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.postAPI.id ) expect(res.body.userId).to.equal(responseData.postAPI.userId ) expect(res.body.title).to.equal(responseData.postAPI.title ) expect(res.body.body).to.equal(responseData.postAPI.body ) }) // expected response body .end(done) // end the test case }); }); 运行该测试用例确认数据驱动是否生效 若用 demo 项目运行数据驱动支持测试用例：dataDrivingTest.spec.js，建议先屏蔽掉 test.spec.js 测试用例，否则会报错\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-data-driven/","summary":"专注于 SuperTest 的高级用法，侧重于数据驱动测试。您将学习如何通过数据参数化来扩展和优化您的 SuperTest 测试套件，提高测试覆盖率。","title":"SuperTest 接口自动化测试教程：进阶用法 - 数据驱动"},{"content":"常用断言 下面会一次介绍一下 SuperTest,CHAI 和 Jest 常用的断言。\nSuperTest 的内置断言 Supertest 是基于SuperAgent 构建的一个更高级的库，所以 Supertest 可以很轻松的使用 SuperAgent 的 HTTP 断言。\n示例如下：\n.expect(status[, fn]) //断言响应状态代码。 .expect(status, body[, fn]) // 断言响应状态代码和正文。 .expect(body[, fn]) // 用字符串、正则表达式或解析后的正文对象断言响应正文文本。 .expect(field, value[, fn]) // 用字符串或正则表达式断言标题字段值。 .expect(function(res) {}) // 传递一个自定义断言函数。它将得到要检查的响应对象。如果检查失败，则抛出错误。 CHAI 的常用断言 相等性断言（Equality Assertions） expect(actual).to.equal(expected) // 验证实际值是否等于期望值。 expect(actual).to.deep.equal(expected) // 验证实际值和期望值是否深度相等，适用于对象和数组比较。 expect(actual).to.eql(expected) // 与 deep.equal 一样，用于深度相等的比较。 包含性断言（Inclusion Assertions） expect(array).to.include(value) // 验证数组是否包含指定的值。 expect(string).to.include(substring) // 验证字符串是否包含指定的子字符串。 expect(object).to.include(key) // 验证对象是否包含指定的键。 类型断言（Type Assertions） expect(actual).to.be.a(type) // 验证实际值的类型是否等于指定类型。 expect(actual).to.be.an(type) // 与 to.be.a 一样，用于类型断言。 expect(actual).to.be.an.instanceof(constructor) // 验证实际值是否是指定构造函数的实例。 真假性断言（Truthiness Assertions） expect(value).to.be.true // 验证值是否为真。 expect(value).to.be.false // 验证值是否为假。 expect(value).to.exist // 验证值是否存在，非 null 和非 undefined。 长度断言（Length Assertions） expect(array).to.have.length(length) // 验证数组的长度是否等于指定长度。 expect(string).to.have.lengthOf(length) // 验证字符串的长度是否等于指定长度。 空值断言（Empty Assertions） expect(array).to.be.empty // 验证数组是否为空。 expect(string).to.be.empty // 验证字符串是否为空。 范围断言（Range Assertions） expect(value).to.be.within(min, max) // 验证值是否在指定的范围内。 expect(value).to.be.above(min) // 验证值是否大于指定值。 expect(value).to.be.below(max) // 验证值是否小于指定值。 异常断言（Exception Assertions） expect(fn).to.throw(error) // 验证函数是否抛出指定类型的异常。 expect(fn).to.throw(message) // 验证函数是否抛出包含指定消息的异常。 存在性断言（Existence Assertions） expect(object).to.have.property(key) // 验证对象是否包含指定属性。 expect(array).to.have.members(subset) // 验证数组是否包含指定的成员。 更多 chai 的断言，请查看https://www.chaijs.com/api/assert/\nJest 的常用断言 相等性断言（Equality Assertions） expect(actual).toBe(expected) // 验证实际值是否严格等于期望值。 expect(actual).toEqual(expected) // 验证实际值和期望值是否深度相等，适用于对象和数组比较。 不相等性断言 expect(actual).not.toBe(expected) // 验证实际值与期望值不相等。 包含性断言（Inclusion Assertions） expect(array).toContain(value) // 验证数组是否包含指定的值。 类型断言（Type Assertions） expect(actual).toBeTypeOf(expected) // 验证实际值的类型是否等于指定类型。 真假性断言（Truthiness Assertions） expect(value).toBeTruthy() // 验证值是否为真。 expect(value).toBeFalsy() // 验证值是否为假。 异步断言 await expect(promise).resolves.toBe(expected) // 验证异步操作是否成功完成并返回与期望值匹配的结果。 异常断言 expect(fn).toThrow(error) // 验证函数是否抛出指定类型的异常。 expect(fn).toThrow(message) // 验证函数是否抛出包含指定消息的异常。 范围断言 expect(value).toBeGreaterThanOrEqual(min) // 验证值是否大于或等于指定的最小值。 expect(value).toBeLessThanOrEqual(max) // 验证值是否小于或等于指定的最大值。 对象属性断言 expect(object).toHaveProperty(key, value) // 验证对象是否包含指定属性，并且该属性的值等于指定值。 更多 Jest 的断言，请查看https://jestjs.io/docs/expect\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-common-assertions/","summary":"聚焦于 Supertest 的高级用法，特别关注常用断言。您将学习如何使用这些断言来验证 API 响应，包括状态码、响应内容、和响应头部等。","title":"SuperTest 接口自动化测试教程：进阶用法 - 常用断言"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nMocha 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 mocha.yml。\n编辑 mocha.yml 文件：将以下内容复制到文件中\nname: RUN SuperTest API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-SuperTest-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive SuperTest mochawesome test report uses: actions/upload-artifact@v3 with: name: SuperTest-mochawesome-test-report path: Report - name: Upload SuperTest mochawesome report to GitHub uses: actions/upload-artifact@v3 with: name: SuperTest-mochawesome-test-report path: Report 提交代码：将 mocha.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN SuperTest API Test CI 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Jest 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 jest.yml。\n编辑 jest.yml 文件：将以下内容复制到文件中\nname: RUN SuperTest API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-SuperTest-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive SuperTest test report uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: Report - name: Upload SuperTest report to GitHub uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: Report 提交代码：将 jest.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN-SuperTest-API-Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-integration-ci-cd-and-github-action/","summary":"深入探讨 Supertest 的高级用法，着重介绍如何将 Supertest 集成到 CI/CD 流程中，以及如何使用 GitHub Actions 实现自动化测试。","title":"SuperTest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action"},{"content":"从 0 到 1 搭建 SuperTest 接口自动化测试项目 下面会从 0 到 1 搭建一个 SuperTest 接口自动化测试项目，会使用 Jest 或 Mocha 作为测试框架进行 demo 演示。\nMocha 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n新建项目文件夹 mkdir SuperTest-Mocha-demo 项目初始化 // 进入项目文件夹下 cd SuperTest-Mocha-demo // nodejs 项目初始化 npm init -y 安装依赖 // 安装 supertest npm install supertest --save-dev // 安装 mocha测试框架 npm install mocha --save-dev // 安装 chai断言库 npm install chai --save-dev 新建测试文件及测试用例 // 新建测试文件夹 mkdir Specs // 新建测试用例文件 cd Specs touch test.spec.js 编写测试用例 测试接口可参考项目中 demoAPI.md 文件\n// Test: test.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest const chai = require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect // Test Suite describe(\u0026#39;Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;Verify that the GET API returns correctly\u0026#39;, function(done){ request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .get(\u0026#39;/posts/1\u0026#39;) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(1 ) expect(res.body.userId).to.equal(1) expect(res.body.title).to.equal(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;) expect(res.body.body). to.equal(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;Verify that the POST API returns correctly\u0026#39;, function(done){ request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .post(\u0026#39;/posts\u0026#39;) // API endpoint .send({ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(101 ) expect(res.body.userId).to.equal(1) expect(res.body.title).to.equal(\u0026#34;foo\u0026#34;) expect(res.body.body).to.equal(\u0026#34;bar\u0026#34;) }) // expected response body .end(done) // end the test case }); }); 配置 mocha 配置文件 新建配置文件 // 项目根目录下新建配置文件 touch .mocharc.js 更新配置文件 // mocha config module.exports = { timeout: 5000, // 设置测试用例的默认超时时间（毫秒） spec: [\u0026#39;Specs/**/*.js\u0026#39;], // 指定测试文件的位置 }; 调整测试脚本 在 package.json 文件中添加测试脚本\n\u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;mocha\u0026#34; }, 运行测试用例 // 运行测试用例 npm run test 测试报告 命令行测试报告 集成 mochawesome 测试报告 安装 mochawesome npm install --save-dev mochawesome 更新 mocha 配置文件 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n// mocha config module.exports = { timeout: 5000, // 设置测试用例的默认超时时间（毫秒） reporter: \u0026#39;mochawesome\u0026#39;, // 使用 mochawesome 报告生成器 \u0026#39;reporter-option\u0026#39;: [ \u0026#39;reportDir=Report\u0026#39;, // 报告生成路径 \u0026#39;reportFilename=[status]_[datetime]-[name]-report\u0026#39;, //报告名称 \u0026#39;html=true\u0026#39;, // 生成 html 格式报告 \u0026#39;json=false\u0026#39;, // 不生成 json 格式报告 \u0026#39;overwrite=false\u0026#39;, // 不覆盖已经存在的报告 \u0026#39;timestamp=longDate\u0026#39;, // 给报告添加时间戳 ], // 传递给报告生成器的参数 spec: [\u0026#39;Specs/**/*.js\u0026#39;], // 指定测试文件的位置 }; 运行测试用例 // 运行测试用例 npm run test 查看测试报告 测试报告文件夹：Report，点击使用浏览器打开最新 html 报告文件\nJest 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n新建 Jest demo 项目文件夹 mkdir SuperTest-Jest-demo Jest demo 项目初始化 // 进入项目文件夹下 cd SuperTest-Mocha-demo // nodejs 项目初始化 npm init -y Jest demo 安装依赖 // 安装 supertest npm install supertest --save-dev // 安装 Jest测试框架 npm install jest --save-dev 新建 Jest demo 项目的测试文件及测试用例 // 新建测试文件夹 mkdir Specs // 新建测试用例文件 cd Specs touch test.spec.js 编写 Jest demo 测试用例 测试接口可参考项目中 demoAPI.md 文件\nconst request = require(\u0026#39;supertest\u0026#39;); // Test Suite describe(\u0026#39;Verify that the Get and POST API returns correctly\u0026#39;, () =\u0026gt; { // Test case 1 it(\u0026#39;Verify that the GET API returns correctly\u0026#39;, async () =\u0026gt; { const res = await request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .get(\u0026#39;/posts/1\u0026#39;) // API endpoint .send() // request body .expect(200); // use supertest\u0026#39;s expect to verify that the status code is 200 // user jest\u0026#39;s expect to verify the response body expect(res.status).toBe(200); // Verify that the status code is 200 expect(res.body.id).toEqual(1); // Verify that the id is 1 expect(res.body.userId).toEqual(1); // Verify that the userId is 1 expect(res.body.title) .toEqual(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;); expect(res.body.body) .toEqual(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;); }); // Test case 2 it(\u0026#39;Verify that the POST API returns correctly\u0026#39;, async() =\u0026gt;{ const res = await request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .post(\u0026#39;/posts\u0026#39;) // API endpoint .send({ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }) // request body .expect(201); // use supertest\u0026#39;s expect to verify that the status code is 201 // user jest\u0026#39;s expect to verify the response body expect(res.statusCode).toBe(201); expect(res.body.id).toEqual(101); expect(res.body.userId).toEqual(1); expect(res.body.title).toEqual(\u0026#34;foo\u0026#34;); expect(res.body.body).toEqual(\u0026#34;bar\u0026#34;); }); }); 配置 Jest 配置文件 新建配置文件 // 项目根目录下新建配置文件 touch jest.config.js 更新配置文件 // Desc: Jest configuration file module.exports = { // 测试文件的匹配规则 testMatch: [\u0026#39;**/Specs/*.spec.js\u0026#39;], }; 调整 Jest 测试脚本 在 package.json 文件中添加测试脚本\n\u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;jest\u0026#34; }, 运行 Jest 测试用例 // 运行测试用例 npm run test Jest 测试报告 Jest 命令行测试报告 集成 jest-html-reporters 测试报告 安装 jest-html-reporters npm install --save-dev jest-html-reporters 更新 Jest 配置文件 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n// Desc: Jest configuration file module.exports = { // 测试文件的匹配规则 testMatch: [\u0026#39;**/Specs/*.spec.js\u0026#39;], // 测试报告生成器 reporters: [ \u0026#39;default\u0026#39;, [ \u0026#39;jest-html-reporters\u0026#39;, { publicPath: \u0026#39;./Report\u0026#39;, // 报告生成路径 filename: \u0026#39;report.html\u0026#39;, // 报告名称 pageTitle: \u0026#39;SuperTest and Jest API Test Report\u0026#39;, // 报告标题 overwrite: true, // 报告文件是否覆盖 expand: true, // 展开所有测试套件 }, ], ], }; 运行 Jest 测试用例 // 运行测试用例 npm run test 查看测试报告 测试报告文件夹：Report，点击使用浏览器打开最新 html 报告文件\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-building-your-own-project-from-0-to-1/","summary":"从零开始教您如何建立 SuperTest 接口自动化测试项目。您将学习如何创建项目的基础结构，设置环境，编写测试用例，以及执行自动化测试。","title":"SuperTest 接口自动化测试教程：从 0 到 1 搭建 Supertest 接口自动化测试项目"},{"content":"介绍 本项目是一个使用 SuperTest 进行 API 自动化测试的快速启动项目教程，会使用 Jest 或 Mocha 作为测试框架进行 demo 演示。\n下面会依次介绍 SuperTest、Jest 和 Mocha，让大家提前了解这些工具的基本使用。\nSuperTest 介绍 \u0026ldquo;Supertest\u0026rdquo; 是一个用于测试 Node.js 应用程序的流行 JavaScript 库。它主要用于进行端到端（End-to-End）测试，也称为集成测试，以确保你的应用程序在不同组件之间正常运行。Supertest 通常与 Mocha、Jasmine 或 Jest 等测试框架一起使用，以编写和运行测试用例。\n以下是 Supertest 的一些关键特点和用途：\n发起 HTTP 请求：Supertest 允许你轻松地模拟 HTTP 请求，例如 GET、POST、PUT、DELETE 等，以测试你的应用程序的路由和端点。 链式语法：Supertest 提供了一种链式语法，使你能够在单个测试用例中构建和执行多个请求，这有助于模拟用户在应用程序中的不同操作。 断言和期望：你可以使用 Supertest 结合断言库（如 Chai）来检查响应的内容、状态码、头信息等，以确保应用程序的期望行为。 身份验证测试：Supertest 可以用于测试需要身份验证的端点，以确保用户登录和授权功能正常。 异步支持：Supertest 可以处理异步操作，例如等待响应返回后执行进一步的测试代码。 方便的集成：Supertest 可以轻松与不同的 Node.js 框架（如 Express、Koa、Hapi 等）一起使用，因此你可以测试各种类型的应用程序。 使用 Supertest 可以帮助你验证你的应用程序是否按预期工作，以及在应用程序发生更改时快速捕获潜在的问题。通常，你需要在项目中安装 Supertest 和测试框架，然后编写测试用例来模拟不同的请求和检查响应。这有助于提高代码质量和可维护性，确保你的应用程序在不断演化的过程中保持稳定性。\n官方文档：https://github.com/ladjs/supertest\n备注：Supertest 不止可以用来做 API 测试，也可以用来做单元测试和集成测试\n代码示例：\n// 导入 supertest const request = require(\u0026#39;supertest\u0026#39;); request({URL}) // 请求 (url) 或 请求 (app) .get() or .put() or.post() // http method .set() // http 选项 .send() // 请求的 body .expect() // 断言 .end() // 结束请求 Jest 介绍 Jest 是一个流行的 JavaScript 测试框架，用于编写和运行 JavaScript 应用程序的单元测试、集成测试和端到端测试。它的目标是提供简单、快速和易于使用的测试工具，适用于各种 JavaScript 应用程序，包括前端和后端应用程序。\n以下是 Jest 的一些关键特点和用途：\n内置断言库：Jest 包括一个强大的断言库，使你能够轻松地编写断言，以验证代码的行为是否符合预期。 自动模拟：Jest 自动创建模拟（mocks），帮助你模拟函数、模块和外部依赖，从而让测试更加简单和可控。 快速和并行：Jest 通过智能地选择要运行的测试以及并行执行测试，可以快速地运行大量测试用例，从而节省时间。 全面的测试套件：Jest 支持单元测试、集成测试和端到端测试，并可以测试 JavaScript、TypeScript、React、Vue、Node.js 等各种应用程序类型。 快照测试：Jest 具有快照测试功能，可用于检查 UI 组件的渲染是否与之前的快照匹配，从而捕获 UI 变化。 自动监视模式：Jest 具有一个监视模式，可在代码更改时自动重新运行相关测试，从而支持开发人员进行持续测试。 丰富的生态系统：Jest 有丰富的插件和扩展，可用于扩展其功能，如覆盖率报告、测试报告和其他工具的集成。 社区支持：Jest 是一个流行的测试框架，拥有庞大的社区，提供了大量的文档、教程和支持资源。 Jest 通常与其他工具如 Babel（用于转译 JavaScript）、Enzyme（用于 React 组件测试）、Supertest（用于 API 测试）等一起使用，以实现全面的测试覆盖和确保代码质量。无论你是在编写前端代码还是后端代码，Jest 都是一个强大的测试工具，可以帮助你捕获潜在的问题，提高代码质量和可维护性。\n官方文档：https://jestjs.io/docs/zh-Hans/getting-started\n代码示例：\n// 导入 jest const jest = require(\u0026#39;jest\u0026#39;); describe(): // 测试场景 it(): // 测试用例，it() 在 describe() 里面 before(): // 这个动作在所有测试用例之前执行 after(): // 这个动作在所有测试用例之后执行 Mocha 介绍 Mocha 是一个流行的 JavaScript 测试框架，用于编写和运行 JavaScript 应用程序的各种测试，包括单元测试、集成测试和端到端测试。Mocha 提供了灵活性和可扩展性，使开发人员能够轻松地定制测试套件以满足其项目的需求。\n以下是 Mocha 的一些关键特点和用途：\n多种测试风格：Mocha 支持多种测试风格，包括 BDD（行为驱动开发）和 TDD（测试驱动开发）。这使开发人员可以根据自己的偏好编写测试用例。 丰富的断言库：Mocha 本身并不包括断言库，但它可以与多种断言库（如 Chai、Should.js、Expect.js 等）结合使用，使你能够使用喜欢的断言风格来编写测试。 异步测试：Mocha 内置支持异步测试，允许你测试异步代码、Promise、回调函数等，确保代码在异步场景下的正确性。 并行测试：Mocha 可以并行运行测试套件中的测试用例，提高测试执行效率。 丰富的插件和扩展：Mocha 有丰富的插件生态系统，可以用于扩展其功能，如测试覆盖率报告、测试报告生成等。 易于集成：Mocha 可以与各种断言库、测试运行器（如 Karma 和 Jest）、浏览器（使用浏览器测试运行器）等一起使用，以适应不同的项目和测试需求。 命令行界面：Mocha 提供了一个易于使用的命令行界面，用于运行测试套件，生成报告以及其他测试相关操作。 持续集成支持：Mocha 可以轻松集成到持续集成（CI）工具中，如 Jenkins、Travis CI、CircleCI 等，以确保代码在每次提交后都能得到测试。 Mocha 的灵活性和可扩展性使其成为一个受欢迎的测试框架，适用于各种 JavaScript 项目，包括前端和后端应用程序。开发人员可以根据自己的需求和喜好选择测试工具、断言库和其他扩展，以满足项目的要求。无论你是在编写浏览器端代码还是服务器端代码，Mocha 都是一个强大的测试工具，可帮助你确保代码质量和可靠性。\n官方文档：https://mochajs.org/\n代码示例：\n// 导入 mocha const mocha = require(\u0026#39;mocha\u0026#39;); describe(): // 测试场景 it(): // 测试用例，it() 在 describe() 里面 before(): // 这个动作在所有测试用例之前执行 after(): // 这个动作在所有测试用例之后执行 CHAI 简介 Chai 是一个 JavaScript 断言库，用于编写和运行测试用例时进行断言和期望值的验证。它是一个流行的测试工具，通常与测试框架（如 Mocha、Jest 等）一起使用，以帮助开发者编写和执行各种类型的测试，包括单元测试和集成测试。\n以下是一些 Chai 的主要特点和用途：\n可读性强的断言语法：Chai 提供了一个易于阅读和编写的断言语法，使测试用例更易于理解。它支持自然语言的断言风格，例如 expect(foo).to.be.a(\u0026lsquo;string\u0026rsquo;) 或 expect(bar).to.equal(42)。 多种断言风格：Chai 提供了多种不同的断言风格，以适应不同开发者的偏好。主要的风格包括 BDD（Behavior-Driven Development）风格、TDD（Test-Driven Development）风格和 assert 风格。 插件扩展：Chai 可以通过插件进行扩展，以支持更多的断言类型和功能。这使得 Chai 可以满足各种测试需求，包括异步测试、HTTP 请求测试等。 易于集成：Chai 可以轻松集成到各种测试框架中，例如 Mocha、Jest、Jasmine 等。这使得它成为编写测试用例的强大工具。 支持链式断言：Chai 允许你对多个断言进行链式调用，以便更容易进行复杂的测试和验证。 官方文档：https://www.chaijs.com/\n代码示例：\n// 导入 chai const chai = require(\u0026#39;chai\u0026#39;); const expect = chai.expect; // demo 断言 .expect(\u0026lt;actual result\u0026gt;).to.{assert}(\u0026lt;expected result\u0026gt;) // 断言目标严格等于值 .expect(‘hello\u0026#39;).to.equal(\u0026#39;hello\u0026#39;); // 断言目标严格等于值 .expect({ foo: \u0026#39;bar\u0026#39; }).to.not.equal({ foo: \u0026#39;bar\u0026#39; }); // 断言目标值不严格等于值。 .expect(\u0026#39;foobar\u0026#39;).to.contain(\u0026#39;foo\u0026#39;); // 断言目标字符串包含给定的子字符串。 .expect(foo).to.exist; // 断言目标既不是 null 也不是未定义。 .expect(5).to.be.at.most(5); // 断言目标值小于或等于值。 项目依赖 需提前安装好以下环境\nnodejs, demo 版本为 v21.1.0 项目文件结构 以下是一个 SuperTest 接口自动化测试项目的文件结构，其中包含了测试配置文件、测试用例文件、测试工具文件和测试报告文件。可进行参考。\nSuperTest-Jest-demo ├── README.md ├── package.json ├── package-lock.json ├── Config // 测试配置文件 │ └── config.js ├── Specs // 测试用例文件 │ └── test.spec.js ├── Utils // 测试工具文件 │ └── utils.js ├── Report // 测试报告文件 │ └── report.html ├── .gitignore └── node_modules // 项目依赖 Next 下一篇文章将会介绍如何使用 Supertest 从 0 到 1 搭建 SuperTest 接口自动化测试项目，敬请期待。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/supertest-tutorial-getting-started-and-own-environment-preparation/","summary":"关于 Supertest 的教程，主要包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 Supertest 以及如何开始使用它来进行 API 测试。","title":"SuperTest 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nGradle 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gradle.yml。\n编辑 gradle.yml 文件：将以下内容复制到文件中\nname: Gradle and REST Assured Tests on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v3 - name: Setup Java uses: actions/setup-java@v3 with: java-version: \u0026#39;11\u0026#39; distribution: \u0026#39;adopt\u0026#39; - name: Build and Run REST Assured Tests with Gradle uses: gradle/gradle-build-action@bd5760595778326ba7f1441bcf7e88b49de61a25 # v2.6.0 with: arguments: build - name: Archive REST-Assured results uses: actions/upload-artifact@v2 with: name: REST-Assured-results path: build/reports/tests/test - name: Upload REST-Assured results to GitHub uses: actions/upload-artifact@v2 with: name: REST-Assured-results path: build/reports/tests/test 提交代码：将 gradle.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Gradle and REST Assured Tests 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Maven 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 maven.yml。\n编辑 maven.yml 文件：将以下内容复制到文件中\nname: Maven and REST Assured Tests on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: Run-Rest-Assured-Tests: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up JDK 17 uses: actions/setup-java@v3 with: java-version: \u0026#39;17\u0026#39; distribution: \u0026#39;temurin\u0026#39; cache: maven - name: Build and Run REST Assured Tests with Maven run: mvn test - name: Archive REST-Assured results uses: actions/upload-artifact@v3 with: name: REST-Assured-results path: target/surefire-reports - name: Upload REST-Assured results to GitHub uses: actions/upload-artifact@v3 with: name: REST-Assured-results path: target/surefire-reports 提交代码：将 maven.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Maven and REST Assured Tests 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 集成 allure 测试报告 allure 简介 Allure是一个用于生成漂亮、交互式测试报告的开源测试框架。它可以与多种测试框架（如JUnit、TestNG、Cucumber等）和多种编程语言（如Java、Python、C#等）一起使用。\nAllure 测试报告具有以下特点：\n美观和交互式：Allure 测试报告以美观和交互式的方式呈现测试结果，包括图形、图表和动画。这使得测试报告更容易阅读和理解。 多语言支持：Allure 支持多种编程语言，因此您可以在不同的语言中编写测试，并生成统一的测试报告。 测试用例级别的详细信息：Allure 允许您为每个测试用例添加详细信息，包括描述、类别、标签、附件、历史数据等。这些信息有助于更全面地了解测试结果。 历史趋势分析：Allure 支持测试历史趋势分析，您可以查看测试用例的历史表现，识别问题和改进测试质量。 类别和标签：您可以为测试用例添加类别和标签，以更好地组织和分类测试用例。这使得报告更具可读性。 附件和截图：Allure 允许您附加文件、截图和其他附件，以便更好地记录测试过程中的信息。 集成性：Allure 可以与各种测试框架和构建工具（如 Maven、Gradle）无缝集成，使得生成报告变得简单。 开源社区支持：Allure 是一个开源项目，拥有一个活跃的社区，提供了广泛的文档和支持。这使得它成为许多自动化测试团队的首选工具。 Allure 测试报告的主要目标是提供一个清晰、易于阅读的方式来展示测试结果，以帮助开发团队更好地理解测试的状态和质量，快速识别问题，并采取必要的行动。无论您是开发人员、测试人员还是项目经理，Allure 测试报告都能为您提供有用的信息，以改进软件质量和可靠性。\n官方网站：https://docs.qameta.io/allure/\n集成步骤 Maven 版本集成 allure 在 POM.xml 中添加 allure 依赖 可 copy 本项目中的 pom.xml 文件内容\n\u0026lt;!-- https://mvnrepository.com/artifact/io.qameta.allure/allure-testng --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-testng\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.24.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/io.qameta.allure/allure-rest-assured --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.24.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在 POM.xml 中添加 allure 插件 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-maven\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;resultsDirectory\u0026gt;../allure-results\u0026lt;/resultsDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 在 src/test/java 下创建用于测试 REST API 的测试代码 以下为 demo 示例，详细部分可参考 项目：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\npackage com.example; import io.qameta.allure.*; import io.qameta.allure.restassured.AllureRestAssured; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; @Epic(\u0026#34;REST API Regression Testing using TestNG\u0026#34;) @Feature(\u0026#34;Verify that the Get and POST API returns correctly\u0026#34;) public class TestDemo { @Test(description = \u0026#34;To get the details of post with id 1\u0026#34;, priority = 1) @Story(\u0026#34;GET Request with Valid post id\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the GET API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;To create a new post\u0026#34;, priority = 2) @Story(\u0026#34;POST Request\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 运行测试并生成 Allure 报告 mvn clean test 生成的 Allure 报告在项目根目录的 allure-results 文件下\n预览 Allure 报告 mvn allure:serve 运行命令会自动打开浏览器，预览 Allure 报告\nGradle 版本集成 allure 在 build.gradle 中添加 allure 插件 可 copy 本项目中的 build.gradle 文件内容\nid(\u0026#34;io.qameta.allure\u0026#34;) version \u0026#34;2.11.2\u0026#34; 在 build.gradle 中添加 allure 依赖 可 copy 本项目中的 build.gradle 文件内容\nimplementation \u0026#39;io.qameta.allure:allure-testng:2.24.0\u0026#39; // Add allure report dependency implementation \u0026#39;io.qameta.allure:allure-rest-assured:2.24.0\u0026#39; // Add allure report dependency 在 src/test/java 下创建用于测试 REST API 的测试代码 以下为 demo 示例，详细部分可参考 项目：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\npackage com.example; import io.qameta.allure.*; import io.qameta.allure.restassured.AllureRestAssured; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; @Epic(\u0026#34;REST API Regression Testing using TestNG\u0026#34;) @Feature(\u0026#34;Verify that the Get and POST API returns correctly\u0026#34;) public class TestDemo { @Test(description = \u0026#34;To get the details of post with id 1\u0026#34;, priority = 1) @Story(\u0026#34;GET Request with Valid post id\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the GET API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;To create a new post\u0026#34;, priority = 2) @Story(\u0026#34;POST Request\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 运行测试并生成 Allure 报告 gradle clean test 生成的 Allure 报告在项目根目录的 build/allure-results 文件下\n预览 Allure 报告 gradle allureServe 运行命令会自动打开浏览器，预览 Allure 报告\n参考资料 Rest assured 官方文档：https://rest-assured.io/\nRest assured 官方 github：https://github.com/rest-assured/rest-assured\nRest assured 官方文档中文翻译：https://github.com/RookieTester/rest-assured-doc\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-integration-ci-cd-and-allure-report/","summary":"深入研究 REST Assured 的高级应用，侧重于如何集成 CI/CD（持续集成/持续交付）工具和整合 Allure 测试报告。","title":"REST Assured 接口自动化测试教程：进阶用法 - 集成 CI/CD 和集成 allure 测试报告"},{"content":"进阶用法 验证响应数据 您还可以验证状态码，状态行，Cookie，headers，内容类型和正文。\n响应体断言 json 格式断言 假设某个 get 请求 (http://localhost:8080/lotto) 返回 JSON 如下：\n{ \u0026#34;lotto\u0026#34;:{ \u0026#34;lottoId\u0026#34;:5, \u0026#34;winning-numbers\u0026#34;:[2,45,34,23,7,5,3], \u0026#34;winners\u0026#34;:[{ \u0026#34;winnerId\u0026#34;:23, \u0026#34;numbers\u0026#34;:[2,45,34,23,3,5] },{ \u0026#34;winnerId\u0026#34;:54, \u0026#34;numbers\u0026#34;:[52,3,12,11,18,22] }] } } REST assured 可以帮您轻松地进行 get 请求并对响应信息进行处理。\n断言 lottoId 的值是否等于 5，示例： get(\u0026#34;/lotto\u0026#34;).then().body(\u0026#34;lotto.lottoId\u0026#34;, equalTo(5)); 断言 winnerId 的取值包括 23 和 54，示例： get(\u0026#34;/lotto\u0026#34;).then().body(\u0026#34;lotto.winners.winnerId\u0026#34;, hasItems(23, 54)); 提醒一下：equalTo 和 hasItems是 Hamcrest matchers 提供的方法，所以需要静态导入入 org.hamcrest.Matchers。\nxml 格式断言 XML 可以一种通过简单的方式解析。假设一个 POST 请求http://localhost:8080/greetXML返回：\n\u0026lt;greeting\u0026gt; \u0026lt;firstName\u0026gt;{params(\u0026#34;firstName\u0026#34;)}\u0026lt;/firstName\u0026gt; \u0026lt;lastName\u0026gt;{params(\u0026#34;lastName\u0026#34;)}\u0026lt;/lastName\u0026gt; \u0026lt;/greeting\u0026gt; 断言 firstName 是否返回正确，示例： given(). parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;). when(). post(\u0026#34;/greetXML\u0026#34;). then(). body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;)). 同时断言 firstname 和 lastname 是否返回正确，示例： given(). parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;). when(). post(\u0026#34;/greetXML\u0026#34;). then(). body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;)). body(\u0026#34;greeting.lastName\u0026#34;, equalTo(\u0026#34;Doe\u0026#34;)); with().parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;) .when().post(\u0026#34;/greetXML\u0026#34;) .then().body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;), \u0026#34;greeting.lastName\u0026#34;, equalTo(\u0026#34;Doe\u0026#34;)); Cookie 断言 断言 cookie 的值是否等于 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().cookie(\u0026#34;cookieName\u0026#34;, \u0026#34;cookieValue\u0026#34;) 同时断言 多个 cookie 的值是否等于 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().cookies(\u0026#34;cookieName1\u0026#34;, \u0026#34;cookieValue1\u0026#34;, \u0026#34;cookieName2\u0026#34;, \u0026#34;cookieValue2\u0026#34;) 断言 cookie 的值是否包含 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().cookies(\u0026#34;cookieName1\u0026#34;, \u0026#34;cookieValue1\u0026#34;, \u0026#34;cookieName2\u0026#34;, containsString(\u0026#34;Value2\u0026#34;)) 状态码 Status Code 断言 断言 状态码是否等于 200，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusCode(200) 断言 状态行是否为 something，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusLine(\u0026#34;something\u0026#34;) 断言 状态行是否包含 some，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusLine(containsString(\u0026#34;some\u0026#34;)) Header 断言 断言 Header 的值是否等于 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().header(\u0026#34;headerName\u0026#34;, \u0026#34;headerValue\u0026#34;) 同时断言 多个 Header 的值是否等于 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().headers(\u0026#34;headerName1\u0026#34;, \u0026#34;headerValue1\u0026#34;, \u0026#34;headerName2\u0026#34;, \u0026#34;headerValue2\u0026#34;) 断言 Header 的值是否包含 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().headers(\u0026#34;headerName1\u0026#34;, \u0026#34;headerValue1\u0026#34;, \u0026#34;headerName2\u0026#34;, containsString(\u0026#34;Value2\u0026#34;)) 断言 Header 的“Content-Length”小于 1000，示例： 可以先使用映射函数首先将头值转换为 int，然后在使用 Hamcrest 验证前使用“整数”匹配器进行断言：\nget(\u0026#34;/something\u0026#34;).then() .assertThat().header(\u0026#34;Content-Length\u0026#34;, Integer::parseInt, lessThan(1000)); Content-Type 断言 断言 Content-Type 的值是否等于 application/json，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().contentType(ContentType.JSON) 内容全匹配断言 断言 响应体是否完全等于 something，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().body(equalTo(\u0026#34;something\u0026#34;)) 响应时间断言 REST Assured 2.8.0 开始支持测量响应时间，例如：\nlong timeInMs = get(\u0026#34;/lotto\u0026#34;).time() 或使用特定时间单位：\nlong timeInSeconds = get(\u0026#34;/lotto\u0026#34;).timeIn(SECONDS); 其中 SECONDS 只是一个标准的 TimeUnit。您还可以使用 DSL 验证：\nwhen(). get(\u0026#34;/lotto\u0026#34;). then(). time(lessThan(2000L)); // Milliseconds 或\nwhen(). get(\u0026#34;/lotto\u0026#34;). then(). time(lessThan(2L), SECONDS); 需要注意的是，您只能参考性地将这些测量数据与服务器请求处理时间相关联（因为响应时间将包括 HTTP 往返和 REST Assured 处理时间等，不能做到十分准确）。\n文件上传 通常我们在向服务器传输大容量的数据时，比如文件时会使用 multipart 表单数据技术。 rest-assured 提供了一种multiPart方法来辨别这究竟是文件、二进制序列、输入流还是上传的文本。\n表单中上只传一个文件，示例： given(). multiPart(new File(\u0026#34;/path/to/file\u0026#34;)). when(). post(\u0026#34;/upload\u0026#34;); 存在 control 名的情况下上传文件，示例： given(). multiPart(\u0026#34;controlName\u0026#34;, new File(\u0026#34;/path/to/file\u0026#34;)). when(). post(\u0026#34;/upload\u0026#34;); 同一个请求中存在多个\u0026quot;multi-parts\u0026quot;事务，示例： byte[] someData = .. given(). multiPart(\u0026#34;controlName1\u0026#34;, new File(\u0026#34;/path/to/file\u0026#34;)). multiPart(\u0026#34;controlName2\u0026#34;, \u0026#34;my_file_name.txt\u0026#34;, someData). multiPart(\u0026#34;controlName3\u0026#34;, someJavaObject, \u0026#34;application/json\u0026#34;). when(). post(\u0026#34;/upload\u0026#34;); MultiPartSpecBuilder 用法，示例： 更多使用方法可以使用MultiPartSpecBuilder：\nGreeting greeting = new Greeting(); greeting.setFirstName(\u0026#34;John\u0026#34;); greeting.setLastName(\u0026#34;Doe\u0026#34;); given(). multiPart(new MultiPartSpecBuilder(greeting, ObjectMapperType.JACKSON_2) .fileName(\u0026#34;greeting.json\u0026#34;) .controlName(\u0026#34;text\u0026#34;) .mimeType(\u0026#34;application/vnd.custom+json\u0026#34;).build()). when(). post(\u0026#34;/multipart/json\u0026#34;). then(). statusCode(200); MultiPartConfig 用法，示例： MultiPartConfig可用来指定默认的 control 名和文件名\ngiven().config(config().multiPartConfig(multiPartConfig() .defaultControlName(\u0026#34;something-else\u0026#34;))) 默认把 control 名配置为\u0026quot;something-else\u0026quot;而不是\u0026quot;file\u0026quot;。 更多用法查看 博客介绍\nLogging 日志 当我们在编写接口测试脚本的时候，我们可能需要在测试过程中打印一些日志，以便于我们在测试过程中查看接口的请求和响应信息，以及一些其他的信息。RestAssured 提供了一些方法来打印日志，我们可以根据需要选择合适的方法来打印日志。\nRestAssured 提供了一个全局的日志配置方法，可以在测试开始前配置日志，然后在测试过程中打印日志。这种方法适用于所有的测试用例，但是它只能打印请求和响应的信息，不能打印其他的信息。\nRestAssured 还提供了一个局部的日志配置方法，可以在测试过程中打印日志。这种方法可以打印请求和响应的信息，也可以打印其他的信息。\n全局日志配置 添加全局日志步骤 引入日志相关的依赖类 import io.restassured.config.LogConfig; import io.restassured.filter.log.LogDetail; import io.restassured.filter.log.RequestLoggingFilter; import io.restassured.filter.log.ResponseLoggingFilter; 在 setup() 方法中添加日志配置 使用 LogConfig 配置，启用了请求和响应的日志记录，以及启用了漂亮的输出格式。启用了请求和响应的日志记录过滤器，这将记录请求和响应的详细信息。\n// 启用全局请求和响应日志记录 RestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); 在 setup() 方法中启用了全局日志记录过滤器 // 启用全局请求和响应日志记录过滤器 RestAssured.filters(new RequestLoggingFilter(), new ResponseLoggingFilter()); 全局日志代码示例 package com.example; import io.restassured.RestAssured; // 引入日志相关的类 import io.restassured.config.LogConfig; import io.restassured.filter.log.LogDetail; import io.restassured.filter.log.RequestLoggingFilter; import io.restassured.filter.log.ResponseLoggingFilter; import org.testng.annotations.BeforeClass; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @BeforeClass public void setup() { // 启用全局请求和响应日志记录 RestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); // 启用全局请求和响应日志记录过滤器 RestAssured.filters(new RequestLoggingFilter(), new ResponseLoggingFilter()); } @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // 测试用例已省略，可参考 demo } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // 测试用例已省略，可参考 demo } } 查看全局日志输出 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 查看日志输出 局部日志配置 在 RestAssured 中，你可以进行局部日志配置，以便在特定的测试方法或请求中启用或禁用日志记录，而不影响全局配置。\n添加日志步骤 在想要打印日志的测试方法中启用了添加日志配置，示例： @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .log().everything(true) // 输出 request 相关日志 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .log().everything(true) // 输出 response 相关日志 .statusCode(200) } 查看局部日志输出 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 查看日志输出 LogConfig 配置说明 在 RestAssured 中，你可以使用 LogConfig 类来配置请求和响应的日志记录。LogConfig 允许你定义日志详细程度、输出格式、输出位置等。以下是一些常见的 LogConfig 配置示例：\n启用请求和响应的日志记录：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL)); 这将启用请求和响应的日志记录，只有当验证失败时才记录。\n配置输出级别：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.HEADERS)); 这将只记录请求和响应的头部信息。\n配置输出位置：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true) .defaultStream(FileOutputStream(\u0026#34;log.txt\u0026#34;))); 这将日志记录输出到名为 \u0026ldquo;log.txt\u0026rdquo; 的文件。\n配置漂亮的输出格式：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); 这将启用漂亮的输出格式，使日志更易于阅读。\n你可以根据你的具体需求组合这些配置选项，并将其设置为 RestAssured.config 以配置全局的请求和响应日志记录。这将有助于在 RestAssured 中记录和审查请求和响应，以便调试和分析问题。\nRequest Logging 请求日志记录 从版本 1.5 开始，REST Assured 支持在使用 RequestLoggingFilter 将请求规范发送到服务器之前记录请求规范。请注意，HTTP Builder 和 HTTP Client 可能会添加日志中打印的内容之外的其他标头。筛选器将仅记录请求规范中指定的详细信息。也就是说，您不能将 RequestLoggingFilter 记录的详细信息视为实际发送到服务器的详细信息。此外，后续筛选器可能会在日志记录发生后更改请求。如果您需要记录网络上实际发送的内容，请参阅 HTTP 客户端日志记录文档或使用外部工具，例如 Wireshark。\n示例：\ngiven().log().all() // 记录所有请求规范细节，包括参数、标头和正文 given().log().params() // 只记录请求的参数 given().log().body() // 只记录请求正文 given().log().headers() // 只记录请求头 given().log().cookies() // 只记录请求 cookies given().log().method() // 只记录请求方法 given().log().path() // 只记录请求路径 Response Logging 响应日志记录 只想要打印响应正文，而不考虑状态代码，可以执行以下操作， 示例： get(\u0026#34;/x\u0026#34;).then().log().body() 不管是否发生错误，都将打印响应正文。如果只对在发生错误时打印响应正文感兴趣，示例： get(\u0026#34;/x\u0026#34;).then().log().ifError() 在响应中记录所有详细信息，包括状态行、标头和 Cookie，示例： get(\u0026#34;/x\u0026#34;).then().log().all() 在响应中记录只记录状态行、标题或 Cookie，示例： get(\u0026#34;/x\u0026#34;).then().log().statusLine() // 只记录状态行 get(\u0026#34;/x\u0026#34;).then().log().headers() // 只记录响应头 get(\u0026#34;/x\u0026#34;).then().log().cookies() // 只记录响应 cookies 配置为仅当状态代码与某个值匹配时才记录响应，示例： get(\u0026#34;/x\u0026#34;).then().log().ifStatusCodeIsEqualTo(302) // 仅在状态代码等于 302 时记录日志 get(\u0026#34;/x\u0026#34;).then().log().ifStatusCodeMatches(matcher) // 仅在状态代码与提供的配置匹配时才记录日志 只在验证失败时记录日志 从 REST Assured 2.3.1 开始，只有在验证失败时才能记录请求或响应。要记录请求日志，示例： given().log().ifValidationFails() 要记录响应日志，示例： then().log().ifValidationFails() 可以使用 LogConfig 同时为请求和响应启用此功能，示例： given().config(RestAssured.config().logConfig(logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(HEADERS))) 如果验证失败，日志仅记录请求头。\n另外一个快捷方式，用于在验证失败时为所有请求启用请求和响应的日志记录，示例： RestAssured.enableLoggingOfRequestAndResponseIfValidationFails(); 从版本 4.5.0 开始，您还可以使用 指定 onFailMessage 测试失败时将显示的消息，示例： when(). get(). then(). onFailMessage(\u0026#34;Some specific message\u0026#34;). statusCode(200); Header 黑名单配置 从 REST Assured 4.2.0 开始，可以将标头列入黑名单，以便它们不会显示在请求或响应日志中。相反，标头值将替换为 [ BLACKLISTED ] .您可以使用 LogConfig 启用此基于每个标头的功能，示例：\ngiven().config(config().logConfig(logConfig().blacklistHeader(\u0026#34;Accept\u0026#34;))) Filters 过滤器 在 RestAssured 中，你可以使用过滤器来修改请求和响应。过滤器允许你在请求和响应的不同阶段修改请求和响应。例如，你可以在请求之前修改请求，或者在响应之后修改响应。你可以使用过滤器来添加请求头、请求参数、请求体、响应头、响应体等。\n过滤器可用于实现自定义身份验证方案、会话管理、日志记录等。若要创建筛选器，需要实现 io.restassured.filter.Filter 接口。要使用过滤器，您可以执行以下操作：\ngiven().filter(new MyFilter()) REST Assured 提供了几个可供使用的过滤器：\nio.restassured.filter.log.RequestLoggingFilter ：将打印请求规范详细信息的筛选器。 io.restassured.filter.log.ResponseLoggingFilter ：如果响应与给定状态代码匹配，则将打印响应详细信息的筛选器。 io.restassured.filter.log.ErrorLoggingFilter ：在发生错误时打印响应正文的筛选器（状态代码介于 400 和 500 之间）。 Ordered Filters 有序过滤器 从 REST Assured 3.0.2 开始，如果需要控制筛选器排序，可以实现 io.restassured.filter.OrderedFilter 接口。在这里，您将实现返回一个整数的方法，getOrder 该整数表示筛选器的优先级。值越低，优先级越高。您可以定义的最高优先级是 Integer.MIN_VALUE，最低优先级是 Integer.MAX_VALUE。未实现 io.restassured.filter.OrderedFilter 的过滤器的默认优先级为 1000。\n示例\nResponse Builder 响应生成器 如果需要更改筛选器中的响应内容，可以使用 ResponseBuilder 基于原始响应创建新的响应。例如，如果要将原始响应的正文更改为其他内容，可以执行以下操作：\nResponse newResponse = new ResponseBuilder() .clone(originalResponse).setBody(\u0026#34;Something\u0026#34;).build(); 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-verifying-response-and-logging/","summary":"深入介绍 REST Assured 的进阶用法，重点放在验证 API 响应、日志记录和过滤器的应用上。","title":"REST Assured 接口自动化测试教程：进阶用法 - 验证响应和日志记录，过滤器，文件上传"},{"content":"从 0 到 1 搭建 REST Assured 接口测试项目 REST Assured 支持 Gradle 和 Maven 两种构建工具，你可以根据自己的喜好选择其中一种。下面分别介绍 Gradle 和 Maven 两种构建工具的项目初始化过程。\n本项目使用 Gradle 8.44 和 Maven 3.9.5 进行构建，如果你使用的是其他版本，可能会有不同。\nGradle 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\n创建一个空的 Gradle 工程 mkdir RestAssured-gradle-demo cd RestAssured-gradle-demo gradle init 配置项目 build.gradle demo 项目引入了 testNG 测试框架，仅供参考\n在项目根目录下创建一个 build.gradle 文件，用于配置项目 示例配置如下，可供参考 // 插件配置 plugins { id \u0026#39;java\u0026#39; // 使用 java 插件 } // 仓库资源配置 repositories { mavenCentral() // 使用 maven中央版本库源 } // 项目依赖配置 dependencies { testImplementation \u0026#39;io.rest-assured:rest-assured:5.3.1\u0026#39; // 添加rest-assured依赖 testImplementation \u0026#39;org.testng:testng:7.8.0\u0026#39; // 添加TestNG测试框架依赖 implementation \u0026#39;org.uncommons:reportng:1.1.4\u0026#39; // 添加testng 测试报告依赖 implementation \u0026#39;org.slf4j:slf4j-api:2.0.9\u0026#39; // 添加测试日志依赖 implementation \u0026#39;org.slf4j:slf4j-simple:2.0.9\u0026#39; // 添加测试日志依赖 implementation group: \u0026#39;com.google.inject\u0026#39;, name: \u0026#39;guice\u0026#39;, version: \u0026#39;7.0.0\u0026#39; } // 项目测试配置 test { reports.html.required = false // 禁用 gradle 原生HTML 报告生成 reports.junitXml.required = false // 禁用 gradle 原生 JUnit XML 报告生成 // 告诉 Gradle 使用 TestNG 作为测试框架 useTestNG() { useDefaultListeners = true suites \u0026#39;src/test/resources/testng.xml\u0026#39; // 声明 testng 的 xml 配置文件路径 } testLogging.showStandardStreams = true // 将测试日志输出到控制台 testLogging.events \u0026#34;passed\u0026#34;, \u0026#34;skipped\u0026#34;, \u0026#34;failed\u0026#34; // 定义测试日志事件类型 } 可 copy 本项目中的 build.gradle 文件内容，更多配置可参考官方文档\ntestng.xml 配置 在 src/test目录下创建一个 resources 目录，用于存放测试配置文件\n在 resources 目录下创建一个 testng.xml 文件，用于配置 TestNG 测试框架\n示例配置如下，可供参考\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE suite SYSTEM \u0026#34;http://testng.org/testng-1.0.dtd\u0026#34;\u0026gt; \u0026lt;suite name=\u0026#34;restAssured-gradleTestSuite\u0026#34;\u0026gt; \u0026lt;test thread-count=\u0026#34;1\u0026#34; name=\u0026#34;Demo\u0026#34;\u0026gt; \u0026lt;classes\u0026gt; \u0026lt;class name=\u0026#34;com.example.TestDemo\u0026#34;/\u0026gt; \u0026lt;!-- 测试脚本 class--\u0026gt; \u0026lt;/classes\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- Test --\u0026gt; \u0026lt;/suite\u0026gt; \u0026lt;!-- Suite --\u0026gt; gradle build 项目并初始化 用编辑器打开本项目 Terminal 窗口，执行以下命令确认项目 build 成功 gradle build 初始化完成：完成向导后，Gradle 将在项目目录中生成一个基本的 Gradle 项目结构 初始化目录 目录结构可参考 \u0026raquo; 项目结构\n在项目的测试源目录下创建一个新的测试类。默认情况下，Gradle 通常将测试源代码放在 src/test/java 目录中。你可以在该目录下创建测试类的包，并在包中创建新的测试类\n创建一个 TestDemo 的测试类，可以按以下结构创建文件\nsrc └── test └── java └── com └── example └── TestDemo.java demo 测试接口 Get 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts/1 请求方式：GET 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：无 返回状态码：200 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; } Post 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts 请求方式：POST 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：raw json 格式 body 内容如下： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 返回状态码：201 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } 编写脚本 打开 TestDemo.java 文件，开始编写测试脚本\n示例脚本如下，可供参考\npackage com.example; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 调试脚本 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 gradle test 查看测试报告 命令行报告 testng html 报告 打开项目 build/reports/tests/test 目录 点击 index.html 文件，查看测试报告 Maven 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\n创建一个空的 Maven 工程 mvn archetype:generate -DgroupId=com.example -DartifactId=RestAssured-maven-demo -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 初始化完成：完成向导后，Maven 将在新建项目目录并生成一个基本的 Maven 项目结构\n配置项目 pom.xml 在 项目中 pom.xml 文件中添加以下内容\n可 copy 本项目中的 pom.xml 文件内容，更多配置可参考官方文档\n\u0026lt;!-- 依赖配置 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/io.rest-assured/rest-assured --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.rest-assured\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.testng/testng --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.testng\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;testng\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.8.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 插件配置 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;suiteXmlFiles\u0026gt; \u0026lt;suiteXmlFile\u0026gt;src/test/resources/testng.xml\u0026lt;/suiteXmlFile\u0026gt; \u0026lt;/suiteXmlFiles\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; testng.xml 配置 在 src/test目录下创建一个 resources 目录，用于存放测试配置文件\n在 resources 目录下创建一个 testng.xml 文件，用于配置 TestNG 测试框架\n示例配置如下，可供参考\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE suite SYSTEM \u0026#34;http://testng.org/testng-1.0.dtd\u0026#34;\u0026gt; \u0026lt;suite name=\u0026#34;restAssured-gradleTestSuite\u0026#34;\u0026gt; \u0026lt;test thread-count=\u0026#34;1\u0026#34; name=\u0026#34;Demo\u0026#34;\u0026gt; \u0026lt;classes\u0026gt; \u0026lt;class name=\u0026#34;com.example.TestDemo\u0026#34;/\u0026gt; \u0026lt;!-- 测试脚本 class--\u0026gt; \u0026lt;/classes\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- Test --\u0026gt; \u0026lt;/suite\u0026gt; \u0026lt;!-- Suite --\u0026gt; 初始化目录 目录结构可参考 \u0026raquo; 项目结构\n在项目的测试源目录下创建一个新的测试类。默认情况下，Gradle 通常将测试源代码放在 src/test/java 目录中。你可以在该目录下创建测试类的包，并在包中创建新的测试类\n创建一个 TestDemo 的测试类，可以按以下结构创建文件\nsrc └── test └── java └── com └── example └── TestDemo.java demo 测试接口 Get 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts/1 请求方式：GET 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：无 返回状态码：200 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; } Post 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts 请求方式：POST 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：raw json 格式 body 内容如下： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 返回状态码：201 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } 编写脚本 打开 TestDemo.java 文件，开始编写测试脚本\n示例脚本如下，可供参考\npackage com.example; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 调试脚本 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 mvn test 查看测试报告 命令行报告 testng html 报告 打开项目 target/surefire-reports 目录 点击 index.html 文件，查看测试报告 更多信息 访问我的个人博客：https://naodeng.tech/ 我的 QA 自动化快速启动项目页面：https://github.com/Automation-Test-Starter 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-building-your-own-project-from-0-to-1/","summary":"深入探讨如何从零开始构建一个 REST Assured 接口自动化测试项目。","title":"REST Assured 接口自动化测试教程：从 0 到 1 搭建 REST Assured 接口自动化测试项目"},{"content":"RestAssured 介绍 REST Assured 是一种用于测试 RESTful API 的 Java 测试框架，它使开发人员/测试人员能够轻松地编写和执行 API 测试。它的设计旨在使 API 测试变得简单和直观，同时提供了丰富的功能和灵活性。以下是 REST Assured 的一些重要特点和用法：\n发起 HTTP 请求：REST Assured 允许你轻松地构建和发起 HTTP GET、POST、PUT、DELETE 等类型的请求。你可以指定请求的 URL、头部、参数、体等信息。\n链式语法：REST Assured 使用链式语法，使测试代码更加可读和易于编写。你可以按照一种自然的方式描述你的测试用例，而不需要编写大量的代码。\n断言和校验：REST Assured 提供了丰富的校验方法，可以用于验证 API 响应的状态码、响应体、响应头等。你可以根据你的测试需求添加多个断言。\n支持多种数据格式：REST Assured 支持多种数据格式，包括 JSON、XML、HTML、Text 等。你可以使用适当的方法来处理不同格式的响应数据。\n集成 BDD（行为驱动开发）：REST Assured 可以与 BDD 框架（如 Cucumber）结合使用，使你可以更好地描述和管理测试用例。\n模拟 HTTP 服务器：REST Assured 还包括一个模拟 HTTP 服务器的功能，允许你模拟 API 的行为以进行端到端测试。\n可扩展性：REST Assured 可以通过插件和扩展进行定制，以满足特定的测试需求。\n总的来说，REST Assured 是一个功能强大且易于使用的 API 测试框架，它可以帮助你轻松地进行 RESTful API 测试，并提供了许多工具来验证 API 的正确性和性能。无论是初学者还是有经验的开发人员/测试人员，REST Assured 都是一个非常有价值的工具，可用于快速的上手 API 自动化 测试。\n项目结构 Gradle 构建的版本 - src - main - java - (应用的主要源代码) - test - java - api - (REST Assured 测试代码) - UsersAPITest.java - ProductsAPITest.java - util - TestConfig.java - resources - (配置文件、测试数据等) - (其他项目文件和资源) - build.gradle (Gradle 项目配置文件) 在这个示例目录结构中：\nsrc/test/java/api 目录用于存放 REST Assured 的测试类，每个测试类通常涉及到一个或多个相关的 API 端点的测试。例如，UsersAPITest.java 和 ProductsAPITest.java 可以包含用户管理和产品管理的测试。 src/test/java/util 目录可用于存放测试中共享的工具类，例如用于配置 REST Assured 的 TestConfig.java。 src/test/resources 目录可以包含测试数据文件、配置文件等资源，这些资源可以在测试中使用。 build.gradle 是 gradle 项目的配置文件，它用于定义项目的依赖项、构建配置以及其他项目设置。 Maven 构建的版本 - src - main - java - (应用的主要源代码) - test - java - api - (REST Assured 测试代码) - UsersAPITest.java - ProductsAPITest.java - util - TestConfig.java - resources - (配置文件、测试数据等) - (其他项目文件和资源) - pom.xml (Maven 项目配置文件) 在这个示例目录结构中：\nsrc/test/java/api 目录用于存放 REST Assured 的测试类，每个测试类通常涉及到一个或多个相关的 API 端点的测试。例如，UsersAPITest.java 和 ProductsAPITest.java 可以包含用户管理和产品管理的测试。 src/test/java/util 目录可用于存放测试中共享的工具类，例如用于配置 REST Assured 的 TestConfig.java。 src/test/resources 目录可以包含测试数据文件、配置文件等资源，这些资源可以在测试中使用。 pom.xml 是 Maven 项目的配置文件，它用于定义项目的依赖项、构建配置以及其他项目设置。 项目依赖 JDK 1.8+ ，我使用的 JDK 19 Gradle 6.0+ 或 Maven 3.0+，我使用的 Gradle 8.44 和 Maven 3.9.5 RestAssured 4.3.3+，我使用的是最新的 5.3.1 版本 语法示例 以下是一个简单的 RestAssured 语法示例，演示如何执行一个 GET 请求并验证响应：\n首先，确保你的 Gradle 或 Maven 项目中已添加了 RestAssured 依赖。\nGradle 依赖：\ndependencies { implementation \u0026#39;io.rest-assured:rest-assured:5.3.1\u0026#39; } Maven 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.rest-assured\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接下来，创建一个测试类，编写以下代码：\nimport io.restassured.RestAssured; import io.restassured.response.Response; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class RestAssuredDemo { @Test public void testGetRequest() { // 设置基本 URI，这里以 JSONPlaceholder 为例 RestAssured.baseURI = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;; // 发送 GET 请求，并保存响应 Response response = given() .when() .get(\u0026#34;/posts/1\u0026#34;) .then() .extract() .response(); // 打印响应的 JSON 内容 System.out.println(\u0026#34;Response JSON: \u0026#34; + response.asString()); // 验证状态码为 200 response.then().statusCode(200); // 验证响应中的特定字段值 response.then().body(\u0026#34;userId\u0026#34;, equalTo(1)); response.then().body(\u0026#34;id\u0026#34;, equalTo(1)); response.then().body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)); response.then().body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } } 上述代码执行了一个 GET 请求到 JSONPlaceholder 的 /posts/1 端点，并验证了响应的状态码和特定字段的值。你可以根据你的需求修改基本 URI 和验证条件。\n在这个示例中，我们使用了 TestNG 测试框架，但你也可以使用其他测试框架，例如 JUnit。确保你的测试类中包含了合适的导入语句，并根据需要进行适当的配置。\n这是一个简单的 RestAssured 语法示例，用于执行 GET 请求和验证响应。你可以根据项目的需求和接口的复杂性来构建更复杂的测试用例。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/rest-assured-tutorial-and-environment-preparation/","summary":"包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 REST Assured 以及如何开始使用它来进行 API 测试。教程将涵盖 REST Assured 的基本概念，包括如何设置测试环境，准备所需的工具和资源，以便读者可以开始编写和执行他们自己的 API 测试。","title":"REST Assured 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nGradle + Scala 版本 可参考 demo：https://github.com/Automation-Test-Starter/gatling-gradle-scala-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gatling.yml。\n编辑 gatling.yml 文件：将以下内容复制到文件中。\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | ./gradlew gatlingRun env: GATLING_SIMULATIONS_FOLDER: src/gatling/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling 提交代码：将 gatling.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Maven + Scala 版本 可参考 demo：https://github.com/Automation-Test-Starter/gatling-maven-scala-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gatling.yml。\n编辑 gatling.yml 文件：将以下内容复制到文件中。\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | mvn gatling:test env: GATLING_SIMULATIONS_FOLDER: src/test/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling 提交代码：将 gatling.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 参考 galting 官网：https://gatling.io/ galting 官方文档：https://gatling.io/docs/gatling/ galting 官方 github: https://github.com/gatling/ 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro-ci-cd-integration/","summary":"文章介绍性能测试工具 gatling 的进阶用法：CI/CD 集成，以 github action 为例来介绍如何集成 gatling 到 CI/CD 流程中","title":"gatling 性能测试教程 - 进阶用法：CI/CD 集成"},{"content":"测试报告解析 总览 总览图 性能测试执行结束后打开详细的 html 报告，可以看到详细的性能测试报告； 可通过指标、活跃用户和随时间变化的请求/响应以及分布来分析您的报告\n页面中间标题处显示 Simulation 的名字 左侧的列表展示不同类型的报告菜单，可点击切换 页面中部展示性能测试报告的总览信息，包括：请求总数、成功请求总数、失败请求总数、最短响应时间、最长响应时间、平均响应时间、吞吐量、标准差、百分比分布等。也会展示 gatling 的版本及本次报告运行的时间和时长 全局菜单指向综合统计数据。 详细信息菜单指向每个请求类型的统计信息。 请求数\u0026amp;响应时间分布图 此图表展示了响应时间在标准范围内的分布情况 左侧的列表显示所有的请求以及请求响应的时间分布，红色代表失败的请求 右边 Number of request 代表用户并发数量，以及各个请求的请求数量及其成功失败状态\n这些范围可以在 gatling.conf 文件中配置\n请求标准统计分析图 此图表显示了一些标准统计数据，例如全局和每个请求的最小值、最大值、平均值、标准差和百分位数。 stats 显示了所有请求具体的成功失败情况 OK 代表成功，KO 代表失败，百分比 99th pct 代表对于这一个 API 总的请求中有百分之 99 的请求 response time 是这个数值\n这些百分位数可以在 gatling.conf 文件中配置。\n活跃用户数统计图 此图表展示了活跃用户数指的是在测试时间段内，正在进行请求的用户数。在测试开始时，活跃用户数为 0。当用户开始发送请求时，活跃用户数开始增加。当用户完成请求时，活跃用户数开始减少。活跃用户数的最大值是在测试期间同时发送请求的用户数。\n响应时间分布图 此图表显示了响应时间的分布，包括请求成功的响应时间和请求失败的响应时间。\n响应时间百分位对比图 此图表显示一段时间内的各种响应时间百分位数，但仅适用于成功的请求。由于失败的请求可能会提前结束或由超时引起，因此它们会对百分位数的计算产生巨大影响。\n每秒请求数图 此图表展示了每秒的请求数，包括成功的请求数和失败的请求数。\n每秒响应数图 此图表展示了每秒的响应数，包括成功的响应数和失败的响应数。\n单个请求分析报告 可点击报告页面上的 details 菜单切换到 details tab 页面，查看单个请求的详细报告\nDetails 页面主要展示了每个请求的统计数据，与全局报告相似地包括了响应时间分布图，响应时间百分位图，每秒请求数图，每秒响应数图。不同的是最底下有一张图是描述单个请求相对于全局所有请求的响应时间。该图横坐标是每秒全局所有请求数，纵坐标是单个请求的响应时间。\n性能场景设置 Injection 注入 什么是 Injection 在 Gatling 性能测试中，\u0026ldquo;Injection\u0026quot;是指将虚拟用户（或负载）引入系统的一种方式。它定义了模拟用户如何被引入测试场景，包括用户的数量、速率和方式。Injection 是 Gatling 中用于控制负载和并发度的关键概念，允许你模拟不同的用户行为和负载模型。\n用户注入配置文件的定义是通过 injectOpen 和 injectClosed 方法（Scala 中的 inject）完成的。此方法将按顺序处理的注入步骤序列作为参数。每个步骤都定义了一组用户，以及如何将这些用户注入到场景中。\n官网更多介绍：https://gatling.io/docs/gatling/reference/current/core/injection/\n常用 Injection 场景 Open Model 开放模型场景 setUp( scn.inject( nothingFor(4), // 1 atOnceUsers(10), // 2 rampUsers(10).during(5), // 3 constantUsersPerSec(20).during(15), // 4 constantUsersPerSec(20).during(15).randomized, // 5 rampUsersPerSec(10).to(20).during(10.minutes), // 6 rampUsersPerSec(10).to(20).during(10.minutes).randomized, // 7 stressPeakUsers(1000).during(20) // 8 ).protocols(httpProtocol) ) nothingFor(duration)：设置一段停止的时间，这段时间什么都不做 atOnceUsers(nbUsers)：立即注入一定数量的虚拟用户 rampUsers(nbUsers) during(duration)：在指定时间内，设置一定数量逐步注入的虚拟用户 constantUsersPerSec(rate) during(duration)：定义一个在每秒钟恒定的并发用户数，持续指定的时间 constantUsersPerSec(rate) during(duration) randomized：定义一个在每秒钟围绕指定并发数随机增减的并发，持续指定时间 rampUsersPerSec(rate1) to (rate2) during(duration)：定义一个并发数区间，运行指定时间，并发增长的周期是一个规律的值 rampUsersPerSec(rate1) to(rate2) during(duration) randomized：定义一个并发数区间，运行指定时间，并发增长的周期是一个随机的值 stressPeakUsers(nbUsers).during(duration) ：按照拉伸到给定持续时间的阶跃函数的平滑近似注入给定数量的用户。 Closed Model 闭合模型场景 setUp( scn.inject( constantConcurrentUsers(10).during(10), // 1 rampConcurrentUsers(10).to(20).during(10) // 2 ) ) constantConcurrentUsers(nbUsers).during(duration) ：注入以使系统中的并发用户数恒定 rampConcurrentUsers(fromNbUsers).to(toNbUsers).during(duration) ：注入，使系统中的并发用户数从一个数字线性增加到另一个数字 Meta DSL 场景 \u0026ldquo;Meta DSL\u0026quot;是一种特殊的领域特定语言（DSL），用于描述性能测试场景的元数据（metadata）和全局配置。Meta DSL 允许你定义性能测试中的一些全局设置和参数，以影响整个测试过程，而不是特定于某个场景。\n可以使用 Meta DSL 的元素以更简单的方式编写测试。如果您想要链接级别和斜坡以达到应用程序的极限（有时称为容量负载测试的测试），您可以使用常规 DSL 手动完成，并使用 map 和 flatMap 进行循环。\nincrementUsersPerSec setUp( // 生成一个开放的工作量注入配置文件 // 每秒分别有 10、15、20、25 和 30 个用户到达 // 每个级别持续 10 秒 // 每级持续 10 秒 scn.inject( incrementUsersPerSec(5.0) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Double ) incrementConcurrentUsers setUp( // 生成一个封闭的工作负载注入配置文件 // 并发用户分别为 10、15、20、25 和 30 级 // 每个级别持续 10 秒 // 每级持续 10 秒 scn.inject( incrementConcurrentUsers(5) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Int ) ) incrementUsersPerSec 用于开放式工作负载，incrementConcurrentUsers 用于封闭式工作负载（用户数/秒与并发用户数）。\nseparatedByRampsLasting 和 startingFrom 都是可选的。如果您不指定斜坡，测试完成后就会立即从一个级别跳到另一个级别。如果您不指定启动用户数，测试将从 0 个并发用户或每秒 0 个用户开始，并立即进入下一步。\nConcurrent Scenarios 并发场景 setUp( scenario1.inject(injectionProfile1), scenario2.inject(injectionProfile2) ) 您可以在同一个 setUp 块中配置多个场景同时启动并并发执行。\n其他场景 查看官网介绍：https://gatling.io/docs/gatling/reference/current/core/injection/\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro-advanced-usage/","summary":"文章介绍性能测试工具 gatling 的进阶用法：性能测试报告的解析，不同类型的测试报告报表介绍，不同业务类型下的性能测试场景配置","title":"gatling 性能测试教程 - 进阶用法：报告解析和场景设置"},{"content":"从 0 到 1 搭建自己的 Gatling 工程 Gradle + Scala 版本 创建一个空的 Gradle 工程 mkdir gatling-gradle-demo cd gatling-gradle-demo gradle init 配置项目 build.gradle 在 项目中 build.gradle 文件中添加以下内容\n可 copy 本项目中的 build.gradle 文件内容，更多配置可参考官方文档\n// 插件配置 plugins { id \u0026#39;scala\u0026#39; // scala插件声明（基于开发工具插件） id \u0026#39;io.gatling.gradle\u0026#39; version \u0026#39;3.9.5.6\u0026#39; // 基于gradle的gatling框架插件版本声明 } //仓库源配置 repositories { // 使用 maven 中心仓库源 mavenCentral() } // gatling 配置 gatling { // logback root level，如果配置文件夹中不存在 logback.xml，则默认 Gatling 控制台日志级别 logLevel = \u0026#39;WARN\u0026#39; // 执行记录 HTTP 请求的详细程度 // set to \u0026#39;ALL\u0026#39; for all HTTP traffic in TRACE, \u0026#39;FAILURES\u0026#39; for failed HTTP traffic in DEBUG logHttp = \u0026#39;FAILURES\u0026#39; // Simulations 过滤器 simulations = { include \u0026#34;**/simulation/*.scala\u0026#34; } } // 依赖配置 dependencies { // 图表库，用于生成报告图表 gatling \u0026#39;io.gatling.highcharts:gatling-charts-highcharts:3.8.3\u0026#39; } gradle build 项目并初始化 用编辑器打开本项目 Terminal 窗口，执行以下命令确认项目 build 成功 gradle build 初始化完成：完成向导后，Gradle 将在项目目录中生成一个基本的 Gradle 项目结构 初始化目录 在 src/gatling/scala 目录下创建一个 simulation 目录，用于存放测试脚本\nGatling 测试通常位于 src/gatling 目录中。你需要在项目根目录下手动创建 src 目录，然后在 src 目录下创建 gatling 目录。在 gatling 目录下，你可以创建你的测试模拟文件夹 simulation，以及其他文件夹，如 data、bodies、resources 等。\n编写脚本 在 simulation 目录下创建一个 demo.scala 文件，用于编写测试脚本\n示例脚本如下，可供参考\n脚本包含了两个场景，一个是 get 请求，一个是 post 请求 get 接口验证接口返回状态码为 200，post 接口验证接口返回状态码为 201 get 接口使用了 rampUsers，post 接口使用了 constantConcurrentUsers rampUsers：在指定时间内逐渐增加并发用户数，constantConcurrentUsers：在指定时间内保持并发用户数不变 两个接口的并发用户数都是 10 个，持续时间都是 10 秒 两个接口的请求间隔都是 2 秒\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } 调试脚本 执行以下命令，运行测试脚本并查看报告\ngradle gatlingRun Maven + Scala 版本 创建一个空的 Maven 工程 mvn archetype:generate -DgroupId=demo.gatlin.maven -DartifactId=gatling-maven-demo 初始化完成：完成向导后，Maven 将在新建项目目录并生成一个基本的 Maven 项目结构\n配置项目 pom.xml 在 项目中 pom.xml 文件中添加以下内容\n可 copy 本项目中的 pom.xml 文件内容，更多配置可参考官方文档\n\u0026lt;!-- 依赖配置 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.gatling.highcharts\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-charts-highcharts\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.9.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 插件配置 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.gatling\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.6.0\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;net.alchim31.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;scalaVersion\u0026gt;2.13.12\u0026lt;/scalaVersion\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;testCompile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;jvmArgs\u0026gt; \u0026lt;jvmArg\u0026gt;-Xss100M\u0026lt;/jvmArg\u0026gt; \u0026lt;/jvmArgs\u0026gt; \u0026lt;args\u0026gt; \u0026lt;arg\u0026gt;-deprecation\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-feature\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-unchecked\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:implicitConversions\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:postfixOps\u0026lt;/arg\u0026gt; \u0026lt;/args\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 初始化目录 在 src/test/scala 目录下创建一个 simulation 目录，用于存放测试脚本\nscala 测试通常位于 src/test 目录中。你需要在项目 test 目录下创建 scala 目录。在 scala 目录下，你可以创建你的测试模拟文件夹 simulation，以及其他文件夹，如 data、bodies、resources 等。\n编写脚本 在 simulation 目录下创建一个 demo.scala 文件，用于编写测试脚本\n示例脚本如下，可供参考\n脚本包含了两个场景，一个是 get 请求，一个是 post 请求 get 接口验证接口返回状态码为 200，post 接口验证接口返回状态码为 201 get 接口使用了 rampUsers，post 接口使用了 constantConcurrentUsers rampUsers：在指定时间内逐渐增加并发用户数，constantConcurrentUsers：在指定时间内保持并发用户数不变 两个接口的并发用户数都是 10 个，持续时间都是 10 秒 两个接口的请求间隔都是 2 秒\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } 调试脚本 执行以下命令，运行测试脚本并查看报告\nmvn gatling:test 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro2/","summary":"文章介绍性能测试工具 gatling 的进阶介绍：从 0 到 1 搭建自己的 Gatling 工程，介绍了 Gatling 的基本使用方法，以及如何搭建自己的 Gatling 工程，编写性能测试脚本，查看测试报告等","title":"gatling 性能测试教程：从 0 到 1 搭建自己的 Gatling 工程"},{"content":"Gatling 介绍 Gatling 是一个用于性能测试和负载测试的开源工具，特别适用于测试 Web 应用程序。它是一个基于 Scala 编程语言的高性能工具，用于模拟并测量应用程序在不同负载下的性能。\n以下是 Gatling 的一些重要特点和优势：\n基于 Scala 编程语言：Gatling 的测试脚本使用 Scala 编写，这使得它具有强大的编程能力，允许用户编写复杂的测试场景和逻辑。 高性能：Gatling 被设计为高性能的负载测试工具。它使用了非阻塞的 I/O 和异步编程模型，能够模拟大量并发用户，从而更好地模拟真实世界中的负载情况。 易于学习和使用：尽管 Gatling 的测试脚本是使用 Scala 编写的，但它的 DSL（领域特定语言）非常简单，容易上手。即使你不熟悉 Scala，也可以快速学会如何创建测试脚本。 丰富的功能：Gatling 提供了丰富的功能，包括请求和响应处理、数据提取、条件断言、性能报告生成等。这些功能使你能够创建复杂的测试场景，并对应用程序的性能进行全面的评估。 多协议支持：除了 HTTP 和 HTTPS，Gatling 还支持其他协议，如 WebSocket，JMS，和 SMTP。这使得它适用于测试各种不同类型的应用程序。 实时结果分析：Gatling 可以在测试运行期间提供实时的性能数据和图形化报告，帮助你快速发现性能问题。 开源和活跃的社区：Gatling 是一个开源项目，拥有一个活跃的社区，不断更新和改进工具。 支持 CI/CD 集成：Gatling 可以与 CI/CD 工具（如 Jenkins）集成，以便在持续集成和持续交付流程中执行性能测试。 总的来说，Gatling 是一个功能强大的性能测试工具，适用于测试各种类型的应用程序，帮助开发团队识别和解决性能问题，以确保应用程序在生产环境中具有稳定的性能和可伸缩性。\n环境搭建 由于我是 macbook，后面的介绍几本会以 macbook demo 为例，windows 的同学可以自行参考\nVSCode + Gradle + Scala 版本 准备工作 开发工具：VSCode 安装 Gradle 版本\u0026gt;=6.0，我使用的 Gradle 8.44 安装 JDK 版本\u0026gt;=8，我使用的 JDK 19 安装插件 VSCode 搜索 Scala (Metals) 插件进行安装 VSCode 搜索 Gradle for Java 插件进行安装 官方 demo 初始化\u0026amp;调试 前面先会用官方 demo 工程来做初始化和调试，后面再介绍如何自己创建工程\n克隆官方 demo 工程 git clone git@github.com:gatling/gatling-gradle-plugin-demo-scala.git 使用 VSCode 打开克隆下来的官方 demo 工程\n用 VSCode 打开本项目 Terminal 窗口，执行以下命令\ngradle build 运行工程中的 demo gradle gatlingRun 查看命令行运行结果 点击命令行报告中的 html 报告链接，并使用浏览器打开，即可查看详细的报告信息 VSCode + Maven + Scala 版本 准备工作 开发工具：VSCode 安装 Maven，我使用的 Maven 3.9.5 JDK 版本\u0026gt;=8，我使用的 JDK 19 安装插件 VSCode 搜索 Scala (Metals) 插件进行安装 VSCode 搜索 Maven for Java 插件进行安装 官方 demo 初始化\u0026amp;调试 前面先会用官方 demo 工程来做初始化和调试，后面再介绍如何自己创建工程\n克隆官方 demo 工程 git clone git@github.com:gatling/gatling-maven-plugin-demo-scala.git 使用 VSCode 打开克隆下来的官方 demo 工程\n用 VSCode 打开本项目 Terminal 窗口，执行以下命令运行工程中的 demo\nmvn gatling:test 查看命令行运行结果 点击命令行报告中的 html 报告链接，并使用浏览器打开，即可查看详细的报告信息 IDEA + Gradle + Scala 版本 与 VSCode 下基本类似，这里就不再赘述了\n差异点如下：\nIDEA 搜索 Scala 插件进行安装 新的运行方式：右键选择项目目录下的 Engine.scala 文件，选择 Run \u0026lsquo;Engine\u0026rsquo;也可以运行 demo（运行过程中需要按回车键确认哦） IDEA + Maven + Scala 版本 与 VSCode 下基本类似，这里就不再赘述了\n差异点如下：\nIDEA 搜索 Scala 插件进行安装 新的运行方式：右键选择项目目录下的 Engine.scala 文件，选择 Run \u0026lsquo;Engine\u0026rsquo;也可以运行 demo（运行过程中需要按回车键确认哦） 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/performance-testing/gatling-tool-intro1/","summary":"文章介绍性能测试工具 gatling 的新手入门介绍，环境搭建，如何将官方 demo 跑起来","title":"gatling 性能测试教程：入门介绍"},{"content":"为什么选择 bruno 官方说明：https://github.com/usebruno/bruno/discussions/269\n与 postman 的对比：https://www.usebruno.com/compare/bruno-vs-postman\n开源，MIT License\n客户端全平台支持 (Mac/linux/Windows)\n离线客户端，无云同步功能计划\n支持 Postman/insomina 脚本导入（只能导入 API 请求脚本，无法导入测试脚本）\n社区相对活跃，产品开发路线图清晰\n安装 bruno Download link: https://www.usebruno.com/downloads\nMac 电脑推荐 brew 命令下载\n​ brew install Bruno\n客户端使用入门 默认主界面 API 请求集 创建 API 请求集 首页点击‘Create Collection’链接，打开创建 API 请求集的弹窗\n弹窗上依次输入\nName: 输入 API 请求集的名字\nLocation：输入想要保存 API 请求集文件的文件夹路径 (建议选择此项目所在路径)\nFolder Name：可输入 API 请求集名字（会在刚才选择的路径下创建一个对应名字的文件夹）\n点击 Create 按钮即可完成 API 请求集的创建，并展示在界面上 (左侧 请求集列表会展示新建的 API 请求集的信息)\n打开 API 请求集 首页点击‘Open Collection’链接，打开选择已有的 bruno 格式的 API 请求集文件夹 点击 open 即可完成选择，并展示在界面上 (左侧 collection 列表会展示选择的 API 请求集信息) 导入 API collection 首页点击‘Import Collection’链接，打开导入 API collection 的弹窗 (支持 Bruno/Postman/Insomnia 的导入) 弹窗上选择对应格式的的链接，再选在已存在的对应格式的文件路径 点击 open 即可完成选择，并展示在界面上 (左侧 collection 列表会展示选择的 API collection 信息) 本地运行 API collection 在主界面左侧 collection 列表选择想要运行的 API 请求集 在菜单上选择 Run，右侧界面会打开 Runner tab，会展示所选择 API 请求集里面 requests 的一些信息 点击 Run Collection 按钮即可本地运行 (运行完界面上会展示允许结果) 导出 API 请求集 在主界面左侧 collection 列表选择想要运行的 API 请求集，右键打开菜单 在菜单上选择 Export，再选择想要导出文件的路径即可完成导出 (导出文件也是为 json 格式) API 请求 新建 API 请求 前置条件：已经创建了 API 请求集 (参考上面的创建 API 请求集) 在主界面左侧 collection 列表选择想要新建 API 请求的 API 请求集 在菜单上选择 New Request，右侧界面会打开 Request tab，会展示所选择 API 请求集里面 requests 的一些信息 在 new Request 窗口上先选择请求类型：HTTP/GraphQL 依次输入 Name: 输入 API 请求的名字 URL：输入 API 请求的 URL Method：选择 API 请求的 Method 点击 Create 按钮即可完成 API 请求的创建，并展示在界面上 (左侧 请求集列表会展示新建的 API 请求的信息) 编辑 API 请求 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)\n在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求\n然后可以根据 API 请求类型再来编辑请求的不同字段 Body：输入 API 请求的 Body\nHeaders：输入 API 请求的 Headers\nParams：输入 API 请求的 Params\nAuth：输入 API 请求的 Auth\nVars：输入 API 请求的 Vars\nScript：输入 API 请求的 Script\nAssert：输入 API 请求的 Assert\nTests：输入 API 请求的 Tests\n点击 Save 按钮即可完成 API 请求的编辑，并展示在界面上 (左侧 请求集列表会展示编辑的 API 请求的信息)\n运行 API 请求 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) API 请求生成代码 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 菜单右键选择 Generate Code，再选择想要生成代码的语言 Generate Code 窗口即可展示不同语言的请求代码 编写 API 请求测试脚本 API 请求 Assert Assert 介绍 打开任意的 API 请求，切换到 Assert tab\nAssert tab 会展示 API 请求的 Assert 信息\nAssert 用来判断 API 请求的返回结果是否符合预期\nExpr：输入预期结果的表达式，可以是 API 请求的返回结果的某个字段的值，可输入两种类型：Status Code 和 Response Body Status Code：判断 API 请求的返回状态码是否符合预期 (默认为 200) Response Body：判断 API 请求的返回结果是否符合预期 (默认为 true)\nOperator：输入预期结果的验证方式。支持多种判断方式：Equal 和 Not Equal 等 Equal：判断 API 请求的返回结果是否等于预期结果 Not Equal：判断 API 请求的返回结果是否不等于预期结果\nValue：输入预期结果的值，支持两种预期结果的输入方式：Static 和 Dynamic Static：输入预期结果的静态值 Dynamic：输入预期结果的动态值，可以是 API 请求的返回结果的某个字段的值\nAssert 示例 Assert status code 为 200 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 status 是否为 200， 打开该 API 请求，切换到 Assert tab 依次输入如下信息 Expr: res.status Operator：Equal Value：200 Assert repsponse body 符合预期 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 repsponse body 是否符合预期 打开该 API 请求，切换到 Assert tab Assert1 依次输入如下信息 Expr: res.body.id Operator：Equal Value：1 Assert2 依次输入如下信息 Expr: res.body.title Operator：contains Value：provident 调试 Assert 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也按照 demo 编写了对应的 Assert 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) 切换到 Tests tab，会展示 API 请求的 Tests 信息，里面也会包括请求的 Assert 信息 API 请求 Tests Tests 介绍 打开任意的 API 请求，切换到 Tests tab Tests tab 会展示 API 请求的 Tests 信息 Tests 用来编写 API 请求的测试脚本，目前较好支持 javascript 语言 Tests 里面可以编写多个测试脚本，每个测试脚本都可以单独运行 Tests 示例 验证 status code 为 200 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 status 是否为 200， 打开该 API 请求，切换到 Tests tab 输入如下脚本 test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); Assert repsponse body 符合预期 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 repsponse body 是否符合预期 打开该 API 请求，切换到 Tests tab 输入如下脚本 test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.id).to.equal(1); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调试 Tests 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也按照 demo 编写了对应的 Tests 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) 切换到 Tests tab，会展示 API 请求的 Tests 信息，里面也会包括请求的 Tests 信息 环境变量 创建环境变量 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 选择想要创建环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗（支持创建新的环境变量和导入已有的环境变量） 弹窗上点击 Create Environment 按钮，输入环境变量的名字，点击 create 按钮即可创建环境变量 然后在弹窗上点击 Add Variable 按钮，输入环境变量的 key 和 value，点击 Save 按钮即可添加环境变量 环境变量 demo 需求：创建一个 demo 环境变量，里面包含一个 key 为 host，value 为 https://jsonplaceholder.typicode.com 的环境变量\n选择想要创建环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗 弹窗上点击 Create Environment 按钮，输入环境变量的名字 demo，点击 create 按钮即可创建环境变量 demo 选择 demo 环境变量，然后在页面上点击 Add Variable 按钮，输入环境变量的 key 为 host，value 为 https://jsonplaceholder.typicode.com ，点击 Save 按钮即可添加环境变量 如下图所示 使用环境变量 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也创建了 demo 环境变量 选择想要使用环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 demo 按钮即可使用 demo 环境变量 然后在 API 请求的 URL 变更为输入 {{host}}/posts/1 即可使用环境变量 测试脚本接口自动化 前置条件 已创建了 API 请求集（示例名为:api-collects） 已创建了 API 请求（示例名为:api request1） 已创建了环境变量（示例名为:demo） 也为 API 请求编写了 assert 或者 tests 脚本 接口自动化项目 demo 安装 node.js 安装 npm 新建项目文件夹（示例名为:bruno-test） 项目文件夹下执行 npm init 将项目初始化为 npm 项目 安装 @usebruno/cli 依赖 (脚本为：npm install @usebruno/cli) 打开保存 API 请求集的文件夹目录，将 api-collects 目录下的所有文件都复制到 bruno-test 项目目录下下 项目目录如下所示 bruno-test //项目主文件夹 api request1.bru //api 请求 enviroments //环境变量 demo.bru bruno.json node_modules //node 包依赖 package-lock.json package.json //npm 项目配置文件 运行接口自动化脚本 bruno run --env demo 运行结果如下 接入 CI 接入 github action 以 github action 为例，其他 CI 工具类似\n前置准备：在项目 package.json 文件中添加如下脚本 \u0026#34;test\u0026#34;: \u0026#34;bru run --env demo\u0026#34; 在项目根目录下创建 .github/workflows 文件夹 在 .github/workflows 文件夹下创建 main.yml 文件 main.yml 文件内容如下 name: bruno cli CI on: push: branches: [ main ] pull_request: branches: [ main ] jobs: run_bruno_api_test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - run: npm install - name: run tests run: npm run test 提交代码到 github，会自动触发 github action 查看 github action 运行结果，如图示例： 可拉取本项目代码进行参考：https://github.com/dengnao-tw/Bruno-API-Test-Starter\n测试报告\u0026mdash;TODO bruno 更多用法\u0026mdash;TODO Postman 脚本迁移 API 请求集迁移 在首页点击‘Import Collection’链接，打开导入 API collection 的弹窗 点击选择 Postman Collection 的链接，再选在已存在的 Postman 请求集文件路径 即可导入 Postman 的请求集 但是目前只支持导入 API 请求，无法导入测试脚本，如图所示（但不影响请求调用） 环境变量迁移 在首页选择刚才导入的 Postman 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗 点击‘Import Environment’链接，打开导入 Environment 的弹窗 点击选择 Postman Environment 的链接，再选在已存在的 Postman 环境变量文件路径 即可导入 Postman 的环境变量 测试脚本迁移参考 两个工具测试脚本的语法存在一部分差异，需要手动修改\nPostman 测试脚本语法参考：https://learning.postman.com/docs/writing-scripts/test-scripts/ Postman 测试脚本示例 pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); Bruno 测试脚本语法参考：https://docs.usebruno.com/testing/introduction.html Bruno 测试脚本示例 test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.id).to.equal(1); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/introduction_of_bruno/","summary":"文章介绍 postman 替换工具 Bruno 的新手入门介绍，如何迁移 postman 脚本到 Bruno","title":"postman 替换工具 bruno 使用介绍"},{"content":"什么是二八法则 二八法则，也被称为帕累托法则（Pareto principle），是一种经济学原理和管理学理论，描述了一种观察结果：80% 的结果往往来自于 20% 的原因。这个法则最初由意大利经济学家维尔弗雷多·帕累托（Vilfredo Pareto）提出。\n二八法则可以应用于各个领域，包括经济、生产、销售、时间管理等。具体来说，它意味着一个系统或者群体中，少数重要的因素往往对于大部分结果产生了主要的影响，而其余的因素只起到了次要的作用。换句话说，大部分的产出、收益或者结果来自于少数关键的因素或者部分。\n举个例子，二八法则可以应用于销售领域。80% 的销售额往往来自于 20% 的顾客，或者说 80% 的问题往往来自于 20% 的产品。这意味着经营者可以通过专注于那些最重要的 20% 顾客或产品，获得最大的收益。\n二八法则的应用还可以帮助人们更有效地管理时间。根据这个原理，80% 的成果往往来自于 20% 的时间和精力投入。因此，人们可以通过识别那些最重要的任务和活动，并优先处理它们，来提高工作效率和成果。\n需要注意的是，二八法则的具体数字并不一定是严格的 80-20 比例，这只是一个常见的例子。在实际应用中，比例可能会有所不同，但基本思想保持一致：少数重要的因素或者部分对于整体结果起到了关键作用。\n软件研发过程中的二八法则 在软件研发中，二八法则可以应用于多个方面，包括功能开发、缺陷修复、需求管理和团队效率等。以下是一些常见的应用场景：\n功能开发：根据二八法则，80% 的用户使用率通常来自于 20% 的核心功能。在软件开发过程中，团队可以优先开发和完善这些核心功能，以满足大部分用户的需求。这有助于提高产品的可用性和用户体验。 缺陷修复：类似地，80% 的软件缺陷往往由 20% 的核心功能引起。因此，在缺陷修复过程中，团队应该重点关注那些最常见、最严重或者影响最广泛的缺陷。这有助于快速改善软件的质量和稳定性。 需求管理：根据二八法则，80% 的用户需求通常来自于 20% 的关键需求。在需求管理过程中，团队应该专注于梳理和管理那些最重要、最紧急的需求，确保其优先级得到合理的安排。这有助于提高项目的交付价值和满足用户期望。 团队效率：二八法则也可以应用于团队效率的管理。根据这个原则，80% 的工作成果往往来自于 20% 的高效工作时间。团队可以通过优化工作流程、减少低价值的任务和降低工作负荷，来提高团队的整体效率和生产力。 需要注意的是，二八法则在软件研发中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，以达到最佳的开发效果和资源利用。同时，综合考虑其他因素，如用户反馈、市场需求和团队能力等，以实现整体的项目成功。\n软件研发质量中的二八法则 在软件质量管理中，二八法则可以应用于缺陷管理、测试策略和持续改进等方面。以下是一些常见的应用场景：\n缺陷管理：根据二八法则，80% 的缺陷通常来自于 20% 的功能模块或者代码区域。在软件质量管理过程中，团队应该重点关注那些最容易引发缺陷的核心功能或者代码部分。这有助于提高缺陷发现和修复的效率，确保关键功能的质量和稳定性。 测试策略：根据二八法则，80% 的软件缺陷往往由 20% 的核心功能或者测试用例引起。在测试策略制定过程中，团队可以优先选择那些最关键、最具代表性的功能进行测试。同时，重点关注那些最有可能引发缺陷的测试用例，以提高测试覆盖和效果。 持续改进：二八法则也可以应用于持续改进的过程中。根据这个原则，80% 的改进效果通常来自于 20% 的关键改进措施。团队应该重点关注那些最重要、最有影响力的改进项目，以最大程度地提升软件质量和用户体验。 用户反馈和需求：根据二八法则，80% 的用户满意度通常来自于 20% 的关键功能或者需求。在软件质量管理中，团队应该重点关注那些对用户最重要、最有价值的功能和需求。通过积极收集用户反馈和需求，团队可以针对性地改进和优化这些关键领域，提升软件的质量和用户满意度。 需要注意的是，二八法则在软件质量管理中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，并结合其他质量管理方法和工具，以实现最佳的软件质量和用户体验。\n软件测试中的二八法则 在软件测试中，二八法则可以被应用于缺陷定位和优先级管理。根据这个原则，大约 80% 的缺陷通常来自于 20% 的功能模块或测试用例。这意味着测试团队可以通过重点关注那些最有可能引发缺陷的关键功能，以及那些覆盖最广泛、最重要的测试用例，来获得最佳的测试覆盖和缺陷发现效果。\n具体应用二八法则的方法包括：\n重点测试关键功能：根据系统的复杂性和业务重要性，确定关键的功能模块或者业务流程。将更多的测试资源和时间分配给这些关键功能，以确保其质量和稳定性。 优先处理高风险区域：通过分析过往的缺陷数据、用户反馈和业务需求，确定系统中最容易出现问题的区域。将更多的测试活动放在这些高风险区域，以提前发现和修复潜在的问题。 选择关键测试用例：在测试用例设计和执行过程中，根据业务价值、功能复杂度和影响范围等因素，选择那些最具代表性和最重要的测试用例进行执行。确保这些关键测试用例的覆盖率和测试深度，以有效检测潜在的缺陷。 精细化缺陷管理：将测试团队的精力集中在那些最关键、最严重的缺陷上，确保这些缺陷得到及时的处理和修复。同时，对于一些次要的或影响较小的缺陷，可以在资源允许的情况下进行适当的延后处理，以保证测试团队的效率和优先级的合理分配。 需要注意的是，二八法则在软件测试中的应用并非严格的数值比例，具体的比例可能会因项目的特点、复杂性和风险等因素而有所不同。测试团队应根据具体情况灵活运用这个原则，以实现最佳的测试效果和资源利用。\n如何优化软件研发质量中的二八法则 要优化软件质量管理中的二八法则应用，可以考虑以下几点：\n数据驱动决策：收集和分析准确、全面的数据是优化的基础。通过使用测试管理工具、缺陷跟踪系统和用户反馈渠道等，获取有关缺陷、功能使用率、用户需求等方面的数据。这样可以更准确地确定哪些功能模块或代码区域是关键的，从而更有针对性地进行测试和改进。 重点关注核心功能：根据数据分析的结果，重点关注那些最关键、最常用的功能模块或代码区域。在测试过程中，为这些核心功能分配更多的资源和测试覆盖，以确保其质量和稳定性。 细化测试策略：根据数据分析和风险评估，制定细化的测试策略。考虑到功能的重要性、复杂性和用户影响，确定关键测试用例，并确保其充分覆盖核心功能。同时，可以利用自动化测试工具和技术，提高测试效率和覆盖率。 高效缺陷管理：建立有效的缺陷管理流程，确保缺陷能够及时被跟踪、分析和修复。优先处理那些最严重、最影响用户体验的缺陷，并跟踪缺陷修复的进度和效果。同时，进行缺陷分析，找出常见的缺陷模式和根本原因，以便改进开发过程和减少类似缺陷的再次发生。 用户参与和反馈：积极与用户进行互动，了解他们的需求、问题和意见。通过用户调研、用户体验测试和用户反馈渠道，获取用户的反馈和建议。将用户需求和反馈作为优化软件质量管理的重要依据，并将其纳入开发和改进的决策过程中。 持续改进和学习：软件质量管理是一个持续改进的过程。团队应该定期评估和反思当前的质量管理实践，寻找改进的机会。借鉴行业的最佳实践，关注新技术和工具的发展，不断学习和提升团队的能力和水平。 综合运用以上策略，可以优化软件质量管理中的二八法则应用，提高软件的质量和用户满意度。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/80-20-rule/","summary":"什么是二八法则 二八法则，也被称为帕累托法则（Pareto principle），是一种经济学原理和管理学理论，描述了一种观察结果：80% 的结果往往来自于 20% 的原因。这个法则最初由意大利经济学家维尔弗雷多·帕累托（Vilfredo Pareto）提出。\n二八法则可以应用于各个领域，包括经济、生产、销售、时间管理等。具体来说，它意味着一个系统或者群体中，少数重要的因素往往对于大部分结果产生了主要的影响，而其余的因素只起到了次要的作用。换句话说，大部分的产出、收益或者结果来自于少数关键的因素或者部分。\n举个例子，二八法则可以应用于销售领域。80% 的销售额往往来自于 20% 的顾客，或者说 80% 的问题往往来自于 20% 的产品。这意味着经营者可以通过专注于那些最重要的 20% 顾客或产品，获得最大的收益。\n二八法则的应用还可以帮助人们更有效地管理时间。根据这个原理，80% 的成果往往来自于 20% 的时间和精力投入。因此，人们可以通过识别那些最重要的任务和活动，并优先处理它们，来提高工作效率和成果。\n需要注意的是，二八法则的具体数字并不一定是严格的 80-20 比例，这只是一个常见的例子。在实际应用中，比例可能会有所不同，但基本思想保持一致：少数重要的因素或者部分对于整体结果起到了关键作用。\n软件研发过程中的二八法则 在软件研发中，二八法则可以应用于多个方面，包括功能开发、缺陷修复、需求管理和团队效率等。以下是一些常见的应用场景：\n功能开发：根据二八法则，80% 的用户使用率通常来自于 20% 的核心功能。在软件开发过程中，团队可以优先开发和完善这些核心功能，以满足大部分用户的需求。这有助于提高产品的可用性和用户体验。 缺陷修复：类似地，80% 的软件缺陷往往由 20% 的核心功能引起。因此，在缺陷修复过程中，团队应该重点关注那些最常见、最严重或者影响最广泛的缺陷。这有助于快速改善软件的质量和稳定性。 需求管理：根据二八法则，80% 的用户需求通常来自于 20% 的关键需求。在需求管理过程中，团队应该专注于梳理和管理那些最重要、最紧急的需求，确保其优先级得到合理的安排。这有助于提高项目的交付价值和满足用户期望。 团队效率：二八法则也可以应用于团队效率的管理。根据这个原则，80% 的工作成果往往来自于 20% 的高效工作时间。团队可以通过优化工作流程、减少低价值的任务和降低工作负荷，来提高团队的整体效率和生产力。 需要注意的是，二八法则在软件研发中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，以达到最佳的开发效果和资源利用。同时，综合考虑其他因素，如用户反馈、市场需求和团队能力等，以实现整体的项目成功。\n软件研发质量中的二八法则 在软件质量管理中，二八法则可以应用于缺陷管理、测试策略和持续改进等方面。以下是一些常见的应用场景：\n缺陷管理：根据二八法则，80% 的缺陷通常来自于 20% 的功能模块或者代码区域。在软件质量管理过程中，团队应该重点关注那些最容易引发缺陷的核心功能或者代码部分。这有助于提高缺陷发现和修复的效率，确保关键功能的质量和稳定性。 测试策略：根据二八法则，80% 的软件缺陷往往由 20% 的核心功能或者测试用例引起。在测试策略制定过程中，团队可以优先选择那些最关键、最具代表性的功能进行测试。同时，重点关注那些最有可能引发缺陷的测试用例，以提高测试覆盖和效果。 持续改进：二八法则也可以应用于持续改进的过程中。根据这个原则，80% 的改进效果通常来自于 20% 的关键改进措施。团队应该重点关注那些最重要、最有影响力的改进项目，以最大程度地提升软件质量和用户体验。 用户反馈和需求：根据二八法则，80% 的用户满意度通常来自于 20% 的关键功能或者需求。在软件质量管理中，团队应该重点关注那些对用户最重要、最有价值的功能和需求。通过积极收集用户反馈和需求，团队可以针对性地改进和优化这些关键领域，提升软件的质量和用户满意度。 需要注意的是，二八法则在软件质量管理中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，并结合其他质量管理方法和工具，以实现最佳的软件质量和用户体验。\n软件测试中的二八法则 在软件测试中，二八法则可以被应用于缺陷定位和优先级管理。根据这个原则，大约 80% 的缺陷通常来自于 20% 的功能模块或测试用例。这意味着测试团队可以通过重点关注那些最有可能引发缺陷的关键功能，以及那些覆盖最广泛、最重要的测试用例，来获得最佳的测试覆盖和缺陷发现效果。\n具体应用二八法则的方法包括：","title":"软件研发质量中的二八法则"},{"content":"什么是 API? API:应用程序接口（全称：application programming interface），缩写为 API，是一种计算接口，它定义多个软件中介之间的交互，以及可以进行的调用（call）或请求（request）的种类，如何进行调用或发出请求，应使用的数据格式，应遵循的惯例等。它还可以提供扩展机制，以便用户可以通过各种方式对现有功能进行不同程度的扩展。一个 API 可以是完全定制的，针对某个组件的，也可以是基于行业标准设计的以确保互操作性。通过信息隐藏，API 实现了模块化编程，从而允许用户实现独立地使用接口。\n什么是 API 测试？ 接口测试是软件测试的一种，它包括两种测试类型：狭义上指的是直接针对应用程序接口（下面使用缩写 API 指代，其中文简称为接口）的功能进行的测试；广义上指集成测试中，通过调用 API 测试整体的功能完成度、可靠性、安全性与性能等指标。\nAPI Best Practice:\nAPI 定义遵循 RESTFUL API 风格，语意化的 URI 定义，准确的 HTTP 状态码，通过 API 的定义就可以知道资源间的关系 配有详细且准确的 API 文档（如 Swagger 文档） 对外的 API 可以包含版本号以快速迭代（如 https://thoughtworks.com/v1/users/） API 测试与测试四象限 测试四象限中不同象限的测试，其测试目的跟测试策略也不同，API 测试主要位于第二、第四象限\nAPI 测试与测试金字塔 API 测试在测试金子塔中处于一个相对靠上的位置，主要站在系统、服务边界来测试功能和业务逻辑，执行时机是在服务完成构建、部署到测试环境之后再执行、验证。\nAPI 测试类型 功能测试\n正确性测试 异常处理 内部逻辑 …… 非功能测试\n性能 安全 …… API 测试步骤 发送请求 得到响应 验证响应结果 API 功能测试设计 设计理论\n正面 负面 异常处理 内部逻辑 …… 测试方法\n等价类划分 边界值 错误推断 …… API 非功能测试设计 安全测试\n随机测试 SQL 注入 XSS …… 性能测试\n性能瓶颈 稳定性测试 …… API 测试工具 API 请求工具\nCURL Soap UI Postman Swagger UI …… Http proxy 工具\nFiddler Charles …… API 性能测试工具\nab(apache bench) Jmeter …… 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/api-automation-testing/introduction_of_api_test/","summary":"文章介绍接口测试的简介，类型和工具","title":"接口测试简介"},{"content":"Google Bard Google Bard 进入公开测试版。测试申请中~~~\n申请链接：https://bard.google.com/\n谷歌发布 Bard，这是其在创建人工智能竞赛中的竞争对手推出 ChatGPT 之后的放的大招。\n经过多年的谨慎开发，这家互联网巨头将授予用户访问聊天机器人的权限，以追逐竞争对手 OpenAI 和微软的引人注目的首次亮相之后的惊艳表现。\n百度文心一言 百度于 3 月 16 日正式公布大语言模型“文心一言”，这是一款基于人工智能技术的智能对话系统，可进行语义理解、智能问答和情感交流等多种形式的对话。\n3 月 16 日起，首批用户即可通过邀请测试码在文心一言官网体验产品，后续将陆续开放给更多用户。 此外，百度智能云即将面向企业客户开放文心一言 API 接口调用服务。\n3 月 16 日起正式开放预约，搜索“百度智能云”进入官网，可申请加入文心一言云服务测试。\n申请链接：https://yiyan.baidu.com/welcome\n合作申请链接：https://cloud.baidu.com/survey_summit/wenxin.html?track=C856571\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/different-types-of-ai-join-waiting-list/","summary":"Google Bard Google Bard 进入公开测试版。测试申请中~~~\n申请链接：https://bard.google.com/\n谷歌发布 Bard，这是其在创建人工智能竞赛中的竞争对手推出 ChatGPT 之后的放的大招。\n经过多年的谨慎开发，这家互联网巨头将授予用户访问聊天机器人的权限，以追逐竞争对手 OpenAI 和微软的引人注目的首次亮相之后的惊艳表现。\n百度文心一言 百度于 3 月 16 日正式公布大语言模型“文心一言”，这是一款基于人工智能技术的智能对话系统，可进行语义理解、智能问答和情感交流等多种形式的对话。\n3 月 16 日起，首批用户即可通过邀请测试码在文心一言官网体验产品，后续将陆续开放给更多用户。 此外，百度智能云即将面向企业客户开放文心一言 API 接口调用服务。\n3 月 16 日起正式开放预约，搜索“百度智能云”进入官网，可申请加入文心一言云服务测试。\n申请链接：https://yiyan.baidu.com/welcome\n合作申请链接：https://cloud.baidu.com/survey_summit/wenxin.html?track=C856571\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。","title":"不同类型 AI 申请加入等待列表入口"},{"content":" 打开 edge 浏览器 在地址栏输入命令 edge://flags/ 在 flags 的页面输入 11 进行搜索 在搜索结果下选择“Show Windows 11 visual effects in title bar and toolbar”将状态变更为启用 重启浏览器，即可看到新的 edge 浏览器 UI 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/edge-enablenew-ui/","summary":"打开 edge 浏览器 在地址栏输入命令 edge://flags/ 在 flags 的页面输入 11 进行搜索 在搜索结果下选择“Show Windows 11 visual effects in title bar and toolbar”将状态变更为启用 重启浏览器，即可看到新的 edge 浏览器 UI 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。","title":"新技术分享：Mac OS 下 edge 浏览器开启新 UI"},{"content":"如果你的项目是采用敏捷测试，那么欢迎加入很棒的 30 天敏捷测试挑战。\n以下是 30 个挑战的列表，每月每天一个，打印下面的列表，把它保存在某个地方。打印出来。把它贴在墙上。让我们这样做吧！\n规则是什么？ 目标是尽可能多地的完成挑战。您可以在自己的时间范围和能力范围内做到这一点。\n您可能有图像可以分享，博客文章，视频，状态更新，无论它是什么！来参加吧！\n以下是分享进度的方法：\n在微博和朋友圈上 - 使用**#30DaysOfTesting**标签 30 天敏捷测试列表 Day 1 Buy an agile testing related book and share something you\u0026rsquo;ve learnt by day 30 买一本敏捷测试相关的书，并在第 30 天结束时分享你的所学 Day 2 Create a mindmap, document, diagram or sketchnote about what you think agile testing is\n用图表或文档的方式列出你理解的敏捷测试 Day 3 Find a video on YouTuBe about agile testing, then watch it!\n看一个敏捷测试的视频 Day 4 Read the agile manifesto and reflect on the implications for your role\n读敏捷宣言，并反思对你角色的影响 Day 5 Pair with a developer on a feature\n跟 Dev pair Day 6 Map out what your exploratory testing looks like, compare it to what other testers do\n列出你理解的探索式测试，并与其他人员的进行比较 Day 7 Find a visual way of representing your tests - e.g. A mind map, diagram, model, etc\n找一个可视化的方式展示你的测试 Day 8 Speak to a developer about a bug you found instead of loging it in the tracking system\n跟 dev 直接说你发现的 bug，而不是在 bug 管理系统里记录 Day 9 Pair whth a developer on a code review. Can you identify any risks?\n参加 dev 的 code review。你能定位任何的风险吗？ Day 10 Learn where the application logs are and how to read them.\n了解应用程序的 log 记录在哪里，并学习看 log。 Day 11 Find out what customers are saying about your product. What did you learn?\n了解客户对你的产品的评价。从中学到了什么？ Day 12 What test documentation does your team have? How can you improve it?\n你的团队有什么样的测试文档？你觉得可以怎么改进一下？ Day 13 Learn to use a tool that your developers use - e.g. an IDE\n学习使用 Dev 在用的工具 Day 14 How can you deliver greater value to your customer?\n如何能够交付更多的价值给客户？ Day 15 How can you make your testing processes (more) lean?\n如何能让你的测试流程更加精益？ Day 16 What barriers do you feel exist in testing in agile?\n你感觉敏捷测试中存在什么障碍？ Day 17 Map out your current team structure. How does it compare to other teams?\n绘制出您当前的团队结构。它与其他团队相比如何？ Day 18 How can you make testing jobs easier?\n如何让测试工作变得更轻松？ Day 19 How can you make jobs for your team easier?\n如何让你的团队工作更轻松？ Day 20 Investigate what is in your and your team\u0026rsquo;s tool kit\n调查你和你团队使用的工具有哪些 Day 21 How are you managing your testing, is it really agile?\n你如何管理你的测试，真的敏捷吗？ Day 22 Find out what testing is being done by other team members.\n了解其他团队成员正在进行的测试 Day 23 What agile strategies are there for managing tests?\n有哪些管理测试的敏捷策略？ Day 24 Look for a task that can be automated.\n找一个可以自动化的 task. Day 25 What can\u0026rsquo;t you automate? Communicate that to your team\n什么是你不能自动化的？跟团队沟通一下 Day 26 What does your Test Plan look like, what format do you use?\n你的测试计划什么样的，使用的什么格式？ Day 27 Look into zero bug tolerance, is this something your team could do?\n了解 bug 零容忍，这是你的团队可以做的吗？ Day 28 What learning culture exist in your company? How can you contribute to it?\n公司的学习文化是什么样的？你如何为此贡献？ Day 29 What columns do you have on your work tracker or kanban board?\n你们的看板上有哪些 column？ Day 30 What action does your team take on a red build?\nbuild 红了团队会采取什么 action？ Day 31 BONUS: Debrief your whole team on your last session of testing\n跟整个团队汇报你的测试 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n| ","permalink":"https://naodeng.com.cn/zh/posts/others/30-days-of-agile-testing/","summary":"如果你的项目是采用敏捷测试，那么欢迎加入很棒的 30 天敏捷测试挑战。\n以下是 30 个挑战的列表，每月每天一个，打印下面的列表，把它保存在某个地方。打印出来。把它贴在墙上。让我们这样做吧！\n规则是什么？ 目标是尽可能多地的完成挑战。您可以在自己的时间范围和能力范围内做到这一点。\n您可能有图像可以分享，博客文章，视频，状态更新，无论它是什么！来参加吧！\n以下是分享进度的方法：\n在微博和朋友圈上 - 使用**#30DaysOfTesting**标签 30 天敏捷测试列表 Day 1 Buy an agile testing related book and share something you\u0026rsquo;ve learnt by day 30 买一本敏捷测试相关的书，并在第 30 天结束时分享你的所学 Day 2 Create a mindmap, document, diagram or sketchnote about what you think agile testing is\n用图表或文档的方式列出你理解的敏捷测试 Day 3 Find a video on YouTuBe about agile testing, then watch it!\n看一个敏捷测试的视频 Day 4 Read the agile manifesto and reflect on the implications for your role","title":"敏捷测试的 30 天挑战"},{"content":"下面的信息是对 playwright 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\n安装 Install 非 VS Code 编辑器安装 新建项目文件 使用命令行工具进入新建的项目文件夹 输入命令进行项目初始化 npm init playwright@latest 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo VS Code 编辑器安装 新建项目文件 使用 VS Code 编辑器打开新建的项目文件夹 在 VS Code 编辑器安装 Playwright Test for VSCode 插件 然后在 VS Code 编辑器的命令面板上输入 Install Playwright 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo 运行测试 Run test VS Code 运行 通过 Playwright Test for VSCode 插件运行 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击绿色三角形就可以运行 demo 测试用例了 可以点击是否选中'show browser'来控制是否无头浏览器运行用例和打开浏览器运行用例 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 点击测试块旁边的绿色三角形 就可以运行测试来运行单个测试 命令行运行 运行所有测试\nnpx playwright test 运行单个测试文件\nnpx playwright test landing-page.spec.ts 运行一组测试文件\nnpx playwright test tests/todo-page/ tests/landing-page/ 运行文件名中有landing或login的文件\nnpx playwright test landing login 运行带有标题的测试\nnpx playwright test -g \u0026#34;add a todo item\u0026#34; 在引导模式 (打开浏览器) 下运行测试\nnpx playwright test landing-page.spec.ts --headed 在特定项目上运行测试\nnpx playwright test landing-page.ts --project=chromium 调试 Debug 由于 Playwright 在 Node.js 中运行，您可以使用您选择的调试器对其进行调试，例如使用console.log或在您的 IDE 内部或直接在 VS 代码中使用[VS 代码扩展](https://playwright.dev/docs/getting-started-vscode)。Playwright 带有[Playwright Inspector](https://playwright.dev/docs/debug#playwright-inspector)，它允许您单步执行 Playwright API 调用，查看他们的调试日志并探索[选择器](https://playwright.dev/docs/selectors)。\n命令行调试 调试所有测试：\nnpx playwright test --debug 调试一个测试文件：\nnpx playwright test example.spec.ts --debug 从test(..定义的行号调试测试：\nnpx playwright test example.spec.ts:42 --debug VS code 调试 通过 Playwright Test for VSCode 插件调试 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击第二个运行按钮就可以调试 demo 测试用例了 可以之前在想要调试的测试脚本文件中提前打一些断点 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 选中测试代码块，然后右键选择 debug test 就可以调试测试用例了 测试报告 Test report 命令行输入如下命令，就可以打开 html 版本的测试报告 npx playwright show-report 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/playwright-get-started/","summary":"下面的信息是对 playwright 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\n安装 Install 非 VS Code 编辑器安装 新建项目文件 使用命令行工具进入新建的项目文件夹 输入命令进行项目初始化 npm init playwright@latest 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo VS Code 编辑器安装 新建项目文件 使用 VS Code 编辑器打开新建的项目文件夹 在 VS Code 编辑器安装 Playwright Test for VSCode 插件 然后在 VS Code 编辑器的命令面板上输入 Install Playwright 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo 运行测试 Run test VS Code 运行 通过 Playwright Test for VSCode 插件运行 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击绿色三角形就可以运行 demo 测试用例了 可以点击是否选中'show browser'来控制是否无头浏览器运行用例和打开浏览器运行用例 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 点击测试块旁边的绿色三角形 就可以运行测试来运行单个测试 命令行运行 运行所有测试","title":"Playwright 自动化框架入门"},{"content":"Cypress Studio 提供了一种在测试运行程序中生成测试的可视化方法，通过记录与被测应用程序的交互。支持.click（）、.type（）、.check（）、.uncheck（）和.select（）Cypress 命令，这些命令将在与 Cypress Studio 内部的 DOM 交互时生成测试代码\n通过阅读文章你会学到什么：\n如何使用 Cypress Studio 以交互方式扩展测试\n如何使用 Cypress Studio 以交互方式添加新测试\n概述 Cypress Studio 通过记录与 被测应用程序的交互，提供了一种在 Test Runner 中生成测试的可视化方式。\n支持、.click()、.type()、和 Cypress 命令 .check() ，并在与 Cypress Studio 内部的 DOM 交互时生成测试代码。您还可以通过右键单击要断言的元素来生成断言。 .uncheck() .select()\n使用 Cypress Studio Cypress Studio 是一项实验性功能，可以通过将 experimentalStudio 属性添加到您的配置文件来启用（ cypress.json 默认情况下）。\n{ \u0026#34;experimentalStudio\u0026#34;: true} Cypress Real World App (RWA) 是一个开源项目，它实现了一个支付应用程序，以展示 Cypress 测试方法、模式和工作流程的实际使用情况。下面将使用它来演示 Cypress Studio 的功能。\n扩展测试 您可以扩展任何预先存在的测试，或者通过使用以下测试脚手架在您的 integrationFolder（默认情况下）中创建一个新测试来开始。\n第 1 步 - 运行用例 我们将使用 Cypress Studio 执行“新交易”用户流程。首先，启动 Test Runner 并运行在上一步中创建的用例。\n[image:F5CF37A4-27C0-4A6A-82DA-52C19191EB41-665-000000B8AF4F75E1/640.jpeg]\n第 2 步 - 启动 Cypress Studio 测试完成运行后，将鼠标悬停在命令日志中的测试上以显示“Add commands to Test”按钮。\n单击“Add Commands to Test”将启动 Cypress Studio。\nCypress Studio 直接与 命令日志集成。\n[image:7C04963F-638B-492C-B6D1-0C2C6FD31021-665-000000B8AF4F2B69/_640.jpeg]\nCypress 将自动执行所有挂钩和当前存在的测试代码，然后可以从该点开始扩展测试（例如，我们登录到 beforeEach 块内的应用程序）。\n接下来，Test Runner 将单独执行测试，并在测试中的最后一条命令后暂停。\n[image:E57D4269-75B6-49C2-9EC7-CB2BA527070D-665-000000B8AF4ECFAF/__640.jpeg]\n现在，我们可以开始更新测试以在用户之间创建新事务。\n第 3 步 - 与应用程序交互 要记录操作，请开始与应用程序交互。在这里，我们将单击标题右侧的“新建”按钮，结果我们将看到我们的单击记录在命令日志中。\n[image:B55CC01A-E8EF-4B70-9687-CC8A6423AD9A-665-000000B8AF4E893E/___640.jpeg]\n接下来，我们可以开始输入我们想要支付的用户名。\n[image:F647E6CB-2456-4602-84CB-B37B2B313DCF-665-000000B8AF4E4B07/____640.jpeg]\n一旦我们看到名字出现在结果中，我们想要添加一个断言来确保我们的搜索功能正常工作。右键单击用户名将弹出一个菜单，我们可以从中添加断言以检查元素是否包含正确的文本（用户名）。\n[image:F347B11C-142A-4EFC-821F-9B3F36B68119-665-000000B8AF4E15D4/_____640.jpeg] 然后，我们可以单击该用户以进入下一个屏幕。我们将通过单击并输入金额和描述输入来完成交易表格。\n[image:1A5CFBED-CD31-4912-90A1-960E05992DC7-665-000000B8AF4DE240/______640.jpeg]\n注意命令日志中生成的命令。\n现在是时候完成交易了。您可能已经注意到，在我们输入输入之前，“支付”按钮已被禁用。为了确保我们的表单验证正常工作，让我们添加一个断言以确保启用“支付”按钮。\n[image:F3E5EBF7-FB37-4A50-AF65-607939F664F0-665-000000B8AF4DAF00/_______640.jpeg]\n最后，我们将单击“支付”按钮，并显示我们新交易的确认页面。\n[image:AFF8F1D8-4FDC-42DF-BEEA-EDB769B0588A-665-000000B8AF4D783F/________640.jpeg]\n要放弃交互，请单击“取消”按钮退出 Cypress Studio。如果对与应用程序的交互感到满意，请单击“保存命令”，测试代码将保存到您的规范文件中。或者，您可以选择“复制”按钮以将生成的命令复制到剪贴板。\n生成的测试代码 查看我们的测试代码，我们可以看到在点击“Save Commands”后测试更新了我们在 Cypress Studio 中记录的操作。\n添加新测试 您可以通过单击我们定义的块上的“Add New Test”来向任何现有 describe 或块添加新测试。 context describe\n[image:0A8CA77E-9AEF-45B9-9B70-F15C01983DFF-665-000000B8AF4D4166/_________640.jpeg]\n我们被启动到 Cypress Studio 并可以开始与我们的应用程序交互以生成测试。\n对于此测试，我们将添加一个新的银行帐户。我们的互动如下：\n点击左侧导航中的“银行账户” [image:02219635-D587-4A52-BD45-738DA52F08E2-665-000000B8AF4D0E28/__________640.jpeg]\n点击银行账户页面上的“创建”按钮 [image:42C66725-A8B3-4ED6-9472-C0A0FF5AB64A-665-000000B8AF4CD946/___________640.jpeg]\n填写银行账户信息 [image:2E4443DE-C9A6-4D7A-84BB-6E6A5AA3F476-665-000000B8AF4CA262/____________640.jpeg]\n点击“保存”按钮 [image:655AAC92-065E-438E-B62C-145A771AD889-665-000000B8AF4C6D6F/_____________640.jpeg]\n要放弃交互，请单击“取消”按钮退出 Cypress Studio。\n如果对与应用程序的交互感到满意，请单击“保存命令”，提示将询问测试名称。单击“保存测试”，测试将保存到文件中。\n[image:A9CFD28A-A32C-42B5-97D7-7BD34A46D85F-665-000000B8AF4C390B/______________640.jpeg]\n保存后，该文件将在 Cypress 中再次运行。\n[image:560BE965-9C4C-4E9A-A17F-4992200B053B-665-000000B8AF4BF3D8/_______________640.jpeg]\n最后，查看我们的测试代码，我们可以看到点击“Save Commands”后测试更新了我们在 Cypress Studio 中记录的操作。\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo6/","summary":"Cypress Studio 提供了一种在测试运行程序中生成测试的可视化方法，通过记录与被测应用程序的交互。支持.click（）、.type（）、.check（）、.uncheck（）和.select（）Cypress 命令，这些命令将在与 Cypress Studio 内部的 DOM 交互时生成测试代码\n通过阅读文章你会学到什么：\n如何使用 Cypress Studio 以交互方式扩展测试\n如何使用 Cypress Studio 以交互方式添加新测试\n概述 Cypress Studio 通过记录与 被测应用程序的交互，提供了一种在 Test Runner 中生成测试的可视化方式。\n支持、.click()、.type()、和 Cypress 命令 .check() ，并在与 Cypress Studio 内部的 DOM 交互时生成测试代码。您还可以通过右键单击要断言的元素来生成断言。 .uncheck() .select()\n使用 Cypress Studio Cypress Studio 是一项实验性功能，可以通过将 experimentalStudio 属性添加到您的配置文件来启用（ cypress.json 默认情况下）。\n{ \u0026#34;experimentalStudio\u0026#34;: true} Cypress Real World App (RWA) 是一个开源项目，它实现了一个支付应用程序，以展示 Cypress 测试方法、模式和工作流程的实际使用情况。下面将使用它来演示 Cypress Studio 的功能。\n扩展测试 您可以扩展任何预先存在的测试，或者通过使用以下测试脚手架在您的 integrationFolder（默认情况下）中创建一个新测试来开始。\n第 1 步 - 运行用例 我们将使用 Cypress Studio 执行“新交易”用户流程。首先，启动 Test Runner 并运行在上一步中创建的用例。","title":"Cypress UI 自动化测试框架学习（6）- 用例编辑和脚本录制工具 Cypress Studio 介绍"},{"content":"Cypress UI 自动化测试框架学习（5）- 命令大全 命令大全 and：创建断言 as：创建别名 blur：失去焦点 check：选中 check 或者 radio children：获取一组 DOM 元素中每个元素的子元素 clear：清除 input 或者 textarea 的值 clearCookie：清除特定的浏览器 cookie clearCookies：清除浏览器的所有 cookie clearLocalStorage：清除 localstorage 的数据 click：点击 DOM 元素 clock：覆盖全局与时间相关的函数 closest：获取与选择器匹配的第一个 DOM 元素 contains：获取包含文本的 DOM 元素 dblclick：双击 DOM 元素 debug：设置调试器并记录上一个命令产生的内容 document：获取 window.document 对象 each：迭代数组结构 end：结束一系列命令 eq：在元素数组中获取特定索引的 DOM 元素 exec：执行系统命令 filter：获取特定选择器匹配的元素 find：查找特定选择器的特定后代元素 first：获取一组 DOM 元素中的第一个 DOM 元素 fixture：加载文件中的数据集 focus：使一个 DOM 元素获取焦点 focused：获取当前获取焦点的 DOM 元素 get：通过选择器或者别名获取一个或者多个 DOM 元素 getCookie：获取浏览器的特定 cookie getCookies：获取浏览器的所有 cookie go：前进或者后退 hash：获取当前页面地址的哈希值 hover：不存在这个命令 invoke：在前边生成的主题上调用函数 its：获取前边生成的主题的属性值 last：获取一组 DOM 元素的最后一个 DOM 元素 location：获取活动页面的 window.location 对象 log：打印 cypress 日志信息 next：获取紧接的下一个兄弟 DOM 元素 nextAll：获取所有兄弟 DOM 元素 nextUntil：获取一组匹配的 DOM 元素中的每个后续兄弟元素，不包括提供的元素 not：过滤 DOM 元素 parent：获取父元素 parents：获取所有的父元素 parentsUntil：获取所有的父元素，不包括提供的元素 pause：暂停执行 cypress 命令 prev：获取前一个兄弟节点 prevAll：获取前边的所有兄弟节点 prevUntil：获取前边所有的兄弟节点，不包括提供的元素 readFile：读取文件内容 reload：重新加载页面 request：发送 HTTP 请求 root：获取页面根节点 route：管理网络请求的行为 screenshot：生成截图 scrollIntoView：将元素滚动到视图中 scrollTo：滚动到特定位置 select：选择 select 中的 option server：启动服务器开始讲响应路由到 cy.route() 和 cy.request() setCookie：设置浏览器 cookie should：创建断言，同 and() siblings：获取兄弟 DOM 元素 spread：将数组扩展为多个参数 spy：包装方法，记录函数的调用和参数 stub：替换函数，记录其用法并控制其行为 submit：提交一个表单 task：通过 task 插件，在 Node.js 中执行代码 then：使用上一个命令产生的结果 tick：移动时间 title：获取活动页面的 document.title trigger：触发 DOM 元素上的事件 type：给 DOM 元素输入内容 uncheck：取消选中复选框 url：获取当前活动页面的 URL viewport：控制应用程序的屏幕大小和方向 visit：访问远程 URL wait：等待方法 window：获取当前活动窗口的 window 对象 within：将后续命令限制在此元素内 wrap：产生传递给 .wrap() 的对象 writeFile：写入指定内容到文件 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo5/","summary":"Cypress UI 自动化测试框架学习（5）- 命令大全 命令大全 and：创建断言 as：创建别名 blur：失去焦点 check：选中 check 或者 radio children：获取一组 DOM 元素中每个元素的子元素 clear：清除 input 或者 textarea 的值 clearCookie：清除特定的浏览器 cookie clearCookies：清除浏览器的所有 cookie clearLocalStorage：清除 localstorage 的数据 click：点击 DOM 元素 clock：覆盖全局与时间相关的函数 closest：获取与选择器匹配的第一个 DOM 元素 contains：获取包含文本的 DOM 元素 dblclick：双击 DOM 元素 debug：设置调试器并记录上一个命令产生的内容 document：获取 window.document 对象 each：迭代数组结构 end：结束一系列命令 eq：在元素数组中获取特定索引的 DOM 元素 exec：执行系统命令 filter：获取特定选择器匹配的元素 find：查找特定选择器的特定后代元素 first：获取一组 DOM 元素中的第一个 DOM 元素 fixture：加载文件中的数据集 focus：使一个 DOM 元素获取焦点 focused：获取当前获取焦点的 DOM 元素 get：通过选择器或者别名获取一个或者多个 DOM 元素 getCookie：获取浏览器的特定 cookie getCookies：获取浏览器的所有 cookie go：前进或者后退 hash：获取当前页面地址的哈希值 hover：不存在这个命令 invoke：在前边生成的主题上调用函数 its：获取前边生成的主题的属性值 last：获取一组 DOM 元素的最后一个 DOM 元素 location：获取活动页面的 window.","title":"Cypress UI 自动化测试框架学习（5）- 命令大全"},{"content":"下面的信息是自动化测试框架学习第四篇数据驱动方法封装参数化和测试框架的介绍。 在自动化测试框架学习中，有很多方法可以用来驱动测试框架。例如，数据驱动方法封装参数化和测试框架。这两个方法都可以将测试框架的数据处理和预设环境等现有模型结合起来。这样就可以方便地开发、测试和运行新的测试框架。\n测试数据驱动 js 格式测试数据驱动 简介 数据以 js 格式存储，使用 js 的 import 方法导入使用\n使用方法 新建测试数据 js 文件 示例：在项目的 cypress/integration 文件夹下新建 testData 目录，然后在该目录下创建一个 js 文件，示例文件名为：testLogin.data.js\ntestLogin.data.js 示例代码如下：\nexport const testLoginUserEmail = [ { summary: \u0026#34;正确邮箱账号登录验证\u0026#34;, username:\u0026#34;dengnao.123@163.com\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserId = [ { summary: \u0026#34;正确id账号登录验证\u0026#34;, username:\u0026#34;waitnoww\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserMobilephone = [ { summary: \u0026#34;正确手机号账号登录验证\u0026#34;, username:\u0026#34;18888139031\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_js.js\n示例代码如下：\nimport { testLoginUserEmail, testLoginUserId, testLoginUserMobilephone } from \u0026#34;./testData/testLogin.data\u0026#34;; // 测试用例 describe(\u0026#34;光谷社区登录验证\u0026#34;, function () { // 执行用例执行用例之前先进入首页 beforeEach(function () { // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) //正确邮箱账号登录 it(testLoginUserEmail[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserEmail[0].username) //输入邮箱用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserEmail[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确ID账号登录 it(testLoginUserId[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserId[0].username) //输入ID用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserId[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确手机账号登录 it(testLoginUserMobilephone[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserMobilephone[0].username) //输入手机号用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserMobilephone[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }) // 执行用例执行用例之后清除登录信息 afterEach(function () { // 清除cookies cy.clearCookies() }) }) 运行测试用例 运行脚本：npm run cypress:open 点击运行 testLogin_guanggoo_data_by_js.js 用例 查看运行结果 (测试数据能正常获取到) fixture 测试数据驱动介绍 fixture 数据驱动方式是 cypress 框架推荐的方法，支持的格式也很多，如.json/txt/html/jpg/gif/mp3/zip 等，具体可参考：https://docs.cypress.io/api/commands/fixture\n简介 Cypress 使用 cypress/fixture 目录存放 json 文件数据，cy.fixture() 加载测试数据，如果不指定文件路径，默认从 cypress/fixtures 文件下去查找，也可以自己设置文件路径\n使用方法 以 json 格式读取举例介绍\n新建测试数据 json 文件 示例：在项目的 cypress/fixtures 文件夹下新建一个 json 文件，示例文件名为：testLoginData.json\ntestLoginData.json 示例代码如下（账号密码记得换成自己的）：\n\u0026#34;testLoginUserEmail\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确邮箱账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;dengnao.123@163.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; }, \u0026#34;testLoginUserId\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确 id 账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;waitnoww\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; }, \u0026#34;testLoginUserMobilephone\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确手机号账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;18888889031\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; } } 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_fixture.js\n示例代码如下：\ndescribe(\u0026#34;光谷社区登录验证\u0026#34;, function () { // 执行用例执行用例之前先进入首页 beforeEach(function () { // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 // 获取测试数据 cy.fixture(\u0026#39;testLoginData.json\u0026#39;).as(\u0026#39;loginData\u0026#39;) }) //正确邮箱账号登录 it(\u0026#34;正确邮箱账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserEmail.username) //输入邮箱用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserEmail.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确ID账号登录 it(\u0026#34;正确id账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserId.username) //输入ID用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserId.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确手机账号登录 it(\u0026#34;正确手机号账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserMobilephone.username) //输入手机号用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserMobilephone.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }) // 执行用例执行用例之后清除登录信息 afterEach(function () { // 清除cookies cy.clearCookies() }) }) 运行测试用例 运行脚本：npm run cypress:open 点击运行 testLogin_guanggoo_data_by_fixture.js 用例 查看运行结果 (测试数据能正常获取到) 方法封装参数化 简介 cypress 框架提供了一个 commands.js 可以自定义各种命令，用来封装各种通用方法，参数化方法，常用脚本等；\n将常用的通用方法如登录方法在 cypress/support/commands.js 中编写完成之后，与 cy.get()/cy.visit() 一样，可以直接用 cy.xxx() 形式调用，非常方便，减少维护成本\n使用介绍 示例会介绍常用的参数化登录命令和进入首页命令\n登录参数化登录封装 代码编写 打开 cypress/support/commands.js 文件 输入如下代码： Cypress.Commands.add(\u0026#34;login\u0026#34;,(username,password) =\u0026gt; { cy.clearCookies() //清除 cookies,保证页面为未登录状态 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问 url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标 url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(username) //输入参数化的用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(password) //输入参数化的密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;:nth-child(2) \u0026gt; .nav-collapse\u0026#39;).should(\u0026#39;contain\u0026#39;, \u0026#39;设置\u0026#39;) //验证登录成功回到首页，设置按钮展示正确 }) 代码使用 在测试用例中可直接进行方法调用 cy.login(username,password) 换成自己的账号密码进行登录操作了 cy.login(\u0026#34;dengnao.123@163.com\u0026#34;,\u0026#34;xxxx\u0026#34;) 进入首页方法封装 代码编写 打开 cypress/support/commands.js 文件 输入如下代码： Cypress.Commands.add(\u0026#34;initHomePage\u0026#34;,() =\u0026gt; { cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问 url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标 url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) 代码使用 在测试用例中可直接进行方法调用 cy.initHomePage() 即可进入首页 cy.initHomePage() 测试框架介绍 简介 Cypress 框架采用了 Mocha 框架的语法，故 Mocha 框架的测试语法可在 cypress 上直接使用\n语法介绍 describe() 定义测试套件，里面还可以定义多个 context 或 it\ncontext() 定义测试套件，是 describe() 的别名，可以替代 describe\nit() 定义测试用例\nbefore() 在一个测试套件中的所有测试用例之前执行，设置一些运行 testcase 的前置条件\n// runs once before the first test in this block }); beforeEach() 在每个测试用例之前执行\n// 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) afterEach() 在每个测试用例之后执行，可以执行清除数据等操作\n// 清除 cookies cy.clearCookies() }) after() 在一个测试套件中的所有测试用例之后执行\n// runs once after the last test in this block }); .only() 设置只执行某个 testcase/testsuite\ndescribe.only(\u0026#39;#indexOf()\u0026#39;, function() { // ... }); }); .skip() 设置跳过执行某个 testcase/testsuite\ndescribe(\u0026#39;#indexOf()\u0026#39;, function() { it.skip(\u0026#39;should return -1 unless present\u0026#39;, function() { // this test will not be run }); it(\u0026#39;should return the index when present\u0026#39;, function() { // this test will be run }); }); }); 参考网址 https://docs.cypress.io/guides/references/bundled-tools#Mocha 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo4/","summary":"下面的信息是自动化测试框架学习第四篇数据驱动方法封装参数化和测试框架的介绍。 在自动化测试框架学习中，有很多方法可以用来驱动测试框架。例如，数据驱动方法封装参数化和测试框架。这两个方法都可以将测试框架的数据处理和预设环境等现有模型结合起来。这样就可以方便地开发、测试和运行新的测试框架。\n测试数据驱动 js 格式测试数据驱动 简介 数据以 js 格式存储，使用 js 的 import 方法导入使用\n使用方法 新建测试数据 js 文件 示例：在项目的 cypress/integration 文件夹下新建 testData 目录，然后在该目录下创建一个 js 文件，示例文件名为：testLogin.data.js\ntestLogin.data.js 示例代码如下：\nexport const testLoginUserEmail = [ { summary: \u0026#34;正确邮箱账号登录验证\u0026#34;, username:\u0026#34;dengnao.123@163.com\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserId = [ { summary: \u0026#34;正确id账号登录验证\u0026#34;, username:\u0026#34;waitnoww\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserMobilephone = [ { summary: \u0026#34;正确手机号账号登录验证\u0026#34;, username:\u0026#34;18888139031\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_js.js\n示例代码如下：\nimport { testLoginUserEmail, testLoginUserId, testLoginUserMobilephone } from \u0026#34;.","title":"Cypress UI 自动化测试框架学习（4）- 数据驱动，方法封装参数化和测试框架"},{"content":"下面的信息是对于框架学习第 3 篇的介绍。在该篇文章中，我们学习了如何使用元素定位、操作和断言。该框架可以帮助用户定位相关的元素，并且可以帮助用户进行操作。这些操作可以帮助用户断言事件。\n元素定位 谈到 UI 自动化测试，不管是 web 端还是移动端，页面元素的各种操作在编写测试脚本时都会涉及，如果想写出高通过率和高健壮性的自动化测试用例，必须要确保正确高效的页面元素识别和使用。\ncypress 框架除了支持常用的元素定位，还提供了好用的 JQuery css 选择器。\n下面会介绍常用的元素定位方法，常用的定位方式，以及框架自带可视化自助元素定位方法\n常用元素定位 #id 定位 描述：通过元素的 id 属性来定位\n前提：定位的元素 css 样式须存在 id 属性且唯一\n//元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码 cy.get('#email') .class 定位 描述：通过元素的 class 属性来定位\n前提：定位的元素 css 样式存在 class 属性且唯一\n//元素前端代码示例 \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;img width=\u0026quot;150\u0026quot; height=\u0026quot;28\u0026quot; border=\u0026quot;0\u0026quot; align=\u0026quot;default\u0026quot; alt=\u0026quot;光谷社区\u0026quot; src=\u0026quot;http://cdn.guanggoo.com//static/images/guanggoonew.png\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\n示例代码 cy.get('.navbar-brand')\nname 定位 描述：通过元素 name 定位\n前提：定位的元素 css 样式存在 name 属性且唯一 //元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码\ncy.get('input[name=\u0026quot;email\u0026quot;]')\n常用定位方式 .get() 描述：使用 get() 定位元素，定位元素用 CSS selectors，跟 jQuery 一样 示例代码 cy.get('#email')\n.contains() 描述：可以使用 cy.contains（）根据元素的内容找到元素\n示例代码\ncy.contains(‘value’) cy.get(‘div[name=“div_name”]’).contains(‘value’)\n.within() 描述：可以在特定的 DOM 元素中找到元素\n示例代码\ncy.get('.query-form').within(() =\u0026gt; { cy.get('input:first').should('have.attr', 'placeholder', 'Email') cy.get('input:last').should('have.attr', 'placeholder', 'Password') })\nCypress.$ 描述：Cypress 也提供了 JQuery 选择器，调用 Cypress.$(\u0026lsquo;button\u0026rsquo;）会自动在您的窗口中查询元素。换句话说，Cypress 会自动将文档设置为您当前通过 cy.visit() 导航到的任何内容，这是从开发人员工具调试时同步查询元素的好方法。\n示例代码\nCypress.$(selector) // other proxied jQuery methods Cypress.$.Event Cypress.$.Deferred Cypress.$.ajax Cypress.$.get Cypress.$.getJSON Cypress.$.getScript Cypress.$.post\n框架自带可视化自助元素定位 1.前提：demo 代码已经跑起来 (运行脚本：npm run cypress:open) 2.点击运行调试用例，进入定位元素对应的页面 3.在页面上选择瞄准镜标识（open selector playground）\n4.选择页面上的元素区域，元素的定位信息就会展示在定位信息展示区域，点击复制就可使用\n元素常用操作 .click() 描述：单击\n示例代码\ncy.get('.btn-success').click()\n.type(value) 描述：输入内容\n示例代码 cy.get(‘input[name=“username”]’).type(\u0026lsquo;dengnao.123@163.com\u0026rsquo;)``\n.clear() 描述：清空输入内容\n示例代码\ncy.get(‘[type=“text”]’).clear()\n.submit() 描述：提交表单\n示例代码\ncy.get(‘.ant-input’).submit()\n.dbclick()/.rightclick() 描述：鼠标双击操作/鼠标右击操作\n示例代码\ncy.get('.menu').rightclick() // 鼠标右击 .menu 菜单元素\n.select() 描述：针对元素选择一个选项\n示例代码\ncy.get('color').select('red') // 颜色选项中选择红色\n.check()/.uncheck() 描述：单选或多选进行勾选/取消选中 (反选)\n示例代码\ncy.get('[type=\u0026quot;checkbox\u0026quot;]').check() // 对 checkbox 进行选中操作 cy.get('[type=\u0026quot;checkbox\u0026quot;]').uncheck() // 对 checkbox 进行取消选中操作\n.focus()/.blur() 描述：对选项进行聚焦/失焦操作\n示例代码\ncy.get(‘input[name=“username”]’).focus() //对于用户名输入框进行聚焦操作\n断言 BDD 断言 断言类型 .should()： 描述：创建断言，断言会自动重试，直到它们通过或超时。\n示例代码\ncy.get(‘.ant-checkbox).should(‘be.checked’)\n.expect()： 描述：预期结果\n示例代码\nexpect(name).to.not.equal(‘dengnao.123@163.com’)\n常用断言 可参考官网文档:https://docs.cypress.io/guides/references/assertions#BDD-Assertions\nTDD 断言 断言类型 .assert()： 描述：断言\n示例代码\nassert.equal(3,3,’vals equal’)\n常用断言 可参考官网文档:https://docs.cypress.io/guides/references/assertions#TDD-Assertions\n常用断言 针对长度（length）的断言 `//重试，直到找到 3 个匹配的\u0026lt;li.selected\u0026gt; cy.get('li.selected').should('have.length',3)` 针对类（Class）的断言 `//重试，直到 input 元素没有类被 disabled 为止（或者超时为止） cy.get('from').fijd('input').should('not.have.class','disabled')` 针对值（Value）断言 `//重试，直到 textarea 的值为‘iTesting’ cy.get('textarea').should('have.value','iTesting')` 针对文本内容（Text Content）的断言 //重试，直到这个 span 不包含“click me”字样 cy.get('a').parent('span.help').should('not.contain','click me') //重试，直到这个 span 包含“click me”字样 cy.get('a').parent('span.help').should('contain','click me')\n针对元素可见与否（Visibility）的断言 //重试，直到这个 button 是可为止 cy.get('button').should('be.visible')\n针对元素存在与否（Existence）的断言 //重试，直到 id 为 loading 的 spinner 不在存在 cy.get('#loading').should('not.exist')\n针对元素状态的（status）的断言 `//重试，直到这个 radio button 是选中状态 cy.get('：radio').should('be.checked')` 针对 CSS 的断言 `//重试，直到 completed 这个类有匹配的 css 为止 cy.get('.completed').should('have.css','text-decoration','line-through')` 运行出错问题记录 运行 npm run cypress:open 报错，提示 No version of Cypress is installed 报错截图如下： 修复方式 //项目根目录下运行如下命令即可解决 ./node_modules/.bin/cypress install\n原因 电脑使用过清理软件，安装的 cypress 缓存信息被删除了，重新安装就好\n运行 npm run cypress:open 报错，提示 Cypress verification timed out 报错截图如下： 修复方式 重新运行 npm run cypress:open 尝试即可\n原因 电脑 cypress 验证超时了，一般重新操作即可恢复\n欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo3/","summary":"下面的信息是对于框架学习第 3 篇的介绍。在该篇文章中，我们学习了如何使用元素定位、操作和断言。该框架可以帮助用户定位相关的元素，并且可以帮助用户进行操作。这些操作可以帮助用户断言事件。\n元素定位 谈到 UI 自动化测试，不管是 web 端还是移动端，页面元素的各种操作在编写测试脚本时都会涉及，如果想写出高通过率和高健壮性的自动化测试用例，必须要确保正确高效的页面元素识别和使用。\ncypress 框架除了支持常用的元素定位，还提供了好用的 JQuery css 选择器。\n下面会介绍常用的元素定位方法，常用的定位方式，以及框架自带可视化自助元素定位方法\n常用元素定位 #id 定位 描述：通过元素的 id 属性来定位\n前提：定位的元素 css 样式须存在 id 属性且唯一\n//元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码 cy.get('#email') .class 定位 描述：通过元素的 class 属性来定位\n前提：定位的元素 css 样式存在 class 属性且唯一\n//元素前端代码示例 \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;img width=\u0026quot;150\u0026quot; height=\u0026quot;28\u0026quot; border=\u0026quot;0\u0026quot; align=\u0026quot;default\u0026quot; alt=\u0026quot;光谷社区\u0026quot; src=\u0026quot;http://cdn.guanggoo.com//static/images/guanggoonew.png\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\n示例代码 cy.get('.navbar-brand')\nname 定位 描述：通过元素 name 定位\n前提：定位的元素 css 样式存在 name 属性且唯一 //元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;","title":"Cypress UI 自动化测试框架学习（3）- 元素定位，操作和断言"},{"content":"下面的信息是介绍 cypress 自动化测试框架学习第 3 篇的测试报告的内容 主要介绍一下如何去使用不同格式的 cypress 自动化测试报告模版\n写在前面 由于 Cypress 测试报告是建立在 Mocha 测试报告之上的，这意味着任何为 Mocha 构建的报告程序都可以与 Cypress 一起使用。\n以下是内置的 Mocha 测试类型列表（Cypress 也同样支持）：https://mochajs.org/#reporters\n前置准备工作 在 package.json 文件的 scripts 模块加入了如下脚本：\u0026ldquo;cypress:run\u0026rdquo;:\u0026ldquo;cypress run\u0026rdquo;，便于后面生成报告\n不同运行脚本的区别：\ncypress run：是以无头浏览器模式跑测试用例文件夹下的所有测试用例 cypress open：会打开测试用例集的界面，需要手动运行 常用报告类型 spec 格式报告 运行命令 $ npm run cypress:run --reporter=spec 报告截图 Dot 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026quot;: \u0026ldquo;dot\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 json 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;json\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 List 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;list\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 NYAN 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;nyan\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 高大上报告类型 Mochawesome 格式报告 前置：安装 Mocha、Mochawesome 至项目中 npm install --save-dev mocha npm install --save-dev mochawesome 在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;mochawesome\u0026quot;信息\n运行命令\n$ npm run cypress:run 报告截图 allure 格式报告 前置：安装 allure（推荐使用 brew 安装） $ brew install allure 在 cypress.json 文件新增如下信息 \u0026#34;reporter\u0026#34;: \u0026#34;junit\u0026#34;, \u0026#34;reporterOptions\u0026#34;: { \u0026#34;mochaFile\u0026#34;: \u0026#34;results/test_report_[hash].xml\u0026#34;, \u0026#34;toConsole\u0026#34;: true } 运行命令 $ npm run cypress:run 生成报告 $ allure serve results 报告截图 Dashboard 格式报告 待完善，参考资料：https://docs.cypress.io/guides/dashboard/introduction#Features\n运行命令 npx cypress run --record --key 7aaee33b-f67b-4993-8d6c-2c392a1bd1c8 报告截图 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo2/","summary":"下面的信息是介绍 cypress 自动化测试框架学习第 3 篇的测试报告的内容 主要介绍一下如何去使用不同格式的 cypress 自动化测试报告模版\n写在前面 由于 Cypress 测试报告是建立在 Mocha 测试报告之上的，这意味着任何为 Mocha 构建的报告程序都可以与 Cypress 一起使用。\n以下是内置的 Mocha 测试类型列表（Cypress 也同样支持）：https://mochajs.org/#reporters\n前置准备工作 在 package.json 文件的 scripts 模块加入了如下脚本：\u0026ldquo;cypress:run\u0026rdquo;:\u0026ldquo;cypress run\u0026rdquo;，便于后面生成报告\n不同运行脚本的区别：\ncypress run：是以无头浏览器模式跑测试用例文件夹下的所有测试用例 cypress open：会打开测试用例集的界面，需要手动运行 常用报告类型 spec 格式报告 运行命令 $ npm run cypress:run --reporter=spec 报告截图 Dot 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026quot;: \u0026ldquo;dot\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 json 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;json\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 List 格式报告 前置：在 cypress.","title":"Cypress UI 自动化测试框架学习（2）- 测试报告"},{"content":"下面的信息是对 Cypress 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\nIntroduction 基于 JavaScript 的前端自动化测试工具，可以对浏览器中运行的任何内容进行快速、简单、可靠的测试\nCypress 是自集成的，提供了一套完整的端到端测试，无须借助其他外部工具，安装后即可快速地创建、编写、运行测试用例，且对每一步操作都支持回看\n不同于其他只能测试 UI 层的前端测试工具，Cypress 允许编写所有类型的测试，覆盖了测试金字塔模型的所有测试类型【界面测试，集成测试，单元测试】\nCypress 官网：https://www.cypress.io/\nGetting Started 下面以 MacOS 来进行介绍，其他系统可参考官网信息\nOperating System macOS 10.9 and above (64-bit only) Node.js 12 or 14 and above Before Started 已安装好 node.js 和 npm 已安装好 vs code 或者其他代码编辑器 Started and Run Step1：通过 npm 新建项目 # 新建项目文件夹 $ mkdir cypress-demo # 进入项目文件夹 $ cd cypress-demo # npm项目环境准备 $ npm init Step2：安装 cypress # 项目安装cypress包 $ npm install cypress --save-dev Step3：运行 cypress 程序 若提示：npm ERR! missing script: cypress:open，可在项目根目录 package.json 文件的 scripts 下新增\u0026quot;cypress:open\u0026quot;: \u0026ldquo;cypress open\u0026rdquo;，保存后再次运行命令即可\n# 启动demo $ npm run cypress:open Started Screenshot 运行截图 demo 用例执行截图 Try First Testscript Testcase 1.访问光谷社区主页http://www.guanggoo.com/ 2.验证是否正确跳转到光谷社区页面 3.验证网页标题是否正确 4.点击登录按钮，验证正确跳转到登录页面 5.在登录页面输入用户名和输入密码 6.点击登录按钮，验证登录成功 Testscript 在项目 cypress/integration 下新建 demo 文件夹\n在 demo 文件夹下新建 demo-guanggoo.js\ndemo-guanggoo.js 编写测试脚本\n脚本中账号密码需换成自己的账号密码\ndescribe(\u0026#39;first testcase for cypress\u0026#39;,function(){ it(\u0026#39;visit guanggoo homepage and login for guanggoo:\u0026#39;,function(){ // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;,\u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;,\u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;,\u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(\u0026#39;dengnao.123@163.com\u0026#39;) //输入用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(\u0026#39;xxxxxxx\u0026#39;) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 }) }) Run Screenshot 运行 cypress 程序 # 启动 $ npm run cypress:open 页面上选择点击运行 demo-guanggoo.js 即可 运行通过无报错，代表用例编写成功 欢迎关注软件测试同学的公众号“软件测试同学”，原创 QA 技术文章第一时间推送。\n","permalink":"https://naodeng.com.cn/zh/posts/others/cypress-demo1/","summary":"下面的信息是对 Cypress 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\nIntroduction 基于 JavaScript 的前端自动化测试工具，可以对浏览器中运行的任何内容进行快速、简单、可靠的测试\nCypress 是自集成的，提供了一套完整的端到端测试，无须借助其他外部工具，安装后即可快速地创建、编写、运行测试用例，且对每一步操作都支持回看\n不同于其他只能测试 UI 层的前端测试工具，Cypress 允许编写所有类型的测试，覆盖了测试金字塔模型的所有测试类型【界面测试，集成测试，单元测试】\nCypress 官网：https://www.cypress.io/\nGetting Started 下面以 MacOS 来进行介绍，其他系统可参考官网信息\nOperating System macOS 10.9 and above (64-bit only) Node.js 12 or 14 and above Before Started 已安装好 node.js 和 npm 已安装好 vs code 或者其他代码编辑器 Started and Run Step1：通过 npm 新建项目 # 新建项目文件夹 $ mkdir cypress-demo # 进入项目文件夹 $ cd cypress-demo # npm项目环境准备 $ npm init Step2：安装 cypress # 项目安装cypress包 $ npm install cypress --save-dev Step3：运行 cypress 程序 若提示：npm ERR!","title":"Cypress UI 自动化测试框架学习（1）- 上手"}]