[{"content":"K6 常用功能 HTTP Requests 使用 K6 进行性能测试的第一步就是定义要测试的 HTTP 请求。\nGET 请求例子 使用 k6 new 命令创建的 demo 测试脚本中，已经包含了一个简单的 GET 方法 HTTP 请求：\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export default function() { http.get(\u0026#39;https://test.k6.io\u0026#39;); sleep(1); } POST 请求例子 这个 POST 请求例子展示一些复杂的场景的应用（带有电子邮件/密码身份验证负载的 POST 请求）\nimport http from \u0026#39;k6/http\u0026#39;; export default function () { const url = \u0026#39;http://test.k6.io/login\u0026#39;; const payload = JSON.stringify({ email: \u0026#39;aaa\u0026#39;, password: \u0026#39;bbb\u0026#39;, }); const params = { headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, }; http.post(url, payload, params); } 以上内容参考自 K6 官方文档\n支持的 HTTP 方法 K6 提供的 HTTP 模块能处理各种 HTTP 请求和方法。以下是支持的 HTTP 方法列表：\n方法 作用 batch() 并行发出多个 HTTP 请求（例如浏览器往往会这样做）。 del() 发出 HTTP DELETE 请求。 get() 发出 HTTP GET 请求。 head() 发出 HTTP HEAD 请求。 options() 发出 HTTP OPTIONS 请求。 patch() 发出 HTTP PATCH 请求。 post() 发出 HTTP POST 请求。 put() 发出 HTTP PUT 请求。 request() 发出任何类型的 HTTP 请求。 HTTP 请求标签 K6 允许为每个 HTTP 请求添加标签，结合标签和分组，可以很方便的在测试结果中更好地组织，分组请求和过滤结果组织分析。\n以下为支持的标签列表：\n标签 作用 name 请求名称。默认为请求的 URL method 请求方法（GET、POST、PUT 等） url 默认为请求的 URL。 expected_response 默认情况下，200 到 399 之间的响应状态为 true。使用 setResponseCallback 更改默认行为。 group 当请求在组内运行时，标记值是组名称。默认为空。 scenario 当请求在场景内运行时，标记值是场景名称。默认为 default。 status 响应状态 HTTP 请求使用 tag 和 group 标签的例子会在后续的 demo 中展示。\n大家也可以参考官方的例子：https://grafana.com/docs/k6/latest/using-k6/http-requests/\nMetrics 指标 指标用于衡量系统在测试条件下的性能。默认情况下，k6 会自动收集内置指标。除了内置指标，您还可以创建自定义指标。\n指标一般分为四大类：\n计数器（Counters）：对值求和。 计量器（Gauges）：跟踪最小、最大和最新的值。 比率（Rates）：跟踪非零值发生的频率。 趋势（Trends）：计算多个值的统计信息（如均值、模式或百分位数）。 要使测试断言符合需求标准，可以根据性能测试要求的指标条件编写阈值（表达式的具体内容取决于指标类型）。\n为了后续进行筛选指标，可以使用标签和分组，这样可以更好地组织测试结果。\n测试结果输出文件可以以各种摘要和细粒度格式导出指标，具体信息请参阅结果输出文档。（后面测试结果输出文档会详细介绍这一部分）\nK6 内置指标 每个 k6 测试执行都会发出内置和自定义指标。每个支持的协议也有其特定的指标。\n标准内置指标 无论测试使用什么协议，k6 始终收集以下指标：\n指标名称 指标分类 指标描述 vus Gauge 当前活跃虚拟用户数 vus_max Gauge 最大可能虚拟用户数（VU 资源已预先分配，以避免扩大负载时影响性能） iterations 迭代 Counter VU 执行 JS 脚本（default 函数）的总次数。 iteration_duration Trend 完成一次完整迭代的时间，包括在 setup 和 teardown 中花费的时间。要计算特定场景的迭代函数的持续时间，请尝试此解决方法 dropped_iterations Counter 由于缺少 VU（对于到达率执行程序）或时间不足（基于迭代的执行程序中的 maxDuration 已过期）而未启动的迭代次数。关于删除迭代 data_received Counter 接收到的数据量。此示例介绍如何跟踪单个 URL 的数据。 data_sent Counter 发送的数据量。跟踪单个 URL 的数据以跟踪单个 URL 的数据。 checks Rate 设置的检查成功率。 指标分类分别为：计数器（Counter）、计量器（Gauges）、比率（Rates）、趋势（Trends）\nHTTP 特定的内置指标 HTTP 特定的内置指标是仅在 HTTP 请求期间才会生成和收集的指标。其他类型的请求（例如 WebSocket）不会生成这些指标。\n注意：对于所有 http_req_* 指标，时间戳在请求结束时发出。换句话说，时间戳发生在 k6 收到响应正文末尾或请求超时时。\n下表列出了 HTTP 特定的内置指标：\n指标名称 指标分类 指标描述 http_reqs Counter k6 总共生成了多少个 HTTP 请求。 http_req_blocked Trend 在发起请求之前阻塞（等待空闲 TCP 连接槽）所花费的时间。float类型 http_req_connecting Trend 与远程主机建立 TCP 连接所花费的时间。float类型 http_req_tls_handshaking Trend 与远程主机握手 TLS 会话所花费的时间 http_req_sending Trend 向远程主机发送数据所花费的时间。float类型 http_req_waiting Trend 等待远程主机响应所花费的时间（也称为“第一个字节的时间”或“TTFB”）。float类型 http_req_receiving Trend 从远程主机接收响应数据所花费的时间。float类型 http_req_duration Trend 请求的总时间。它等于 http_req_sending + http_req_waiting + http_req_receiving（即远程服务器处理请求和响应所需的时间，没有初始 DNS 查找/连接时间）。float类型 http_req_failed Rate 根据 setResponseCallback 的失败请求率。 指标分类分别为：计数器（Counter）、计量器（Gauges）、比率（Rates）、趋势（Trends）\n其他内置指标 K6 内置指标除了标准内置指标和 HTTP 特定的内置指标外，还有其他内置指标：\nBrowser metrics 浏览器指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#browser Built-in WebSocket metrics 内置 WebSocket 指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#websockets Built-in gRPC metrics 内置 gRPC 指标：https://grafana.com/docs/k6/latest/using-k6/metrics/reference/#grpc 自定义指标 除了系统内建的指标之外，您还可以创建自定义指标。例如，您可以计算与业务逻辑相关的指标，或者利用 Response.timings 对象为特定的一组端点创建指标。\n每种指标类型都有一个构造函数，用于生成自定义指标。该构造函数会生成一个声明类型的指标对象。每种类型都有一个 add 方法，用于记录指标测量值。\n注意：必须在 init 上下文中创建自定义指标。这会限制内存并确保 K6 可以验证所有阈值是否评估了定义的指标。\n自定义指标 demo 示例 以下示例演示如何创建等待时间的自定义趋势指标：\n项目文件中的 demo_custom_metrics.js 文件已经包含了这个 demo 示例，可以直接运行查看结果。\n1.从导入 k6/metrics 模块引入 Trend 构造函数 import { Trend } from \u0026#39;k6/metrics\u0026#39;; 等待时间趋势指标属于趋势（Trends）指标，所以需要从 k6/metrics 模块引入 Trend 构造函数。\n2.在 init 上下文中构造一个新的自定义度量 Trend 对象 const myTrend = new Trend(\u0026#39;waiting_time\u0026#39;); 在 init 上下文中构造一个新的自定义度量 Trend 对象，脚本中的对象为 myTrend，其指标在结果输出中显示为 waiting_time。\n3.在脚本中使用 add 方法记录指标测量值 export default function() { const res = http.get(\u0026#39;https://test.k6.io\u0026#39;); myTrend.add(res.timings.waiting); } 在脚本中使用 add 方法记录指标测量值，这里使用了 res.timings.waiting，即等待时间。\n4.demo_custom_metrics.js 自定义指标完整代码 import http from \u0026#39;k6/http\u0026#39;; import { Trend } from \u0026#39;k6/metrics\u0026#39;; const myTrend = new Trend(\u0026#39;waiting_time\u0026#39;); export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); myTrend.add(res.timings.waiting); console.log(myTrend.name); // waiting_time } 5.运行 demo_custom_metrics.js 并查看自动化趋势指标 k6 run demo_custom_metrics.js 运行结果如下：\n可以看到，自定义指标 waiting_time 已经在结果输出中显示出来了。\n更多关于自定义指标的内容，请参考官方文档：https://k6.io/docs/using-k6/metrics/#custom-metrics\nChecks 检查 这里也可以理解为断言，即对测试结果进行验证。\n检查用来检验不同测试中的具体测试条件是否正确相应，和我们常规在做其他类型测试时也会对测试结果进行验证，以确保系统是否以期望的内容作出响应。\n例如，一个验证可以确保 POST 请求的响应状态为 201，或者响应体的大小是否符合预期。\n检查类似于许多测试框架中称为断言的概念，但是K6 在验证失败并不会中止测试或以失败状态结束。相反，k6 会在测试继续运行时追踪失败验证的比率。\n每个检查都创建一个速率指标。要使检查中止或导致测试失败，可以将其与阈值结合使用。\n下面会介绍如何使用不同类型的检查，以及如何在测试结果中查看检查结果。\n1.检查 HTTP 响应状态 K6 的检查非常适用于与 HTTP 请求相关的响应断言。\n示例，以下代码片段来检查 HTTP 响应代码为 200：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, }); } 运行该脚本，可以看到如下结果：\n当脚本包含检查时，摘要报告会显示通过了多少测试检查。\n在此示例中，请注意检查“HTTP response code is status 200”在调用时是 100% 成功的。\n2.检查 HTTP 响应体 除了检查 HTTP 响应状态外，还可以检查 HTTP 响应体。\n示例，以下代码片段来检查 HTTP 响应体大小为 9591 bytes：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response body size is 9591 bytes\u0026#39;: (r) =\u0026gt; r.body.length == 9591, }); } 运行该脚本，可以看到如下结果：\n当脚本包含检查时，摘要报告会显示通过了多少测试检查。\n在此示例中，请注意检查“HTTP response body size is 9591 bytes”在调用时是 100% 成功的。\n3.添加多个检查 有时候我们在一个测试脚本中需要添加多个检查，那可以直接在单​​个 check() 语句中添加多个检查，如下面脚本所示：\nimport { check } from \u0026#39;k6\u0026#39;; import http from \u0026#39;k6/http\u0026#39;; export default function () { const res = http.get(\u0026#39;https://httpbin.test.k6.io\u0026#39;); check(res, { \u0026#39;HTTP response code is status 200\u0026#39;: (r) =\u0026gt; r.status === 200, \u0026#39;HTTP response body size is 9591 bytes\u0026#39;: (r) =\u0026gt; r.body.length == 9591, }); } 运行该脚本，可以看到如下结果：\n在此示例中，两个检查都是正常通过的（调用是 100% 成功的）。\n注意：当检查失败时，脚本将继续成功执行，并且不会返回“失败”退出状态。如果您需要根据检查结果使整个测试失败，则必须将检查与阈值结合起来。这在特定环境中特别有用，例如将 k6 集成到 CI 管道中或在安排性能测试时接收警报。\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ ","permalink":"https://naodeng.com.cn/posts/performance-testing/k6-tutorial-common-functions-1-http-request-metrics-and-checks/","summary":"这篇文章详细介绍了 K6 中的 HTTP 请求（http request）功能，解析了常用的性能指标和检查功能。学会如何使用 K6 进行强大的性能测试，通过 HTTP 请求模拟用户行为，了解性能指标以评估系统响应。文章还深入讲解了如何配置和执行检查，确保性能符合预期标准。无论您是初学者还是经验丰富的性能测试专业人员，这篇教程将为您提供实用知识，助您充分发挥 K6 的性能测试潜力。点击链接，开启高效性能测试之旅！","title":"K6 性能测试教程：常用功能（1）- HTTP 请求，指标和检查"},{"content":"文章由 UI 测试最佳实践项目 内容翻译而来，大家有条件的话可以去 UI 测试最佳实践项目阅读原文。\n什么样的测试策略才更合理 上一篇文章讲到了不同的测试类型，以及它们的优缺点。在这篇文章中，我们将深入探讨什么样的测试策略才更为合理。 会从在开始阶段，避免追求完美主义，选择一个参考浏览器，发现了 bug？先编写测试，然后再着手修复，和单个长的端到端测试还是多个小的独立测试？等方面阐述了什么样的测试策略才更合理\n在开始阶段，避免追求完美主义 测试真的改变了你的工作方式，但就像所有事情一样，需要一些经验才能真正发挥其威力。在一开始，务必避免完美主义的陷阱。为什么呢？\n测试本质上就是小程序。完美主义可能会导致你在了解如何处理不同的测试上下文之前编写非常复杂的测试。\n复杂的测试是个大敌人，因为调试失败的测试比调试失败的应用程序更加困难。而且复杂的测试让你失去了测试实践本身的优势，浪费了很多时间，最终不可避免地会让你放弃。如果你有这样的经历，不要气馁，对很多测试初学者来说都是一样的（对我来说也是，这就是我开始写这个 repo 的原因 😊），不要害怕向同事或其他开发人员寻求帮助。\n误报：完美主义导致很多误报。误报是指应用程序按预期工作，但测试失败的情况。\n误报在一开始确实让人泄气，因为你开始写测试是为了有一个盟友来检查应用程序状态\u0026hellip; 但最终你却得到了另一个需要维护的应用程序，而测试并没有提供任何帮助。如果你发现自己在与误报作斗争，请停下来，重新学习，并寻求帮助！\n测试的实用性：成功的测试在失败时直接指向问题。正确的断言和确定性事件使你的测试强大而且非常重要的是，它们在失败时是有用的。相反，过多的断言和检查可能会使你的测试因为无用而变得脆弱。\n所谓完美主义是指检查每一个前端细节。在开始时，你的有限的测试经验不允许你有针对性地测试所有的交互。开始时，测试一些简单的事情，比如\n页面是否正确加载？ 菜单按钮是否正常工作？ 用户是否能够填写表单并成功跳转到感谢页面？ 而在开始阶段，不要过于关注测试一些诸如\n条件数据加载 复杂的表单规则 无控制的（第三方）集成 元素选择器 等复杂的交互。 为了避免陷入完美主义的陷阱，初学者的待办事项清单可以是：\n选择最简单的测试对象（对用户有用的东西）。 从用户的角度考虑。记住用户关心内容和功能，而不关心选择器和内部应用程序状态。 编写你的测试。 运行测试多次以确保它的稳定性。 当测试成功时，在前端应用程序中插入一个导致它失败的错误，然后检查测试是否失败。然后移除你故意插入的错误。 以无头和非无头模式运行测试。 根据你的经验（也问问同事），思考从你测试的内容的角度看，可能导致前端应用程序失败的原因是什么。 模拟不同的前端故障（关闭服务器、插入其他错误）并检查测试是否提供足够的反馈，以了解哪里失败了。 仅对两三种故障进行测试，记住你有限的经验可能导致你测试错误的东西。 然后，转移到另一个测试对象并重复所有先前的步骤。 软件测试是一场奇妙的旅程，这个 repo 的目标是帮助你避免最常见的陷阱。\n建议的流程只是可能方法之一。我知道一切都是主观的，请为每个建议提出请求以进行改进！\n选择一个参考浏览器 每个人都关心跨浏览器测试。我们通常习惯在每个浏览器上手动测试所有内容，因为我们知道，不同浏览器之间存在许多差异。当我们开始评估合适的测试工具时，跨浏览器测试是一个重要的话题，也是你在考虑时可能首先想到的。但是不要担心：首先从功能测试和视觉测试分离开始，这是正确评估跨浏览器支持需求（也是选择正确测试工具的第一步）。视觉测试可以集成到每个测试工具中，感谢诸如 Applitools 和 Percy 这样的服务。\n换句话说，不要仅仅基于跨浏览器支持来选择测试工具。以下是一些建议：\nSelenium 和 Puppeteer 是通用的自动化工具。它们可以用作测试工具（有许多插件和模块可帮助你实现），但它们并非专为测试而设计，因此它们缺少一些集成实用工具，这可能使测试编写更加简便。\n只考虑 Cypress、Playwright 和 TestCafé，因为它们是专为简化 UI 测试过程而创建的工具。这些工具自动处理一半的最佳实践，而在测试中的一些方面，它们可能更符合你的需求。在 UI 测试方面，由于其\n困难性，花些时间试验这些工具是值得的。\n仔细思考你需要测试什么。如果你需要测试特定的移动能力，请选择 TestCafé，但如果你只需要测试表单和按钮是否正常工作，你在选择上就更加灵活。\n查看 Cypress Test Runner，这是使 Cypress 异于常人的工具，对于测试开发过程中非常有帮助。\n研究 Playwright 在调试方面的优势。Playwright 非常快速稳定，最近其开发体验有了很大改进。\n跨浏览器测试通常涉及到视觉测试（CSS 浏览器差异），但这与功能测试不同。视觉测试得益于许多专用插件和工具的支持。详细了解 视觉测试对应的章节 Applitools，其中我们讨论了一些专用产品，这些产品可以与几乎所有测试工具集成，通过将被测试页面的快照上传到其服务器并进行呈现来进行工作。\n你还可以在 等待，不是休眠 章节中了解各种测试工具之间的一些差异。\n发现了 bug？先编写测试，然后再着手修复 所以，当你在前端应用程序中发现错误并已经进行了调试时，你可以系统地复现它，准备好修复它。以测试为导向的思维必须经历以下步骤：\n确定预期的行为。 编写一个测试，旨在以正确的方式使用前端应用程序。 测试必须失败，因为错误不允许用户完成任务。 修复错误。 检查测试现在是否通过。 为什么要采用这种方法？为什么要编写测试呢？我知道直接修复错误可能看起来更快，但请考虑以下几点：\n通常情况下，你的测试工具比你更快地达到显示错误的应用程序状态（参见使用测试工具作为主要开发工具 章节）。\n有时你认为你能够系统地复现错误，但这并不总是正确的。编写一个揭示错误的测试可以确保你百分之百确定错误是可重现的，排除了许多偏差变量，如现有的会话、缓存、服务工作者、浏览器扩展、浏览器版本等，这些可能会影响你的信心。有时你可能会发现你并没有完全正确地识别错误。\n与此同时，当测试通过了你的修复时，你确实知道你的解决方\n案按预期工作。可能影响错误识别过程的相同变量可能会影响工作效果的虚假感觉。\n有了测试，错误就可以永远修复了！ 测试将被执行成千上万次，让你对错误修复感到百分之百的信心。\n成功的测试可以作为你所做工作的验证轨迹。\n最后但同样重要的是：确保你编写的测试一开始是失败的！而且它之所以失败是因为有错误！\n测试不仅仅是为了重现错误并在视觉上检查它，而是必须在修复错误后获得积极的反馈。与错误相关的测试如果一开始就没有失败，那真的非常危险，因为你可能认为你做得很好，而实际上你从一开始就没有完全正确地重现错误。\n作为一般规则：破碎的流程必须有一个破碎的测试，一个成功的测试必须与一个正常工作的应用程序相关联。\n单个长的端到端测试还是多个小的独立测试？ 在讨论对 CRUD 应用进行测试时，我们应该如何组织“创建”、“修改”和“删除”端到端（E2E）测试呢？\n完整的选项列表如下：\n有三个小的 E2E 测试，依赖于执行顺序（测试 B 假设测试 A 已运行）- 这是唯一的不良解决方案，我将解释原因。 有三个小的 E2E 测试，独立于执行顺序（测试 B 不受测试 A 是否运行的影响）- 从理论上讲，是最好的解决方案。但仍然需要大量样板代码，而且为了快速执行。 有一个执行所有操作的扩展 E2E 测试 - 对于本文介绍的案例来说，这是一个很好的折中方案。 这取决于情况，我提到的大多数问题与 E2E 测试的隐含问题有关，这是我们应该尽量减少这类测试的强烈信号。作为前端工程师，我更喜欢投资时间编写无需服务器的测试，而不是 E2E 测试。继续阅读，你将了解原因。\n1 - 有三个小的 E2E 测试，依赖于执行顺序（测试 B 假设测试 A 已运行） 测试流程如下：\n开始（应用程序状态为空） 测试 1: 创建实体 测试 2: 修改实体 测试 3: 删除实体 结束（应用程序状态为空） 在这种情况下，这些测试不是独立的，而是依赖于执行顺序。为了测试 CRUD 流程，有三个主要测试：\u0026ldquo;创建实体\u0026rdquo;、\u0026ldquo;修改实体\u0026rdquo;、\u0026ldquo;删除实体\u0026rdquo;。第二个测试（\u0026ldquo;修改实体\u0026rdquo;）假设在其启动时应用程序状态是正确的，因为它在 \u0026ldquo;创建实体\u0026rdquo; 之后运行。\u0026ldquo;删除实体\u0026rdquo; 也必须在 \u0026ldquo;修改实体\u0026rdquo; 之后运行，依此类推。\n将多个测试耦合在一起是一种反模式，原因如下：\n误报：一旦一个测试失败，后续测试会连续失败。 难以调试：由于不确定性较高，理解失败的根本原因更加复杂。测试失败是因为代码本身失败？还是因为先前测试的状态发生了变化？然后，当一个测试失败时，你必须调试两个测试。 难以调试（再次）：开发人员会浪费大量时间，因为他们无法运行单个测试，也无法使用 skip 和 only 仅运行其中一部分测试。 难以重构：测试无法移动到其他位置。如果测试代码变得太长、太复杂等，你无法将其移动到专用文件/目录中，因为它依赖于先前的测试。 难以阅读：读者无法知道一个测试的作用，因为他们还必须了解先前的测试。你必须阅读两个测试，而不是一个，这是不好的。 我不建议以这种方式编写耦合的测试，但我想包含它们以确保您明白原因。\n2 - 设计三个小型端到端（E2E）测试，使其独立于执行顺序 为了确保每个测试的独立性，每个测试在运行前都应该创建所需的应用程序状态，然后在完成后进行清理。相较于原有的顺序（创建-\u0026gt;修改-\u0026gt;删除），前文提到的流程应该调整如下（斜体 表示与原有流程相比的新步骤）：\n开始（应用程序状态为空） 测试 1：创建实体 之前：加载页面（应用程序状态为空） 创建实体 之后：删除实体（应用程序状态为空） 测试 2：修改实体 之前：通过 API 创建实体 之前：加载页面（应用程序状态为空） 修改实体 之后：通过 API 删除实体（应用程序状态为空） 测试 3：删除实体 之前：通过 API 创建实体 之前：加载页面（应用程序状态为空） 删除实体 之后：删除操作（应用程序状态为空） 结束（应用程序状态为空） 通过这种方式，每个测试都是相互独立的。需要注意的是，之前和之后的操作直接通过调用服务器 API 完成，因为通过 UI 完成这些操作将会很慢。然而，这种方法的问题在于测试变得更加耗时，因为每个测试都需要创建实体，并且每个测试都需要访问页面。当应用程序加载需要花费 10 秒钟时（Hasura 的控制台最初的情况），重新加载应用程序将成为一个问题。\n为了确保测试既独立又高效，我们需要进一步改进上述流程：\n充分利用前一个测试的应用状态。 同时，如果尚未运行测试，还需要创建所需的应用状态。 具体来说，流程如下（与前一章节相比，斜体表示新步骤）：\n开始（应用状态为空）\n测试 1： 创建实体\n之前：实体 是否存在？ 否：没问题！ 是：通过 API 删除实体 之前：加载页面（应用状态为空） 创建实体 测试 2： 修改实体\n之前：实体 是否存在？ 是：没问题！ 否：通过 API 创建实体 之前：实体 是否已包含测试即将进行的更改？ 是：没问题！ 否：通过 API 修改实体 之前：我们是否已经在正确的页面上？ 是：没问题！ 否：加载页面 修改实体 测试 3： 删除实体\n之前：实体是否存在？ 是：没问题！ 否：通过 API 创建实体 之前：我们是否已经在正确的页面上？ 是：没问题！ 否：加载页面 删除实体\n结束（应用状态为空）\n现在，如果你一次运行所有测试，每个测试都会利用之前测试的应用状态。如果只运行“修改实体”测试，它会创建所需的一切，然后运行测试本身。\n现在我们既有测试的独立性又有测试的性能！很不错！\n嗯\u0026hellip; 你是否注意到我们需要编写大量代码？cypress-data-session 插件很方便，但存在两个问题：\n有很多与 cypress-data-session 相关的样板代码 在 E2E 测试中，必须维护许多可能与主应用程序中使用的 API 调用不同步的 API 调用。 这是一个与 cypress-data-session 相关的样板代码示例（来自 Hasura Console 代码库）。\nimport { readMetadata } from \u0026#39;../services/readMetadata\u0026#39;; import { deleteHakunaMatataPermission } from \u0026#39;../services/deleteHakunaMatataPermission\u0026#39;; /** * Ensure the Action does not have the Permission. * * ATTENTION: if you get the \u0026#34;setup function changed for session...\u0026#34; error, simply close the * Cypress-controlled browser and re-launch the test file. */ export function hakunaMatataPermissionMustNotExist( settingUpApplicationState = true ) { cy.dataSession({ name: \u0026#39;hakunaMatataPermissionMustNotExist\u0026#39;, // Without it, cy.dataSession run the setup function also the very first time, trying to // delete a Permission that does not exist init: () =\u0026gt; true, // Check if the Permission exists validate: () =\u0026gt; { Cypress.log({ message: \u0026#39;**--- Action check: start**\u0026#39; }); return readMetadata().then(response =\u0026gt; { const loginAction = response.body.actions?.find( action =\u0026gt; action.name === \u0026#39;login\u0026#39; ); if (!loginAction || !loginAction.permissions) return true; const permission = loginAction.permissions.find( permission =\u0026gt; permission.role === \u0026#39;hakuna_matata\u0026#39; ); // Returns true if the permission does not exist return !permission; }); }, preSetup: () =\u0026gt; Cypress.log({ message: \u0026#39;**--- The permission must be deleted**\u0026#39; }), // Delete the Permission setup: () =\u0026gt; { deleteHakunaMatataPermission(); if (settingUpApplicationState) { // Ensure the UI read the latest data if it were previously loaded cy.reload(); } }, }); } 以下是用于创建实体的 API 调用示例（来自 Hasura Console 代码库）。\n/** * Create the Action straight on the server. */ export function createLoginAction() { Cypress.log({ message: \u0026#39;**--- Action creation: start**\u0026#39; }); cy.request(\u0026#39;POST\u0026#39;, \u0026#39;http://localhost:8080/v1/metadata\u0026#39;, { type: \u0026#39;bulk\u0026#39;, source: \u0026#39;default\u0026#39;, args: [ { type: \u0026#39;set_custom_types\u0026#39;, args: { scalars: [], input_objects: [ { name: \u0026#39;SampleInput\u0026#39;, fields: [ { name: \u0026#39;username\u0026#39;, type: \u0026#39;String!\u0026#39; }, { name: \u0026#39;password\u0026#39;, type: \u0026#39;String!\u0026#39; }, ], }, ], objects: [ { name: \u0026#39;SampleOutput\u0026#39;, fields: [{ name: \u0026#39;accessToken\u0026#39;, type: \u0026#39;String!\u0026#39; }], }, { name: \u0026#39;LoginResponse\u0026#39;, description: null, fields: [ { name: \u0026#39;accessToken\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, ], }, { name: \u0026#39;AddResult\u0026#39;, fields: [{ name: \u0026#39;sum\u0026#39;, type: \u0026#39;Int\u0026#39; }], }, ], enums: [], }, }, { type: \u0026#39;create_action\u0026#39;, args: { name: \u0026#39;login\u0026#39;, definition: { arguments: [ { name: \u0026#39;username\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, { name: \u0026#39;password\u0026#39;, type: \u0026#39;String!\u0026#39;, description: null, }, ], kind: \u0026#39;synchronous\u0026#39;, output_type: \u0026#39;LoginResponse\u0026#39;, handler: \u0026#39;https://hasura-actions-demo.glitch.me/login\u0026#39;, type: \u0026#39;mutation\u0026#39;, headers: [], timeout: 25, request_transform: null, }, comment: null, }, }, ], }).then(() =\u0026gt; Cypress.log({ message: \u0026#39;**--- Action creation: end**\u0026#39; })); } 因此，拥有独立的测试是至关重要的，但也伴随着一些成本。\n这就是为什么，针对这个具体问题，我选择了最后一种选择\u0026hellip;\n3 - 进行一次全面的端到端测试 优点：可以减少很多样板文件。\n缺点：与测试一起工作变得更慢了（你不能再仅运行第三个测试了）\n与我们需要编写的样板和需要维护的代码相比，将它们统一起来是值得的。毕竟，我正在处理的特定 CRUD 流程大约需要 20 秒。\n开始 (应用程序状态为空) 测试：CRUD 之前*：如果存在实体，则删除它（应用程序状态为空）* 之前*：加载页面* 创建实体 修改实体 删除实体 之后*：如果存在实体，则删除它（应用程序状态为空）* 结束 (应用程序状态为空) 同时，这也使得 cypress-data-session 变得无用。因此，少了一个需要保持更新的依赖。\n结论 处理端到端测试很困难。处理真实数据、清除真实应用程序状态等都是有成本的。我知道端到端测试是唯一能够提供完整信心的测试，但作为一名前端工程师（请记住，我不是 QA 工程师），我更愿意使用无需服务器的测试。\n相关章节 🔗 从金字塔的顶端着手构建测试！ 🔗 把你的测试工具当作主要的开发工具来使用 由 NoriSte 在 dev.to上进行了跨发表。\n参考资料 UI 测试最佳实践项目:https://github.com/NoriSte/ui-testing-best-practices UI 测试最佳实践项目中文翻译:https://github.com/naodeng/ui-testing-best-practices ","permalink":"https://naodeng.com.cn/posts/ui-automation-testing/ui-testing-best-practice-testing-strategy-2-more-reasonable-testing-strategy-for-ui-testing/","summary":"这篇博文深入探讨 UI 测试最佳实践的测试策略（二），着重介绍了更为合理的测试策略。从避免追求完美主义、选择参考浏览器、发现 Bug 时的处理方式，到在修复之前编写测试、单个长的端到端测试与多个小的独立测试的选择，全面阐述了什么样的测试策略更为合理。无论是初学者还是经验丰富的测试专业人员，这篇博文都将为您提供实用的指导，帮助您制定更明智、高效的 UI 测试策略。点击链接，探索更合理的 UI 测试方法！","title":"UI 测试最佳实践的测试策略（二）：什么样的测试策略才更合理"},{"content":"一段简要说明 在谈论 UI 测试时（请记住我们只谈论 UI，而不是底层 JavaScript 代码），有三种主要的测试类型：\n组件测试：UI 的单元测试，它们在隔离的环境中测试每个单独的组件。\n在隔离中开发组件很重要，因为它允许你将它们与相应的容器/用途隔离开来。组件存在是为了隔离单一的行为/内容（单一职责原则），因此，在隔离中编码是有益的。\n有许多在隔离中开发组件的方法和工具，但由于其效果和生态系统，Storybook 成为了标准选择。\n组件有三种类型的契约：生成的输出（HTML），它们的视觉方面（CSS）和外部 API（props 和回调）。测试每个方面可能很繁琐，这就是 Storyshots 可以派上用场的地方。它允许你自动化：\n快照测试：快照是组件生成的输出，一个包含所有呈现 HTML 的字符串。如果生成的 HTML 更改，无论是意外还是非意外，快照测试都会失败，你可以选择这些更改是有意还是无意。\n视觉回归测试：与先前的组件相比，组件的视觉方面逐像素比较，同样，你被提示选择是否接受更改。\n这些测试由 Storyshots 在每个 Storybook 页面（又名“故事”）上自动启动。\n回调测试：一个小的 React 容器应用呈现组件并传递一些回调。然后，模拟用户交互并传递期望调用的回调。React Testing Library 是这类测试的标准库。\n交互/状态测试：与组件的一些交互期望正确的状态管理。这种类型的测试必须从消费者的角度编写，而不是从内部的角度（例如，用户填写输入字段时的输入字段值，而不是内部组件状态）。交互/状态测试应在触发键盘事件后断言输入字段的值。\n或者，Cypress 推出了自己的解决方案，以便在其中启动组件测试，请查看 使用 Cypress 进行 React 组件单元测试 章节。\nUI 集成测试：它们在真实浏览器中运行整个应用 而不连接真实服务器。这些测试是每个前端开发人员的王牌。它们运行速度快，不容易出现随机失败或假阴性。\n前端应用程序并不知道没有真实服务器：每个 AJAX 调用都会被测试工具在瞬间解决。静态 JSON 响应（称为“fixtures”）用于模拟服务器响应。Fixtures 允许我们测试前端状态，模拟每种可能的后端状态。\n另一个有趣的效果是：Fixtures 允许您在没有工作的后端 应用程序的情况下工作。您可以将 UI 集成测试视为“仅前端”测试。\n在最成功的测试套件的核心，有很多 UI 集成测试，考虑到对前端应用程序的最佳测试类型。\n端到端（E2E）测试：它们与真实服务器进行交互，运行整个应用程序。从用户交互（其中之一是“端”）到业务数据（另一个“端”）：一切都必须按设计工作。E2E 测试通常很慢，因为\n它们需要一个 工作的后端 应用程序，通常在前端应用程序旁边启动。没有服务器，你不能启动它们，所以你依赖于后端开发人员的工作 它们需要 可靠的数据，在每次测试之前进行种植和清理 这就是为什么 E2E 测试不可行作为唯一/主要测试类型的原因。它们非常重要，因为它们测试所有内容（前端 + 后端），但必须小心使用，以避免脆弱且持续时间长的测试套件。\n在具有许多 UI 集成测试的完整套件中，您可以将 E2E 测试视为“后端测试”。通过它们，您应该测试哪些流程？\n快乐路径流程：您需要确保至少用户能够完成基本操作 对您的业务有价值 在具有许多 UI 集成测试的完整套件中，您可以将 E2E 测试视为“后端测试”。通过它们，您应该测试哪些流程？\n快乐路径流程：您需要确保至少用户能够完成基本操作 对您的业务有价值的一切：无论是快乐路径还是其他，都要测试您的业务关心的任何内容（明显是优先考虑它们） 经常中断的一切：系统的薄弱区域也必须受到监视 识别/定义测试类型对于对它们进行分组、合理命名测试文件、限制它们的\n范围以及选择是否在整个应用程序和部署流水线中运行它们很有用。\n由NoriSte在dev.to和Medium上进行了跨发表。\n翻译自：Component vs (UI) Integration vs E2E Tests*\n","permalink":"https://naodeng.com.cn/posts/ui-automation-testing/ui-testing-best-practice-testing-strategy-1-component-tests-vs-ui-integration-tests-vs-e2e-tests/","summary":"这篇博文深入研究 UI 测试最佳实践，首篇聚焦于测试策略的选择：组件测试、UI 集成测试和端到端（E2E）测试的区别。了解每种测试类型的优缺点，帮助您在 UI 测试中做出明智的选择。不论您是开发者还是测试专业人员，这篇文章将为您提供深入洞察，助力您设计出更可靠、高效的 UI 测试策略。点击链接，探索 UI 测试的最佳实践，提升您的测试流程质量。","title":"UI 测试最佳实践的测试策略（一）：组件测试 vs（UI）集成测试 vs E2E 测试"},{"content":"什么是 K6 k6 是一款用于性能测试和负载测试的开源工具，主要用于评估和验证应用程序的性能和稳定性。以下是关于 k6 的一些主要特点和信息：\n开源性： k6 是一款完全开源的性能测试工具，代码存储在 GitHub 上。这意味着用户可以自由访问、使用和修改工具的源代码。\nJavaScript 编写脚本： k6 使用 JavaScript 语言编写测试脚本，这使得编写测试用例相对简单，并且对于开发人员而言更加友好。脚本可以包含 HTTP 请求、WebSocket 连接、脚本执行逻辑等。\n支持多种协议： k6 支持多种常见的协议，包括 HTTP、WebSocket、Socket.IO、gRPC 等，使其可以广泛应用于各种类型的应用程序。\n分布式测试： k6 具有分布式测试的能力，允许在多个节点上运行测试，从而模拟更真实的生产环境负载。\n实时结果和报告： k6 提供实时结果，包括请求响应时间、吞吐量等，并能够生成详细的 HTML 报告，帮助用户更好地理解应用程序的性能状况。\n容器化支持： k6 适应容器化环境，可以轻松集成到 CI/CD 流水线中，并与常见的容器编排工具（如 Kubernetes）配合使用。\n插件生态系统： k6 支持插件，用户可以通过插件扩展其功能，满足特定需求。\n活跃的社区： 由于 k6 是一个开源项目，拥有一个积极的社区，提供支持、文档和示例，使用户更容易上手和解决问题。\n总体而言，k6 是一个灵活、强大且易于使用的性能测试工具，适用于各种规模的应用程序和系统。\n官方网站及文档 官方网站 官方文档 安装 Mac 系统安装 Mac 系统可以通过 Homebrew 安装 k6：\nbrew install k6 Windows 系统安装 Windows 系统可以通过 Chocolatey 安装 k6：\nchoco install k6 或者通过 winget 安装 k6：\nwinget install k6 Docker 安装 k6 也可以通过 Docker 安装：\ndocker pull grafana/k6 其他系统安装 K6 除了支持上述系统外，还支持 Linux（Debian/Ubuntu/Fedora/CentOS），也支持下载 K6 二进制文件和 K6 扩展进行安装，具体安装方式请参考官方文档。\n确认 K6 安装成功 安装完成后，可以通过以下命令确认 k6 是否安装成功：\nk6 version 如果安装成功，会显示 k6 的版本信息：\n第一个 K6 测试脚本 编写第一个测试脚本 新建一个 K6 性能测试项目目录并进入 mkdir k6-demo cd k6-demo 创建一个名为 demo.js 的文件，用于编写测试脚本 可以通过 k6 new 命令创建一个测试脚本文件： k6 new demo.js 也可以直接创建一个名为 demo.js 的测试脚本文件 touch demo.js 编辑测试脚本 如果是通过 k6 new 命令创建的测试脚本文件，会自动生成一个简单的测试脚本，如下所示：\nimport http from \u0026#39;k6/http\u0026#39;; import { sleep } from \u0026#39;k6\u0026#39;; export const options = { // A number specifying the number of VUs to run concurrently. vus: 10, // A string specifying the total duration of the test run. duration: \u0026#39;30s\u0026#39;, // The following section contains configuration options for execution of this // test script in Grafana Cloud. // // See https://grafana.com/docs/grafana-cloud/k6/get-started/run-cloud-tests-from-the-cli/ // to learn about authoring and running k6 test scripts in Grafana k6 Cloud. // // ext: { // loadimpact: { // // The ID of the project to which the test is assigned in the k6 Cloud UI. // // By default tests are executed in default project. // projectID: \u0026#34;\u0026#34;, // // The name of the test in the k6 Cloud UI. // // Test runs with the same name will be grouped. // name: \u0026#34;demo.js\u0026#34; // } // }, // Uncomment this section to enable the use of Browser API in your tests. // // See https://grafana.com/docs/k6/latest/using-k6-browser/running-browser-tests/ to learn more // about using Browser API in your test scripts. // // scenarios: { // // The scenario name appears in the result summary, tags, and so on. // // You can give the scenario any name, as long as each name in the script is unique. // ui: { // // Executor is a mandatory parameter for browser-based tests. // // Shared iterations in this case tells k6 to reuse VUs to execute iterations. // // // // See https://grafana.com/docs/k6/latest/using-k6/scenarios/executors/ for other executor types. // executor: \u0026#39;shared-iterations\u0026#39;, // options: { // browser: { // // This is a mandatory parameter that instructs k6 to launch and // // connect to a chromium-based browser, and use it to run UI-based // // tests. // type: \u0026#39;chromium\u0026#39;, // }, // }, // }, // } }; // The function that defines VU logic. // // See https://grafana.com/docs/k6/latest/examples/get-started-with-k6/ to learn more // about authoring k6 scripts. // export default function() { http.get(\u0026#39;https://test.k6.io\u0026#39;); sleep(1); } 如果是直接创建的测试脚本文件，可以将上述内容复制到 demo.js 文件中。\n运行测试脚本 在 demo.js 文件所在目录下，运行以下命令：\nk6 run demo.js 查看测试结果 如果一切正常，会看到类似如下的输出：\n包含以下信息：\nexecution: 执行信息，包括开始时间、结束时间、持续时间、VU 数量、迭代次数等。 scenarios: 场景信息，包括场景名称、VU 数量、迭代次数、持续时间、平均响应时间、吞吐量等。 http_reqs: HTTP 请求信息，包括请求名称、请求数量、失败数量、平均响应时间、吞吐量等。 解析 demo 测试脚本 import http from 'k6/http';：导入 k6 的 HTTP 模块，用于发送 HTTP 请求。\nimport { sleep } from 'k6';：导入 k6 的 sleep 方法，用于执行脚本等待。\nexport const options = { ... }：定义测试脚本的配置项，包括 VU 数量、持续时间等。\nvus: 10,：定义 VU 数量为 10（指定并发运行的 VU 数量）。\nduration: '30s',：定义持续时间为 30 秒（指定测试运行总持续时间）。\nexport default function() { ... }：定义测试脚本的逻辑，包括发送 HTTP 请求、执行等待等。\nhttp.get('https://test.k6.io');：发送一个 GET 请求到 https://test.k6.io。\nsleep(1);：执行等待 1 秒。\n其他注释内容可以忽略，这些内容是关于 k6 的一些高级功能，后续会介绍。\n参考文档 K6 文档：https://k6.io/docs/ k6 官方网站：https://k6.io/ K6 性能测试快速启动项目：https://github.com/Automation-Test-Starter/K6-Performance-Test-starter/ ","permalink":"https://naodeng.com.cn/posts/performance-testing/k6-tutorial-getting-started-and-your-first-k6-test-script/","summary":"这篇文章将带您进入 K6 性能测试的世界。博文内容涵盖了 K6 性能测试的入门知识、环境搭建步骤，以及如何编写您的第一个测试脚本。无论您是初学者还是有经验的性能测试专业人员，这篇教程都将为您提供清晰的指导，帮助您快速上手 K6，并开始构建高效的性能测试脚本","title":"K6 性能测试教程：入门介绍，环境搭建和编写第一个 K6 测试脚本"},{"content":"亲爱的读者们，\n最近，在搜索引擎上检查个人博客文章的收录情况时，我不得不向大家通报一件令人痛心的事情。我发现我的博客文章竟然被一位 CSDN 博主原封不动地抄袭复制到他的博客上，而且更令人遗憾的是，他并未注明出处。\n对于这种不道德的行为，我感到愤怒和失望。我一直努力为大家提供原创、有价值的内容，而这样的抄袭行为是对我的辛勤努力和付出的严重不尊重。为了捍卫自己的权益，我认为有必要发布这篇声明，让大家了解事实真相。\n首先，我要明确表示，我坚决反对一切形式的抄袭和侵权行为。我运营的博客是我的个人创作空间，我希望它能成为分享和交流的平台，而不是被他人肆意剽窃的对象。\n在确认了 CSDN 博主的行为后，我深感遗憾，也决定采取一切必要的法律手段来维护自己的合法权益。同时，我呼吁所有博主和创作者共同努力，维护良好的创作环境，杜绝抄袭现象。\n最后，我要感谢一直以来支持我的读者们。你们的支持是我创作的动力，也是我战胜困难的力量。我会继续为大家带来真实、有价值的内容。\n抄袭博客链接：https://blog.csdn.net/2301_76387166?type=blog\n我已经联系 CSDN 下架。\n再次感谢大家的关注和支持。\n","permalink":"https://naodeng.com.cn/posts/others/article-plagiarism-statement/","summary":"这篇博文是关于我的文章被抄袭的声明。","title":"关于我的文章被抄袭的声明"},{"content":"Java 和 REST Assured 框架实现接口自动化项目 REST Assured 框架教程目录 目录不可点击，仅为展示目录结构\nRestAssured 接口自动化测试快速启动项目 RestAssured 介绍 项目结构 Gradle 构建的版本 Maven 构建的版本 项目依赖 从 0 到 1 搭建 REST Assured 接口测试项目 Gradle 版本 Maven 版本 进阶用法 验证响应数据 文件上传 Logging 日志 Filters 过滤器 持续集成 接入 github action 集成 allure 测试报告 数据驱动 多环境支持 REST Assured 框架教程对应文章 REST Assured 接口自动化测试教程：进阶用法 - 集成 CI/CD 和集成 allure 测试报告:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-integration-ci-cd-and-allure-report/\nREST Assured 接口自动化测试教程：进阶用法 - 验证响应和日志记录，过滤器，文件上传:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-advance-usage-verifying-response-and-logging/\nREST Assured 接口自动化测试教程：从 0 到 1 搭建 REST Assured 接口自动化测试项目:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-building-your-own-project-from-0-to-1/\nREST Assured 接口自动化测试教程：入门介绍和环境搭建准备:https://naodeng.tech/zh/posts/api-automation-testing/rest-assured-tutorial-and-environment-preparation/\nREST Assured 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/RestAssured-API-Test-Starter/ Rest assured 官方文档：https://rest-assured.io/ Rest assured 官方 github：https://github.com/rest-assured/rest-assured Rest assured 官方文档中文翻译：https://github.com/RookieTester/rest-assured-doc Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions JavaScript 和 SuperTest 框架实现接口自动化项目 SuperTest 框架教程目录 目录不可点击，仅为展示目录结构\nSuperTest 接口自动化测试快速启动项目 介绍 项目依赖 项目文件结构 从 0 到 1 搭建 SuperTest 接口自动化测试项目 Mocha 版本 Jest 版本 进阶用法 持续集成 接入 github action 常用断言 SuperTest 的内置断言 CHAI 的常用断言 Jest 的常用断言 数据驱动 多环境支持 SuperTest 框架教程对应文章 SuperTest 接口自动化测试教程：进阶用法 - 多环境支持：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-multiple-environment-support/ SuperTest 接口自动化测试教程：进阶用法 - 数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-data-driven/ SuperTest 接口自动化测试教程：进阶用法 - 常用断言：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-common-assertions/ SuperTest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action:https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-advance-usage-integration-ci-cd-and-github-action/ SuperTest 接口自动化测试教程：从 0 到 1 搭建 Supertest 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-building-your-own-project-from-0-to-1/ SuperTest 接口自动化测试教程：入门介绍和环境搭建准备：https://naodeng.tech/zh/posts/api-automation-testing/supertest-tutorial-getting-started-and-own-environment-preparation/ SuperTest 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/SuperTest-API-Test-Starter SuperTest 文档：https://github.com/ladjs/supertest Jest 文档：https://jestjs.io/docs/en/getting-started Mocha 文档：https://mochajs.org/ Chai 文档：https://www.chaijs.com/ Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions Python 和 Pytest 框架实现接口自动化项目 Pytest 框架教程目录 目录不可点击，仅为展示目录结构\nPytest 接口自动化测试快速启动项目 介绍 Pytest 介绍 python 虚拟环境介绍 项目依赖 项目目录结构 从 0 到 1 搭建 Pytest 接口自动化测试项目 进阶用法 持续集成 接入 github action 常用断言 数据驱动 多环境支持 集成 allure 报告 并发测试和分布式测试 筛选用例执行 Pytest 框架教程对应文章 Pytest 接口自动化测试教程：进阶用法 - 筛选测试用例执行，并发测试和分布式测试：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-filter-testcase-and-concurrent-testing-distributed-testing/ Pytest 接口自动化测试教程：进阶用法 - 多环境支持 和 集成 allure 报告：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-multiple-environment-support-and-integration-allure-report/ Pytest 接口自动化测试教程：进阶用法 - 常用断言和数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-common-assertions-and-data-driven/ Pytest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-advance-usage-integration-ci-cd-and-github-action/ Pytest 接口自动化测试教程：从 0 到 1 搭建 Pytest 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-building-your-own-project-from-0-to-1/ Pytest 接口自动化测试教程：入门介绍和环境搭建准备：https://naodeng.tech/zh/posts/api-automation-testing/pytest-tutorial-getting-started-and-own-environment-preparation/ Pytest 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Pytest-API-Test-Starter Pytest 文档：https://docs.pytest.org/en/stable/ Pytest-html 文档：https://pypi.org/project/pytest-html/ Pytest-xdist 文档：https://pypi.org/project/pytest-xdist/ Allure-pytest 文档：https://pypi.org/project/allure-pytest/ Allure 文档：https://docs.qameta.io/allure/ gitHub action 文档：https://docs.github.com/en/actions 测试工具实现接口自动化测试 Postman 接口自动化测试 Postman 框架教程目录 目录不可点击，仅为展示目录结构\nPostman-API-Test-Starter 介绍 接口测试简介 Postman 与 newman 介绍 项目依赖 项目文件结构 从 0 到 1 搭建 Postman 接口自动化测试项目 进阶用法 输出 html 测试报告 CI/CD 持续集成 接入 github action 集成 allure 测试报告 常用测试脚本 响应测试脚本 请求前脚本 测试脚本中可用的第三方库 chai.js 断言库方法 使用 cheerio 操作 HTML 文件 使用 tv4 来验证 JSON Schema 生成 uuid 使用 xml2js 将 XML 转换为 JavaScript 对象 常用工具函数 util stream 流操作 定时器 timers 时间处理 events 数据驱动 使用环境变量 使用数据文件 文件上传 并发测试 Postman 框架教程对应文章 Postman 接口自动化测试教程：进阶用法 - 常用命令行选项，文件上传场景和 SSL 证书场景：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-command-line-options-and-file-upload/ Postman 接口自动化测试教程：进阶用法 - 数据驱动：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-data-driven-and-environment-data-driven/ Postman 接口自动化测试教程：进阶用法 - 常用的测试脚本和常用的第三方包用法示例：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-common-test-scripts-and-commonly-used-third-party-packages/ Postman 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action，接入 allure 测试报告：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-advance-usage-integration-html-report-and-allure-report-integration-github-action/ Postman 接口自动化测试教程：入门介绍和从 0 到 1 搭建 Postman 接口自动化测试项目：https://naodeng.tech/zh/posts/api-automation-testing/postman-tutorial-getting-started-and-building-your-own-project-from-0-to-1/ Postman 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Postman-API-Test-Starter Postman 官方文档:https://learning.postman.com/docs/getting-started/introduction/ Newman 官方文档:https://github.com/postmanlabs/newman gitHub action 文档：https://docs.github.com/en/actions allure 文档：https://docs.qameta.io/allure/ Bruno 接口自动化测试 Bruno 框架教程目录 目录不可点击，仅为展示目录结构\nbruno-user-guide 为什么选择 bruno 安装 bruno 客户端使用入门 默认主界面 API 请求集 API 请求 编写 API 请求测试脚本 环境变量 测试脚本接口自动化 前置条件 接口自动化项目 demo 接入 CI 接入 github action Postman 脚本迁移 API 请求集迁移 环境变量迁移 测试脚本迁移参考 Bruno 框架教程对应文章 postman 替换工具 bruno 使用介绍:https://naodeng.tech/zh/posts/api-automation-testing/introduction_of_bruno/ Bruno 框架教程参考文档 Demo 项目地址：https://github.com/Automation-Test-Starter/Bruno-API-Test-Starter Bruno 文档：https://docs.usebruno.com/ gitHub action 文档：https://docs.github.com/en/actions 推荐阅读 使用 Postman 进行接口自动化测试快速开启教程系列 使用 Pytest 进行接口自动化测试快速开启教程系列 使用 SuperTest 进行接口自动化测试快速开启教程系列 使用 Rest Assured 进行接口自动化测试快速开启教程系列 使用 Galting 进行性能测试快速开启教程系列 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/a-collection-of-tutorials-on-api-automation-testing-for-different-frameworks-and-different-development-languages/","summary":"这篇博文汇总了关于不同框架和开发语言的接口自动化测试教程，为读者提供全面的学习资源。涵盖了各种流行测试框架和编程语言，让您能够选择适合自己项目的最佳方案。无论您是 Python、Java、JavaScript 还是其他语言的开发者，无论您偏好使用的是 REST Assured、SuperTest 还是其他框架，这个合集都将为您提供深入的学习指南，帮助您在接口自动化测试领域更加游刃有余。不容错过的资源，助您全面掌握接口自动化测试的各种工具和技术。","title":"接口测试新手入门教程：不同框架和不同开发语言"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括常用命令行选项、文件上传场景和 SSL 证书场景。\n文件上传场景 在 postman 和 newman 做接口自动化时，文件上传可以通过 form-data 的方式来实现。\n文件必须存在于当前工作目录中。请求的 \u0026ldquo;src \u0026ldquo;属性中也必须包含文件名。\n在此集合中，当前工作目录中应包含名为 \u0026ldquo;demo.txt\u0026rdquo; 的文件。\n{ \u0026#34;info\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;file-upload\u0026#34; }, \u0026#34;item\u0026#34;: [ { \u0026#34;request\u0026#34;: { \u0026#34;url\u0026#34;: \u0026#34;https://postman-echo.com/post\u0026#34;, \u0026#34;method\u0026#34;: \u0026#34;POST\u0026#34;, \u0026#34;body\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;formdata\u0026#34;, \u0026#34;formdata\u0026#34;: [ { \u0026#34;key\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;enabled\u0026#34;: true, \u0026#34;src\u0026#34;: \u0026#34;demo.txt\u0026#34; } ] } } } ] } 注意：调整文件上传的路径，确保文件存在路径在项目根目录下存在或者使用绝对路径\nNewman 常用命令行选项 newman 是一个命令行工具，可以使用它来运行 postman 集合。newman 提供了许多选项，可以在运行集合时使用这些选项。\n以下是一些常用的 newman 命令行选项的介绍和示例：\n基本命令 newman run \u0026lt;collection\u0026gt;： 用于运行 Postman 集合。\nnewman run collection.json -e, --environment \u0026lt;environment\u0026gt;： 指定环境文件。\nnewman run collection.json -e environment.json -g, --globals \u0026lt;globals\u0026gt;： 指定全局变量文件。\nnewman run collection.json -g globals.json -d, --iteration-data \u0026lt;data\u0026gt;： 指定数据文件，用于数据驱动测试。\nnewman run collection.json -d data-file.csv 输出和报告 -r, --reporters \u0026lt;reporters\u0026gt;： 指定报告器，可以生成多个报告，如 cli、json、html 等。\nnewman run collection.json -r cli,json --reporter-json-export \u0026lt;file\u0026gt;： 将测试结果导出为 JSON 文件。\nnewman run collection.json --reporters json --reporter-json-export output.json --reporter-html-export \u0026lt;file\u0026gt;： 将测试结果导出为 HTML 文件。\nnewman run collection.json --reporters html --reporter-html-export output.html --reporter-html-template \u0026lt;file\u0026gt;： 使用自定义 HTML 模板生成 HTML 报告。\nnewman run collection.json --reporters html --reporter-html-template custom-template.hbs 其他选项 -h, --help： 显示帮助信息，列出所有命令行选项。\nnewman run --help -v, --version： 显示 Newman 版本信息。\nnewman --version -x, --suppress-exit-code： 在运行失败时，不返回非零的退出代码。\nnewman run collection.json -x --delay-request \u0026lt;ms\u0026gt;： 设置请求之间的延迟时间，以模拟实际场景。\nnewman run collection.json --delay-request 1000 --timeout \u0026lt;ms\u0026gt;： 设置请求的超时时间。\nnewman run collection.json --timeout 5000 --no-color： 禁用控制台输出的颜色。\nnewman run collection.json --no-color --bail： 在第一个失败的测试时停止运行。\nnewman run collection.json --bail 这只是一些常见的 Newman 命令行选项。你可以通过运行 newman run --help 查看所有可用选项以及它们的描述。根据你的测试需求，你可能需要调整和组合这些选项。\nSSL 证书配置 客户端证书是传统身份验证机制的替代方案。这些允许用户使用公共证书和验证证书所有权的可选私钥向服务器发出经过身份验证的请求。在某些情况下，私钥也可能受到秘密密码的保护，从而提供额外的身份验证安全层。\nNewman 通过以下 CLI 选项支持 SSL 客户端证书：\n使用单个 SSL 客户端证书 直接在 newman 命令后面根据证书的实际情况添加以下选项即可\n--ssl-client-cert 参数后跟着公共客户端证书文件的路径。\n--ssl-client-key 参数后跟着客户端私钥的路径（可选）。\n--ssl-client-passphrase 参数后跟着用于保护私有客户端密钥的秘密密码（可选）。\n使用多个 SSL 客户端证书 适用于每次运行需要支持多个证书的情况\n--ssl-client-cert-list SSL 客户端证书列表配置文件（JSON 格式）的路径。 参考示例/ssl-client-cert-list.json。\n[ { \u0026#34;name\u0026#34;: \u0026#34;domain1\u0026#34;, \u0026#34;matches\u0026#34;: [\u0026#34;https://test.domain1.com/*\u0026#34;, \u0026#34;https://www.domain1/*\u0026#34;], \u0026#34;key\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain1.key\u0026#34;}, \u0026#34;cert\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain1.crt\u0026#34;}, \u0026#34;passphrase\u0026#34;: \u0026#34;changeme\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;domain2\u0026#34;, \u0026#34;matches\u0026#34;: [\u0026#34;https://domain2.com/*\u0026#34;], \u0026#34;key\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain2.key\u0026#34;}, \u0026#34;cert\u0026#34;: {\u0026#34;src\u0026#34;: \u0026#34;./client.domain2.crt\u0026#34;}, \u0026#34;passphrase\u0026#34;: \u0026#34;changeme\u0026#34; } ] 另外这种 json 配置也适用于不同证书不同环境的情况，根据 matches 匹配不同的环境和域名。\n备注：此选项允许根据 URL 或主机名设置不同的 SSL 客户端证书。此选项优先于 \u0026ndash;ssl-client-cert、 \u0026ndash;ssl-client-key 和 \u0026ndash;ssl-client-passphrase 选项。如果列表中没有匹配的 URL，这些选项将用作后备选项。\nTrusted CA 证书 适用于需要信任自定义 CA 证书的情况\n如果不想使用 \u0026ndash;insecure 选项，可以像这样提供额外的可信 CA 证书：\n--ssl-extra-ca-certs 参数后跟着保存一个或多个 PEM 格式可信 CA 证书的文件路径的列表。 参考文档 Postman 官方文档:https://learning.postman.com/docs/getting-started/introduction/ Newman 官方文档:https://github.com/postmanlabs/newman?tab=readme-ov-file#command-line-options ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/postman-tutorial-advance-usage-common-command-line-options-and-file-upload/","summary":"这篇博文深度挖掘 Postman 接口自动化测试的进阶用法，集中讨论常用命令行选项、文件上传场景和 SSL 证书场景。学会如何运用常用命令行选项优化测试流程，解决文件上传和 SSL 证书等特殊场景的测试挑战","title":"Postman 接口自动化测试教程：进阶用法 - 常用命令行选项，文件上传场景和 SSL 证书场景"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括数据文件驱动和环境变量数据驱动。\n数据驱动 在 API 自动化测试的过程中。使用数据驱动是一种常规测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。\n测试数据可以很容易地修改，而不需要修改测试用例代码。\n数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\n可参考 demo：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n在 Postman 中进行数据驱动测试，特别是使用 JSON 数据作为测试数据，可以通过环境变量和数据文件配合 Postman 提供的测试脚本来实现，以下会分别以简单的示例来介绍环境变量和数据文件的使用。\n使用环境变量 大致的步骤是：将测试数据存储在环境变量中，然后在测试脚本中读取环境变量中的数据，进行测试。\n1. 创建环境变量 在 Postman 中，你可以在 \u0026ldquo;Manage Environments\u0026rdquo; 窗口中创建环境变量。在 \u0026ldquo;Manage Environments\u0026rdquo; 窗口中，你可以创建多个环境，每个环境都有一组环境变量。\n之前在 demo 中创建了一个环境变量，名为 DemoEnv，其中包含了一个环境变量 baseURL，用于存储 API 的基本 URL。 这一次我们在 DemoEnv 环境中添加多个环境变量，用于存储 get-demo 接口和 post-demo 接口的各类测试数据。\n点击编辑DemoEnv环境，添加以下环境变量：\nKey Value getAPI posts/1 getAPIResponseStatus 200 getAPIResponseData {\u0026ldquo;userId\u0026rdquo;:1,\u0026ldquo;id\u0026rdquo;:1,\u0026ldquo;title\u0026rdquo;:\u0026ldquo;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026rdquo;,\u0026ldquo;body\u0026rdquo;:\u0026ldquo;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026rdquo;} postAPI posts postAPIResponseStatus 201 postAPIResponseData {\u0026ldquo;title\u0026rdquo;:\u0026ldquo;foo\u0026rdquo;,\u0026ldquo;body\u0026rdquo;:\u0026ldquo;bar\u0026rdquo;,\u0026ldquo;userId\u0026rdquo;:1,\u0026ldquo;id\u0026rdquo;:101} 2. 使用环境变量 在 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用环境变量来存储和获取数据。在请求 Body 中，你可以通过 pm.environment.get 获取环境变量的值。\n注意：在 JavaScript 中，环境变量获取的值是字符串\n编辑 get-demo 接口 将 URL 修改为 {{baseURL}}/{{getAPI}}， 编辑 Tests 脚本用来验证响应数据： // 获取环境变量中的数据 const getAPIResponseStatus = parseInt(pm.environment.get(\u0026#34;getAPIResponseStatus\u0026#34;)); const getAPIResponseData = JSON.parse(pm.environment.get(\u0026#39;getAPIResponseData\u0026#39;)); pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(getAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(getAPIResponseData.id); pm.expect(data.userId).to.equal(getAPIResponseData.userId); pm.expect(data.title).to.equal(getAPIResponseData.title); pm.expect(data.body).to.equal(getAPIResponseData.body); }); 点击保存，然后点击发送，可以看到测试通过。 编辑 post-demo 接口 将 URL 修改为 {{baseURL}}/{{postAPI}}， 编辑 Tests 脚本用来验证响应数据： // 获取环境变量中的数据 const postAPIResponseStatus = parseInt(pm.environment.get(\u0026#34;postAPIResponseStatus\u0026#34;)); const postAPIResponseData = JSON.parse(pm.environment.get(\u0026#39;postAPIResponseData\u0026#39;)); pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(postAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(postAPIResponseData.id); pm.expect(data.userId).to.equal(postAPIResponseData.userId); pm.expect(data.title).to.equal(postAPIResponseData.title); pm.expect(data.body).to.equal(postAPIResponseData.body); }); 点击保存，然后点击发送，可以看到测试通过。 3. 调试环境变量数据驱动脚本 选择对应的环境变量和更新后的测试用例，运行整个 demo collection，确认测试通过\n4.自动化运行环境变量数据驱动脚本 将更新后的测试用例导出到自动化测试项目测试用例文件夹下 调整 package.json 在 package.json 文件中，更新测试脚本，用于运行环境变量数据驱动测试用例：\ndemo 项目为了区分不同场景，新增了测试命令为 environment-driven-test\n\u0026#34;environment-driven-test\u0026#34;: \u0026#34;newman run Testcase/Environment-Driven.postman_collection.json -e Env/Environment-Driven-DemoEnv.postman_environment.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34;, 运行测试 npm run environment-driven-test 使用数据文件 大致的步骤是：将测试数据存放在数据文件中，然后在测试脚本中读取数据文件中的数据，进行测试。\npostman 的数据文件支持 json，csv 和 txt 等多种格式，以下示例会以 json 格式 进行\n1.创建数据文件 在 postma 接口自动化测试项目下新建 Data 文件夹 mkdir Data 在 Data 文件夹下新建 json 格式数据文件 testdata.json cd Data touch testdata.json 更新测试数据文件 testdata.json [ { \u0026#34;getAPI\u0026#34;: \u0026#34;posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;: \u0026#34;posts\u0026#34;, \u0026#34;getAPIResponseStatus\u0026#34;: 200, \u0026#34;getAPIResponseData\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPIResponseStatus\u0026#34;: 201, \u0026#34;postAPIResponseData\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } ] 2.更新测试用例 更新 get-demo 接口 编辑 Pre-request Script 脚本来从测试数据文件中获取 请求 url const getAPI = pm.iterationData.get(\u0026#39;getAPI\u0026#39;); 将 URL 修改为 {{baseURL}}/{{getAPI}}，\n编辑 test 脚本来从测试数据文件中获取测试数据\nconst getAPIResponseStatus = pm.iterationData.get(\u0026#39;getAPIResponseStatus\u0026#39;); const getAPIResponseData = pm.iterationData.get(\u0026#39;getAPIResponseData\u0026#39;); pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(getAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(getAPIResponseData.id); pm.expect(data.userId).to.equal(getAPIResponseData.userId); pm.expect(data.title).to.equal(getAPIResponseData.title); pm.expect(data.body).to.equal(getAPIResponseData.body); }); 更新 post-demo 接口 编辑 Pre-request Script 脚本来从测试数据文件中获取 请求 url const postAPI = pm.iterationData.get(\u0026#39;postAPI\u0026#39;); 将 URL 修改为 {{baseURL}}/{{postAPI}}，\n编辑 test 脚本来从测试数据文件中获取测试数据\n// 从数据文件获取测试数据 const postAPIResponseStatus = pm.iterationData.get(\u0026#39;postAPIResponseStatus\u0026#39;); const postAPIResponseData = pm.iterationData.get(\u0026#39;postAPIResponseData\u0026#39;); pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(postAPIResponseStatus); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(postAPIResponseData.id); pm.expect(data.userId).to.equal(postAPIResponseData.userId); pm.expect(data.title).to.equal(postAPIResponseData.title); pm.expect(data.body).to.equal(postAPIResponseData.body); }); 3.调试 在 postman 页面选择 get-demo request 和 post-demo request 所在的 demo Collection，点击右上角的三个点，选择 Run Collection 在 runner 准备页面右侧区域点击 Data 的 Select File 按钮，选择之前的测试数据文件 testdata.json 然后点击 Run demo，确认运行通过即可导出测试用例文件 4.自动化运行数据驱动脚本 将更新后的测试用例导出到自动化测试项目测试用例文件夹下 调整 package.json 在 package.json 文件中，更新测试测试脚本，用于运行数据驱动测试用例：\ndemo 项目为了区分不同场景，新增了测试命令为 data-driven-test，且命令后加了-d 参数 用于指定测试数据文件路径\n\u0026#34;data-driven-test\u0026#34;: \u0026#34;newman run Testcase/Data-Driven.postman_collection.json -e Env/DemoEnv.postman_environment.json -d Data/testdata.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34; 运行测试 npm run data-driven-test 参考文档 Postman 官方文档 newman 官方文档 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/postman-tutorial-advance-usage-data-driven-and-environment-data-driven/","summary":"这篇博文深入研究 Postman 接口自动化测试的高级技巧，专注于数据文件驱动和环境变量数据驱动。学习如何通过外部数据文件和灵活的环境变量，优雅地进行测试数据的驱动，提高测试覆盖率。博文将为您展示如何以更智能的方式管理和利用数据，使测试用例更具可扩展性和灵活性。","title":"Postman 接口自动化测试教程：进阶用法 - 数据驱动"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括常用测试响应测试脚本，测试前置脚本和常用的测试脚本可用的第三方包等。\n常用测试脚本 Postman 提供了测试脚本功能，可以使用 JavaScript 编写脚本来验证 API 的响应和行为。这些脚本可以在请求的“Tests”标签下添加，分为请求前脚本（Pre-request Script）和响应后脚本（Tests）两个部分。下面是一些常用的 Postman 和 Newman 测试脚本：\n响应测试脚本 状态码检查：\npm.test(\u0026#34;Status code is 200\u0026#34;, function () { pm.response.to.have.status(200); }); 响应时间检查：\npm.test(\u0026#34;Response time is less than 200ms\u0026#34;, function () { pm.expect(pm.response.responseTime).to.be.below(200); }); 响应体 JSON 格式检查：\npm.test(\u0026#34;Response body is a valid JSON\u0026#34;, function () { pm.response.to.be.json; }); 响应体字段值检查：\npm.test(\u0026#34;Response body contains expected value\u0026#34;, function () { pm.expect(pm.response.json().key).to.eql(\u0026#34;expectedValue\u0026#34;); }); 响应体数组长度检查：\npm.test(\u0026#34;Response body array has correct length\u0026#34;, function () { pm.expect(pm.response.json().arrayKey).to.have.lengthOf(3); }); 响应体属性存在性检查：\npm.test(\u0026#34;Response body has required properties\u0026#34;, function () { pm.expect(pm.response.json()).to.have.property(\u0026#34;key\u0026#34;); }); 请求前脚本 动态设置请求参数：\npm.variables.set(\u0026#34;dynamicVariable\u0026#34;, \u0026#34;dynamicValue\u0026#34;); 使用全局变量设置请求头：\npm.request.headers.add({ key: \u0026#39;Authorization\u0026#39;, value: pm.globals.get(\u0026#39;authToken\u0026#39;) }); 生成随机数并设置为变量：\nconst randomNumber = Math.floor(Math.random() * 1000); pm.variables.set(\u0026#34;randomNumber\u0026#34;, randomNumber); 签名生成或加密等操作：\n// 示例：使用 CryptoJS 进行 HMAC SHA256 签名 const CryptoJS = require(\u0026#39;crypto-js\u0026#39;); const secretKey = \u0026#39;yourSecretKey\u0026#39;; const message = \u0026#39;dataToSign\u0026#39;; const signature = CryptoJS.HmacSHA256(message, secretKey).toString(CryptoJS.enc.Base64); pm.variables.set(\u0026#34;signature\u0026#34;, signature); 测试脚本中可用的第三方库 提供的 require 方法允许您使用沙箱内置库模块。下面列出了个人常用的可用库和示例 更多可用的库可以在这里找到\nchai.js 断言库方法 在 Postman 的测试脚本中，你可以使用 Chai 断言库来编写断言，以验证你的 API 响应是否符合预期。Chai 提供了多种断言风格，包括 BDD（Behavior Driven Development）、TDD（Test Driven Development）等。以下是一些基本的 Chai 使用方法：\n1. 安装 Chai 在 Postman 的脚本环境中，你无需单独安装 Chai，因为 Postman 默认已经内置了 Chai。\n2. 使用 BDD 风格断言 在 Postman 的 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用 Chai 的 BDD 风格断言，例如：\n// 引入 Chai 库 const chai = require(\u0026#39;chai\u0026#39;); // 使用 BDD 风格断言 const expect = chai.expect; // 示例：验证响应状态码为 200 pm.test(\u0026#39;Status code is 200\u0026#39;, function() { expect(pm.response.code).to.equal(200); }); // 示例：验证响应体是 JSON pm.test(\u0026#39;Response body is JSON\u0026#39;, function() { expect(pm.response.headers.get(\u0026#39;Content-Type\u0026#39;)).to.include(\u0026#39;application/json\u0026#39;); }); 3. 使用 TDD 风格断言 // 引入 Chai 库 const chai = require(\u0026#39;chai\u0026#39;); // 使用 TDD 风格断言 const assert = chai.assert; // 示例：使用 assert 断言响应状态码为 200 assert.equal(pm.response.code, 200, \u0026#39;Status code should be 200\u0026#39;); 4. Chai 支持的一些常用断言 相等性：\nexpect(actual).to.equal(expected); 包含：\nexpect(actual).to.include(expected); 类型检查：\nexpect(actual).to.be.a(\u0026#39;string\u0026#39;); 大于/小于：\nexpect(actual).to.be.above(expected); expect(actual).to.be.below(expected); 空/非空：\nexpect(actual).to.be.null; expect(actual).to.not.be.null; 深度相等性：\nexpect(actual).to.deep.equal(expected); 以上只是 Chai 断言库的一些基本用法，你可以根据需要使用更多的断言方法和组合。Chai 提供了丰富的断言功能，可以满足各种测试需求。更多详细信息，请查阅 Chai 的官方文档：Chai Documentation。\n使用 cheerio 操作 HTML 文件 在 Postman 中，Cheerio 是一个基于 jQuery 的库，用于在服务器端操作 HTML 文档。它允许你使用类似于 jQuery 的语法来选择和操作 HTML 元素，非常适用于解析和提取 HTML 页面中的信息。在 Postman 中，你可以使用 Cheerio 库进行 HTML 响应的解析。以下是 Cheerio 在 Postman 中的基本用法：\n安装 Cheerio：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 Cheerio 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，可以使用以下方式安装 Cheerio： // 安装 Cheerio const cheerio = require(\u0026#39;cheerio\u0026#39;); 使用 Cheerio 解析 HTML：\n在请求的 \u0026ldquo;Tests\u0026rdquo; 部分中，你可以使用 Cheerio 解析 HTML。以下是一个简单的例子： // 从响应中获取 HTML 内容 const htmlContent = pm.response.text(); // 使用 Cheerio 解析 HTML const $ = cheerio.load(htmlContent); // 示例：从 HTML 中提取标题文本 const titleText = $(\u0026#39;title\u0026#39;).text(); console.log(\u0026#39;Title:\u0026#39;, titleText); // 示例：从 HTML 中提取所有链接的 href 属性 const links = []; $(\u0026#39;a\u0026#39;).each(function () { const link = $(this).attr(\u0026#39;href\u0026#39;); links.push(link); }); console.log(\u0026#39;Links:\u0026#39;, links); 在上述例子中，cheerio.load(htmlContent) 用于加载 HTML 内容，并使用类似于 jQuery 的语法来选择和操作元素。\n注意事项：\nCheerio 主要用于解析静态 HTML，对于使用 JavaScript 动态生成的内容，可能无法正常获取。在这种情况下，你可能需要考虑使用 Puppeteer 或其他支持 JavaScript 执行的工具。 这只是 Cheerio 在 Postman 中的基本用法。你可以根据具体的需求使用 Cheerio 提供的各种选择器和方法。请查阅 Cheerio 的官方文档以获取更详细的信息：Cheerio Documentation。\n使用 tv4 来验证 JSON Schema 在 Postman 中，tv4 是一个 JSON Schema 验证库，用于验证 JSON 数据是否符合给定的 JSON Schema。JSON Schema 是一种描述 JSON 数据结构的规范，它定义了 JSON 对象的属性、类型和其他约束。\n以下是在 Postman 中使用 tv4 进行 JSON Schema 验证的基本步骤：\n安装 tv4 库：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 tv4 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 tv4： // 安装 tv4 const tv4 = require(\u0026#39;tv4\u0026#39;); 定义 JSON Schema：\n在 Postman 中，你可以在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分定义 JSON Schema。JSON Schema 可以作为一个 JavaScript 对象进行定义。以下是一个简单的例子： // 定义 JSON Schema const jsonSchema = { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;number\u0026#34; } }, \u0026#34;required\u0026#34;: [\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;] }; 使用 tv4 进行验证：\n在请求的 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用 tv4 对 JSON 数据进行验证。以下是一个简单的例子： // 获取响应的 JSON 数据 const jsonResponse = pm.response.json(); // 使用 tv4 进行 JSON Schema 验证 const isValid = tv4.validate(jsonResponse, jsonSchema); // 检查验证结果 pm.test(\u0026#39;JSON is valid according to the schema\u0026#39;, function() { pm.expect(isValid).to.be.true; }); 在上述例子中，tv4.validate(jsonResponse, jsonSchema) 用于验证 jsonResponse 是否符合 jsonSchema 定义的规范。验证结果存储在 isValid 变量中，然后使用 pm.test 来检查验证结果。\n这只是 tv4 在 Postman 中的基本用法。你可以根据实际需求，定义更复杂的 JSON Schema，并使用 tv4 的其他功能进行更灵活的验证。请查阅 tv4 的官方文档以获取更详细的信息：tv4 Documentation。\n生成 uuid 在 Postman 中，你可以使用 uuid 模块来生成 UUID（Universally Unique Identifier），也被称为 GUID。以下是在 Postman 中使用 uuid 模块的基本用法：\n1. 安装 uuid 模块 在 Postman 的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 uuid 模块：\n// 安装 uuid 模块 const uuid = require(\u0026#39;uuid\u0026#39;); 2. 生成 UUID // 生成 UUID const generatedUUID = uuid.v4(); console.log(\u0026#39;Generated UUID:\u0026#39;, generatedUUID); 在上述例子中，uuid.v4() 用于生成一个基于随机数的 UUID。你可以在 Postman 脚本中使用生成的 UUID，例如将其设置为请求头或参数的值。\n示例 以下是一个在 Postman \u0026ldquo;Pre-request Script\u0026rdquo; 中生成 UUID 并设置为请求头的示例：\n// 安装 uuid 模块 const uuid = require(\u0026#39;uuid\u0026#39;); // 生成 UUID const generatedUUID = uuid.v4(); // 设置请求头 pm.request.headers.add({ key: \u0026#39;X-Request-ID\u0026#39;, value: generatedUUID }); 在上述例子中，X-Request-ID 是一个常见的请求头，用于标识请求的唯一性。生成的 UUID 被设置为这个请求头的值，以确保每个请求都有唯一的标识。\n请注意，Postman 在运行脚本时会自动执行安装依赖项的步骤，无需手动安装 uuid 模块。\n使用 xml2js 将 XML 转换为 JavaScript 对象 在 Postman 中，xml2js 是一个用于将 XML 转换为 JavaScript 对象的库。在 Postman 的脚本中，你可以使用 xml2js 来处理 XML 响应并将其转换为易于处理的 JavaScript 对象。以下是在 Postman 中使用 xml2js 的基本步骤：\n安装 xml2js 库：\n由于 Postman 使用的是 Node.js 运行时环境，你可以通过在 Postman 的脚本中安装 xml2js 来使用它。在请求的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，你可以使用以下方式安装 xml2js： // 安装 xml2js const xml2js = require(\u0026#39;xml2js\u0026#39;); 解析 XML 响应：\n获取 XML 响应后，你可以使用 xml2js 将其解析为 JavaScript 对象。以下是一个简单的例子： // 获取响应的 XML 内容 const xmlContent = pm.response.text(); // 使用 xml2js 解析 XML xml2js.parseString(xmlContent, function (err, result) { if (err) { console.error(\u0026#39;Error parsing XML:\u0026#39;, err); return; } // result 是解析后的 JavaScript 对象 console.log(\u0026#39;Parsed XML:\u0026#39;, result); }); 在上述例子中，xml2js.parseString(xmlContent, function (err, result) {...} 用于异步地解析 XML 内容。解析后的 JavaScript 对象存储在 result 中。\n处理解析后的 JavaScript 对象：\n一旦你获得了解析后的 JavaScript 对象，你就可以按照普通的 JavaScript 对象处理方式访问和操作它的属性。 // 示例：访问解析后的 JavaScript 对象的属性 const value = result.root.element[0].subelement[0]._; console.log(\u0026#39;Value from parsed XML:\u0026#39;, value); 在上述例子中，result.root.element[0].subelement[0]._ 是一个访问解析后对象属性的示例。具体的结构取决于你的 XML 结构。\n这只是 xml2js 在 Postman 中的基本用法。你可以根据实际需求使用 xml2js 的其他功能，例如设置解析选项，处理命名空间等。请查阅 xml2js 的官方文档以获取更详细的信息：xml2js Documentation。\n常用工具函数 util 在 Postman 中，util 是一个全局对象，提供了一些常用的实用工具函数，可以在 Postman 脚本中使用。以下是一些常见的 util 对象的用法：\n1. util.guid() - 生成全局唯一标识符（GUID） // 生成一个全局唯一标识符 const uniqueId = util.guid(); console.log(\u0026#39;Unique ID:\u0026#39;, uniqueId); 2. util.timestamp() - 获取当前时间戳 // 获取当前时间戳（毫秒） const timestamp = util.timestamp(); console.log(\u0026#39;Timestamp:\u0026#39;, timestamp); 3. util.randomInt(min, max) - 生成指定范围内的随机整数 // 生成 1 到 100 之间的随机整数 const randomInt = util.randomInt(1, 100); console.log(\u0026#39;Random Integer:\u0026#39;, randomInt); 4. util.unixTimestamp() - 获取当前时间戳（Unix 时间戳，秒） // 获取当前时间戳（秒） const unixTimestamp = util.unixTimestamp(); console.log(\u0026#39;Unix Timestamp:\u0026#39;, unixTimestamp); 5. util.encodeBase64(str) 和 util.decodeBase64(base64Str) - Base64 编码和解码 // Base64 编码 const encodedString = util.encodeBase64(\u0026#39;Hello, World!\u0026#39;); console.log(\u0026#39;Encoded String:\u0026#39;, encodedString); // Base64 解码 const decodedString = util.decodeBase64(encodedString); console.log(\u0026#39;Decoded String:\u0026#39;, decodedString); 6. util.each(obj, callback) - 遍历对象或数组 // 遍历数组 const array = [1, 2, 3, 4]; util.each(array, function (value, index) { console.log(`Index ${index}: ${value}`); }); // 遍历对象 const obj = { a: 1, b: 2, c: 3 }; util.each(obj, function (value, key) { console.log(`Key ${key}: ${value}`); }); 注意事项 在 Postman 脚本中，可以通过 util 对象直接调用这些实用工具函数。 util 对象提供的这些方法能够简化在 Postman 脚本中的一些常见任务，如生成随机数、处理时间戳等。 请注意查阅 Postman 的官方文档，因为 Postman 会不断更新和改进其脚本环境，可能会引入新的实用工具函数。 stream 流操作 在 Node.js 中使用流（Streams）通常用于处理大量的数据，可以有效地降低内存占用并提高性能。以下是一些在 Node.js 中使用流的基本用法，可以参考这些方法来处理数据或文件。\n1. 读取流（Readable Streams）： const fs = require(\u0026#39;fs\u0026#39;); // 创建可读流 const readableStream = fs.createReadStream(\u0026#39;input.txt\u0026#39;); // 设置编码（如果是文本文件） readableStream.setEncoding(\u0026#39;utf-8\u0026#39;); // 处理数据 readableStream.on(\u0026#39;data\u0026#39;, function(chunk) { console.log(\u0026#39;Received chunk:\u0026#39;, chunk); }); // 处理结束 readableStream.on(\u0026#39;end\u0026#39;, function() { console.log(\u0026#39;Stream ended.\u0026#39;); }); // 处理错误 readableStream.on(\u0026#39;error\u0026#39;, function(err) { console.error(\u0026#39;Error:\u0026#39;, err); }); 2. 写入流（Writable Streams）： const fs = require(\u0026#39;fs\u0026#39;); // 创建可写流 const writableStream = fs.createWriteStream(\u0026#39;output.txt\u0026#39;); // 写入数据 writableStream.write(\u0026#39;Hello, World!\\n\u0026#39;); writableStream.write(\u0026#39;Another line.\u0026#39;); // 结束写入 writableStream.end(); // 处理结束 writableStream.on(\u0026#39;finish\u0026#39;, function() { console.log(\u0026#39;Write completed.\u0026#39;); }); // 处理错误 writableStream.on(\u0026#39;error\u0026#39;, function(err) { console.error(\u0026#39;Error:\u0026#39;, err); }); 3. 转换流（Transform Streams）： const { Transform } = require(\u0026#39;stream\u0026#39;); // 创建转换流 const myTransform = new Transform({ transform(chunk, encoding, callback) { // 转换数据 const transformedData = chunk.toString().toUpperCase(); this.push(transformedData); callback(); } }); // 管道连接读取流、转换流和写入流 readableStream.pipe(myTransform).pipe(writableStream); 这只是 Node.js 中使用流的一些基本用法。在 Postman 中，你可以在请求的脚本中使用这些方法，例如 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分，通过 Node.js 运行环境来执行这些脚本。请注意，Node.js 中的流 API 可以更复杂，例如通过使用 pipeline 函数来处理多个流的连接。\n定时器 timers 在 Postman 中，你可以使用 Node.js 的定时器功能来处理定时任务或延时执行的操作。以下是一些基本的 Node.js 定时器的用法，这些用法可以在 Postman 的脚本中使用。\n1. setTimeout - 延时执行 // 延时执行操作 setTimeout(function() { console.log(\u0026#39;Delayed operation.\u0026#39;); }, 2000); // 2000 毫秒（2 秒） 2. setInterval - 定时执行重复操作 // 定时执行重复操作 const intervalId = setInterval(function() { console.log(\u0026#39;Repeated operation.\u0026#39;); }, 3000); // 3000 毫秒（3 秒） // 取消定时执行 // clearInterval(intervalId); 3. 在 Postman 中使用 在 Postman 中，你可以在 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分中使用这些定时器。例如，在 \u0026ldquo;Tests\u0026rdquo; 部分中延时执行操作：\n// 在 \u0026#34;Tests\u0026#34; 部分延时执行操作 setTimeout(function() { console.log(\u0026#39;Delayed operation in Tests.\u0026#39;); }, 2000); // 2000 毫秒（2 秒） 请注意，在 Postman 的 \u0026ldquo;Pre-request Script\u0026rdquo; 或 \u0026ldquo;Tests\u0026rdquo; 部分执行的代码是在 Node.js 环境中运行的，因此你可以使用 Node.js 支持的大多数功能，包括定时器。\n在以上例子中，setTimeout 会在指定的延时后执行一次操作，而 setInterval 会在每隔指定的时间间隔后执行一次操作。在 Postman 中，你可以根据实际需求使用这些定时器功能。\n时间处理 events 在 Postman 的脚本环境中，你可以使用 Node.js 的 events 模块来处理事件。events 模块提供了 EventEmitter 类，该类可以用于定义和触发事件。以下是在 Postman 中使用 Node.js 的 events 模块的一些基本用法：\n1. 创建事件发射器 const EventEmitter = require(\u0026#39;events\u0026#39;); const myEmitter = new EventEmitter(); 2. 定义事件处理函数 // 定义事件处理函数 function myEventHandler() { console.log(\u0026#39;Event handled.\u0026#39;); } 3. 注册事件处理函数 // 注册事件处理函数 myEmitter.on(\u0026#39;myEvent\u0026#39;, myEventHandler); 4. 触发事件 // 触发事件 myEmitter.emit(\u0026#39;myEvent\u0026#39;); 示例 在 Postman 的脚本环境中，你可以使用事件来实现异步操作的回调或处理。以下是一个简单的例子，演示如何在异步操作完成后触发事件：\nconst EventEmitter = require(\u0026#39;events\u0026#39;); const myEmitter = new EventEmitter(); // 模拟异步操作 function performAsyncOperation() { setTimeout(function() { console.log(\u0026#39;Async operation completed.\u0026#39;); // 触发事件 myEmitter.emit(\u0026#39;asyncOperationComplete\u0026#39;); }, 2000); } // 注册事件处理函数 myEmitter.on(\u0026#39;asyncOperationComplete\u0026#39;, function() { console.log(\u0026#39;Handling async operation completion.\u0026#39;); // 这里可以执行异步操作完成后的处理逻辑 }); // 执行异步操作 performAsyncOperation(); 在上述例子中，performAsyncOperation 函数模拟了一个异步操作，当该操作完成时，通过 myEmitter.emit 触发了 asyncOperationComplete 事件。在事件处理函数中，你可以编写处理异步操作完成后的逻辑。\n请注意，在 Postman 的脚本中，异步操作的执行方式可能受到限制，因此在实际使用中需要谨慎考虑。\n参考文档 Postman 官方文档 newman 官方文档 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/postman-tutorial-advance-usage-common-test-scripts-and-commonly-used-third-party-packages/","summary":"深入研究 Postman 接口自动化测试的高级用法，专注于常用的测试脚本和第三方包示例。探讨如何编写强大的测试脚本，涵盖各种测试场景，并介绍一些常用的第三方包，优化测试流程。","title":"Postman 接口自动化测试教程：进阶用法 - 常用的测试脚本和常用的第三方包用法示例"},{"content":"进阶用法 以下会介绍 Postman 和 Newman 的一些进阶用法，包括测试数据、测试脚本、测试报告和测试报告集成等。 也会介绍如何将 Postman 和 Newman 集成到 CI/CD 流程中，以实现自动化测试。\n输出 html 测试报告 demo 会以集成newman-reporter-htmlextra为例，介绍如何输出 html 测试报告。\n安装 newman-reporter-htmlextra 依赖包 npm install newman-reporter-htmlextra --save-dev 注意：目前 newman 最新 V6 版本在 html 测试报告的一些包兼容性上有问题，所以这里使用 5.1.2 版本\n调整 package.json 在 package.json 文件中，更新测试测试脚本，用于运行测试用例并输出 html 测试报告：\n\u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r htmlextra --reporter-htmlextra-export ./Report/Postman-newman-demo-api-testing-report.html\u0026#34; 指定输出 html 测试报告的路径为 Report/Postman-newman-demo-api-testing-report.html\n运行测试用例输出 html 报告 运行测试用例 npm run test 检查报告文件 浏览器打开报告文件 输出多种格式的测试报告 前面的配置是输出 html 格式的测试报告，如果想要输出多种格式的测试报告，如命令行 cli 的报告，可以在 package.json 文件中添加以下脚本：\n\u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r cli,htmlextra --reporter-htmlextra-export ./Report/Postman-newman-demo-api-testing-report.html\u0026#34; 再次运行测试用例，可以看到在 Report 文件夹下，除了 html 格式的测试报告，还有 cli 格式的测试报告。\nCI/CD 持续集成 将接口自动化测试的代码集成到 CI/CD 流程中，可以实现自动化测试，提高测试效率。\n接入 github action 以 github action 为例，其他 CI 工具类似\n可参考 demo：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 postman.yml。\n编辑 postman.yml 文件：将以下内容复制到文件中\nname: RUN Postman API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-Postman-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive Postman test report uses: actions/upload-artifact@v3 with: name: Postman-test-report path: Report - name: Upload Postman report to GitHub uses: actions/upload-artifact@v3 with: name: Postman-test-report path: Report 提交代码：将 postman.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN-Postman-API-Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 集成 allure 测试报告 allure 是一个轻量级的、灵活的、多语言支持的测试报告工具，可以生成各种各样的测试报告，包括饼图、柱状图、曲线图等，可以方便地查看测试结果。\n安装 allure 测试报告依赖 npm install newman-reporter-allure --save-dev 调整 package.json 中输出 allure 测试报告的脚本 \u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json -r cli,allure --reporter-allure-export ./allure-results\u0026#34; 调整 Postman 测试用例 调整 get-demo 的 Tests 脚本，添加以下脚本，用于生成 allure 测试报告： // @allure.label.suite=postman-new-api-testing-demo // @allure.label.story=\u0026#34;Verify-the-get-api-return-correct-data\u0026#34; // @allure.label.owner=\u0026#34;naodeng\u0026#34; // @allure.label.tag=\u0026#34;GETAPI\u0026#34; pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调整 post-demo 的 Tests 脚本，添加以下脚本，用于生成 allure 测试报告： // @allure.label.suite=postman-new-api-testing-demo // @allure.label.story=\u0026#34;Verify-the-post-api-return-correct-data\u0026#34; // @allure.label.owner=\u0026#34;naodeng\u0026#34; // @allure.label.tag=\u0026#34;POSTAPI\u0026#34; pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(201); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(101); pm.expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 保存更改后的 postman 测试用例，重新导出测试用例文件并替换原来的测试用例文件。 运行测试用例输出 allure 报告 运行测试用例 npm run test 会在项目文件夹下生成 allure-results 文件夹，里面包含了测试用例的执行结果。\n预览 allure 测试报告 allure serve 参考文档 Postman 官方文档 newman 官方文档 newman-reporter-htmlextra newman-reporter-allure github action 官方文档 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/postman-tutorial-advance-usage-integration-html-report-and-allure-report-integration-github-action/","summary":"Postman 接口自动化测试的进阶应用，专注于 CI/CD 和 GitHub Actions 的集成，以及 Allure 测试报告的接入。学习如何将 Postman 测试无缝整合到 CI/CD 流程中，通过 GitHub Actions 实现自动化测试。此外，了解如何集成 Allure 测试报告框架，生成详尽的测试结果报告","title":"Postman 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action，接入 allure 测试报告"},{"content":"介绍 接口测试简介 什么是 API? API:应用程序接口（全称：application programming interface），缩写为 API，是一种计算接口，它定义多个软件中介之间的交互，以及可以进行的调用（call）或请求（request）的种类，如何进行调用或发出请求，应使用的数据格式，应遵循的惯例等。它还可以提供扩展机制，以便用户可以通过各种方式对现有功能进行不同程度的扩展。一个 API 可以是完全定制的，针对某个组件的，也可以是基于行业标准设计的以确保互操作性。通过信息隐藏，API 实现了模块化编程，从而允许用户实现独立地使用接口。\n什么是 API 测试？ 接口测试是软件测试的一种，它包括两种测试类型：狭义上指的是直接针对应用程序接口（下面使用缩写 API 指代，其中文简称为接口）的功能进行的测试；广义上指集成测试中，通过调用 API 测试整体的功能完成度、可靠性、安全性与性能等指标。\nAPI Best Practice:\nAPI 定义遵循 RESTFUL API 风格，语意化的 URI 定义，准确的 HTTP 状态码，通过 API 的定义就可以知道资源间的关系 配有详细且准确的 API 文档（如 Swagger 文档） 对外的 API 可以包含版本号以快速迭代（如 https://thoughtworks.com/v1/users/） 测试四象限中不同象限的测试，其测试目的跟测试策略也不同，API 测试主要位于第二、第四象限\nAPI 测试在测试金子塔中处于一个相对靠上的位置，主要站在系统、服务边界来测试功能和业务逻辑，执行时机是在服务完成构建、部署到测试环境之后再执行、验证。\nAPI 测试类型 功能测试\n正确性测试 异常处理 内部逻辑 …… 非功能测试\n性能 安全 …… API 测试步骤 发送请求 得到响应 验证响应结果 Postman 与 newman 介绍 Postman 是一个流行的 API 开发工具，它提供了一个易于使用的图形界面，可用于创建，测试和调试 API。Postman 还提供了一个可以轻松编写和共享测试脚本的功能。它支持多种 HTTP 请求方法，包括 GET，POST，PUT，DELETE 等，并且可以使用各种身份验证和授权方式来测试 API。\nNewman 是 Postman 的命令行工具，可用于在不使用 Postman GUI 的情况下运行测试集。使用 Newman，用户可以轻松地将 Postman 集合导出为一个可执行文件，并在任何环境中运行它。此外，Newman 还支持生成 HTML 或 Junit 格式的测试报告，以及集成到 CI/CD 管道中以实现自动化测试。\n总的来说，Postman 是一个强大的 API 开发和测试工具，而 Newman 则是一个方便的命令行工具，用于在不使用 Postman GUI 的情况下运行测试集。它们的结合使用可以提高 API 测试和开发的效率和准确性。\n除了基本功能，Postman 还具有以下特性：\n环境和变量管理：Postman 支持在不同环境之间切换，例如在开发、测试和生产环境之间切换。同时，它还支持变量管理，可以轻松地为不同的测试用例和请求设置变量。 自动化测试：用户可以使用 Postman 创建和运行自动化测试，以便在持续集成或部署流程中集成。这使得测试变得更加准确和高效。 协作和共享：Postman 支持将集合和环境与团队共享，方便团队成员之间的协作。 监控：Postman 还提供 API 监控功能，可以实时监控 API 的可用性和性能。 而 Newman 则主要有以下特点：\n命令行接口：Newman 可以在命令行中运行，因此可以方便地自动化测试和集成到 CI/CD 流程中。 支持多种输出格式：Newman 支持多种输出格式，包括 HTML、JSON 和 JUnit 格式，方便用户在不同场景下使用。 并发执行：Newman 支持并发执行测试，从而提高了测试的效率。 轻量级：与 Postman GUI 相比，Newman 是一个轻量级的工具，因此在运行测试时需要更少的资源。 总之，Postman 和 Newman 是现代 API 测试的重要工具，它们提供了强大的功能，可以使 API 测试变得更加高效、准确和自动化。\n除了上述提到的功能和特点，Postman 和 Newman 还有其他一些重要的功能和优势：\n集成：Postman 和 Newman 可以与许多其他工具和服务进行集成，例如 GitHub、Jenkins、Slack 等。这使得它们可以轻松地集成到开发和部署流程中，以实现更高效的 API 开发和测试。 文档生成：Postman 可以使用 API 的请求和响应来生成 API 文档。这可以使 API 文档更加准确和及时。 测试脚本：Postman 可以使用 JavaScript 编写测试脚本，这可以使测试变得更加灵活和自定义。用户可以轻松地编写自定义测试脚本，以确保 API 的行为符合预期。 历史记录：Postman 可以存储 API 请求的历史记录，这可以方便用户查看和管理以前的请求和响应。这对于调试和问题排查非常有用。 多平台支持：Postman 和 Newman 可以在多种平台上运行，包括 Windows、MacOS 和 Linux 等。 总之，Postman 和 Newman 是现代 API 测试和开发的强大工具。它们提供了丰富的功能和灵活的测试脚本，可以帮助开发人员和测试人员更快、更准确地构建和测试 API。\n项目依赖 需提前安装好以下环境\nnodejs, demo 版本为 v21.1.0 Postman 安装完成，可通过官方网站下载安装包进行安装 项目文件结构 以下是一个 Postman 和 Newman 的接口自动化测试项目的文件结构，其中包含了测试配置文件、测试用例文件、测试工具文件和测试报告文件。可进行参考。\nPostman-Newman-demo ├── README.md ├── package.json ├── package-lock.json ├── Data // 测试配置文件 │ └── testdata.csv // 测试数据 ├── Testcase // 测试用例文件夹 │ └── APITestDemo.postman_collection.json // 测试用例文件 ├── Env // 不同测试环境文件夹 │ └── DemoEnv.postman_environment.json // 测试环境配置文件 ├── Report // 测试报告文件 │ └── report.html ├── .gitignore └── node_modules // 项目依赖 从 0 到 1 搭建 Postman 接口自动化测试项目 下面会介绍从 0 到 1 搭建一个 Postman 和 Newman 的接口自动化测试项目，包括测试配置、测试用例、测试环境、测试工具和测试报告等。\n可参考 demo 项目：https://github.com/Automation-Test-Starter/Postman-Newman-demo\n新建项目文件夹 mkdir Postman-Newman-demo 项目初始化 // 进入项目文件夹下 cd Postman-Newman-demo // nodejs 项目初始化 npm init -y 安装依赖 目前 newman 最新版本在 html 测试报告的一些包兼容性上有问题，所以这里使用 4.2.3 版本\n// 安装 newman npm install newman@4.2.3 --save-dev Postman 编写接口测试用例 新建 Collection 和 Request 打开 Postman，点击左上角的 New 按钮，选择 Collection，输入 Collection 的名称，点击 Create Collection 按钮，创建一个名称为 demo 的 Collection。 在 Collection 中，点击右上角的三个点，选择 Add Request，输入 Request 的名称，点击 Save 按钮，创建一个 Request 命名为 get-demo。再添加一个 Request 命名为 post-demo。 编辑 Request 和编写测试用例 可根据项目文件下的 demoAPI.md 文件中的接口文档，获取 demo 使用的 Request 的 URL、请求方法、请求头、请求体等信息。\nget-demo 在 get-demo 的 Request 中，选择 GET 请求方法，输入 URL 为https://jsonplaceholder.typicode.com/posts/1 在 Headers 中，添加一个 Key 为 Content-Type，Value 为 application/json; 的请求头。 在 Tests 下，添加以下脚本，用于验证响应结果： pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 点击 Send 按钮，发送请求，验证响应结果。 确认响应结果正确后，点击 Save 按钮，保存 Request。\npost-demo 在 post-demo 的 Request 中，选择 POST 请求方法，输入 URL 为https://jsonplaceholder.typicode.com/posts 在 Headers 中，添加一个 Key 为 Content-Type，Value 为 application/json; 的请求头。 在 Body 中，选择 raw，选择 JSON 格式，输入以下请求体： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 在 Tests 下，添加以下脚本，用于验证响应结果： pm.test(\u0026#34;res.status should be 201\u0026#34;, function () { pm.response.to.have.status(201); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(101); pm.expect(data.title).to.equal(\u0026#39;foo\u0026#39;); }); 确认响应结果正确后，点击 Save 按钮，保存 Request。\nPostman 编写测试环境配置文件 下面会取接口请求的 host 为环境变量来进行 demo\n添加环境变量 在 Postman 的右上角，点击齿轮图标，选择 Manage Environments，点击 Add 按钮，输入环境名称为 DemoEnv，点击 Add 按钮，创建一个名称为 DemoEnv 的环境。 编辑环境变量，添加一个 Key 为 host，Value 为https://jsonplaceholder.typicode.com的环境变量。 点击 Add 按钮，保存环境变量。 更新 Request 在 get-demo 的 Request 中，更新 URL 为{{host}}/posts/1 在 post-demo 的 Request 中，更新 URL 为{{host}}/posts 验证环境变量 在 Postman 的右上角，点击齿轮图标，选择 DemoEnv，切换环境变量为 DemoEnv。 选择 get-demo 的 Request，点击 Send 按钮，发送请求，验证响应结果。确认响应结果正确后，点击 Save 按钮，保存 Request。 选择 post-demo 的 Request，点击 Send 按钮，发送请求，验证响应结果。确认响应结果正确后，点击 Save 按钮，保存 Request。 导出环境变量和测试用例文件 在 Postman 的右上角，点击齿轮图标，选择 Export，选择 DemoEnv，点击 Export 按钮，导出环境变量。 选择 get-demo request 和 post-demo request 所在的 demo Collection，点击右上角的三个点，选择 Export，选择 Collection v2.1，点击 Export 按钮，导出测试用例文件。 调整项目文件结构 新建 Env 和 Testcase 文件夹 在项目文件夹下，新建一个名为 Env 的文件夹，用于存放环境变量文件。 // 新建 Env 文件夹 mkdir Env 在项目文件夹下，新建一个名为 Testcase 的文件夹，用于存放测试用例文件。 // 新建 Testcase 文件夹 mkdir Testcase 调整用例文件和环境变量文件 将导出的环境变量文件和测试用例文件放到项目文件夹下的 Env 和 Testcase 文件夹下。\n调整 package.json 文件 在 package.json 文件中，添加以下脚本，用于运行测试用例： \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;newman run Testcase/demo.postman_collection.json -e Env/DemoEnv.postman_environment.json\u0026#34; } 运行测试用例 npm run test 参考文档 Postman 官方文档 newman 官方文档 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/postman-tutorial-getting-started-and-building-your-own-project-from-0-to-1/","summary":"关于 Postman 接口自动化测试的导引，全面介绍入门基础和从零开始搭建项目的步骤。学习如何有效地使用 Postman 进行 API 测试，了解项目搭建的基础结构、环境设置和测试用例的编写","title":"Postman 接口自动化测试教程：入门介绍和从 0 到 1 搭建 Postman 接口自动化测试项目"},{"content":"进阶用法 并发测试和分布式测试 在日常的接口自动化测试过程中，需要并发执行测试用例，以提高测试效率。\n有时候也需要引入分布式测试，以便在多台机器上同时运行测试用例，也能更好的提升测试效率。\npytest-xdist 是 Pytest 的一个插件，能提供了一些对应的功能，主要用于支持并发测试和分布式测试。\npytest-xdist 功能介绍 并发执行测试：\n使用 -n 选项：pytest -n NUM 允许并发运行测试，其中 NUM 是并发 worker 的数量。这可以加速测试执行，特别是在拥有多个 CPU 内核的计算机上。 pytest -n 3 # 启动 3 个并发 worker 执行测试 分布式测试：\n使用 pytest --dist=loadscope：允许在多个节点上执行测试，通过分布式测试可以更快地完成测试运行。 pytest --dist=loadscope 使用 pytest --dist=each：每个节点运行一组测试，适用于分布式测试。 pytest --dist=each 参数化测试和并发：\n使用 pytest.mark.run：结合 pytest.mark.run 标记，可以选择在不同的进程或节点上运行具有不同标记的测试。 @pytest.mark.run(processes=2) def test_example(): pass 分布式环境设置：\n使用 pytest_configure_node：可以在节点上运行测试之前进行配置。 def pytest_configure_node(node): node.slaveinput[\u0026#39;my_option\u0026#39;] = \u0026#39;some value\u0026#39; 使用 pytest_configure_node：可以在节点上运行测试之前进行配置。 def pytest_configure_node(node): node.slaveinput[\u0026#39;my_option\u0026#39;] = \u0026#39;some value\u0026#39; 分布式测试环境销毁：\n使用 pytest_configure_node：可以在节点上运行测试之后进行清理。 def pytest_configure_node(node): # 配置节点 yield # 在节点上运行测试后执行清理 print(\u0026#34;Cleaning up after test run on node %s\u0026#34; % node.gateway.id) 这些是 pytest-xdist 提供的一些功能，可以帮助您更有效地执行并发测试和分布式测试，以加速测试执行并提高效率。确保在使用前查阅 pytest-xdist 的文档以获取更详细的信息和用法示例。\n安装 pytest-xdist 依赖 pip install pytest-xdist 并发运行测试用例示例 并发 3 个 worker 执行测试用例 分别运行以下命令，查看测试用例的执行时长\n并发执行 pytest -n 3 默认串行执行 pytest 串行执行耗时 9.81s，而并发执行耗时 1.63s，可以看到并发执行测试用例可以大大提高测试效率。\n并发 3 个 worker 执行测试用例，并且每个 worker 都会打印测试用例的进度 pytest -n 3 -v 测试结果中会打印测试进度，可以更好的了解测试用例的执行情况。\n分布式测试示例 分布式测试，每个节点运行一组测试 pytest --dist=each 分布式测试可以更快地完成测试运行。\n分布式测试，每个节点运行一组测试，并且每个 worker 都会打印测试用例的进度 pytest --dist=each -v 测试结果中会打印测试进度，可以更好的了解测试用例的执行情况。\n分布式测试，每个节点运行一组测试，并且每个 worker 都会打印测试用例的进度，同时打印测试日志的输出 pytest --dist=each -v --capture=no 测试结果中会打印测试日志的输出，可以更好的了解测试用例的执行情况。\n筛选用例执行 在日常的接口测试过程中，我们需要根据实际情况来选择性地执行测试用例，以提高测试效率。\n一般我们使用 allure 测试报告的时候，可以使用 Allure 标签特性来进行筛选对应标签的的用例来执行测试，但 Pytest 框架不直接支持运行基于 Allure 标签的测试。所以可以使用 Pytest 标记来实现这一点。\nPytest 提供 marks标记功能可以用来标记不同类型的测试用例，然后进行筛选对应类型的测试用例进行执行。\n大致流程为你可以用自定义标记（如 Regression/Smoke）来标记测试，然后使用 pytest 的 -m 选项只运行这些测试。\n定义 Pytest 标记 编辑 pytest.ini 文件，添加以下内容：自定义标记的类型\nRegression:标记为回归测试的用例 Smoke:标记为冒烟测试的用例 markers = Regression: marks tests as Regression Smoke: marks tests as Smoke 标记用例 操作步骤为：\n引入 pytest 使用 @pytest.mark 标记测试用例 为做区分，这里新建测试用例文件，文件名为 test_demo_filter.py\nimport pytest import requests import json class TestPytestMultiEnvDemo: @pytest.mark.Regression # mark the test case as regression def test_get_demo_filter(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send request response = requests.get(host+get_api) # assert assert response.status_code == 200 assert response.json() == get_api_response_data @pytest.mark.Smoke # mark the test case as smoke def test_post_demo_filter(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] print(\u0026#34;make the request\u0026#34;) post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # Your test code here response = requests.post(host + post_api, json=post_api_request_data) print(\u0026#34;verify the response status code\u0026#34;) assert response.status_code == 201 print(\u0026#34;verify the response data\u0026#34;) assert response.json() == post_api_response_data 筛选测试用例执行 运行 Regression 标记的测试用例 pytest -m Regression 这条命令告诉 pytest 只运行标有 Regression 的测试。\n运行 Smoke 标记的测试用例 pytest -m Smoke 这条命令告诉 pytest 只运行标有 Smoke 的测试。\n参考资料 pytest-xdist 文档:https://pytest-xdist.readthedocs.io/en/stable/ pytest makers 文档:https://docs.pytest.org/en/6.2.x/example/markers.html pytest 文档:https://docs.pytest.org/en/6.2.x/ ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/pytest-tutorial-advance-usage-filter-testcase-and-concurrent-testing-distributed-testing/","summary":"聚焦于测试用例筛选、并发测试和分布式测试。学会如何有针对性地执行测试用例，提高测试效率。探索 Pytest 的并发测试特性，了解如何同时执行多个测试用例，缩短测试时间。","title":"Pytest 接口自动化测试教程：进阶用法 - 筛选测试用例执行，并发测试和分布式测试"},{"content":"进阶用法 多环境支持 在实际的 API 自动化测试过程中，我们需要在不同的环境中运行测试用例，以确保 API 在各个环境中都能正常运行。\n通过使用 Pytest 的 fixture 功能，我们可以轻松地实现多环境支持。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n新建不同环境测试配置文件 配置文件会以 json 格式存储为例，其他格式如 YAML、CSV 等类似，均可参考\n// 新建测试配置文件夹 mkdir config // 进入测试配置文件夹 cd config // 新建开发环境测试配置文件 touch dev_config.json // 新建生产环境测试配置文件 touch prod_config.json 编写不同环境测试配置文件 编写开发环境测试配置文件 根据实际情况配置开发环境测试配置文件\n{ \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 编写生产环境测试配置文件 根据实际情况配置生产环境测试配置文件\n{ \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 新建不同环境测试数据文件 不同环境请求数据文件和响应数据文件分别存储测试用例的不同环境请求数据和不同环境预期响应数据。\n// 新建测试数据文件夹 mkdir data // 进入测试数据文件夹 cd data // 新建开发环境请求数据文件 touch dev_request_data.json // 新建开发环境响应数据文件 touch dev_response_data.json // 新建生产环境请求数据文件 touch prod_request_data.json // 新建生产环境响应数据文件 touch prod_response_data.json 编写不同环境测试数据文件 编写开发环境请求数据文件 开发环境请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写开发环境响应数据文件 开发环境响应数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 编写生产环境请求数据文件 生产环境请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写生产环境响应数据文件 生产环境响应数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 配置支持多环境的 fixture fixture 会以 conftest.py 文件存储为例，其他格式如 YAML、CSV 等类似，均可参考\n项目根目录新建 conftest.py 文件 mkdrir conftest.py 编写 conftest.py 文件 import pytest import json import json import os @pytest.fixture(scope=\u0026#34;session\u0026#34;) def env_config(request): # get config file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;config/{env}_config.json\u0026#39;, \u0026#39;r\u0026#39;) as config_file: config = json.load(config_file) return config @pytest.fixture(scope=\u0026#34;session\u0026#34;) def env_request_data(request): # get request data file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;data/{env}_request_data.json\u0026#39;, \u0026#39;r\u0026#39;) as request_data_file: request_data = json.load(request_data_file) return request_data @pytest.fixture (scope=\u0026#34;session\u0026#34;) def env_response_data(request): # get response data file from different env env = os.getenv(\u0026#39;ENV\u0026#39;, \u0026#39;dev\u0026#39;) with open(f\u0026#39;data/{env}_response_data.json\u0026#39;, \u0026#39;r\u0026#39;) as response_data_file: response_data = json.load(response_data_file) return response_data 更新测试用例来支持多环境 为做区分，这里新建测试用例文件，文件名为 test_demo_multi_environment.py\nimport requests import json class TestPytestMultiEnvDemo: def test_get_demo_multi_env(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send request response = requests.get(host+get_api) # assert assert response.status_code == 200 assert response.json() == get_api_response_data def test_post_demo_multi_env(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # send request response = requests.post(host + post_api, post_api_request_data) # assert assert response.status_code == 201 assert response.json() == post_api_response_data 运行该测试用例确认多环境支持是否生效 运行开发环境测试用例 ENV=dev pytest test_case/test_demo_multi_environment.py 运行生产环境测试用例 ENV=prod pytest test_case/test_demo_multi_environment.py 集成 allure 报告 allure 是一个轻量级的、灵活的、易于扩展的测试报告工具，它提供了丰富的报告类型和功能，可以帮助您更好地可视化测试结果。\nallure 报告可以与 Pytest 集成，以生成详细的测试报告。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n安装 allure-pytest 依赖 pip install allure-pytest 避免之前安装的 pytest-html-reporter 与 allure-pytest 冲突，建议先卸载 pytest-html-reporter\npip uninstall pytest-html-reporter 配置 allure-pytest 更新 pytest.ini 文件来指定 allure 报告的存储位置\n[pytest] # allure addopts = --alluredir ./allure-results 调整测试用例来支持 allure 报告 为做区分，这里新建测试用例文件，文件名为 test_demo_allure.py\nimport allure import requests @allure.feature(\u0026#34;Test example API\u0026#34;) class TestPytestAllureDemo: @allure.story(\u0026#34;Test example get endpoint\u0026#34;) @allure.title(\u0026#34;Verify the get API\u0026#34;) @allure.description(\u0026#34;verify the get API response status code and data\u0026#34;) @allure.severity(\u0026#34;blocker\u0026#34;) def test_get_example_endpoint_allure(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] get_api = env_config[\u0026#34;getAPI\u0026#34;] get_api_request_data = env_request_data[\u0026#34;getAPI\u0026#34;] get_api_response_data = env_response_data[\u0026#34;getAPI\u0026#34;] # send get request response = requests.get(host + get_api) # assert print(\u0026#34;response status code is\u0026#34; + str(response.status_code)) assert response.status_code == 200 print(\u0026#34;response data is\u0026#34; + str(response.json())) assert response.json() == get_api_response_data @allure.story(\u0026#34;Test example POST API\u0026#34;) @allure.title(\u0026#34;Verify the POST API\u0026#34;) @allure.description(\u0026#34;verify the POST API response status code and data\u0026#34;) @allure.severity(\u0026#34;Critical\u0026#34;) def test_post_example_endpoint_allure(self, env_config, env_request_data, env_response_data): host = env_config[\u0026#34;host\u0026#34;] post_api = env_config[\u0026#34;postAPI\u0026#34;] post_api_request_data = env_request_data[\u0026#34;postAPI\u0026#34;] post_api_response_data = env_response_data[\u0026#34;postAPI\u0026#34;] # send request response = requests.post(host + post_api, json=post_api_request_data) # assert print(\u0026#34;response status code is\u0026#34; + str(response.status_code)) assert response.status_code == 201 print(\u0026#34;response data is\u0026#34; + str(response.json())) assert response.json() == post_api_response_data 运行测试用例生成 allure 报告 ENV=dev pytest test_case/test_demo_allure.py 查看 allure 报告 输入以下命令来启动 allure 服务并浏览器中查看 allure 报告\nallure serve allure-results 调整 CI/CD 流程来支持 allure 报告 以 github action 为例，其他 CI 工具类似\n更新.github/workflows/pytest.yml 文件内容来上传 allure 报告到 GitHub\nname: Pytest API Testing on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] permissions: contents: read jobs: Pytes-API-Testing: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python 3.10 uses: actions/setup-python@v3 with: python-version: \u0026#34;3.10\u0026#34; - name: Install dependencies run: | python -m pip install --upgrade pip pip install -r requirements.txt - name: Test with pytest run: | ENV=dev pytest - name: Archive Pytest allure test report uses: actions/upload-artifact@v3 with: name: Pytest-allure-report path: allure-results - name: Upload Pytest allure report to GitHub uses: actions/upload-artifact@v3 with: name: Pytest-allure-report path: allure-results 查看 github action allure 报告 在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Pytest API Testing 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。\n参考 Pytest 文档 Allure 文档 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/pytest-tutorial-advance-usage-multiple-environment-support-and-integration-allure-report/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 如何支持不同环境测试用例执行，以及如何集成 allure 报告来实现测试报告多样化。","title":"Pytest 接口自动化测试教程：进阶用法 - 多环境支持 和 集成 allure 报告"},{"content":"进阶用法 常用断言 使用 Pytest 在接口自动化测试用例编写过程中，我们需要使用各种断言来验证测试的预期结果。\nPytest 提供了更多的断言和灵活的断言库，以满足各种测试需求。\n以下是一些常用的 Pytest 接口自动化测试断言：\n相等性断言：检查两个值是否相等。\nassert actual_value == expected_value 不相等性断言：检查两个值是否不相等。\nassert actual_value != expected_value 包含断言：检查一个值是否包含在另一个值中，通常用于检查字符串是否包含子字符串。\nassert substring in full_string 成员资格断言：检查一个值是否在集合、列表或其他可迭代对象中。\nassert item in iterable 真值断言：检查一个表达式或变量是否为真。\nassert expression 或\nassert variable 假值断言：检查一个表达式或变量是否为假。\nassert not expression 或\nassert not variable 大于、小于、大于等于、小于等于断言：检查一个值是否大于、小于、大于等于或小于等于另一个值。\nassert value \u0026gt; other_value assert value \u0026lt; other_value assert value \u0026gt;= other_value assert value \u0026lt;= other_value 类型断言：检查一个值的类型是否符合预期。\nassert isinstance(value, expected_type) 例如，检查一个值是否是字符串：\nassert isinstance(my_string, str) 异常断言：检查在代码块中是否引发了特定类型的异常。\nwith pytest.raises(ExpectedException): # 代码块，期望引发 ExpectedException 异常 近似相等断言：检查两个浮点数是否在某个误差范围内相等。\nassert math.isclose(actual_value, expected_value, rel_tol=1e-9) 列表相等断言：检查两个列表是否相等。\nassert actual_list == expected_list 字典相等断言：检查两个字典是否相等。\nassert actual_dict == expected_dict 正则表达式匹配断言：检查一个字符串是否匹配给定的正则表达式。\nimport re assert re.match(pattern, string) 空值断言：检查一个值是否为 None。\nassert value is None 非空值断言：检查一个值是否不为 None。\nassert value is not None 布尔值断言：检查一个值是否为 True 或 False。\nassert boolean_expression 空容器断言：检查一个列表、集合或字典是否为空。\nassert not container # 检查容器是否为空 包含子集断言：检查一个集合是否包含另一个集合作为子集。\nassert subset \u0026lt;= full_set 字符串开头或结尾断言：检查一个字符串是否以指定的前缀或后缀开头或结尾。\nassert string.startswith(prefix) assert string.endswith(suffix) 数量断言：检查一个列表、集合或其他可迭代对象的元素数量。\nassert len(iterable) == expected_length 范围断言：检查一个值是否在指定的范围内。\nassert lower_bound \u0026lt;= value \u0026lt;= upper_bound 文件存在断言：检查文件是否存在。\nimport os assert os.path.exists(file_path) 以上是一些 Pytest 常用的断言，但根据具体的测试需求，您可能会使用其他断言或结合多个断言来更全面地验证测试结果。 详细的断言文档可以在 Pytest 官方网站找到：Pytest - Built-in fixtures, marks, and nodes\n数据驱动 在 API 自动化测试的过程中。使用数据驱动是一种常规测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。\n测试数据可以很容易地修改，而不需要修改测试用例代码。\n数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n新建测试配置文件 配置文件会以 json 格式存储为例，其他格式如 YAML、CSV 等类似，均可参考\n// 新建测试配置文件夹 mkdir config // 新建测试配置文件 cd config touch config.json 编写测试配置文件 配置文件存储测试环境的配置信息，如测试环境的 URL、数据库连接信息等。\ndemo 中的测试配置文件内容如下：\n配置 host 信息 配置 getAPI 接口信息 配置 postAPI 接口信息 { \u0026#34;host\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;, \u0026#34;getAPI\u0026#34;: \u0026#34;/posts/1\u0026#34;, \u0026#34;postAPI\u0026#34;:\u0026#34;/posts\u0026#34; } 新建测试数据文件 请求数据文件和响应数据文件分别存储测试用例的请求数据和预期响应数据。\n// 新建测试数据文件夹 mkdir data // 进入测试数据文件夹 cd data // 新建请求数据文件 touch request_data.json // 新建响应数据文件 touch response_data.json 编写测试数据文件 编写请求数据文件 请求数据文件中配置了 getAPI 接口的请求数据和 postAPI 接口的请求数据\n{ \u0026#34;getAPI\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } } 编写响应数据文件 请求数据文件中配置了 getAPI 接口的响应数据和 postAPI 接口的响应数据\n{ \u0026#34;getAPI\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, \u0026#34;postAPI\u0026#34;:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } } 更新测试用例来支持数据驱动 为做区分，这里新建测试用例文件，文件名为 test_demo_data_driving.py\nimport requests import json # 从配置文件夹获取测试配置 with open(\u0026#34;config/config.json\u0026#34;, \u0026#34;r\u0026#34;) as json_file: config = json.load(json_file) # 从测试数据文件夹获取接口请求数据 with open(\u0026#39;data/request_data.json\u0026#39;, \u0026#39;r\u0026#39;) as json_file: request_data = json.load(json_file) # 从测试数据文件夹获取接口响应数据 with open(\u0026#39;data/response_data.json\u0026#39;, \u0026#39;r\u0026#39;) as json_file: response_data = json.load(json_file) class TestPytestDemo: def test_get_demo(self): host = config.get(\u0026#34;host\u0026#34;) get_api = config.get(\u0026#34;getAPI\u0026#34;) get_api_response_data = response_data.get(\u0026#34;getAPI\u0026#34;) # 发起请求 response = requests.get(host+get_api) # 断言 assert response.status_code == 200 assert response.json() == get_api_response_data def test_post_demo(self): host = config.get(\u0026#34;host\u0026#34;) post_api = config.get(\u0026#34;postAPI\u0026#34;) post_api_request_data = request_data.get(\u0026#34;postAPI\u0026#34;) post_api_response_data = response_data.get(\u0026#34;postAPI\u0026#34;) # 发起请求 response = requests.post(host + post_api, post_api_request_data) # 断言 assert response.status_code == 201 assert response.json() == post_api_response_data 运行该测试用例确认数据驱动是否生效 若用 demo 项目运行数据驱动支持测试用例：test_demo_data_driving.py，建议先屏蔽掉其他测试用例，否则可能会报错\n参考 pytest 文档 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/pytest-tutorial-advance-usage-common-assertions-and-data-driven/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 常用断言和数据驱动。","title":"Pytest 接口自动化测试教程：进阶用法 - 常用断言和数据驱动"},{"content":"进阶用法 持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\n可参考 demo：https://github.com/Automation-Test-Starter/Pytest-API-Test-Demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 pytest.yml。\n编辑 pytest.yml 文件：将以下内容复制到文件中\n# This workflow will install Python dependencies, run tests and lint with a single version of Python # For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python name: Pytest API Testing on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] permissions: contents: read jobs: Pytes-API-Testing: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up Python 3.10 uses: actions/setup-python@v3 with: python-version: \u0026#34;3.10\u0026#34; - name: Install dependencies run: | python -m pip install --upgrade pip pip install -r requirements.txt - name: Test with pytest run: | pytest - name: Archive Pytest test report uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: report - name: Upload Pytest report to GitHub uses: actions/upload-artifact@v3 with: name: Pytest-test-report path: report 提交代码：将 pytest.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Pytest API Testing 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 参考 pytest 文档 gitHub action 文档 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/pytest-tutorial-advance-usage-integration-ci-cd-and-github-action/","summary":"深入探讨 Pytest 的高级用法，着重介绍如何将 Pytest 集成到 CI/CD 流程中，以及如何使用 GitHub Actions 实现自动化测试。","title":"Pytest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action"},{"content":"从 0 到 1 搭建 Pytest 接口自动化测试项目 1.创建项目目录 mkdir Pytest-API-Testing-Demo 2.项目初始化 // 进入项目文件夹下 cd Pytest-API-Testing-Demo // 创建项目 python 项目虚拟环境 python -m venv .env // 启用项目 python 项目虚拟环境 source .env/bin/activate 3.安装项目依赖 // 安装 requests 包 pip install requests // 安装pytest 包 pip install pytest // 将项目依赖项保存到 requirements.txt 文件中 pip freeze \u0026gt; requirements.txt 4.新建测试文件及测试用例 // 新建测试文件夹 mkdir tests // 新建测试用例文件 cd tests touch test_demo.py 5.编写测试用例 测试接口可参考项目中 demoAPI.md 文件\nimport requests class TestPytestDemo: def test_get_demo(self): base_url = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34; # 发起请求 response = requests.get(f\u0026#34;{base_url}/posts/1\u0026#34;) # 断言 assert response.status_code == 200 assert response.json()[\u0026#39;userId\u0026#39;] == 1 assert response.json()[\u0026#39;id\u0026#39;] == 1 def test_post_demo(self): base_url = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34; requests_data = { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } # 发起请求 response = requests.post(f\u0026#34;{base_url}/posts\u0026#34;, requests_data) # 断言 assert response.status_code == 201 print(response.json()) assert response.json()[\u0026#39;userId\u0026#39;] == \u0026#39;1\u0026#39; assert response.json()[\u0026#39;id\u0026#39;] == 101 6.运行测试用例 pytest 7.查看测试报告 8.接入 pytest-html-reporter 测试报告 https://github.com/prashanth-sams/pytest-html-reporter\n安装 pytest-html-reporter 依赖 pip install pytest-html-reporter 配置测试报告参数 项目根目录下新建 pytest.ini 文件 添加以下内容 [pytest] addopts = -vs -rf --html-report=./report --title=\u0026#39;PYTEST REPORT\u0026#39; --self-contained-html 运行测试用例 pytest 查看测试报告 报告在项目根目录下的 report 目录下，使用浏览器打开 pytest_html_report.html 文件即可查看\n","permalink":"https://naodeng.com.cn/posts/api-automation-testing/pytest-tutorial-building-your-own-project-from-0-to-1/","summary":"将从零开始教您如何建立 Pytest 接口自动化测试项目。您将学习如何创建项目的基础结构，设置环境，编写测试用例，以及执行自动化测试。","title":"Pytest 接口自动化测试教程：从 0 到 1 搭建 Pytest 接口自动化测试项目"},{"content":"介绍 Pytest 介绍 Pytest 是一个流行的 Python 测试框架，用于编写、组织和运行各种类型的自动化测试。它提供了丰富的功能，使您能够轻松编写和管理测试用例，以及生成详细的测试报告。以下是 Pytest 的一些主要特点和优势：\n简单和易用：Pytest 的设计使得编写测试用例变得简单且易于理解。您可以使用 Python 的标准 assert 语句来编写测试断言，而不需要学习新的断言语法。\n自动发现测试用例：Pytest 可以自动发现和运行项目中的测试用例，而不需要显式配置测试套件。测试用例文件可以命名为 test_*.py 或 *_test.py，或使用特定的测试函数命名规范。\n丰富的插件生态系统：Pytest 可以通过插件扩展其功能。有许多第三方插件可用，以满足不同测试需求，如 Allure 报告、参数化、覆盖率分析等。\n参数化测试：Pytest 支持参数化测试，允许您运行相同的测试用例多次，但使用不同的参数。这可以减少代码重复，提高测试覆盖率。\n异常和故障定位：Pytest 提供详细的错误和异常信息，有助于您更容易地定位和解决问题。它还提供详细的回溯（traceback）信息。\n并行测试执行：Pytest 支持并行执行测试用例，提高了测试执行的速度，特别是在大型项目中。\n多种报告格式：Pytest 支持多种测试报告格式，包括终端输出、JUnit XML、HTML 报告和 Allure 报告等。这些报告可以帮助您可视化测试结果。\n命令行选项：Pytest 提供了丰富的命令行选项，以定制测试运行的行为，包括过滤、重试、覆盖率分析等。\n集成性：Pytest 可以与其他测试框架和工具（如 Selenium、Django、Flask 等）以及持续集成系统（如 Jenkins、Travis CI 等）轻松集成。\n活跃的社区：Pytest 拥有一个活跃的社区，有广泛的文档和教程可供学习和参考。您还可以在社区中获得支持和解决问题。\n总之，Pytest 是一个强大且灵活的测试框架，适用于各种规模和类型的项目。它的易用性、自动化能力以及丰富的插件使它成为 Python 测试领域的首选工具之一。\n官方网站：https://docs.pytest.org/en/latest/\npython 虚拟环境介绍 Python 虚拟环境（Virtual Environment）是一种机制，用于在单个 Python 安装中创建和管理多个隔离的开发环境。虚拟环境有助于解决不同项目之间的依赖冲突问题，确保每个项目都能够使用其独立的 Python 包和库，而不会相互干扰。以下是如何创建和使用 Python 虚拟环境的步骤：\n安装虚拟环境工具: 在开始之前，确保您已安装 Python 的虚拟环境工具。在 Python 3.3 及更高版本中，venv 模块已经内置，可以使用它来创建虚拟环境。如果您使用较旧版本的 Python，您可以安装 virtualenv 工具。\n对于 Python 3.3+，venv 工具已内置，无需额外安装。\n对于 Python 2.x，可以使用以下命令安装 virtualenv 工具：\npip install virtualenv 创建虚拟环境: 打开终端，移动到您希望创建虚拟环境的目录，并运行以下命令以创建虚拟环境：\n使用 venv（适用于 Python 3.3+）：\npython -m venv myenv 使用 virtualenv（适用于 Python 2.x）：\nvirtualenv myenv 在上述命令中，myenv 是虚拟环境的名称，您可以自定义名称。\n激活虚拟环境: 要开始使用虚拟环境，需要激活它。在不同的操作系统中，激活命令略有不同：\n在 macOS 和 Linux 上：\nsource myenv/bin/activate 在 Windows 上（使用 Command Prompt）：\nmyenv\\Scripts\\activate 在 Windows 上（使用 PowerShell）：\n.\\myenv\\Scripts\\Activate.ps1 一旦虚拟环境激活，您会在终端提示符前看到虚拟环境的名称，表示您已进入虚拟环境。\n在虚拟环境中安装依赖: 在虚拟环境中，您可以使用 pip 安装项目所需的任何 Python 包和库，这些依赖将与该虚拟环境关联。例如：\npip install requests 使用虚拟环境: 在虚拟环境中工作时，您可以运行 Python 脚本和使用安装在虚拟环境中的包。这确保了您的项目在独立的环境中运行，不会与全局 Python 安装产生冲突。\n退出虚拟环境: 要退出虚拟环境，只需在终端中运行以下命令：\ndeactivate 这将使您返回到全局 Python 环境。\n通过使用虚拟环境，您可以在不同项目之间维护干净的依赖关系，并确保项目的稳定性和隔离性。这是 Python 开发中的一个良好实践。\n项目依赖 需提前安装好以下环境\npython, demo 版本为 v3.11.6 大家安装 python3.x 以上的版本即可\n项目目录结构 以下为一个 Pytest 接口自动化测试项目的目录结构示例：\n后续 demo 项目会引入 allure 报告，所以会多出一个 allure-report 目录\nPytest-allure-demo/ ├── tests/ # 存放测试用例文件 │ ├── test_login.py # 示例测试用例文件 │ ├── test_order.py # 示例测试用例文件 │ └── ... ├── data/ # 存放测试数据文件（如 JSON、CSV 等） │ ├── dev_test_data.json # 开发环境测试数据文件 │ ├── prod_test_data.json # 生产环境测试数据文件 │ ├── ... ├── config/ │ ├── dev_config.json # 开发环境配置文件 │ ├── prod_config.json # 生产环境配置文件 │ ├── ... ├── conftest.py # Pytest 的全局配置文件 ├── pytest.ini # Pytest 配置文件 ├── requirements.txt # 项目依赖项文件 └── allure-report/ # 存放 Allure 报告 参考 Pytest: https://docs.pytest.org/en/latest/ ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/pytest-tutorial-getting-started-and-own-environment-preparation/","summary":"包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 Pytest 以及如何开始使用它来进行 API 测试。","title":"Pytest 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"多环境支持 在使用 Jest 或 Mocha 进行 API 测试时，你可能需要支持测试不同的环境，例如开发环境、测试环境和生产环境。这可以通过配置不同的测试脚本和环境变量来实现。\n下面会简单描述一下如何在 Jest 和 Mocha 中配置多环境支持，会以支持两个环境来进行 demo 演示。\nMocha 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\nJest 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\nmocha 版本和 Jest 版本类似，这里以 Mocha 版本为例\n新建多环境测试配置文件 // 新建测试配置文件夹 若已有则不用新建 mkdir Config // 新建测试环境测试配置文件 cd Config touch testConfig-test.js // 新建开发环境测试配置文件 touch testConfig-dev.js 编写多环境测试配置文件 编写测试环境测试配置文件 根据实际情况编写测试环境测试配置文件\n// Test config file for test environment module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 编写开发环境测试配置文件 根据实际情况编写开发环境测试配置文件\n// Test config file for dev environment module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 新建多环境测试数据文件 // 新建测试数据文件夹 若已有则不用新建 mkdir testData // 进入测试数据文件夹 cd testData // 新建测试环境请求数据文件 touch requestData-test.js // 新建测试环境响应数据文件 touch responseData-test.js // 新建开发环境请求数据文件 touch requestData-dev.js // 新建开发环境响应数据文件 touch responseData-dev.js 编写多环境测试数据文件 编写测试环境请求数据文件 根据实际情况编写测试环境请求数据文件\n// Test request data file for test environment module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写测试环境响应数据文件 根据实际情况编写测试环境响应数据文件\n// Test response data file for test environment module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 编写开发环境请求数据文件 根据实际情况编写开发环境请求数据文件\n// Test request data file for dev environment module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写开发环境响应数据文件 根据实际情况编写开发环境响应数据文件\n// Test response data file for dev environment module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 更新测试用例来支持多环境 为做区分，这里新建测试用例文件，文件名为 multiEnvTest.spec.js\n// Test: multiEnvTest.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect const config = process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../Config/testConfig-test\u0026#39;) : require(\u0026#39;../Config/testConfig-dev\u0026#39;); // import test config const requestData = process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../TestData/requestData-test\u0026#39;) : require(\u0026#39;../TestData/requestData-dev\u0026#39;); // import request data const responseData= process.env.NODE_ENV === \u0026#39;test\u0026#39; ? require(\u0026#39;../TestData/responseData-test\u0026#39;) : require(\u0026#39;../TestData/responseData-dev\u0026#39;); // import response data // Test Suite describe(\u0026#39;multiEnv-Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;multiEnv-Verify that the GET API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .get(config.getAPI) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.getAPI.id) expect(res.body.userId).to.equal(responseData.getAPI.userId) expect(res.body.title).to.equal(responseData.getAPI.title) expect(res.body.body).to.equal(responseData.getAPI.body) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;multiEnv-Verify that the POST API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .post(config.postAPI) // API endpoint .send(requestData.postAPI) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.postAPI.id ) expect(res.body.userId).to.equal(responseData.postAPI.userId ) expect(res.body.title).to.equal(responseData.postAPI.title ) expect(res.body.body).to.equal(responseData.postAPI.body ) }) // expected response body .end(done) // end the test case }); }); 更新测试脚本来支持多环境 \u0026lsquo;\u0026lsquo;\u0026lsquo;json // package.json \u0026ldquo;scripts\u0026rdquo;: { \u0026ldquo;test\u0026rdquo;: \u0026ldquo;NODE_ENV=test mocha\u0026rdquo; // 运行测试环境测试脚本 \u0026ldquo;dev\u0026rdquo;: \u0026ldquo;NODE_ENV=dev mocha\u0026rdquo; // 运行 dev 环境测试脚本 }, \u0026rsquo;\u0026rsquo;\u0026rsquo;\n运行该测试用例确认多环境支持是否生效 若用 demo 项目运行多环境支持测试用例：multiEnvTest.spec.js，建议先屏蔽掉 dataDrivingTest.spec.js 和 test.spec.js 测试用例，否则会报错\n运行测试环境测试脚本 npm run test 运行开发环境测试脚本 npm run dev ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/supertest-tutorial-advance-usage-multiple-environment-support/","summary":"专注于 SuperTest 的高级用法，着重介绍多环境支持。您将学习如何配置和管理多个测试环境，以适应不同开发和部署阶段。","title":"SuperTest 接口自动化测试教程：进阶用法 - 多环境支持"},{"content":"数据驱动 API 测试的数据驱动是一种测试方法，其中测试用例的输入数据和预期输出数据都被存储在数据文件中，测试框架根据这些数据文件执行多次测试，以验证 API 的各个方面。数据驱动测试可以帮助你有效地覆盖多种情况，确保 API 在各种输入数据下都能正常运行。\nMocha 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\nJest 版本可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\nmocha 版本和 Jest 版本类似，这里以 Mocha 版本为例\n新建测试配置文件 // 新建测试配置文件夹 mkdir Config // 新建测试配置文件 cd Config touch config.js 编写测试配置文件 // Test config file module.exports = { host: \u0026#39;https://jsonplaceholder.typicode.com\u0026#39;, // Test endpoint getAPI: \u0026#39;/posts/1\u0026#39;, // Test GET API URL postAPI: \u0026#39;/posts\u0026#39;, // Test POST API URL }; 新建测试数据文件 // 新建测试数据文件夹 mkdir testData // 进入测试数据文件夹 cd testData // 新建请求数据文件 touch requestData.js // 新建响应数据文件 touch responseData.js 编写测试数据文件 编写请求数据文件 // Test request data file module.exports = { getAPI: \u0026#39;\u0026#39;, // request data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }, // request data for POST API }; 编写响应数据文件 // Test response data file module.exports = { getAPI: { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; }, // response data for GET API postAPI:{ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 }, // response data for POST API }; 更新测试用例来支持数据驱动 为做区分，这里新建测试用例文件，文件名为 dataDrivingTest.spec.js\n// Test: dataDrivingTest.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect const config = require(\u0026#39;../Config/testConfig\u0026#39;); // import test config const requestData = require(\u0026#39;../TestData/requestData\u0026#39;); // import request data const responseData = require(\u0026#39;../TestData/responseData\u0026#39;); // import response data // Test Suite describe(\u0026#39;Data Driving-Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;Data Driving-Verify that the GET API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .get(config.getAPI) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.getAPI.id) expect(res.body.userId).to.equal(responseData.getAPI.userId) expect(res.body.title).to.equal(responseData.getAPI.title) expect(res.body.body).to.equal(responseData.getAPI.body) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;Data Driving-Verify that the POST API returns correctly\u0026#39;, function(done){ request(config.host) // Test endpoint .post(config.postAPI) // API endpoint .send(requestData.postAPI) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(responseData.postAPI.id ) expect(res.body.userId).to.equal(responseData.postAPI.userId ) expect(res.body.title).to.equal(responseData.postAPI.title ) expect(res.body.body).to.equal(responseData.postAPI.body ) }) // expected response body .end(done) // end the test case }); }); 运行该测试用例确认数据驱动是否生效 若用 demo 项目运行数据驱动支持测试用例：dataDrivingTest.spec.js，建议先屏蔽掉 test.spec.js 测试用例，否则会报错\n","permalink":"https://naodeng.com.cn/posts/api-automation-testing/supertest-tutorial-advance-usage-data-driven/","summary":"专注于 SuperTest 的高级用法，侧重于数据驱动测试。您将学习如何通过数据参数化来扩展和优化您的 SuperTest 测试套件，提高测试覆盖率。","title":"SuperTest 接口自动化测试教程：进阶用法 - 数据驱动"},{"content":"常用断言 下面会一次介绍一下 SuperTest,CHAI 和 Jest 常用的断言。\nSuperTest 的内置断言 Supertest 是基于SuperAgent 构建的一个更高级的库，所以 Supertest 可以很轻松的使用 SuperAgent 的 HTTP 断言。\n示例如下：\n.expect(status[, fn]) //断言响应状态代码。 .expect(status, body[, fn]) // 断言响应状态代码和正文。 .expect(body[, fn]) // 用字符串、正则表达式或解析后的正文对象断言响应正文文本。 .expect(field, value[, fn]) // 用字符串或正则表达式断言标题字段值。 .expect(function(res) {}) // 传递一个自定义断言函数。它将得到要检查的响应对象。如果检查失败，则抛出错误。 CHAI 的常用断言 相等性断言（Equality Assertions） expect(actual).to.equal(expected) // 验证实际值是否等于期望值。 expect(actual).to.deep.equal(expected) // 验证实际值和期望值是否深度相等，适用于对象和数组比较。 expect(actual).to.eql(expected) // 与 deep.equal 一样，用于深度相等的比较。 包含性断言（Inclusion Assertions） expect(array).to.include(value) // 验证数组是否包含指定的值。 expect(string).to.include(substring) // 验证字符串是否包含指定的子字符串。 expect(object).to.include(key) // 验证对象是否包含指定的键。 类型断言（Type Assertions） expect(actual).to.be.a(type) // 验证实际值的类型是否等于指定类型。 expect(actual).to.be.an(type) // 与 to.be.a 一样，用于类型断言。 expect(actual).to.be.an.instanceof(constructor) // 验证实际值是否是指定构造函数的实例。 真假性断言（Truthiness Assertions） expect(value).to.be.true // 验证值是否为真。 expect(value).to.be.false // 验证值是否为假。 expect(value).to.exist // 验证值是否存在，非 null 和非 undefined。 长度断言（Length Assertions） expect(array).to.have.length(length) // 验证数组的长度是否等于指定长度。 expect(string).to.have.lengthOf(length) // 验证字符串的长度是否等于指定长度。 空值断言（Empty Assertions） expect(array).to.be.empty // 验证数组是否为空。 expect(string).to.be.empty // 验证字符串是否为空。 范围断言（Range Assertions） expect(value).to.be.within(min, max) // 验证值是否在指定的范围内。 expect(value).to.be.above(min) // 验证值是否大于指定值。 expect(value).to.be.below(max) // 验证值是否小于指定值。 异常断言（Exception Assertions） expect(fn).to.throw(error) // 验证函数是否抛出指定类型的异常。 expect(fn).to.throw(message) // 验证函数是否抛出包含指定消息的异常。 存在性断言（Existence Assertions） expect(object).to.have.property(key) // 验证对象是否包含指定属性。 expect(array).to.have.members(subset) // 验证数组是否包含指定的成员。 更多 chai 的断言，请查看https://www.chaijs.com/api/assert/\nJest 的常用断言 相等性断言（Equality Assertions） expect(actual).toBe(expected) // 验证实际值是否严格等于期望值。 expect(actual).toEqual(expected) // 验证实际值和期望值是否深度相等，适用于对象和数组比较。 不相等性断言 expect(actual).not.toBe(expected) // 验证实际值与期望值不相等。 包含性断言（Inclusion Assertions） expect(array).toContain(value) // 验证数组是否包含指定的值。 类型断言（Type Assertions） expect(actual).toBeTypeOf(expected) // 验证实际值的类型是否等于指定类型。 真假性断言（Truthiness Assertions） expect(value).toBeTruthy() // 验证值是否为真。 expect(value).toBeFalsy() // 验证值是否为假。 异步断言 await expect(promise).resolves.toBe(expected) // 验证异步操作是否成功完成并返回与期望值匹配的结果。 异常断言 expect(fn).toThrow(error) // 验证函数是否抛出指定类型的异常。 expect(fn).toThrow(message) // 验证函数是否抛出包含指定消息的异常。 范围断言 expect(value).toBeGreaterThanOrEqual(min) // 验证值是否大于或等于指定的最小值。 expect(value).toBeLessThanOrEqual(max) // 验证值是否小于或等于指定的最大值。 对象属性断言 expect(object).toHaveProperty(key, value) // 验证对象是否包含指定属性，并且该属性的值等于指定值。 更多 Jest 的断言，请查看https://jestjs.io/docs/expect\n","permalink":"https://naodeng.com.cn/posts/api-automation-testing/supertest-tutorial-advance-usage-common-assertions/","summary":"聚焦于 Supertest 的高级用法，特别关注常用断言。您将学习如何使用这些断言来验证 API 响应，包括状态码、响应内容、和响应头部等。","title":"SuperTest 接口自动化测试教程：进阶用法 - 常用断言"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nMocha 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 mocha.yml。\n编辑 mocha.yml 文件：将以下内容复制到文件中\nname: RUN SuperTest API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-SuperTest-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive SuperTest mochawesome test report uses: actions/upload-artifact@v3 with: name: SuperTest-mochawesome-test-report path: Report - name: Upload SuperTest mochawesome report to GitHub uses: actions/upload-artifact@v3 with: name: SuperTest-mochawesome-test-report path: Report 提交代码：将 mocha.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN SuperTest API Test CI 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Jest 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 jest.yml。\n编辑 jest.yml 文件：将以下内容复制到文件中\nname: RUN SuperTest API Test CI on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: RUN-SuperTest-API-Test: runs-on: ubuntu-latest strategy: matrix: node-version: [ 18.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ steps: - uses: actions/checkout@v3 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} cache: \u0026#39;npm\u0026#39; - name: Installation of related packages run: npm ci - name: RUN SuperTest API Testing run: npm test - name: Archive SuperTest test report uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: Report - name: Upload SuperTest report to GitHub uses: actions/upload-artifact@v3 with: name: SuperTest-test-report path: Report 提交代码：将 jest.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 RUN-SuperTest-API-Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/supertest-tutorial-advance-usage-integration-ci-cd-and-github-action/","summary":"深入探讨 Supertest 的高级用法，着重介绍如何将 Supertest 集成到 CI/CD 流程中，以及如何使用 GitHub Actions 实现自动化测试。","title":"SuperTest 接口自动化测试教程：进阶用法 - 集成 CI/CD 和 Github action"},{"content":"从 0 到 1 搭建 SuperTest 接口自动化测试项目 下面会从 0 到 1 搭建一个 SuperTest 接口自动化测试项目，会使用 Jest 或 Mocha 作为测试框架进行 demo 演示。\nMocha 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n新建项目文件夹 mkdir SuperTest-Mocha-demo 项目初始化 // 进入项目文件夹下 cd SuperTest-Mocha-demo // nodejs 项目初始化 npm init -y 安装依赖 // 安装 supertest npm install supertest --save-dev // 安装 mocha测试框架 npm install mocha --save-dev // 安装 chai断言库 npm install chai --save-dev 新建测试文件及测试用例 // 新建测试文件夹 mkdir Specs // 新建测试用例文件 cd Specs touch test.spec.js 编写测试用例 测试接口可参考项目中 demoAPI.md 文件\n// Test: test.spec.js const request = require(\u0026#39;supertest\u0026#39;); // import supertest const chai = require(\u0026#39;chai\u0026#39;); // import chai const expect = require(\u0026#39;chai\u0026#39;).expect; // import expect // Test Suite describe(\u0026#39;Verify that the Get and POST API returns correctly\u0026#39;, function(){ // Test case 1 it(\u0026#39;Verify that the GET API returns correctly\u0026#39;, function(done){ request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .get(\u0026#39;/posts/1\u0026#39;) // API endpoint .expect(200) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(1 ) expect(res.body.userId).to.equal(1) expect(res.body.title).to.equal(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;) expect(res.body.body). to.equal(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;) }) // expected response body .end(done) // end the test case }); // Test case 2 it(\u0026#39;Verify that the POST API returns correctly\u0026#39;, function(done){ request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .post(\u0026#39;/posts\u0026#39;) // API endpoint .send({ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }) // request body .expect(201) // expected response status code .expect(function (res) { expect(res.body.id).to.equal(101 ) expect(res.body.userId).to.equal(1) expect(res.body.title).to.equal(\u0026#34;foo\u0026#34;) expect(res.body.body).to.equal(\u0026#34;bar\u0026#34;) }) // expected response body .end(done) // end the test case }); }); 配置 mocha 配置文件 新建配置文件 // 项目根目录下新建配置文件 touch .mocharc.js 更新配置文件 // mocha config module.exports = { timeout: 5000, // 设置测试用例的默认超时时间（毫秒） spec: [\u0026#39;Specs/**/*.js\u0026#39;], // 指定测试文件的位置 }; 调整测试脚本 在 package.json 文件中添加测试脚本\n\u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;mocha\u0026#34; }, 运行测试用例 // 运行测试用例 npm run test 测试报告 命令行测试报告 集成 mochawesome 测试报告 安装 mochawesome npm install --save-dev mochawesome 更新 mocha 配置文件 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Mocha-demo\n// mocha config module.exports = { timeout: 5000, // 设置测试用例的默认超时时间（毫秒） reporter: \u0026#39;mochawesome\u0026#39;, // 使用 mochawesome 报告生成器 \u0026#39;reporter-option\u0026#39;: [ \u0026#39;reportDir=Report\u0026#39;, // 报告生成路径 \u0026#39;reportFilename=[status]_[datetime]-[name]-report\u0026#39;, //报告名称 \u0026#39;html=true\u0026#39;, // 生成 html 格式报告 \u0026#39;json=false\u0026#39;, // 不生成 json 格式报告 \u0026#39;overwrite=false\u0026#39;, // 不覆盖已经存在的报告 \u0026#39;timestamp=longDate\u0026#39;, // 给报告添加时间戳 ], // 传递给报告生成器的参数 spec: [\u0026#39;Specs/**/*.js\u0026#39;], // 指定测试文件的位置 }; 运行测试用例 // 运行测试用例 npm run test 查看测试报告 测试报告文件夹：Report，点击使用浏览器打开最新 html 报告文件\nJest 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n新建 Jest demo 项目文件夹 mkdir SuperTest-Jest-demo Jest demo 项目初始化 // 进入项目文件夹下 cd SuperTest-Mocha-demo // nodejs 项目初始化 npm init -y Jest demo 安装依赖 // 安装 supertest npm install supertest --save-dev // 安装 Jest测试框架 npm install jest --save-dev 新建 Jest demo 项目的测试文件及测试用例 // 新建测试文件夹 mkdir Specs // 新建测试用例文件 cd Specs touch test.spec.js 编写 Jest demo 测试用例 测试接口可参考项目中 demoAPI.md 文件\nconst request = require(\u0026#39;supertest\u0026#39;); // Test Suite describe(\u0026#39;Verify that the Get and POST API returns correctly\u0026#39;, () =\u0026gt; { // Test case 1 it(\u0026#39;Verify that the GET API returns correctly\u0026#39;, async () =\u0026gt; { const res = await request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .get(\u0026#39;/posts/1\u0026#39;) // API endpoint .send() // request body .expect(200); // use supertest\u0026#39;s expect to verify that the status code is 200 // user jest\u0026#39;s expect to verify the response body expect(res.status).toBe(200); // Verify that the status code is 200 expect(res.body.id).toEqual(1); // Verify that the id is 1 expect(res.body.userId).toEqual(1); // Verify that the userId is 1 expect(res.body.title) .toEqual(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;); expect(res.body.body) .toEqual(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;); }); // Test case 2 it(\u0026#39;Verify that the POST API returns correctly\u0026#39;, async() =\u0026gt;{ const res = await request(\u0026#39;https://jsonplaceholder.typicode.com\u0026#39;) // Test endpoint .post(\u0026#39;/posts\u0026#39;) // API endpoint .send({ \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 }) // request body .expect(201); // use supertest\u0026#39;s expect to verify that the status code is 201 // user jest\u0026#39;s expect to verify the response body expect(res.statusCode).toBe(201); expect(res.body.id).toEqual(101); expect(res.body.userId).toEqual(1); expect(res.body.title).toEqual(\u0026#34;foo\u0026#34;); expect(res.body.body).toEqual(\u0026#34;bar\u0026#34;); }); }); 配置 Jest 配置文件 新建配置文件 // 项目根目录下新建配置文件 touch jest.config.js 更新配置文件 // Desc: Jest configuration file module.exports = { // 测试文件的匹配规则 testMatch: [\u0026#39;**/Specs/*.spec.js\u0026#39;], }; 调整 Jest 测试脚本 在 package.json 文件中添加测试脚本\n\u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;jest\u0026#34; }, 运行 Jest 测试用例 // 运行测试用例 npm run test Jest 测试报告 Jest 命令行测试报告 集成 jest-html-reporters 测试报告 安装 jest-html-reporters npm install --save-dev jest-html-reporters 更新 Jest 配置文件 可参考 demo 项目：https://github.com/Automation-Test-Starter/SuperTest-Jest-demo\n// Desc: Jest configuration file module.exports = { // 测试文件的匹配规则 testMatch: [\u0026#39;**/Specs/*.spec.js\u0026#39;], // 测试报告生成器 reporters: [ \u0026#39;default\u0026#39;, [ \u0026#39;jest-html-reporters\u0026#39;, { publicPath: \u0026#39;./Report\u0026#39;, // 报告生成路径 filename: \u0026#39;report.html\u0026#39;, // 报告名称 pageTitle: \u0026#39;SuperTest and Jest API Test Report\u0026#39;, // 报告标题 overwrite: true, // 报告文件是否覆盖 expand: true, // 展开所有测试套件 }, ], ], }; 运行 Jest 测试用例 // 运行测试用例 npm run test 查看测试报告 测试报告文件夹：Report，点击使用浏览器打开最新 html 报告文件\n","permalink":"https://naodeng.com.cn/posts/api-automation-testing/supertest-tutorial-building-your-own-project-from-0-to-1/","summary":"从零开始教您如何建立 SuperTest 接口自动化测试项目。您将学习如何创建项目的基础结构，设置环境，编写测试用例，以及执行自动化测试。","title":"SuperTest 接口自动化测试教程：从 0 到 1 搭建 Supertest 接口自动化测试项目"},{"content":"介绍 本项目是一个使用 SuperTest 进行 API 自动化测试的快速启动项目教程，会使用 Jest 或 Mocha 作为测试框架进行 demo 演示。\n下面会依次介绍 SuperTest、Jest 和 Mocha，让大家提前了解这些工具的基本使用。\nSuperTest 介绍 \u0026ldquo;Supertest\u0026rdquo; 是一个用于测试 Node.js 应用程序的流行 JavaScript 库。它主要用于进行端到端（End-to-End）测试，也称为集成测试，以确保你的应用程序在不同组件之间正常运行。Supertest 通常与 Mocha、Jasmine 或 Jest 等测试框架一起使用，以编写和运行测试用例。\n以下是 Supertest 的一些关键特点和用途：\n发起 HTTP 请求：Supertest 允许你轻松地模拟 HTTP 请求，例如 GET、POST、PUT、DELETE 等，以测试你的应用程序的路由和端点。 链式语法：Supertest 提供了一种链式语法，使你能够在单个测试用例中构建和执行多个请求，这有助于模拟用户在应用程序中的不同操作。 断言和期望：你可以使用 Supertest 结合断言库（如 Chai）来检查响应的内容、状态码、头信息等，以确保应用程序的期望行为。 身份验证测试：Supertest 可以用于测试需要身份验证的端点，以确保用户登录和授权功能正常。 异步支持：Supertest 可以处理异步操作，例如等待响应返回后执行进一步的测试代码。 方便的集成：Supertest 可以轻松与不同的 Node.js 框架（如 Express、Koa、Hapi 等）一起使用，因此你可以测试各种类型的应用程序。 使用 Supertest 可以帮助你验证你的应用程序是否按预期工作，以及在应用程序发生更改时快速捕获潜在的问题。通常，你需要在项目中安装 Supertest 和测试框架，然后编写测试用例来模拟不同的请求和检查响应。这有助于提高代码质量和可维护性，确保你的应用程序在不断演化的过程中保持稳定性。\n官方文档：https://github.com/ladjs/supertest\n备注：Supertest 不止可以用来做 API 测试，也可以用来做单元测试和集成测试\n代码示例：\n// 导入 supertest const request = require(\u0026#39;supertest\u0026#39;); request({URL}) // 请求 (url) 或 请求 (app) .get() or .put() or.post() // http method .set() // http 选项 .send() // 请求的 body .expect() // 断言 .end() // 结束请求 Jest 介绍 Jest 是一个流行的 JavaScript 测试框架，用于编写和运行 JavaScript 应用程序的单元测试、集成测试和端到端测试。它的目标是提供简单、快速和易于使用的测试工具，适用于各种 JavaScript 应用程序，包括前端和后端应用程序。\n以下是 Jest 的一些关键特点和用途：\n内置断言库：Jest 包括一个强大的断言库，使你能够轻松地编写断言，以验证代码的行为是否符合预期。 自动模拟：Jest 自动创建模拟（mocks），帮助你模拟函数、模块和外部依赖，从而让测试更加简单和可控。 快速和并行：Jest 通过智能地选择要运行的测试以及并行执行测试，可以快速地运行大量测试用例，从而节省时间。 全面的测试套件：Jest 支持单元测试、集成测试和端到端测试，并可以测试 JavaScript、TypeScript、React、Vue、Node.js 等各种应用程序类型。 快照测试：Jest 具有快照测试功能，可用于检查 UI 组件的渲染是否与之前的快照匹配，从而捕获 UI 变化。 自动监视模式：Jest 具有一个监视模式，可在代码更改时自动重新运行相关测试，从而支持开发人员进行持续测试。 丰富的生态系统：Jest 有丰富的插件和扩展，可用于扩展其功能，如覆盖率报告、测试报告和其他工具的集成。 社区支持：Jest 是一个流行的测试框架，拥有庞大的社区，提供了大量的文档、教程和支持资源。 Jest 通常与其他工具如 Babel（用于转译 JavaScript）、Enzyme（用于 React 组件测试）、Supertest（用于 API 测试）等一起使用，以实现全面的测试覆盖和确保代码质量。无论你是在编写前端代码还是后端代码，Jest 都是一个强大的测试工具，可以帮助你捕获潜在的问题，提高代码质量和可维护性。\n官方文档：https://jestjs.io/docs/zh-Hans/getting-started\n代码示例：\n// 导入 jest const jest = require(\u0026#39;jest\u0026#39;); describe(): // 测试场景 it(): // 测试用例，it() 在 describe() 里面 before(): // 这个动作在所有测试用例之前执行 after(): // 这个动作在所有测试用例之后执行 Mocha 介绍 Mocha 是一个流行的 JavaScript 测试框架，用于编写和运行 JavaScript 应用程序的各种测试，包括单元测试、集成测试和端到端测试。Mocha 提供了灵活性和可扩展性，使开发人员能够轻松地定制测试套件以满足其项目的需求。\n以下是 Mocha 的一些关键特点和用途：\n多种测试风格：Mocha 支持多种测试风格，包括 BDD（行为驱动开发）和 TDD（测试驱动开发）。这使开发人员可以根据自己的偏好编写测试用例。 丰富的断言库：Mocha 本身并不包括断言库，但它可以与多种断言库（如 Chai、Should.js、Expect.js 等）结合使用，使你能够使用喜欢的断言风格来编写测试。 异步测试：Mocha 内置支持异步测试，允许你测试异步代码、Promise、回调函数等，确保代码在异步场景下的正确性。 并行测试：Mocha 可以并行运行测试套件中的测试用例，提高测试执行效率。 丰富的插件和扩展：Mocha 有丰富的插件生态系统，可以用于扩展其功能，如测试覆盖率报告、测试报告生成等。 易于集成：Mocha 可以与各种断言库、测试运行器（如 Karma 和 Jest）、浏览器（使用浏览器测试运行器）等一起使用，以适应不同的项目和测试需求。 命令行界面：Mocha 提供了一个易于使用的命令行界面，用于运行测试套件，生成报告以及其他测试相关操作。 持续集成支持：Mocha 可以轻松集成到持续集成（CI）工具中，如 Jenkins、Travis CI、CircleCI 等，以确保代码在每次提交后都能得到测试。 Mocha 的灵活性和可扩展性使其成为一个受欢迎的测试框架，适用于各种 JavaScript 项目，包括前端和后端应用程序。开发人员可以根据自己的需求和喜好选择测试工具、断言库和其他扩展，以满足项目的要求。无论你是在编写浏览器端代码还是服务器端代码，Mocha 都是一个强大的测试工具，可帮助你确保代码质量和可靠性。\n官方文档：https://mochajs.org/\n代码示例：\n// 导入 mocha const mocha = require(\u0026#39;mocha\u0026#39;); describe(): // 测试场景 it(): // 测试用例，it() 在 describe() 里面 before(): // 这个动作在所有测试用例之前执行 after(): // 这个动作在所有测试用例之后执行 CHAI 简介 Chai 是一个 JavaScript 断言库，用于编写和运行测试用例时进行断言和期望值的验证。它是一个流行的测试工具，通常与测试框架（如 Mocha、Jest 等）一起使用，以帮助开发者编写和执行各种类型的测试，包括单元测试和集成测试。\n以下是一些 Chai 的主要特点和用途：\n可读性强的断言语法：Chai 提供了一个易于阅读和编写的断言语法，使测试用例更易于理解。它支持自然语言的断言风格，例如 expect(foo).to.be.a(\u0026lsquo;string\u0026rsquo;) 或 expect(bar).to.equal(42)。 多种断言风格：Chai 提供了多种不同的断言风格，以适应不同开发者的偏好。主要的风格包括 BDD（Behavior-Driven Development）风格、TDD（Test-Driven Development）风格和 assert 风格。 插件扩展：Chai 可以通过插件进行扩展，以支持更多的断言类型和功能。这使得 Chai 可以满足各种测试需求，包括异步测试、HTTP 请求测试等。 易于集成：Chai 可以轻松集成到各种测试框架中，例如 Mocha、Jest、Jasmine 等。这使得它成为编写测试用例的强大工具。 支持链式断言：Chai 允许你对多个断言进行链式调用，以便更容易进行复杂的测试和验证。 官方文档：https://www.chaijs.com/\n代码示例：\n// 导入 chai const chai = require(\u0026#39;chai\u0026#39;); const expect = chai.expect; // demo 断言 .expect(\u0026lt;actual result\u0026gt;).to.{assert}(\u0026lt;expected result\u0026gt;) // 断言目标严格等于值 .expect(‘hello\u0026#39;).to.equal(\u0026#39;hello\u0026#39;); // 断言目标严格等于值 .expect({ foo: \u0026#39;bar\u0026#39; }).to.not.equal({ foo: \u0026#39;bar\u0026#39; }); // 断言目标值不严格等于值。 .expect(\u0026#39;foobar\u0026#39;).to.contain(\u0026#39;foo\u0026#39;); // 断言目标字符串包含给定的子字符串。 .expect(foo).to.exist; // 断言目标既不是 null 也不是未定义。 .expect(5).to.be.at.most(5); // 断言目标值小于或等于值。 项目依赖 需提前安装好以下环境\nnodejs, demo 版本为 v21.1.0 项目文件结构 以下是一个 SuperTest 接口自动化测试项目的文件结构，其中包含了测试配置文件、测试用例文件、测试工具文件和测试报告文件。可进行参考。\nSuperTest-Jest-demo ├── README.md ├── package.json ├── package-lock.json ├── Config // 测试配置文件 │ └── config.js ├── Specs // 测试用例文件 │ └── test.spec.js ├── Utils // 测试工具文件 │ └── utils.js ├── Report // 测试报告文件 │ └── report.html ├── .gitignore └── node_modules // 项目依赖 Next 下一篇文章将会介绍如何使用 Supertest 从 0 到 1 搭建 SuperTest 接口自动化测试项目，敬请期待。\n","permalink":"https://naodeng.com.cn/posts/api-automation-testing/supertest-tutorial-getting-started-and-own-environment-preparation/","summary":"关于 Supertest 的教程，主要包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 Supertest 以及如何开始使用它来进行 API 测试。","title":"SuperTest 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nGradle 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gradle.yml。\n编辑 gradle.yml 文件：将以下内容复制到文件中\nname: Gradle and REST Assured Tests on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v3 - name: Setup Java uses: actions/setup-java@v3 with: java-version: \u0026#39;11\u0026#39; distribution: \u0026#39;adopt\u0026#39; - name: Build and Run REST Assured Tests with Gradle uses: gradle/gradle-build-action@bd5760595778326ba7f1441bcf7e88b49de61a25 # v2.6.0 with: arguments: build - name: Archive REST-Assured results uses: actions/upload-artifact@v2 with: name: REST-Assured-results path: build/reports/tests/test - name: Upload REST-Assured results to GitHub uses: actions/upload-artifact@v2 with: name: REST-Assured-results path: build/reports/tests/test 提交代码：将 gradle.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Gradle and REST Assured Tests 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Maven 版本接入 github action 可参考 demo：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 maven.yml。\n编辑 maven.yml 文件：将以下内容复制到文件中\nname: Maven and REST Assured Tests on: push: branches: [ \u0026#34;main\u0026#34; ] pull_request: branches: [ \u0026#34;main\u0026#34; ] jobs: Run-Rest-Assured-Tests: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - name: Set up JDK 17 uses: actions/setup-java@v3 with: java-version: \u0026#39;17\u0026#39; distribution: \u0026#39;temurin\u0026#39; cache: maven - name: Build and Run REST Assured Tests with Maven run: mvn test - name: Archive REST-Assured results uses: actions/upload-artifact@v3 with: name: REST-Assured-results path: target/surefire-reports - name: Upload REST-Assured results to GitHub uses: actions/upload-artifact@v3 with: name: REST-Assured-results path: target/surefire-reports 提交代码：将 maven.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Maven and REST Assured Tests 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 集成 allure 测试报告 allure 简介 Allure是一个用于生成漂亮、交互式测试报告的开源测试框架。它可以与多种测试框架（如JUnit、TestNG、Cucumber等）和多种编程语言（如Java、Python、C#等）一起使用。\nAllure 测试报告具有以下特点：\n美观和交互式：Allure 测试报告以美观和交互式的方式呈现测试结果，包括图形、图表和动画。这使得测试报告更容易阅读和理解。 多语言支持：Allure 支持多种编程语言，因此您可以在不同的语言中编写测试，并生成统一的测试报告。 测试用例级别的详细信息：Allure 允许您为每个测试用例添加详细信息，包括描述、类别、标签、附件、历史数据等。这些信息有助于更全面地了解测试结果。 历史趋势分析：Allure 支持测试历史趋势分析，您可以查看测试用例的历史表现，识别问题和改进测试质量。 类别和标签：您可以为测试用例添加类别和标签，以更好地组织和分类测试用例。这使得报告更具可读性。 附件和截图：Allure 允许您附加文件、截图和其他附件，以便更好地记录测试过程中的信息。 集成性：Allure 可以与各种测试框架和构建工具（如 Maven、Gradle）无缝集成，使得生成报告变得简单。 开源社区支持：Allure 是一个开源项目，拥有一个活跃的社区，提供了广泛的文档和支持。这使得它成为许多自动化测试团队的首选工具。 Allure 测试报告的主要目标是提供一个清晰、易于阅读的方式来展示测试结果，以帮助开发团队更好地理解测试的状态和质量，快速识别问题，并采取必要的行动。无论您是开发人员、测试人员还是项目经理，Allure 测试报告都能为您提供有用的信息，以改进软件质量和可靠性。\n官方网站：https://docs.qameta.io/allure/\n集成步骤 Maven 版本集成 allure 在 POM.xml 中添加 allure 依赖 可 copy 本项目中的 pom.xml 文件内容\n\u0026lt;!-- https://mvnrepository.com/artifact/io.qameta.allure/allure-testng --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-testng\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.24.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/io.qameta.allure/allure-rest-assured --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.24.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在 POM.xml 中添加 allure 插件 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.qameta.allure\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;allure-maven\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.12.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;resultsDirectory\u0026gt;../allure-results\u0026lt;/resultsDirectory\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; 在 src/test/java 下创建用于测试 REST API 的测试代码 以下为 demo 示例，详细部分可参考 项目：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\npackage com.example; import io.qameta.allure.*; import io.qameta.allure.restassured.AllureRestAssured; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; @Epic(\u0026#34;REST API Regression Testing using TestNG\u0026#34;) @Feature(\u0026#34;Verify that the Get and POST API returns correctly\u0026#34;) public class TestDemo { @Test(description = \u0026#34;To get the details of post with id 1\u0026#34;, priority = 1) @Story(\u0026#34;GET Request with Valid post id\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the GET API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;To create a new post\u0026#34;, priority = 2) @Story(\u0026#34;POST Request\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 运行测试并生成 Allure 报告 mvn clean test 生成的 Allure 报告在项目根目录的 allure-results 文件下\n预览 Allure 报告 mvn allure:serve 运行命令会自动打开浏览器，预览 Allure 报告\nGradle 版本集成 allure 在 build.gradle 中添加 allure 插件 可 copy 本项目中的 build.gradle 文件内容\nid(\u0026#34;io.qameta.allure\u0026#34;) version \u0026#34;2.11.2\u0026#34; 在 build.gradle 中添加 allure 依赖 可 copy 本项目中的 build.gradle 文件内容\nimplementation \u0026#39;io.qameta.allure:allure-testng:2.24.0\u0026#39; // Add allure report dependency implementation \u0026#39;io.qameta.allure:allure-rest-assured:2.24.0\u0026#39; // Add allure report dependency 在 src/test/java 下创建用于测试 REST API 的测试代码 以下为 demo 示例，详细部分可参考 项目：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\npackage com.example; import io.qameta.allure.*; import io.qameta.allure.restassured.AllureRestAssured; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; @Epic(\u0026#34;REST API Regression Testing using TestNG\u0026#34;) @Feature(\u0026#34;Verify that the Get and POST API returns correctly\u0026#34;) public class TestDemo { @Test(description = \u0026#34;To get the details of post with id 1\u0026#34;, priority = 1) @Story(\u0026#34;GET Request with Valid post id\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the GET API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;To create a new post\u0026#34;, priority = 2) @Story(\u0026#34;POST Request\u0026#34;) @Severity(SeverityLevel.NORMAL) @Description(\u0026#34;Test Description : Verify that the post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .filter(new AllureRestAssured()) //设置 AllureRestAssured 过滤器，用来在测试报告中展示请求和响应信息 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 运行测试并生成 Allure 报告 gradle clean test 生成的 Allure 报告在项目根目录的 build/allure-results 文件下\n预览 Allure 报告 gradle allureServe 运行命令会自动打开浏览器，预览 Allure 报告\n参考资料 Rest assured 官方文档：https://rest-assured.io/\nRest assured 官方 github：https://github.com/rest-assured/rest-assured\nRest assured 官方文档中文翻译：https://github.com/RookieTester/rest-assured-doc\n","permalink":"https://naodeng.com.cn/posts/api-automation-testing/rest-assured-tutorial-advance-usage-integration-ci-cd-and-allure-report/","summary":"深入研究 REST Assured 的高级应用，侧重于如何集成 CI/CD（持续集成/持续交付）工具和整合 Allure 测试报告。","title":"REST Assured 接口自动化测试教程：进阶用法 - 集成 CI/CD 和集成 allure 测试报告"},{"content":"进阶用法 验证响应数据 您还可以验证状态码，状态行，Cookie，headers，内容类型和正文。\n响应体断言 json 格式断言 假设某个 get 请求 (http://localhost:8080/lotto) 返回 JSON 如下：\n{ \u0026#34;lotto\u0026#34;:{ \u0026#34;lottoId\u0026#34;:5, \u0026#34;winning-numbers\u0026#34;:[2,45,34,23,7,5,3], \u0026#34;winners\u0026#34;:[{ \u0026#34;winnerId\u0026#34;:23, \u0026#34;numbers\u0026#34;:[2,45,34,23,3,5] },{ \u0026#34;winnerId\u0026#34;:54, \u0026#34;numbers\u0026#34;:[52,3,12,11,18,22] }] } } REST assured 可以帮您轻松地进行 get 请求并对响应信息进行处理。\n断言 lottoId 的值是否等于 5，示例： get(\u0026#34;/lotto\u0026#34;).then().body(\u0026#34;lotto.lottoId\u0026#34;, equalTo(5)); 断言 winnerId 的取值包括 23 和 54，示例： get(\u0026#34;/lotto\u0026#34;).then().body(\u0026#34;lotto.winners.winnerId\u0026#34;, hasItems(23, 54)); 提醒一下：equalTo 和 hasItems是 Hamcrest matchers 提供的方法，所以需要静态导入入 org.hamcrest.Matchers。\nxml 格式断言 XML 可以一种通过简单的方式解析。假设一个 POST 请求http://localhost:8080/greetXML返回：\n\u0026lt;greeting\u0026gt; \u0026lt;firstName\u0026gt;{params(\u0026#34;firstName\u0026#34;)}\u0026lt;/firstName\u0026gt; \u0026lt;lastName\u0026gt;{params(\u0026#34;lastName\u0026#34;)}\u0026lt;/lastName\u0026gt; \u0026lt;/greeting\u0026gt; 断言 firstName 是否返回正确，示例： given(). parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;). when(). post(\u0026#34;/greetXML\u0026#34;). then(). body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;)). 同时断言 firstname 和 lastname 是否返回正确，示例： given(). parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;). when(). post(\u0026#34;/greetXML\u0026#34;). then(). body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;)). body(\u0026#34;greeting.lastName\u0026#34;, equalTo(\u0026#34;Doe\u0026#34;)); with().parameters(\u0026#34;firstName\u0026#34;, \u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;, \u0026#34;Doe\u0026#34;) .when().post(\u0026#34;/greetXML\u0026#34;) .then().body(\u0026#34;greeting.firstName\u0026#34;, equalTo(\u0026#34;John\u0026#34;), \u0026#34;greeting.lastName\u0026#34;, equalTo(\u0026#34;Doe\u0026#34;)); Cookie 断言 断言 cookie 的值是否等于 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().cookie(\u0026#34;cookieName\u0026#34;, \u0026#34;cookieValue\u0026#34;) 同时断言 多个 cookie 的值是否等于 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().cookies(\u0026#34;cookieName1\u0026#34;, \u0026#34;cookieValue1\u0026#34;, \u0026#34;cookieName2\u0026#34;, \u0026#34;cookieValue2\u0026#34;) 断言 cookie 的值是否包含 cookieValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().cookies(\u0026#34;cookieName1\u0026#34;, \u0026#34;cookieValue1\u0026#34;, \u0026#34;cookieName2\u0026#34;, containsString(\u0026#34;Value2\u0026#34;)) 状态码 Status Code 断言 断言 状态码是否等于 200，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusCode(200) 断言 状态行是否为 something，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusLine(\u0026#34;something\u0026#34;) 断言 状态行是否包含 some，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().statusLine(containsString(\u0026#34;some\u0026#34;)) Header 断言 断言 Header 的值是否等于 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().header(\u0026#34;headerName\u0026#34;, \u0026#34;headerValue\u0026#34;) 同时断言 多个 Header 的值是否等于 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().headers(\u0026#34;headerName1\u0026#34;, \u0026#34;headerValue1\u0026#34;, \u0026#34;headerName2\u0026#34;, \u0026#34;headerValue2\u0026#34;) 断言 Header 的值是否包含 HeaderValue，示例： get(\u0026#34;/x\u0026#34;).then() .assertThat().headers(\u0026#34;headerName1\u0026#34;, \u0026#34;headerValue1\u0026#34;, \u0026#34;headerName2\u0026#34;, containsString(\u0026#34;Value2\u0026#34;)) 断言 Header 的“Content-Length”小于 1000，示例： 可以先使用映射函数首先将头值转换为 int，然后在使用 Hamcrest 验证前使用“整数”匹配器进行断言：\nget(\u0026#34;/something\u0026#34;).then() .assertThat().header(\u0026#34;Content-Length\u0026#34;, Integer::parseInt, lessThan(1000)); Content-Type 断言 断言 Content-Type 的值是否等于 application/json，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().contentType(ContentType.JSON) 内容全匹配断言 断言 响应体是否完全等于 something，示例： get(\u0026#34;/x\u0026#34;).then().assertThat().body(equalTo(\u0026#34;something\u0026#34;)) 响应时间断言 REST Assured 2.8.0 开始支持测量响应时间，例如：\nlong timeInMs = get(\u0026#34;/lotto\u0026#34;).time() 或使用特定时间单位：\nlong timeInSeconds = get(\u0026#34;/lotto\u0026#34;).timeIn(SECONDS); 其中 SECONDS 只是一个标准的 TimeUnit。您还可以使用 DSL 验证：\nwhen(). get(\u0026#34;/lotto\u0026#34;). then(). time(lessThan(2000L)); // Milliseconds 或\nwhen(). get(\u0026#34;/lotto\u0026#34;). then(). time(lessThan(2L), SECONDS); 需要注意的是，您只能参考性地将这些测量数据与服务器请求处理时间相关联（因为响应时间将包括 HTTP 往返和 REST Assured 处理时间等，不能做到十分准确）。\n文件上传 通常我们在向服务器传输大容量的数据时，比如文件时会使用 multipart 表单数据技术。 rest-assured 提供了一种multiPart方法来辨别这究竟是文件、二进制序列、输入流还是上传的文本。\n表单中上只传一个文件，示例： given(). multiPart(new File(\u0026#34;/path/to/file\u0026#34;)). when(). post(\u0026#34;/upload\u0026#34;); 存在 control 名的情况下上传文件，示例： given(). multiPart(\u0026#34;controlName\u0026#34;, new File(\u0026#34;/path/to/file\u0026#34;)). when(). post(\u0026#34;/upload\u0026#34;); 同一个请求中存在多个\u0026quot;multi-parts\u0026quot;事务，示例： byte[] someData = .. given(). multiPart(\u0026#34;controlName1\u0026#34;, new File(\u0026#34;/path/to/file\u0026#34;)). multiPart(\u0026#34;controlName2\u0026#34;, \u0026#34;my_file_name.txt\u0026#34;, someData). multiPart(\u0026#34;controlName3\u0026#34;, someJavaObject, \u0026#34;application/json\u0026#34;). when(). post(\u0026#34;/upload\u0026#34;); MultiPartSpecBuilder 用法，示例： 更多使用方法可以使用MultiPartSpecBuilder：\nGreeting greeting = new Greeting(); greeting.setFirstName(\u0026#34;John\u0026#34;); greeting.setLastName(\u0026#34;Doe\u0026#34;); given(). multiPart(new MultiPartSpecBuilder(greeting, ObjectMapperType.JACKSON_2) .fileName(\u0026#34;greeting.json\u0026#34;) .controlName(\u0026#34;text\u0026#34;) .mimeType(\u0026#34;application/vnd.custom+json\u0026#34;).build()). when(). post(\u0026#34;/multipart/json\u0026#34;). then(). statusCode(200); MultiPartConfig 用法，示例： MultiPartConfig可用来指定默认的 control 名和文件名\ngiven().config(config().multiPartConfig(multiPartConfig() .defaultControlName(\u0026#34;something-else\u0026#34;))) 默认把 control 名配置为\u0026quot;something-else\u0026quot;而不是\u0026quot;file\u0026quot;。 更多用法查看 博客介绍\nLogging 日志 当我们在编写接口测试脚本的时候，我们可能需要在测试过程中打印一些日志，以便于我们在测试过程中查看接口的请求和响应信息，以及一些其他的信息。RestAssured 提供了一些方法来打印日志，我们可以根据需要选择合适的方法来打印日志。\nRestAssured 提供了一个全局的日志配置方法，可以在测试开始前配置日志，然后在测试过程中打印日志。这种方法适用于所有的测试用例，但是它只能打印请求和响应的信息，不能打印其他的信息。\nRestAssured 还提供了一个局部的日志配置方法，可以在测试过程中打印日志。这种方法可以打印请求和响应的信息，也可以打印其他的信息。\n全局日志配置 添加全局日志步骤 引入日志相关的依赖类 import io.restassured.config.LogConfig; import io.restassured.filter.log.LogDetail; import io.restassured.filter.log.RequestLoggingFilter; import io.restassured.filter.log.ResponseLoggingFilter; 在 setup() 方法中添加日志配置 使用 LogConfig 配置，启用了请求和响应的日志记录，以及启用了漂亮的输出格式。启用了请求和响应的日志记录过滤器，这将记录请求和响应的详细信息。\n// 启用全局请求和响应日志记录 RestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); 在 setup() 方法中启用了全局日志记录过滤器 // 启用全局请求和响应日志记录过滤器 RestAssured.filters(new RequestLoggingFilter(), new ResponseLoggingFilter()); 全局日志代码示例 package com.example; import io.restassured.RestAssured; // 引入日志相关的类 import io.restassured.config.LogConfig; import io.restassured.filter.log.LogDetail; import io.restassured.filter.log.RequestLoggingFilter; import io.restassured.filter.log.ResponseLoggingFilter; import org.testng.annotations.BeforeClass; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @BeforeClass public void setup() { // 启用全局请求和响应日志记录 RestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); // 启用全局请求和响应日志记录过滤器 RestAssured.filters(new RequestLoggingFilter(), new ResponseLoggingFilter()); } @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // 测试用例已省略，可参考 demo } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // 测试用例已省略，可参考 demo } } 查看全局日志输出 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 查看日志输出 局部日志配置 在 RestAssured 中，你可以进行局部日志配置，以便在特定的测试方法或请求中启用或禁用日志记录，而不影响全局配置。\n添加日志步骤 在想要打印日志的测试方法中启用了添加日志配置，示例： @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .log().everything(true) // 输出 request 相关日志 .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .log().everything(true) // 输出 response 相关日志 .statusCode(200) } 查看局部日志输出 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 查看日志输出 LogConfig 配置说明 在 RestAssured 中，你可以使用 LogConfig 类来配置请求和响应的日志记录。LogConfig 允许你定义日志详细程度、输出格式、输出位置等。以下是一些常见的 LogConfig 配置示例：\n启用请求和响应的日志记录：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL)); 这将启用请求和响应的日志记录，只有当验证失败时才记录。\n配置输出级别：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.HEADERS)); 这将只记录请求和响应的头部信息。\n配置输出位置：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true) .defaultStream(FileOutputStream(\u0026#34;log.txt\u0026#34;))); 这将日志记录输出到名为 \u0026ldquo;log.txt\u0026rdquo; 的文件。\n配置漂亮的输出格式：\nRestAssured.config = RestAssured.config() .logConfig(LogConfig.logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(LogDetail.ALL) .enablePrettyPrinting(true)); 这将启用漂亮的输出格式，使日志更易于阅读。\n你可以根据你的具体需求组合这些配置选项，并将其设置为 RestAssured.config 以配置全局的请求和响应日志记录。这将有助于在 RestAssured 中记录和审查请求和响应，以便调试和分析问题。\nRequest Logging 请求日志记录 从版本 1.5 开始，REST Assured 支持在使用 RequestLoggingFilter 将请求规范发送到服务器之前记录请求规范。请注意，HTTP Builder 和 HTTP Client 可能会添加日志中打印的内容之外的其他标头。筛选器将仅记录请求规范中指定的详细信息。也就是说，您不能将 RequestLoggingFilter 记录的详细信息视为实际发送到服务器的详细信息。此外，后续筛选器可能会在日志记录发生后更改请求。如果您需要记录网络上实际发送的内容，请参阅 HTTP 客户端日志记录文档或使用外部工具，例如 Wireshark。\n示例：\ngiven().log().all() // 记录所有请求规范细节，包括参数、标头和正文 given().log().params() // 只记录请求的参数 given().log().body() // 只记录请求正文 given().log().headers() // 只记录请求头 given().log().cookies() // 只记录请求 cookies given().log().method() // 只记录请求方法 given().log().path() // 只记录请求路径 Response Logging 响应日志记录 只想要打印响应正文，而不考虑状态代码，可以执行以下操作， 示例： get(\u0026#34;/x\u0026#34;).then().log().body() 不管是否发生错误，都将打印响应正文。如果只对在发生错误时打印响应正文感兴趣，示例： get(\u0026#34;/x\u0026#34;).then().log().ifError() 在响应中记录所有详细信息，包括状态行、标头和 Cookie，示例： get(\u0026#34;/x\u0026#34;).then().log().all() 在响应中记录只记录状态行、标题或 Cookie，示例： get(\u0026#34;/x\u0026#34;).then().log().statusLine() // 只记录状态行 get(\u0026#34;/x\u0026#34;).then().log().headers() // 只记录响应头 get(\u0026#34;/x\u0026#34;).then().log().cookies() // 只记录响应 cookies 配置为仅当状态代码与某个值匹配时才记录响应，示例： get(\u0026#34;/x\u0026#34;).then().log().ifStatusCodeIsEqualTo(302) // 仅在状态代码等于 302 时记录日志 get(\u0026#34;/x\u0026#34;).then().log().ifStatusCodeMatches(matcher) // 仅在状态代码与提供的配置匹配时才记录日志 只在验证失败时记录日志 从 REST Assured 2.3.1 开始，只有在验证失败时才能记录请求或响应。要记录请求日志，示例： given().log().ifValidationFails() 要记录响应日志，示例： then().log().ifValidationFails() 可以使用 LogConfig 同时为请求和响应启用此功能，示例： given().config(RestAssured.config().logConfig(logConfig() .enableLoggingOfRequestAndResponseIfValidationFails(HEADERS))) 如果验证失败，日志仅记录请求头。\n另外一个快捷方式，用于在验证失败时为所有请求启用请求和响应的日志记录，示例： RestAssured.enableLoggingOfRequestAndResponseIfValidationFails(); 从版本 4.5.0 开始，您还可以使用 指定 onFailMessage 测试失败时将显示的消息，示例： when(). get(). then(). onFailMessage(\u0026#34;Some specific message\u0026#34;). statusCode(200); Header 黑名单配置 从 REST Assured 4.2.0 开始，可以将标头列入黑名单，以便它们不会显示在请求或响应日志中。相反，标头值将替换为 [ BLACKLISTED ] .您可以使用 LogConfig 启用此基于每个标头的功能，示例：\ngiven().config(config().logConfig(logConfig().blacklistHeader(\u0026#34;Accept\u0026#34;))) Filters 过滤器 在 RestAssured 中，你可以使用过滤器来修改请求和响应。过滤器允许你在请求和响应的不同阶段修改请求和响应。例如，你可以在请求之前修改请求，或者在响应之后修改响应。你可以使用过滤器来添加请求头、请求参数、请求体、响应头、响应体等。\n过滤器可用于实现自定义身份验证方案、会话管理、日志记录等。若要创建筛选器，需要实现 io.restassured.filter.Filter 接口。要使用过滤器，您可以执行以下操作：\ngiven().filter(new MyFilter()) REST Assured 提供了几个可供使用的过滤器：\nio.restassured.filter.log.RequestLoggingFilter ：将打印请求规范详细信息的筛选器。 io.restassured.filter.log.ResponseLoggingFilter ：如果响应与给定状态代码匹配，则将打印响应详细信息的筛选器。 io.restassured.filter.log.ErrorLoggingFilter ：在发生错误时打印响应正文的筛选器（状态代码介于 400 和 500 之间）。 Ordered Filters 有序过滤器 从 REST Assured 3.0.2 开始，如果需要控制筛选器排序，可以实现 io.restassured.filter.OrderedFilter 接口。在这里，您将实现返回一个整数的方法，getOrder 该整数表示筛选器的优先级。值越低，优先级越高。您可以定义的最高优先级是 Integer.MIN_VALUE，最低优先级是 Integer.MAX_VALUE。未实现 io.restassured.filter.OrderedFilter 的过滤器的默认优先级为 1000。\n示例\nResponse Builder 响应生成器 如果需要更改筛选器中的响应内容，可以使用 ResponseBuilder 基于原始响应创建新的响应。例如，如果要将原始响应的正文更改为其他内容，可以执行以下操作：\nResponse newResponse = new ResponseBuilder() .clone(originalResponse).setBody(\u0026#34;Something\u0026#34;).build(); ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/rest-assured-tutorial-advance-usage-verifying-response-and-logging/","summary":"深入介绍 REST Assured 的进阶用法，重点放在验证 API 响应、日志记录和过滤器的应用上。","title":"REST Assured 接口自动化测试教程：进阶用法 - 验证响应和日志记录，过滤器，文件上传"},{"content":"从 0 到 1 搭建 REST Assured 接口测试项目 REST Assured 支持 Gradle 和 Maven 两种构建工具，你可以根据自己的喜好选择其中一种。下面分别介绍 Gradle 和 Maven 两种构建工具的项目初始化过程。\n本项目使用 Gradle 8.44 和 Maven 3.9.5 进行构建，如果你使用的是其他版本，可能会有不同。\nGradle 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/RestAssured-gradle-demo\n创建一个空的 Gradle 工程 mkdir RestAssured-gradle-demo cd RestAssured-gradle-demo gradle init 配置项目 build.gradle demo 项目引入了 testNG 测试框架，仅供参考\n在项目根目录下创建一个 build.gradle 文件，用于配置项目 示例配置如下，可供参考 // 插件配置 plugins { id \u0026#39;java\u0026#39; // 使用 java 插件 } // 仓库资源配置 repositories { mavenCentral() // 使用 maven中央版本库源 } // 项目依赖配置 dependencies { testImplementation \u0026#39;io.rest-assured:rest-assured:5.3.1\u0026#39; // 添加rest-assured依赖 testImplementation \u0026#39;org.testng:testng:7.8.0\u0026#39; // 添加TestNG测试框架依赖 implementation \u0026#39;org.uncommons:reportng:1.1.4\u0026#39; // 添加testng 测试报告依赖 implementation \u0026#39;org.slf4j:slf4j-api:2.0.9\u0026#39; // 添加测试日志依赖 implementation \u0026#39;org.slf4j:slf4j-simple:2.0.9\u0026#39; // 添加测试日志依赖 implementation group: \u0026#39;com.google.inject\u0026#39;, name: \u0026#39;guice\u0026#39;, version: \u0026#39;7.0.0\u0026#39; } // 项目测试配置 test { reports.html.required = false // 禁用 gradle 原生HTML 报告生成 reports.junitXml.required = false // 禁用 gradle 原生 JUnit XML 报告生成 // 告诉 Gradle 使用 TestNG 作为测试框架 useTestNG() { useDefaultListeners = true suites \u0026#39;src/test/resources/testng.xml\u0026#39; // 声明 testng 的 xml 配置文件路径 } testLogging.showStandardStreams = true // 将测试日志输出到控制台 testLogging.events \u0026#34;passed\u0026#34;, \u0026#34;skipped\u0026#34;, \u0026#34;failed\u0026#34; // 定义测试日志事件类型 } 可 copy 本项目中的 build.gradle 文件内容，更多配置可参考官方文档\ntestng.xml 配置 在 src/test目录下创建一个 resources 目录，用于存放测试配置文件\n在 resources 目录下创建一个 testng.xml 文件，用于配置 TestNG 测试框架\n示例配置如下，可供参考\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE suite SYSTEM \u0026#34;http://testng.org/testng-1.0.dtd\u0026#34;\u0026gt; \u0026lt;suite name=\u0026#34;restAssured-gradleTestSuite\u0026#34;\u0026gt; \u0026lt;test thread-count=\u0026#34;1\u0026#34; name=\u0026#34;Demo\u0026#34;\u0026gt; \u0026lt;classes\u0026gt; \u0026lt;class name=\u0026#34;com.example.TestDemo\u0026#34;/\u0026gt; \u0026lt;!-- 测试脚本 class--\u0026gt; \u0026lt;/classes\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- Test --\u0026gt; \u0026lt;/suite\u0026gt; \u0026lt;!-- Suite --\u0026gt; gradle build 项目并初始化 用编辑器打开本项目 Terminal 窗口，执行以下命令确认项目 build 成功 gradle build 初始化完成：完成向导后，Gradle 将在项目目录中生成一个基本的 Gradle 项目结构 初始化目录 目录结构可参考 \u0026raquo; 项目结构\n在项目的测试源目录下创建一个新的测试类。默认情况下，Gradle 通常将测试源代码放在 src/test/java 目录中。你可以在该目录下创建测试类的包，并在包中创建新的测试类\n创建一个 TestDemo 的测试类，可以按以下结构创建文件\nsrc └── test └── java └── com └── example └── TestDemo.java demo 测试接口 Get 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts/1 请求方式：GET 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：无 返回状态码：200 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; } Post 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts 请求方式：POST 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：raw json 格式 body 内容如下： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 返回状态码：201 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } 编写脚本 打开 TestDemo.java 文件，开始编写测试脚本\n示例脚本如下，可供参考\npackage com.example; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 调试脚本 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 gradle test 查看测试报告 命令行报告 testng html 报告 打开项目 build/reports/tests/test 目录 点击 index.html 文件，查看测试报告 Maven 版本 可参考 demo 项目：https://github.com/Automation-Test-Starter/RestAssured-maven-demo\n创建一个空的 Maven 工程 mvn archetype:generate -DgroupId=com.example -DartifactId=RestAssured-maven-demo -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false 初始化完成：完成向导后，Maven 将在新建项目目录并生成一个基本的 Maven 项目结构\n配置项目 pom.xml 在 项目中 pom.xml 文件中添加以下内容\n可 copy 本项目中的 pom.xml 文件内容，更多配置可参考官方文档\n\u0026lt;!-- 依赖配置 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/io.rest-assured/rest-assured --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.rest-assured\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- https://mvnrepository.com/artifact/org.testng/testng --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.testng\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;testng\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;7.8.0\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 插件配置 --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-surefire-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.2.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;suiteXmlFiles\u0026gt; \u0026lt;suiteXmlFile\u0026gt;src/test/resources/testng.xml\u0026lt;/suiteXmlFile\u0026gt; \u0026lt;/suiteXmlFiles\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; testng.xml 配置 在 src/test目录下创建一个 resources 目录，用于存放测试配置文件\n在 resources 目录下创建一个 testng.xml 文件，用于配置 TestNG 测试框架\n示例配置如下，可供参考\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE suite SYSTEM \u0026#34;http://testng.org/testng-1.0.dtd\u0026#34;\u0026gt; \u0026lt;suite name=\u0026#34;restAssured-gradleTestSuite\u0026#34;\u0026gt; \u0026lt;test thread-count=\u0026#34;1\u0026#34; name=\u0026#34;Demo\u0026#34;\u0026gt; \u0026lt;classes\u0026gt; \u0026lt;class name=\u0026#34;com.example.TestDemo\u0026#34;/\u0026gt; \u0026lt;!-- 测试脚本 class--\u0026gt; \u0026lt;/classes\u0026gt; \u0026lt;/test\u0026gt; \u0026lt;!-- Test --\u0026gt; \u0026lt;/suite\u0026gt; \u0026lt;!-- Suite --\u0026gt; 初始化目录 目录结构可参考 \u0026raquo; 项目结构\n在项目的测试源目录下创建一个新的测试类。默认情况下，Gradle 通常将测试源代码放在 src/test/java 目录中。你可以在该目录下创建测试类的包，并在包中创建新的测试类\n创建一个 TestDemo 的测试类，可以按以下结构创建文件\nsrc └── test └── java └── com └── example └── TestDemo.java demo 测试接口 Get 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts/1 请求方式：GET 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：无 返回状态码：200 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 1, \u0026#34;title\u0026#34;: \u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34; } Post 接口 HOST: https://jsonplaceholder.typicode.com 接口地址：/posts 请求方式：POST 请求参数：无 请求头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 请求体：raw json 格式 body 内容如下： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1 } 返回状态码：201 返回头：\u0026ldquo;Content-Type\u0026rdquo;: \u0026ldquo;application/json; charset=utf-8\u0026rdquo; 返回 body： { \u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;, \u0026#34;userId\u0026#34;: 1, \u0026#34;id\u0026#34;: 101 } 编写脚本 打开 TestDemo.java 文件，开始编写测试脚本\n示例脚本如下，可供参考\npackage com.example; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class TestDemo { @Test(description = \u0026#34;Verify that the Get Post API returns correctly\u0026#34;) public void verifyGetAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .get(\u0026#34;/posts/1\u0026#34;) // Then .then() .statusCode(200) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(1)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } @Test(description = \u0026#34;Verify that the publish post API returns correctly\u0026#34;) public void verifyPostAPI() { // Given given() .baseUri(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) .header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) // When .when() .body(\u0026#34;{\\\u0026#34;title\\\u0026#34;: \\\u0026#34;foo\\\u0026#34;, \\\u0026#34;body\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;, \\\u0026#34;userId\\\u0026#34;: 1\\n}\u0026#34;) .post(\u0026#34;/posts\u0026#34;) // Then .then() .statusCode(201) // To verify correct value .body(\u0026#34;userId\u0026#34;, equalTo(1)) .body(\u0026#34;id\u0026#34;, equalTo(101)) .body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;foo\u0026#34;)) .body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;bar\u0026#34;)); } } 调试脚本 打开本项目的 Terminal 窗口，执行以下命令运行测试脚本 mvn test 查看测试报告 命令行报告 testng html 报告 打开项目 target/surefire-reports 目录 点击 index.html 文件，查看测试报告 更多信息 访问我的个人博客：https://naodeng.tech/ 我的 QA 自动化快速启动项目页面：https://github.com/Automation-Test-Starter ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/rest-assured-tutorial-building-your-own-project-from-0-to-1/","summary":"深入探讨如何从零开始构建一个 REST Assured 接口自动化测试项目。","title":"REST Assured 接口自动化测试教程：从 0 到 1 搭建 REST Assured 接口自动化测试项目"},{"content":"RestAssured 介绍 REST Assured 是一种用于测试 RESTful API 的 Java 测试框架，它使开发人员/测试人员能够轻松地编写和执行 API 测试。它的设计旨在使 API 测试变得简单和直观，同时提供了丰富的功能和灵活性。以下是 REST Assured 的一些重要特点和用法：\n发起 HTTP 请求：REST Assured 允许你轻松地构建和发起 HTTP GET、POST、PUT、DELETE 等类型的请求。你可以指定请求的 URL、头部、参数、体等信息。\n链式语法：REST Assured 使用链式语法，使测试代码更加可读和易于编写。你可以按照一种自然的方式描述你的测试用例，而不需要编写大量的代码。\n断言和校验：REST Assured 提供了丰富的校验方法，可以用于验证 API 响应的状态码、响应体、响应头等。你可以根据你的测试需求添加多个断言。\n支持多种数据格式：REST Assured 支持多种数据格式，包括 JSON、XML、HTML、Text 等。你可以使用适当的方法来处理不同格式的响应数据。\n集成 BDD（行为驱动开发）：REST Assured 可以与 BDD 框架（如 Cucumber）结合使用，使你可以更好地描述和管理测试用例。\n模拟 HTTP 服务器：REST Assured 还包括一个模拟 HTTP 服务器的功能，允许你模拟 API 的行为以进行端到端测试。\n可扩展性：REST Assured 可以通过插件和扩展进行定制，以满足特定的测试需求。\n总的来说，REST Assured 是一个功能强大且易于使用的 API 测试框架，它可以帮助你轻松地进行 RESTful API 测试，并提供了许多工具来验证 API 的正确性和性能。无论是初学者还是有经验的开发人员/测试人员，REST Assured 都是一个非常有价值的工具，可用于快速的上手 API 自动化 测试。\n项目结构 Gradle 构建的版本 - src - main - java - (应用的主要源代码) - test - java - api - (REST Assured 测试代码) - UsersAPITest.java - ProductsAPITest.java - util - TestConfig.java - resources - (配置文件、测试数据等) - (其他项目文件和资源) - build.gradle (Gradle 项目配置文件) 在这个示例目录结构中：\nsrc/test/java/api 目录用于存放 REST Assured 的测试类，每个测试类通常涉及到一个或多个相关的 API 端点的测试。例如，UsersAPITest.java 和 ProductsAPITest.java 可以包含用户管理和产品管理的测试。 src/test/java/util 目录可用于存放测试中共享的工具类，例如用于配置 REST Assured 的 TestConfig.java。 src/test/resources 目录可以包含测试数据文件、配置文件等资源，这些资源可以在测试中使用。 build.gradle 是 gradle 项目的配置文件，它用于定义项目的依赖项、构建配置以及其他项目设置。 Maven 构建的版本 - src - main - java - (应用的主要源代码) - test - java - api - (REST Assured 测试代码) - UsersAPITest.java - ProductsAPITest.java - util - TestConfig.java - resources - (配置文件、测试数据等) - (其他项目文件和资源) - pom.xml (Maven 项目配置文件) 在这个示例目录结构中：\nsrc/test/java/api 目录用于存放 REST Assured 的测试类，每个测试类通常涉及到一个或多个相关的 API 端点的测试。例如，UsersAPITest.java 和 ProductsAPITest.java 可以包含用户管理和产品管理的测试。 src/test/java/util 目录可用于存放测试中共享的工具类，例如用于配置 REST Assured 的 TestConfig.java。 src/test/resources 目录可以包含测试数据文件、配置文件等资源，这些资源可以在测试中使用。 pom.xml 是 Maven 项目的配置文件，它用于定义项目的依赖项、构建配置以及其他项目设置。 项目依赖 JDK 1.8+ ，我使用的 JDK 19 Gradle 6.0+ 或 Maven 3.0+，我使用的 Gradle 8.44 和 Maven 3.9.5 RestAssured 4.3.3+，我使用的是最新的 5.3.1 版本 语法示例 以下是一个简单的 RestAssured 语法示例，演示如何执行一个 GET 请求并验证响应：\n首先，确保你的 Gradle 或 Maven 项目中已添加了 RestAssured 依赖。\nGradle 依赖：\ndependencies { implementation \u0026#39;io.rest-assured:rest-assured:5.3.1\u0026#39; } Maven 依赖：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.rest-assured\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;rest-assured\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 接下来，创建一个测试类，编写以下代码：\nimport io.restassured.RestAssured; import io.restassured.response.Response; import org.testng.annotations.Test; import static io.restassured.RestAssured.given; import static org.hamcrest.Matchers.equalTo; public class RestAssuredDemo { @Test public void testGetRequest() { // 设置基本 URI，这里以 JSONPlaceholder 为例 RestAssured.baseURI = \u0026#34;https://jsonplaceholder.typicode.com\u0026#34;; // 发送 GET 请求，并保存响应 Response response = given() .when() .get(\u0026#34;/posts/1\u0026#34;) .then() .extract() .response(); // 打印响应的 JSON 内容 System.out.println(\u0026#34;Response JSON: \u0026#34; + response.asString()); // 验证状态码为 200 response.then().statusCode(200); // 验证响应中的特定字段值 response.then().body(\u0026#34;userId\u0026#34;, equalTo(1)); response.then().body(\u0026#34;id\u0026#34;, equalTo(1)); response.then().body(\u0026#34;title\u0026#34;, equalTo(\u0026#34;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026#34;)); response.then().body(\u0026#34;body\u0026#34;, equalTo(\u0026#34;quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026#34;)); } } 上述代码执行了一个 GET 请求到 JSONPlaceholder 的 /posts/1 端点，并验证了响应的状态码和特定字段的值。你可以根据你的需求修改基本 URI 和验证条件。\n在这个示例中，我们使用了 TestNG 测试框架，但你也可以使用其他测试框架，例如 JUnit。确保你的测试类中包含了合适的导入语句，并根据需要进行适当的配置。\n这是一个简单的 RestAssured 语法示例，用于执行 GET 请求和验证响应。你可以根据项目的需求和接口的复杂性来构建更复杂的测试用例。\n","permalink":"https://naodeng.com.cn/posts/api-automation-testing/rest-assured-tutorial-and-environment-preparation/","summary":"包括入门介绍和环境搭建准备。在博客中，读者将了解什么是 REST Assured 以及如何开始使用它来进行 API 测试。教程将涵盖 REST Assured 的基本概念，包括如何设置测试环境，准备所需的工具和资源，以便读者可以开始编写和执行他们自己的 API 测试。","title":"REST Assured 接口自动化测试教程：入门介绍和环境搭建准备"},{"content":"CI/CD Integration Accessing github action Take github action as an example, and other CI tools as well.\nGradle + Scala version See the demo at https://github.com/Automation-Test-Starter/gatling-gradle-scala-demo.\nCreate the .github/workflows directory: In your GitHub repository, create a directory called .github/workflows. This will be where the GitHub Actions workflow files will be stored.\nCreate the workflow file: Create a YAML-formatted workflow file, such as gatling.yml, in the .github/workflows directory.\nEdit the gatling.yml file: Copy the following into the file.\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | ./gradlew gatlingRun env: GATLING_SIMULATIONS_FOLDER: src/gatling/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling Commit the code: Add the gatling.yml file to your repository and commit. View the test report: In GitHub, navigate to your repository. Click the Actions tab at the top and then click the Performance Test workflow on the left. You should see the workflow running, wait for the execution to complete and you can view the results. Maven + Scala version See the demo at https://github.com/Automation-Test-Starter/gatling-maven-scala-demo\nCreate the .github/workflows directory: In your GitHub repository, create a directory called .github/workflows. This will be where the GitHub Actions workflow files will be stored.\nCreate the workflow file: Create a YAML-formatted workflow file, such as gatling.yml, in the .github/workflows directory.\nEdit the gatling.yml file: Copy the following into the file.\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | mvn gatling:test env: GATLING_SIMULATIONS_FOLDER: src/test/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling Commit the code: Add the gatling.yml file to your repository and commit. View the test report: In GitHub, navigate to your repository. Click the Actions tab at the top and then click the Performance Test workflow on the left. You should see the workflow running, wait for the execution to complete and you can view the results. reference galting official website: https://gatling.io/ galting official documentation: https://gatling.io/docs/gatling/ galting official github: https://github.com/gatling/ ","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-tutorial-ci-cd-integration/","summary":"This article introduces the advanced usage of the performance testing tool gatling: CI/CD integration, using github action as an example to introduce how to integrate gatling into the CI/CD process.","title":"Gatling Performance Testing Tutorial advanced usage: CI/CD Integration"},{"content":"持续集成 接入 github action 以 github action 为例，其他 CI 工具类似\nGradle + Scala 版本 可参考 demo：https://github.com/Automation-Test-Starter/gatling-gradle-scala-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gatling.yml。\n编辑 gatling.yml 文件：将以下内容复制到文件中。\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | ./gradlew gatlingRun env: GATLING_SIMULATIONS_FOLDER: src/gatling/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: build/reports/gatling 提交代码：将 gatling.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 Maven + Scala 版本 可参考 demo：https://github.com/Automation-Test-Starter/gatling-maven-scala-demo\n创建.github/workflows 目录：在你的 GitHub 仓库中，创建一个名为 .github/workflows 的目录。这将是存放 GitHub Actions 工作流程文件的地方。\n创建工作流程文件：在.github/workflows 目录中创建一个 YAML 格式的工作流程文件，例如 gatling.yml。\n编辑 gatling.yml 文件：将以下内容复制到文件中。\nname: Gatling Performance Test on: push: branches: - main jobs: performance-test: runs-on: ubuntu-latest steps: - name: Checkout code uses: actions/checkout@v2 - name: Set up Java uses: actions/setup-java@v2 with: java-version: 11 distribution: \u0026#39;adopt\u0026#39; - name: Run Gatling tests run: | mvn gatling:test env: GATLING_SIMULATIONS_FOLDER: src/test/scala - name: Archive Gatling results uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling - name: Upload Gatling results to GitHub uses: actions/upload-artifact@v2 with: name: gatling-results path: target/gatling 提交代码：将 gatling.yml 文件添加到仓库中并提交。 查看测试报告：在 GitHub 中，导航到你的仓库。单击上方的 Actions 选项卡，然后单击左侧的 Performance Test 工作流。你应该会看到工作流正在运行，等待执行完成，就可以查看结果。 参考 galting 官网：https://gatling.io/ galting 官方文档：https://gatling.io/docs/gatling/ galting 官方 github: https://github.com/gatling/ ","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-intro-ci-cd-integration/","summary":"文章介绍性能测试工具 gatling 的进阶用法：CI/CD 集成，以 github action 为例来介绍如何集成 gatling 到 CI/CD 流程中","title":"gatling 性能测试教程 - 进阶用法：CI/CD 集成"},{"content":"Test report analysis Overview Overall view Open the detailed html report after the performance test execution is finished; Your report can be analyzed by metrics, active users and requests/responses over time, as well as distributions\nThe name of Simulation is displayed in the center of the page in the header The list on the left side shows a menu of different types of reports, which can be switched by clicking on them. The middle of the page shows an overview of the performance test report, including: total number of requests, total number of successful requests, total number of unsuccessful requests, shortest response time, longest response time, average response time, throughput, standard deviation, percentage distribution, etc. It also shows the version of gatling and the time and duration of this report. The version of gatling and the time and duration of this report run are also displayed. The Global menu points to aggregate statistics. The Details menu points to statistics for each request type. Response time ranges This chart shows the distribution of response times within the standard range The list on the left shows all requests and the distribution of request response times, with the red color representing failed requests. On the right, Number of requests represents the number of concurrent users, as well as the number of requests for each request and their success and failure status.\nThese ranges can be configured in the gatling.conf file\nSummary This chart shows some standard statistics such as minimum, maximum, average, standard deviation and percentile for global and per request. stats shows the specific success and failure of all requests OK for success, KO for failure, and 99th pct for 99th percentile response time for total requests for this API.\nThese percentiles can be configured in the gatling.conf file.\nActive users over time This chart shows that the number of active users refers to the number of users who are making requests during the test time period. At the beginning of the test, the number of active users is 0. When users start sending requests, the number of active users starts to increase. When a user completes a request, the number of active users begins to decrease. The maximum number of active users is the number of users sending requests at the same time during the test period.\nResponse time distribution This chart shows the distribution of response times, including response times for successful requests and response times for failed requests.\nResponse time percentiles over time This chart shows various response time percentiles over time, but only for successful requests. Since failed requests may end early or be caused by timeouts, they can have a huge impact on the percentile calculation.\nRequests per second over time This chart shows the number of requests per second, including the number of successful requests and the number of failed requests.\nResponse per second over time This chart shows the number of responses per second, including the number of successful responses and the number of failed responses.\nSingle request analysis report You can click the details menu on the report page to switch to the details tab and view a detailed report for a single request.\nThe Details page primarily shows per-request statistics, and similarly to the global report includes a graph of response time distribution, response time percentile, requests per second, and responses per second. The difference is that there is a graph at the bottom that depicts the response time of a single request relative to all requests globally. The horizontal coordinate of this graph is the number of all requests per second globally, and the vertical coordinate is the response time of a single request.\nPerformance Scenario Setting Injection What is Injection In Gatling performance testing, \u0026ldquo;Injection\u0026rdquo; refers to a method of introducing virtual users (or load) into the system. It defines how simulated users are introduced into a test scenario, including the number, rate, and manner of users.Injection is a key concept used in Gatling to control load and concurrency, allowing you to simulate different user behaviors and load models.\nUser injection profiles are defined using the injectOpen and injectClosed methods (inject in Scala). This method takes as arguments a sequence of injection steps that are processed sequentially. Each step defines a set of users and how these users are injected into the scene.\nMore from the web site: https://gatling.io/docs/gatling/reference/current/core/injection/\nCommon Injection Scenario Open Model Scenario setUp( scn.inject( nothingFor(4), // 1 atOnceUsers(10), // 2 rampUsers(10).during(5), // 3 constantUsersPerSec(20).during(15), // 4 constantUsersPerSec(20).during(15).randomized, // 5 rampUsersPerSec(10).to(20).during(10.minutes), // 6 rampUsersPerSec(10).to(20).during(10.minutes).randomized, // 7 stressPeakUsers(1000).during(20) // 8 ).protocols(httpProtocol) ) nothingFor(duration): set a period of time to stop, this time to do nothing atOnceUsers(nbUsers): immediately inject a certain number of virtual users rampUsers(nbUsers) during(duration): set a certain number of virtual users to be injected gradually during a specified period of time. constantUsersPerSec(rate) during(duration): Define a constant number of concurrent users per second for a specified period of time. constantUsersPerSec(rate) during(duration) randomized: defines a randomized concurrency increase/decrease around a specified number of concurrencies per second, for a specified period of time rampUsersPerSec(rate1) to (rate2) during(duration): defines a concurrency interval that runs for the specified time, with the concurrency growth period being a regular value. rampUsersPerSec(rate1) to (rate2) during(duration) randomized: define a concurrency interval, run for a specified time, the concurrency growth period is a random value stressPeakUsers(nbUsers).during(duration) : injects a given number of users according to a smooth approximation of a step function that stretches to a given duration. users. Closed Model Scenario setUp( scn.inject( constantConcurrentUsers(10).during(10), // 1 rampConcurrentUsers(10).to(20).during(10) // 2 ) ) constantConcurrentUsers(fromNbUsers).during(duration) : inject to make the number of concurrent users in the system constant rampConcurrentUsers(fromNbUsers).to(toNbUsers).during(duration) : inject so that the number of concurrent users in the system increases linearly from one number to the next Meta DSL Scenario \u0026ldquo;Meta DSL is a special Domain Specific Language (DSL) for describing the metadata and global configuration of performance test scenarios.Meta DSL allows you to define a number of global settings and parameters in a performance test that affect the entire test process, rather than being specific to a particular scenario.\nThe elements of the Meta DSL can be used to write tests in a simpler way. If you want to link levels and ramps to reach the limits of your application (a test sometimes referred to as a capacity load test), you can do this manually using the regular DSL and looping with map and flatMap.\nincrementUsersPerSec setUp( // Generate an open workload injection profile // 10, 15, 20, 25 and 30 users arrive every second // Each level lasts 10 seconds // Each level lasts 10 seconds scn.inject( incrementUsersPerSec(5.0) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Double ) incrementConcurrentUsers setUp( // Generate a closed workload injection profile // Concurrent users at levels 10, 15, 20, 25, and 30 // Each level lasts 10 seconds // Each level lasts 10 seconds scn.inject( incrementConcurrentUsers(5) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Int ) ) incrementUsersPerSec is used for open workloads, incrementConcurrentUsers is used for closed workloads (users/sec vs concurrent users).\nseparatedByRampsLasting and startingFrom are both optional. If you do not specify a ramp, the test jumps from one level to another as soon as it finishes. If you do not specify the number of starting users, the test will start with 0 concurrent users or 0 users per second and move to the next step immediately.\nConcurrent Scenario setUp( scenario1.inject(injectionProfile1), scenario2.inject(injectionProfile2) ) You can configure multiple scenes to start simultaneously and execute concurrently in the same setUp block.\nOther Scenarios Check out the website: https://gatling.io/docs/gatling/reference/current/core/injection/\n","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-tutorial-advanced-usage/","summary":"This article introduces the advanced usage of the performance testing tool gatling: analysis of performance test reports, introduction of different types of test report reports, and configuration of performance test scenarios under different business types.","title":"Gatling Performance Testing Tutorial advanced usage: Test report analysis and Performance Scenario Setting"},{"content":"测试报告解析 总览 总览图 性能测试执行结束后打开详细的 html 报告，可以看到详细的性能测试报告； 可通过指标、活跃用户和随时间变化的请求/响应以及分布来分析您的报告\n页面中间标题处显示 Simulation 的名字 左侧的列表展示不同类型的报告菜单，可点击切换 页面中部展示性能测试报告的总览信息，包括：请求总数、成功请求总数、失败请求总数、最短响应时间、最长响应时间、平均响应时间、吞吐量、标准差、百分比分布等。也会展示 gatling 的版本及本次报告运行的时间和时长 全局菜单指向综合统计数据。 详细信息菜单指向每个请求类型的统计信息。 请求数\u0026amp;响应时间分布图 此图表展示了响应时间在标准范围内的分布情况 左侧的列表显示所有的请求以及请求响应的时间分布，红色代表失败的请求 右边 Number of request 代表用户并发数量，以及各个请求的请求数量及其成功失败状态\n这些范围可以在 gatling.conf 文件中配置\n请求标准统计分析图 此图表显示了一些标准统计数据，例如全局和每个请求的最小值、最大值、平均值、标准差和百分位数。 stats 显示了所有请求具体的成功失败情况 OK 代表成功，KO 代表失败，百分比 99th pct 代表对于这一个 API 总的请求中有百分之 99 的请求 response time 是这个数值\n这些百分位数可以在 gatling.conf 文件中配置。\n活跃用户数统计图 此图表展示了活跃用户数指的是在测试时间段内，正在进行请求的用户数。在测试开始时，活跃用户数为 0。当用户开始发送请求时，活跃用户数开始增加。当用户完成请求时，活跃用户数开始减少。活跃用户数的最大值是在测试期间同时发送请求的用户数。\n响应时间分布图 此图表显示了响应时间的分布，包括请求成功的响应时间和请求失败的响应时间。\n响应时间百分位对比图 此图表显示一段时间内的各种响应时间百分位数，但仅适用于成功的请求。由于失败的请求可能会提前结束或由超时引起，因此它们会对百分位数的计算产生巨大影响。\n每秒请求数图 此图表展示了每秒的请求数，包括成功的请求数和失败的请求数。\n每秒响应数图 此图表展示了每秒的响应数，包括成功的响应数和失败的响应数。\n单个请求分析报告 可点击报告页面上的 details 菜单切换到 details tab 页面，查看单个请求的详细报告\nDetails 页面主要展示了每个请求的统计数据，与全局报告相似地包括了响应时间分布图，响应时间百分位图，每秒请求数图，每秒响应数图。不同的是最底下有一张图是描述单个请求相对于全局所有请求的响应时间。该图横坐标是每秒全局所有请求数，纵坐标是单个请求的响应时间。\n性能场景设置 Injection 注入 什么是 Injection 在 Gatling 性能测试中，\u0026ldquo;Injection\u0026quot;是指将虚拟用户（或负载）引入系统的一种方式。它定义了模拟用户如何被引入测试场景，包括用户的数量、速率和方式。Injection 是 Gatling 中用于控制负载和并发度的关键概念，允许你模拟不同的用户行为和负载模型。\n用户注入配置文件的定义是通过 injectOpen 和 injectClosed 方法（Scala 中的 inject）完成的。此方法将按顺序处理的注入步骤序列作为参数。每个步骤都定义了一组用户，以及如何将这些用户注入到场景中。\n官网更多介绍：https://gatling.io/docs/gatling/reference/current/core/injection/\n常用 Injection 场景 Open Model 开放模型场景 setUp( scn.inject( nothingFor(4), // 1 atOnceUsers(10), // 2 rampUsers(10).during(5), // 3 constantUsersPerSec(20).during(15), // 4 constantUsersPerSec(20).during(15).randomized, // 5 rampUsersPerSec(10).to(20).during(10.minutes), // 6 rampUsersPerSec(10).to(20).during(10.minutes).randomized, // 7 stressPeakUsers(1000).during(20) // 8 ).protocols(httpProtocol) ) nothingFor(duration)：设置一段停止的时间，这段时间什么都不做 atOnceUsers(nbUsers)：立即注入一定数量的虚拟用户 rampUsers(nbUsers) during(duration)：在指定时间内，设置一定数量逐步注入的虚拟用户 constantUsersPerSec(rate) during(duration)：定义一个在每秒钟恒定的并发用户数，持续指定的时间 constantUsersPerSec(rate) during(duration) randomized：定义一个在每秒钟围绕指定并发数随机增减的并发，持续指定时间 rampUsersPerSec(rate1) to (rate2) during(duration)：定义一个并发数区间，运行指定时间，并发增长的周期是一个规律的值 rampUsersPerSec(rate1) to(rate2) during(duration) randomized：定义一个并发数区间，运行指定时间，并发增长的周期是一个随机的值 stressPeakUsers(nbUsers).during(duration) ：按照拉伸到给定持续时间的阶跃函数的平滑近似注入给定数量的用户。 Closed Model 闭合模型场景 setUp( scn.inject( constantConcurrentUsers(10).during(10), // 1 rampConcurrentUsers(10).to(20).during(10) // 2 ) ) constantConcurrentUsers(nbUsers).during(duration) ：注入以使系统中的并发用户数恒定 rampConcurrentUsers(fromNbUsers).to(toNbUsers).during(duration) ：注入，使系统中的并发用户数从一个数字线性增加到另一个数字 Meta DSL 场景 \u0026ldquo;Meta DSL\u0026quot;是一种特殊的领域特定语言（DSL），用于描述性能测试场景的元数据（metadata）和全局配置。Meta DSL 允许你定义性能测试中的一些全局设置和参数，以影响整个测试过程，而不是特定于某个场景。\n可以使用 Meta DSL 的元素以更简单的方式编写测试。如果您想要链接级别和斜坡以达到应用程序的极限（有时称为容量负载测试的测试），您可以使用常规 DSL 手动完成，并使用 map 和 flatMap 进行循环。\nincrementUsersPerSec setUp( // 生成一个开放的工作量注入配置文件 // 每秒分别有 10、15、20、25 和 30 个用户到达 // 每个级别持续 10 秒 // 每级持续 10 秒 scn.inject( incrementUsersPerSec(5.0) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Double ) incrementConcurrentUsers setUp( // 生成一个封闭的工作负载注入配置文件 // 并发用户分别为 10、15、20、25 和 30 级 // 每个级别持续 10 秒 // 每级持续 10 秒 scn.inject( incrementConcurrentUsers(5) .times(5) .eachLevelLasting(10) .separatedByRampsLasting(10) .startingFrom(10) // Int ) ) incrementUsersPerSec 用于开放式工作负载，incrementConcurrentUsers 用于封闭式工作负载（用户数/秒与并发用户数）。\nseparatedByRampsLasting 和 startingFrom 都是可选的。如果您不指定斜坡，测试完成后就会立即从一个级别跳到另一个级别。如果您不指定启动用户数，测试将从 0 个并发用户或每秒 0 个用户开始，并立即进入下一步。\nConcurrent Scenarios 并发场景 setUp( scenario1.inject(injectionProfile1), scenario2.inject(injectionProfile2) ) 您可以在同一个 setUp 块中配置多个场景同时启动并并发执行。\n其他场景 查看官网介绍：https://gatling.io/docs/gatling/reference/current/core/injection/\n","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-intro-advanced-usage/","summary":"文章介绍性能测试工具 gatling 的进阶用法：性能测试报告的解析，不同类型的测试报告报表介绍，不同业务类型下的性能测试场景配置","title":"gatling 性能测试教程 - 进阶用法：报告解析和场景设置"},{"content":"Build your own Gatling project from 0 to 1 Gradle + Scala versions Create an empty Gradle project mkdir gatling-gradle-demo cd gatling-gradle-demo gradle init Configure the project build.gradle Add the following to the build.gradle file in the project\nYou can copy the content of the build.gradle file in this project, for more configurations, please refer to the official documentation.\n// Plugin Configuration plugins { id \u0026#39;scala\u0026#39; // scala plugin declaration (based on the development tools plugin) id \u0026#39;io.gatling.gradle\u0026#39; version \u0026#39;3.9.5.6\u0026#39; // declaration of the version of the gradle-based gatling framework plugin } // Repository source configuration repositories { // Use the maven central repository source mavenCentral() } // gatling configuration gatling { // logback root level, defaults to the Gatling console log level if logback.xml does not exist in the configuration folder logLevel = \u0026#39;WARN\u0026#39; // Enforce logging of HTTP requests at a level of detail // set to \u0026#39;ALL\u0026#39; for all HTTP traffic in TRACE, \u0026#39;FAILURES\u0026#39; for failed HTTP traffic in DEBUG logHttp = \u0026#39;FAILURES\u0026#39; // Simulations filter simulations = { include \u0026#34;**/simulation/*.scala\u0026#34; } } // Dependencies dependencies { // Charts library for generating report charts gatling \u0026#39;io.gatling.highcharts:gatling-charts-highcharts:3.8.3\u0026#39; } gradle build project and initialize Open the Terminal window of the project with an editor and execute the following command to confirm that the project build was successful gradle build Initialization complete: After completing the wizard, Gradle will generate a basic Gradle project structure in the project directory Initialization Directory Create a simulation directory in the src/gatling/scala directory to hold test scripts\nGatling tests are usually located in the src/gatling directory. You need to manually create the src directory in the project root, and then create the gatling directory under the src directory. In the gatling directory, you can create your test simulation folder simulation, as well as other folders such as data, bodies, resources, and so on.\nWriting Scripts Create a demo.scala file in the simulation directory to write your test scripts.\nFor reference, the following is a sample script\nThe script contains two scenarios, one for get requests and one for post requests. The get API validates that the API returns a status code of 200 and the post API validates that the API returns a status code of 201. The get API uses rampUsers, the post API uses constantConcurrentUsers. rampUsers: incrementally increase the number of concurrent users over a specified period of time, constantConcurrentUsers: keep the number of concurrent users constant over a specified period of time. The number of concurrent users is 10 for both APIs, and the duration is 10 seconds for both APIs. The request interval is 2 seconds for both APIs.\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } Debugging Scripts Execute the following command to run the test script and view the report\ngradle gatlingRun Maven + Scala version Create an empty Maven project mvn archetype:generate -DgroupId=demo.gatlin.maven -DartifactId=gatling-maven-demo Initialization complete: After completing the wizard, Maven will create a new project directory and generate a basic Maven project structure in the\nConfigure the project pom.xml Add the following contents to the pom.xml file in the project\nYou can copy the contents of the pom.xml file in this project, for more configuration, please refer to the official documentation.\n\u0026lt;!-- dependencies Configuration --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.gatling.highcharts\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-charts-highcharts\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.9.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- Plugin Configuration --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.gatling\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.6.0\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;net.alchim31.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;scalaVersion\u0026gt;2.13.12\u0026lt;/scalaVersion\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;testCompile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;jvmArgs\u0026gt; \u0026lt;jvmArg\u0026gt;-Xss100M\u0026lt;/jvmArg\u0026gt; \u0026lt;/jvmArgs\u0026gt; \u0026lt;args\u0026gt; \u0026lt;arg\u0026gt;-deprecation\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-feature\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-unchecked\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:implicitConversions\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:postfixOps\u0026lt;/arg\u0026gt; \u0026lt;/args\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; Initialization Directory Create a simulation directory in the src/test/scala directory to hold the test scripts\nscala tests are usually located in the src/test directory. You need to create a scala directory under the project test directory. In the scala directory, you can create your test simulation folder simulation, as well as other folders such as data, bodies, resources, and so on.\nWriting Scripts Create a demo.scala file in the simulation directory to write your test scripts.\nFor reference, the following is a sample script\nThe script contains two scenarios, one for get requests and one for post requests. The get API validates that the API returns a status code of 200 and the post API validates that the API returns a status code of 201. The get API uses rampUsers, the post API uses constantConcurrentUsers. rampUsers: incrementally increase the number of concurrent users over a specified period of time, constantConcurrentUsers: keep the number of concurrent users constant over a specified period of time. The number of concurrent users is 10 for both APIs, and the duration is 10 seconds for both APIs. The request interval is 2 seconds for both APIs.\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } Debugging Scripts Execute the following command to run the test script and view the report\nmvn gatling:test ","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-tutorial2/","summary":"The article introduces the performance testing tool gatling advanced introduction: from 0 to 1 build your own Gatling project, introduces the basic use of Gatling, and how to build your own Gatling project, write performance test scripts, view the test report and so on.","title":"gatling Performance Testing Tutorial: building your own gatling project from 0 to 1"},{"content":"从 0 到 1 搭建自己的 Gatling 工程 Gradle + Scala 版本 创建一个空的 Gradle 工程 mkdir gatling-gradle-demo cd gatling-gradle-demo gradle init 配置项目 build.gradle 在 项目中 build.gradle 文件中添加以下内容\n可 copy 本项目中的 build.gradle 文件内容，更多配置可参考官方文档\n// 插件配置 plugins { id \u0026#39;scala\u0026#39; // scala插件声明（基于开发工具插件） id \u0026#39;io.gatling.gradle\u0026#39; version \u0026#39;3.9.5.6\u0026#39; // 基于gradle的gatling框架插件版本声明 } //仓库源配置 repositories { // 使用 maven 中心仓库源 mavenCentral() } // gatling 配置 gatling { // logback root level，如果配置文件夹中不存在 logback.xml，则默认 Gatling 控制台日志级别 logLevel = \u0026#39;WARN\u0026#39; // 执行记录 HTTP 请求的详细程度 // set to \u0026#39;ALL\u0026#39; for all HTTP traffic in TRACE, \u0026#39;FAILURES\u0026#39; for failed HTTP traffic in DEBUG logHttp = \u0026#39;FAILURES\u0026#39; // Simulations 过滤器 simulations = { include \u0026#34;**/simulation/*.scala\u0026#34; } } // 依赖配置 dependencies { // 图表库，用于生成报告图表 gatling \u0026#39;io.gatling.highcharts:gatling-charts-highcharts:3.8.3\u0026#39; } gradle build 项目并初始化 用编辑器打开本项目 Terminal 窗口，执行以下命令确认项目 build 成功 gradle build 初始化完成：完成向导后，Gradle 将在项目目录中生成一个基本的 Gradle 项目结构 初始化目录 在 src/gatling/scala 目录下创建一个 simulation 目录，用于存放测试脚本\nGatling 测试通常位于 src/gatling 目录中。你需要在项目根目录下手动创建 src 目录，然后在 src 目录下创建 gatling 目录。在 gatling 目录下，你可以创建你的测试模拟文件夹 simulation，以及其他文件夹，如 data、bodies、resources 等。\n编写脚本 在 simulation 目录下创建一个 demo.scala 文件，用于编写测试脚本\n示例脚本如下，可供参考\n脚本包含了两个场景，一个是 get 请求，一个是 post 请求 get 接口验证接口返回状态码为 200，post 接口验证接口返回状态码为 201 get 接口使用了 rampUsers，post 接口使用了 constantConcurrentUsers rampUsers：在指定时间内逐渐增加并发用户数，constantConcurrentUsers：在指定时间内保持并发用户数不变 两个接口的并发用户数都是 10 个，持续时间都是 10 秒 两个接口的请求间隔都是 2 秒\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } 调试脚本 执行以下命令，运行测试脚本并查看报告\ngradle gatlingRun Maven + Scala 版本 创建一个空的 Maven 工程 mvn archetype:generate -DgroupId=demo.gatlin.maven -DartifactId=gatling-maven-demo 初始化完成：完成向导后，Maven 将在新建项目目录并生成一个基本的 Maven 项目结构\n配置项目 pom.xml 在 项目中 pom.xml 文件中添加以下内容\n可 copy 本项目中的 pom.xml 文件内容，更多配置可参考官方文档\n\u0026lt;!-- 依赖配置 --\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.gatling.highcharts\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-charts-highcharts\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.9.5\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;!-- 插件配置 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;io.gatling\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;gatling-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.6.0\u0026lt;/version\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;net.alchim31.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;scala-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;scalaVersion\u0026gt;2.13.12\u0026lt;/scalaVersion\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;testCompile\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;jvmArgs\u0026gt; \u0026lt;jvmArg\u0026gt;-Xss100M\u0026lt;/jvmArg\u0026gt; \u0026lt;/jvmArgs\u0026gt; \u0026lt;args\u0026gt; \u0026lt;arg\u0026gt;-deprecation\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-feature\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-unchecked\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:implicitConversions\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-language:postfixOps\u0026lt;/arg\u0026gt; \u0026lt;/args\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; 初始化目录 在 src/test/scala 目录下创建一个 simulation 目录，用于存放测试脚本\nscala 测试通常位于 src/test 目录中。你需要在项目 test 目录下创建 scala 目录。在 scala 目录下，你可以创建你的测试模拟文件夹 simulation，以及其他文件夹，如 data、bodies、resources 等。\n编写脚本 在 simulation 目录下创建一个 demo.scala 文件，用于编写测试脚本\n示例脚本如下，可供参考\n脚本包含了两个场景，一个是 get 请求，一个是 post 请求 get 接口验证接口返回状态码为 200，post 接口验证接口返回状态码为 201 get 接口使用了 rampUsers，post 接口使用了 constantConcurrentUsers rampUsers：在指定时间内逐渐增加并发用户数，constantConcurrentUsers：在指定时间内保持并发用户数不变 两个接口的并发用户数都是 10 个，持续时间都是 10 秒 两个接口的请求间隔都是 2 秒\npackage simulation import scala.concurrent.duration._ import io.gatling.core.Predef._ import io.gatling.http.Predef._ class demo extends Simulation { val httpProtocol = http .baseUrl(\u0026#34;https://jsonplaceholder.typicode.com\u0026#34;) // 5 val scn = scenario(\u0026#34;GetSimulation\u0026#34;) .exec(http(\u0026#34;get_demo\u0026#34;) .get(\u0026#34;/posts/1\u0026#34;) .check(status.is(200))) .pause(2) val scn1 = scenario(\u0026#34;PostSimulation\u0026#34;) .exec(http(\u0026#34;post_demo\u0026#34;) .post(\u0026#34;/posts\u0026#34;) .body(StringBody(\u0026#34;\u0026#34;\u0026#34;{\u0026#34;title\u0026#34;: \u0026#34;foo\u0026#34;,\u0026#34;body\u0026#34;: \u0026#34;bar\u0026#34;,\u0026#34;userId\u0026#34;: 1}\u0026#34;\u0026#34;\u0026#34;)).asJson .check(status.is(201))) .pause(2) setUp( scn.inject(rampUsers(10) during(10 seconds)), scn1.inject(constantConcurrentUsers(10) during(10 seconds)) ).protocols(httpProtocol) } 调试脚本 执行以下命令，运行测试脚本并查看报告\nmvn gatling:test ","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-intro2/","summary":"文章介绍性能测试工具 gatling 的进阶介绍：从 0 到 1 搭建自己的 Gatling 工程，介绍了 Gatling 的基本使用方法，以及如何搭建自己的 Gatling 工程，编写性能测试脚本，查看测试报告等","title":"gatling 性能测试教程：从 0 到 1 搭建自己的 Gatling 工程"},{"content":"Gatling Introduction Gatling is an open source tool for performance and load testing, especially for testing web applications. It is a high-performance tool based on the Scala programming language for simulating and measuring the performance of applications under different loads.\nHere are some of the key features and benefits of Gatling:\nBased on Scala programming language: Gatling\u0026rsquo;s test scripts are written in Scala, which makes it a powerful programming tool that allows users to write complex test scenarios and logic. High Performance: Gatling is designed as a high performance load testing tool. It uses non-blocking I/O and an asynchronous programming model that is capable of simulating large numbers of concurrent users to better mimic real-world load situations. Easy to learn and use: Although Gatling\u0026rsquo;s test scripts are written in Scala, its DSL (Domain Specific Language) is very simple and easy to learn. Even if you are not familiar with Scala, you can quickly learn how to create test scripts. Rich Features: Gatling provides a rich set of features, including request and response processing, data extraction, conditional assertions, performance report generation, and more. These features enable you to create complex test scenarios and perform comprehensive evaluation of application performance. Multi-Protocol Support: In addition to HTTP and HTTPS, Gatling supports other protocols such as WebSocket, JMS, and SMTP, making it suitable for testing a wide range of different types of applications. Real-time results analysis: Gatling provides real-time performance data and graphical reports during test runs to help you quickly identify performance issues. Open source and active community: Gatling is an open source project with an active community that constantly updates and improves the tool. CI/CD Integration Support: Gatling can be integrated with CI/CD tools such as Jenkins to perform performance testing in continuous integration and continuous delivery processes. Overall, Gatling is a powerful performance testing tool for testing a wide range of application types, helping development teams identify and resolve performance issues to ensure consistent performance and scalability of applications in production environments.\nEnvironment setup Since I\u0026rsquo;m a macbook user, I\u0026rsquo;ll use the macbook demo as an example in the introduction, but windows users can refer to it on their own.\nVSCode + Gradle + Scala Version Preparation Development tool: VSCode Install Gradle version \u0026gt;= 6.0, I am using Gradle 8.44. Install JDK version \u0026gt;= 8, I use JDK 19 install plugins VSCode search for Scala (Metals) plugin for installation VSCode search for Gradle for Java plugin for installation official demo initialization \u0026amp; debugging We will use the official demo project for initialization and debugging first, and then we will introduce how to create your own project later.\nClone the official demo project git clone git@github.com:gatling/gatling-gradle-plugin-demo-scala.git Open the cloned official demo project with VSCode.\nOpen the project\u0026rsquo;s Terminal window with VSCode and execute the following command\ngradle build Run the demo in the project gradle gatlingRun Viewing the results of a command line run Click on the html report link in the command line report and open it with your browser to view the detailed report information VSCode + Maven + Scala version Preparation Development tool: VSCode Install Maven, I use Maven 3.9.5 JDK version \u0026gt;= 8, I use JDK 19 install plugins VSCode search for Scala (Metals) plugins to install VSCode search for Maven for Java plugins to install Official demo initialization \u0026amp; debugging We will use the official demo project for initialization and debugging first, and then we will introduce how to create your own project.\nClone the official demo project git clone git@github.com:gatling/gatling-maven-plugin-demo-scala.git Use VSCode to open the cloned official demo project.\nOpen the Terminal window of this project with VSCode and execute the following command to run the demo in the project\nmvn gatling:test Viewing the results of a command line run Click on the html report link in the command line report and open it with your browser to view the detailed report information IDEA + Gradle + Scala version This is similar to the VSCode version, so I won\u0026rsquo;t repeat it here.\nThe differences are as follows:\nIDEA searches for Scala plugins to install New way to run: right click and select Engine.scala file in the project directory, select Run \u0026lsquo;Engine\u0026rsquo; to run the demo (you need to press enter to confirm the run). IDEA + Maven + Scala version This is similar to the VSCode version, so I won\u0026rsquo;t repeat it here.\nThe differences are as follows:\nIDEA searches for Scala plugins to install New way to run: right-click the Engine.scala file in the project directory and select Run \u0026lsquo;Engine\u0026rsquo; to run the demo (you need to press enter to confirm during the run). ","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-tutorial1/","summary":"This article describes how to get started with the performance testing tool gatling, how to set up the environment, and how to get the official demo up and running.","title":"Gatling Performance Testing Tutorial: Getting Started"},{"content":"Gatling 介绍 Gatling 是一个用于性能测试和负载测试的开源工具，特别适用于测试 Web 应用程序。它是一个基于 Scala 编程语言的高性能工具，用于模拟并测量应用程序在不同负载下的性能。\n以下是 Gatling 的一些重要特点和优势：\n基于 Scala 编程语言：Gatling 的测试脚本使用 Scala 编写，这使得它具有强大的编程能力，允许用户编写复杂的测试场景和逻辑。 高性能：Gatling 被设计为高性能的负载测试工具。它使用了非阻塞的 I/O 和异步编程模型，能够模拟大量并发用户，从而更好地模拟真实世界中的负载情况。 易于学习和使用：尽管 Gatling 的测试脚本是使用 Scala 编写的，但它的 DSL（领域特定语言）非常简单，容易上手。即使你不熟悉 Scala，也可以快速学会如何创建测试脚本。 丰富的功能：Gatling 提供了丰富的功能，包括请求和响应处理、数据提取、条件断言、性能报告生成等。这些功能使你能够创建复杂的测试场景，并对应用程序的性能进行全面的评估。 多协议支持：除了 HTTP 和 HTTPS，Gatling 还支持其他协议，如 WebSocket，JMS，和 SMTP。这使得它适用于测试各种不同类型的应用程序。 实时结果分析：Gatling 可以在测试运行期间提供实时的性能数据和图形化报告，帮助你快速发现性能问题。 开源和活跃的社区：Gatling 是一个开源项目，拥有一个活跃的社区，不断更新和改进工具。 支持 CI/CD 集成：Gatling 可以与 CI/CD 工具（如 Jenkins）集成，以便在持续集成和持续交付流程中执行性能测试。 总的来说，Gatling 是一个功能强大的性能测试工具，适用于测试各种类型的应用程序，帮助开发团队识别和解决性能问题，以确保应用程序在生产环境中具有稳定的性能和可伸缩性。\n环境搭建 由于我是 macbook，后面的介绍几本会以 macbook demo 为例，windows 的同学可以自行参考\nVSCode + Gradle + Scala 版本 准备工作 开发工具：VSCode 安装 Gradle 版本\u0026gt;=6.0，我使用的 Gradle 8.44 安装 JDK 版本\u0026gt;=8，我使用的 JDK 19 安装插件 VSCode 搜索 Scala (Metals) 插件进行安装 VSCode 搜索 Gradle for Java 插件进行安装 官方 demo 初始化\u0026amp;调试 前面先会用官方 demo 工程来做初始化和调试，后面再介绍如何自己创建工程\n克隆官方 demo 工程 git clone git@github.com:gatling/gatling-gradle-plugin-demo-scala.git 使用 VSCode 打开克隆下来的官方 demo 工程\n用 VSCode 打开本项目 Terminal 窗口，执行以下命令\ngradle build 运行工程中的 demo gradle gatlingRun 查看命令行运行结果 点击命令行报告中的 html 报告链接，并使用浏览器打开，即可查看详细的报告信息 VSCode + Maven + Scala 版本 准备工作 开发工具：VSCode 安装 Maven，我使用的 Maven 3.9.5 JDK 版本\u0026gt;=8，我使用的 JDK 19 安装插件 VSCode 搜索 Scala (Metals) 插件进行安装 VSCode 搜索 Maven for Java 插件进行安装 官方 demo 初始化\u0026amp;调试 前面先会用官方 demo 工程来做初始化和调试，后面再介绍如何自己创建工程\n克隆官方 demo 工程 git clone git@github.com:gatling/gatling-maven-plugin-demo-scala.git 使用 VSCode 打开克隆下来的官方 demo 工程\n用 VSCode 打开本项目 Terminal 窗口，执行以下命令运行工程中的 demo\nmvn gatling:test 查看命令行运行结果 点击命令行报告中的 html 报告链接，并使用浏览器打开，即可查看详细的报告信息 IDEA + Gradle + Scala 版本 与 VSCode 下基本类似，这里就不再赘述了\n差异点如下：\nIDEA 搜索 Scala 插件进行安装 新的运行方式：右键选择项目目录下的 Engine.scala 文件，选择 Run \u0026lsquo;Engine\u0026rsquo;也可以运行 demo（运行过程中需要按回车键确认哦） IDEA + Maven + Scala 版本 与 VSCode 下基本类似，这里就不再赘述了\n差异点如下：\nIDEA 搜索 Scala 插件进行安装 新的运行方式：右键选择项目目录下的 Engine.scala 文件，选择 Run \u0026lsquo;Engine\u0026rsquo;也可以运行 demo（运行过程中需要按回车键确认哦） ","permalink":"https://naodeng.com.cn/posts/performance-testing/gatling-tool-intro1/","summary":"文章介绍性能测试工具 gatling 的新手入门介绍，环境搭建，如何将官方 demo 跑起来","title":"gatling 性能测试教程：入门介绍"},{"content":"为什么选择 bruno 官方说明：https://github.com/usebruno/bruno/discussions/269\n与 postman 的对比：https://www.usebruno.com/compare/bruno-vs-postman\n开源，MIT License\n客户端全平台支持 (Mac/linux/Windows)\n离线客户端，无云同步功能计划\n支持 Postman/insomina 脚本导入（只能导入 API 请求脚本，无法导入测试脚本）\n社区相对活跃，产品开发路线图清晰\n安装 bruno Download link: https://www.usebruno.com/downloads\nMac 电脑推荐 brew 命令下载\n​ brew install Bruno\n客户端使用入门 默认主界面 API 请求集 创建 API 请求集 首页点击‘Create Collection’链接，打开创建 API 请求集的弹窗\n弹窗上依次输入\nName: 输入 API 请求集的名字\nLocation：输入想要保存 API 请求集文件的文件夹路径 (建议选择此项目所在路径)\nFolder Name：可输入 API 请求集名字（会在刚才选择的路径下创建一个对应名字的文件夹）\n点击 Create 按钮即可完成 API 请求集的创建，并展示在界面上 (左侧 请求集列表会展示新建的 API 请求集的信息)\n打开 API 请求集 首页点击‘Open Collection’链接，打开选择已有的 bruno 格式的 API 请求集文件夹 点击 open 即可完成选择，并展示在界面上 (左侧 collection 列表会展示选择的 API 请求集信息) 导入 API collection 首页点击‘Import Collection’链接，打开导入 API collection 的弹窗 (支持 Bruno/Postman/Insomnia 的导入) 弹窗上选择对应格式的的链接，再选在已存在的对应格式的文件路径 点击 open 即可完成选择，并展示在界面上 (左侧 collection 列表会展示选择的 API collection 信息) 本地运行 API collection 在主界面左侧 collection 列表选择想要运行的 API 请求集 在菜单上选择 Run，右侧界面会打开 Runner tab，会展示所选择 API 请求集里面 requests 的一些信息 点击 Run Collection 按钮即可本地运行 (运行完界面上会展示允许结果) 导出 API 请求集 在主界面左侧 collection 列表选择想要运行的 API 请求集，右键打开菜单 在菜单上选择 Export，再选择想要导出文件的路径即可完成导出 (导出文件也是为 json 格式) API 请求 新建 API 请求 前置条件：已经创建了 API 请求集 (参考上面的创建 API 请求集) 在主界面左侧 collection 列表选择想要新建 API 请求的 API 请求集 在菜单上选择 New Request，右侧界面会打开 Request tab，会展示所选择 API 请求集里面 requests 的一些信息 在 new Request 窗口上先选择请求类型：HTTP/GraphQL 依次输入 Name: 输入 API 请求的名字 URL：输入 API 请求的 URL Method：选择 API 请求的 Method 点击 Create 按钮即可完成 API 请求的创建，并展示在界面上 (左侧 请求集列表会展示新建的 API 请求的信息) 编辑 API 请求 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)\n在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求\n然后可以根据 API 请求类型再来编辑请求的不同字段 Body：输入 API 请求的 Body\nHeaders：输入 API 请求的 Headers\nParams：输入 API 请求的 Params\nAuth：输入 API 请求的 Auth\nVars：输入 API 请求的 Vars\nScript：输入 API 请求的 Script\nAssert：输入 API 请求的 Assert\nTests：输入 API 请求的 Tests\n点击 Save 按钮即可完成 API 请求的编辑，并展示在界面上 (左侧 请求集列表会展示编辑的 API 请求的信息)\n运行 API 请求 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) API 请求生成代码 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 菜单右键选择 Generate Code，再选择想要生成代码的语言 Generate Code 窗口即可展示不同语言的请求代码 编写 API 请求测试脚本 API 请求 Assert Assert 介绍 打开任意的 API 请求，切换到 Assert tab\nAssert tab 会展示 API 请求的 Assert 信息\nAssert 用来判断 API 请求的返回结果是否符合预期\nExpr：输入预期结果的表达式，可以是 API 请求的返回结果的某个字段的值，可输入两种类型：Status Code 和 Response Body Status Code：判断 API 请求的返回状态码是否符合预期 (默认为 200) Response Body：判断 API 请求的返回结果是否符合预期 (默认为 true)\nOperator：输入预期结果的验证方式。支持多种判断方式：Equal 和 Not Equal 等 Equal：判断 API 请求的返回结果是否等于预期结果 Not Equal：判断 API 请求的返回结果是否不等于预期结果\nValue：输入预期结果的值，支持两种预期结果的输入方式：Static 和 Dynamic Static：输入预期结果的静态值 Dynamic：输入预期结果的动态值，可以是 API 请求的返回结果的某个字段的值\nAssert 示例 Assert status code 为 200 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 status 是否为 200， 打开该 API 请求，切换到 Assert tab 依次输入如下信息 Expr: res.status Operator：Equal Value：200 Assert repsponse body 符合预期 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 repsponse body 是否符合预期 打开该 API 请求，切换到 Assert tab Assert1 依次输入如下信息 Expr: res.body.id Operator：Equal Value：1 Assert2 依次输入如下信息 Expr: res.body.title Operator：contains Value：provident 调试 Assert 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也按照 demo 编写了对应的 Assert 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) 切换到 Tests tab，会展示 API 请求的 Tests 信息，里面也会包括请求的 Assert 信息 API 请求 Tests Tests 介绍 打开任意的 API 请求，切换到 Tests tab Tests tab 会展示 API 请求的 Tests 信息 Tests 用来编写 API 请求的测试脚本，目前较好支持 javascript 语言 Tests 里面可以编写多个测试脚本，每个测试脚本都可以单独运行 Tests 示例 验证 status code 为 200 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 status 是否为 200， 打开该 API 请求，切换到 Tests tab 输入如下脚本 test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); Assert repsponse body 符合预期 以 https://jsonplaceholder.typicode.com/posts/1 为例 (该 API 请求返回的结果为：https://jsonplaceholder.typicode.com/posts/1) 我想验证该 API 请求的返回结果的 repsponse body 是否符合预期 打开该 API 请求，切换到 Tests tab 输入如下脚本 test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.id).to.equal(1); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); 调试 Tests 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也按照 demo 编写了对应的 Tests 在主界面左侧 collection 列表选择想要编辑 API 请求的 API 请求集，再选中想要编辑的 API 请求 点击 API url 编辑框后的向右按钮即可完成 API 请求的运行，并展示在界面上 (右侧 Request tab 会展示运行的 API 请求的信息) 切换到 Tests tab，会展示 API 请求的 Tests 信息，里面也会包括请求的 Tests 信息 环境变量 创建环境变量 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求) 选择想要创建环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗（支持创建新的环境变量和导入已有的环境变量） 弹窗上点击 Create Environment 按钮，输入环境变量的名字，点击 create 按钮即可创建环境变量 然后在弹窗上点击 Add Variable 按钮，输入环境变量的 key 和 value，点击 Save 按钮即可添加环境变量 环境变量 demo 需求：创建一个 demo 环境变量，里面包含一个 key 为 host，value 为 https://jsonplaceholder.typicode.com 的环境变量\n选择想要创建环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗 弹窗上点击 Create Environment 按钮，输入环境变量的名字 demo，点击 create 按钮即可创建环境变量 demo 选择 demo 环境变量，然后在页面上点击 Add Variable 按钮，输入环境变量的 key 为 host，value 为 https://jsonplaceholder.typicode.com ，点击 Save 按钮即可添加环境变量 如下图所示 使用环境变量 前置条件：已经创建了 API 请求集和 API 请求 (参考上面的创建 API 请求集和新建 API 请求)，也创建了 demo 环境变量 选择想要使用环境变量的 API 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 demo 按钮即可使用 demo 环境变量 然后在 API 请求的 URL 变更为输入 {{host}}/posts/1 即可使用环境变量 测试脚本接口自动化 前置条件 已创建了 API 请求集（示例名为:api-collects） 已创建了 API 请求（示例名为:api request1） 已创建了环境变量（示例名为:demo） 也为 API 请求编写了 assert 或者 tests 脚本 接口自动化项目 demo 安装 node.js 安装 npm 新建项目文件夹（示例名为:bruno-test） 项目文件夹下执行 npm init 将项目初始化为 npm 项目 安装 @usebruno/cli 依赖 (脚本为：npm install @usebruno/cli) 打开保存 API 请求集的文件夹目录，将 api-collects 目录下的所有文件都复制到 bruno-test 项目目录下下 项目目录如下所示 bruno-test //项目主文件夹 api request1.bru //api 请求 enviroments //环境变量 demo.bru bruno.json node_modules //node 包依赖 package-lock.json package.json //npm 项目配置文件 运行接口自动化脚本 bruno run --env demo 运行结果如下 接入 CI 接入 github action 以 github action 为例，其他 CI 工具类似\n前置准备：在项目 package.json 文件中添加如下脚本 \u0026#34;test\u0026#34;: \u0026#34;bru run --env demo\u0026#34; 在项目根目录下创建 .github/workflows 文件夹 在 .github/workflows 文件夹下创建 main.yml 文件 main.yml 文件内容如下 name: bruno cli CI on: push: branches: [ main ] pull_request: branches: [ main ] jobs: run_bruno_api_test: runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - run: npm install - name: run tests run: npm run test 提交代码到 github，会自动触发 github action 查看 github action 运行结果，如图示例： 可拉取本项目代码进行参考：https://github.com/dengnao-tw/Bruno-API-Test-Starter\n测试报告\u0026mdash;TODO bruno 更多用法\u0026mdash;TODO Postman 脚本迁移 API 请求集迁移 在首页点击‘Import Collection’链接，打开导入 API collection 的弹窗 点击选择 Postman Collection 的链接，再选在已存在的 Postman 请求集文件路径 即可导入 Postman 的请求集 但是目前只支持导入 API 请求，无法导入测试脚本，如图所示（但不影响请求调用） 环境变量迁移 在首页选择刚才导入的 Postman 请求 点击页面右上角的‘No Environment’链接（默认为 No Environment），选择菜单中的 configure 按钮即可打开环境变量管理弹窗 点击‘Import Environment’链接，打开导入 Environment 的弹窗 点击选择 Postman Environment 的链接，再选在已存在的 Postman 环境变量文件路径 即可导入 Postman 的环境变量 测试脚本迁移参考 两个工具测试脚本的语法存在一部分差异，需要手动修改\nPostman 测试脚本语法参考：https://learning.postman.com/docs/writing-scripts/test-scripts/ Postman 测试脚本示例 pm.test(\u0026#34;res.status should be 200\u0026#34;, function () { pm.response.to.have.status(200); }); pm.test(\u0026#34;res.body should be correct\u0026#34;, function() { var data = pm.response.json(); pm.expect(data.id).to.equal(1); pm.expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); Bruno 测试脚本语法参考：https://docs.usebruno.com/testing/introduction.html Bruno 测试脚本示例 test(\u0026#34;res.status should be 200\u0026#34;, function() { const data = res.getBody(); expect(res.getStatus()).to.equal(200); }); test(\u0026#34;res.body should be correct\u0026#34;, function() { const data = res.getBody(); expect(data.id).to.equal(1); expect(data.title).to.contains(\u0026#39;provident\u0026#39;); }); ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/introduction_of_bruno/","summary":"文章介绍 postman 替换工具 Bruno 的新手入门介绍，如何迁移 postman 脚本到 Bruno","title":"postman 替换工具 bruno 使用介绍"},{"content":"什么是二八法则 二八法则，也被称为帕累托法则（Pareto principle），是一种经济学原理和管理学理论，描述了一种观察结果：80%的结果往往来自于20%的原因。这个法则最初由意大利经济学家维尔弗雷多·帕累托（Vilfredo Pareto）提出。\n二八法则可以应用于各个领域，包括经济、生产、销售、时间管理等。具体来说，它意味着一个系统或者群体中，少数重要的因素往往对于大部分结果产生了主要的影响，而其余的因素只起到了次要的作用。换句话说，大部分的产出、收益或者结果来自于少数关键的因素或者部分。\n举个例子，二八法则可以应用于销售领域。80%的销售额往往来自于20%的顾客，或者说80%的问题往往来自于20%的产品。这意味着经营者可以通过专注于那些最重要的20%顾客或产品，获得最大的收益。\n二八法则的应用还可以帮助人们更有效地管理时间。根据这个原理，80%的成果往往来自于20%的时间和精力投入。因此，人们可以通过识别那些最重要的任务和活动，并优先处理它们，来提高工作效率和成果。\n需要注意的是，二八法则的具体数字并不一定是严格的80-20比例，这只是一个常见的例子。在实际应用中，比例可能会有所不同，但基本思想保持一致：少数重要的因素或者部分对于整体结果起到了关键作用。\n软件研发过程中的二八法则 在软件研发中，二八法则可以应用于多个方面，包括功能开发、缺陷修复、需求管理和团队效率等。以下是一些常见的应用场景：\n功能开发：根据二八法则，80%的用户使用率通常来自于20%的核心功能。在软件开发过程中，团队可以优先开发和完善这些核心功能，以满足大部分用户的需求。这有助于提高产品的可用性和用户体验。 缺陷修复：类似地，80%的软件缺陷往往由20%的核心功能引起。因此，在缺陷修复过程中，团队应该重点关注那些最常见、最严重或者影响最广泛的缺陷。这有助于快速改善软件的质量和稳定性。 需求管理：根据二八法则，80%的用户需求通常来自于20%的关键需求。在需求管理过程中，团队应该专注于梳理和管理那些最重要、最紧急的需求，确保其优先级得到合理的安排。这有助于提高项目的交付价值和满足用户期望。 团队效率：二八法则也可以应用于团队效率的管理。根据这个原则，80%的工作成果往往来自于20%的高效工作时间。团队可以通过优化工作流程、减少低价值的任务和降低工作负荷，来提高团队的整体效率和生产力。 需要注意的是，二八法则在软件研发中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，以达到最佳的开发效果和资源利用。同时，综合考虑其他因素，如用户反馈、市场需求和团队能力等，以实现整体的项目成功。\n软件研发质量中的二八法则 在软件质量管理中，二八法则可以应用于缺陷管理、测试策略和持续改进等方面。以下是一些常见的应用场景：\n缺陷管理：根据二八法则，80%的缺陷通常来自于20%的功能模块或者代码区域。在软件质量管理过程中，团队应该重点关注那些最容易引发缺陷的核心功能或者代码部分。这有助于提高缺陷发现和修复的效率，确保关键功能的质量和稳定性。 测试策略：根据二八法则，80%的软件缺陷往往由20%的核心功能或者测试用例引起。在测试策略制定过程中，团队可以优先选择那些最关键、最具代表性的功能进行测试。同时，重点关注那些最有可能引发缺陷的测试用例，以提高测试覆盖和效果。 持续改进：二八法则也可以应用于持续改进的过程中。根据这个原则，80%的改进效果通常来自于20%的关键改进措施。团队应该重点关注那些最重要、最有影响力的改进项目，以最大程度地提升软件质量和用户体验。 用户反馈和需求：根据二八法则，80%的用户满意度通常来自于20%的关键功能或者需求。在软件质量管理中，团队应该重点关注那些对用户最重要、最有价值的功能和需求。通过积极收集用户反馈和需求，团队可以针对性地改进和优化这些关键领域，提升软件的质量和用户满意度。 需要注意的是，二八法则在软件质量管理中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，并结合其他质量管理方法和工具，以实现最佳的软件质量和用户体验。\n软件测试中的二八法则 在软件测试中，二八法则可以被应用于缺陷定位和优先级管理。根据这个原则，大约80%的缺陷通常来自于20%的功能模块或测试用例。这意味着测试团队可以通过重点关注那些最有可能引发缺陷的关键功能，以及那些覆盖最广泛、最重要的测试用例，来获得最佳的测试覆盖和缺陷发现效果。\n具体应用二八法则的方法包括：\n重点测试关键功能：根据系统的复杂性和业务重要性，确定关键的功能模块或者业务流程。将更多的测试资源和时间分配给这些关键功能，以确保其质量和稳定性。 优先处理高风险区域：通过分析过往的缺陷数据、用户反馈和业务需求，确定系统中最容易出现问题的区域。将更多的测试活动放在这些高风险区域，以提前发现和修复潜在的问题。 选择关键测试用例：在测试用例设计和执行过程中，根据业务价值、功能复杂度和影响范围等因素，选择那些最具代表性和最重要的测试用例进行执行。确保这些关键测试用例的覆盖率和测试深度，以有效检测潜在的缺陷。 精细化缺陷管理：将测试团队的精力集中在那些最关键、最严重的缺陷上，确保这些缺陷得到及时的处理和修复。同时，对于一些次要的或影响较小的缺陷，可以在资源允许的情况下进行适当的延后处理，以保证测试团队的效率和优先级的合理分配。 需要注意的是，二八法则在软件测试中的应用并非严格的数值比例，具体的比例可能会因项目的特点、复杂性和风险等因素而有所不同。测试团队应根据具体情况灵活运用这个原则，以实现最佳的测试效果和资源利用。\n如何优化软件研发质量中的二八法则 要优化软件质量管理中的二八法则应用，可以考虑以下几点：\n数据驱动决策：收集和分析准确、全面的数据是优化的基础。通过使用测试管理工具、缺陷跟踪系统和用户反馈渠道等，获取有关缺陷、功能使用率、用户需求等方面的数据。这样可以更准确地确定哪些功能模块或代码区域是关键的，从而更有针对性地进行测试和改进。 重点关注核心功能：根据数据分析的结果，重点关注那些最关键、最常用的功能模块或代码区域。在测试过程中，为这些核心功能分配更多的资源和测试覆盖，以确保其质量和稳定性。 细化测试策略：根据数据分析和风险评估，制定细化的测试策略。考虑到功能的重要性、复杂性和用户影响，确定关键测试用例，并确保其充分覆盖核心功能。同时，可以利用自动化测试工具和技术，提高测试效率和覆盖率。 高效缺陷管理：建立有效的缺陷管理流程，确保缺陷能够及时被跟踪、分析和修复。优先处理那些最严重、最影响用户体验的缺陷，并跟踪缺陷修复的进度和效果。同时，进行缺陷分析，找出常见的缺陷模式和根本原因，以便改进开发过程和减少类似缺陷的再次发生。 用户参与和反馈：积极与用户进行互动，了解他们的需求、问题和意见。通过用户调研、用户体验测试和用户反馈渠道，获取用户的反馈和建议。将用户需求和反馈作为优化软件质量管理的重要依据，并将其纳入开发和改进的决策过程中。 持续改进和学习：软件质量管理是一个持续改进的过程。团队应该定期评估和反思当前的质量管理实践，寻找改进的机会。借鉴行业的最佳实践，关注新技术和工具的发展，不断学习和提升团队的能力和水平。 综合运用以上策略，可以优化软件质量管理中的二八法则应用，提高软件的质量和用户满意度。\n","permalink":"https://naodeng.com.cn/posts/others/80-20-rule/","summary":"什么是二八法则 二八法则，也被称为帕累托法则（Pareto principle），是一种经济学原理和管理学理论，描述了一种观察结果：80%的结果往往来自于20%的原因。这个法则最初由意大利经济学家维尔弗雷多·帕累托（Vilfredo Pareto）提出。\n二八法则可以应用于各个领域，包括经济、生产、销售、时间管理等。具体来说，它意味着一个系统或者群体中，少数重要的因素往往对于大部分结果产生了主要的影响，而其余的因素只起到了次要的作用。换句话说，大部分的产出、收益或者结果来自于少数关键的因素或者部分。\n举个例子，二八法则可以应用于销售领域。80%的销售额往往来自于20%的顾客，或者说80%的问题往往来自于20%的产品。这意味着经营者可以通过专注于那些最重要的20%顾客或产品，获得最大的收益。\n二八法则的应用还可以帮助人们更有效地管理时间。根据这个原理，80%的成果往往来自于20%的时间和精力投入。因此，人们可以通过识别那些最重要的任务和活动，并优先处理它们，来提高工作效率和成果。\n需要注意的是，二八法则的具体数字并不一定是严格的80-20比例，这只是一个常见的例子。在实际应用中，比例可能会有所不同，但基本思想保持一致：少数重要的因素或者部分对于整体结果起到了关键作用。\n软件研发过程中的二八法则 在软件研发中，二八法则可以应用于多个方面，包括功能开发、缺陷修复、需求管理和团队效率等。以下是一些常见的应用场景：\n功能开发：根据二八法则，80%的用户使用率通常来自于20%的核心功能。在软件开发过程中，团队可以优先开发和完善这些核心功能，以满足大部分用户的需求。这有助于提高产品的可用性和用户体验。 缺陷修复：类似地，80%的软件缺陷往往由20%的核心功能引起。因此，在缺陷修复过程中，团队应该重点关注那些最常见、最严重或者影响最广泛的缺陷。这有助于快速改善软件的质量和稳定性。 需求管理：根据二八法则，80%的用户需求通常来自于20%的关键需求。在需求管理过程中，团队应该专注于梳理和管理那些最重要、最紧急的需求，确保其优先级得到合理的安排。这有助于提高项目的交付价值和满足用户期望。 团队效率：二八法则也可以应用于团队效率的管理。根据这个原则，80%的工作成果往往来自于20%的高效工作时间。团队可以通过优化工作流程、减少低价值的任务和降低工作负荷，来提高团队的整体效率和生产力。 需要注意的是，二八法则在软件研发中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，以达到最佳的开发效果和资源利用。同时，综合考虑其他因素，如用户反馈、市场需求和团队能力等，以实现整体的项目成功。\n软件研发质量中的二八法则 在软件质量管理中，二八法则可以应用于缺陷管理、测试策略和持续改进等方面。以下是一些常见的应用场景：\n缺陷管理：根据二八法则，80%的缺陷通常来自于20%的功能模块或者代码区域。在软件质量管理过程中，团队应该重点关注那些最容易引发缺陷的核心功能或者代码部分。这有助于提高缺陷发现和修复的效率，确保关键功能的质量和稳定性。 测试策略：根据二八法则，80%的软件缺陷往往由20%的核心功能或者测试用例引起。在测试策略制定过程中，团队可以优先选择那些最关键、最具代表性的功能进行测试。同时，重点关注那些最有可能引发缺陷的测试用例，以提高测试覆盖和效果。 持续改进：二八法则也可以应用于持续改进的过程中。根据这个原则，80%的改进效果通常来自于20%的关键改进措施。团队应该重点关注那些最重要、最有影响力的改进项目，以最大程度地提升软件质量和用户体验。 用户反馈和需求：根据二八法则，80%的用户满意度通常来自于20%的关键功能或者需求。在软件质量管理中，团队应该重点关注那些对用户最重要、最有价值的功能和需求。通过积极收集用户反馈和需求，团队可以针对性地改进和优化这些关键领域，提升软件的质量和用户满意度。 需要注意的是，二八法则在软件质量管理中的具体应用可能会因项目的特点、复杂性和业务需求而有所不同。团队应该根据具体情况灵活运用这个原则，并结合其他质量管理方法和工具，以实现最佳的软件质量和用户体验。\n软件测试中的二八法则 在软件测试中，二八法则可以被应用于缺陷定位和优先级管理。根据这个原则，大约80%的缺陷通常来自于20%的功能模块或测试用例。这意味着测试团队可以通过重点关注那些最有可能引发缺陷的关键功能，以及那些覆盖最广泛、最重要的测试用例，来获得最佳的测试覆盖和缺陷发现效果。\n具体应用二八法则的方法包括：\n重点测试关键功能：根据系统的复杂性和业务重要性，确定关键的功能模块或者业务流程。将更多的测试资源和时间分配给这些关键功能，以确保其质量和稳定性。 优先处理高风险区域：通过分析过往的缺陷数据、用户反馈和业务需求，确定系统中最容易出现问题的区域。将更多的测试活动放在这些高风险区域，以提前发现和修复潜在的问题。 选择关键测试用例：在测试用例设计和执行过程中，根据业务价值、功能复杂度和影响范围等因素，选择那些最具代表性和最重要的测试用例进行执行。确保这些关键测试用例的覆盖率和测试深度，以有效检测潜在的缺陷。 精细化缺陷管理：将测试团队的精力集中在那些最关键、最严重的缺陷上，确保这些缺陷得到及时的处理和修复。同时，对于一些次要的或影响较小的缺陷，可以在资源允许的情况下进行适当的延后处理，以保证测试团队的效率和优先级的合理分配。 需要注意的是，二八法则在软件测试中的应用并非严格的数值比例，具体的比例可能会因项目的特点、复杂性和风险等因素而有所不同。测试团队应根据具体情况灵活运用这个原则，以实现最佳的测试效果和资源利用。\n如何优化软件研发质量中的二八法则 要优化软件质量管理中的二八法则应用，可以考虑以下几点：\n数据驱动决策：收集和分析准确、全面的数据是优化的基础。通过使用测试管理工具、缺陷跟踪系统和用户反馈渠道等，获取有关缺陷、功能使用率、用户需求等方面的数据。这样可以更准确地确定哪些功能模块或代码区域是关键的，从而更有针对性地进行测试和改进。 重点关注核心功能：根据数据分析的结果，重点关注那些最关键、最常用的功能模块或代码区域。在测试过程中，为这些核心功能分配更多的资源和测试覆盖，以确保其质量和稳定性。 细化测试策略：根据数据分析和风险评估，制定细化的测试策略。考虑到功能的重要性、复杂性和用户影响，确定关键测试用例，并确保其充分覆盖核心功能。同时，可以利用自动化测试工具和技术，提高测试效率和覆盖率。 高效缺陷管理：建立有效的缺陷管理流程，确保缺陷能够及时被跟踪、分析和修复。优先处理那些最严重、最影响用户体验的缺陷，并跟踪缺陷修复的进度和效果。同时，进行缺陷分析，找出常见的缺陷模式和根本原因，以便改进开发过程和减少类似缺陷的再次发生。 用户参与和反馈：积极与用户进行互动，了解他们的需求、问题和意见。通过用户调研、用户体验测试和用户反馈渠道，获取用户的反馈和建议。将用户需求和反馈作为优化软件质量管理的重要依据，并将其纳入开发和改进的决策过程中。 持续改进和学习：软件质量管理是一个持续改进的过程。团队应该定期评估和反思当前的质量管理实践，寻找改进的机会。借鉴行业的最佳实践，关注新技术和工具的发展，不断学习和提升团队的能力和水平。 综合运用以上策略，可以优化软件质量管理中的二八法则应用，提高软件的质量和用户满意度。","title":"软件研发质量中的二八法则"},{"content":"什么是 API? API:应用程序接口（全称：application programming interface），缩写为 API，是一种计算接口，它定义多个软件中介之间的交互，以及可以进行的调用（call）或请求（request）的种类，如何进行调用或发出请求，应使用的数据格式，应遵循的惯例等。它还可以提供扩展机制，以便用户可以通过各种方式对现有功能进行不同程度的扩展。一个 API 可以是完全定制的，针对某个组件的，也可以是基于行业标准设计的以确保互操作性。通过信息隐藏，API 实现了模块化编程，从而允许用户实现独立地使用接口。\n什么是 API 测试？ 接口测试是软件测试的一种，它包括两种测试类型：狭义上指的是直接针对应用程序接口（下面使用缩写 API 指代，其中文简称为接口）的功能进行的测试；广义上指集成测试中，通过调用 API 测试整体的功能完成度、可靠性、安全性与性能等指标。\nAPI Best Practice:\nAPI 定义遵循 RESTFUL API 风格，语意化的 URI 定义，准确的 HTTP 状态码，通过 API 的定义就可以知道资源间的关系 配有详细且准确的 API 文档（如 Swagger 文档） 对外的 API 可以包含版本号以快速迭代（如 https://thoughtworks.com/v1/users/） API 测试与测试四象限 测试四象限中不同象限的测试，其测试目的跟测试策略也不同，API 测试主要位于第二、第四象限\nAPI 测试与测试金字塔 API 测试在测试金子塔中处于一个相对靠上的位置，主要站在系统、服务边界来测试功能和业务逻辑，执行时机是在服务完成构建、部署到测试环境之后再执行、验证。\nAPI 测试类型 功能测试\n正确性测试 异常处理 内部逻辑 …… 非功能测试\n性能 安全 …… API 测试步骤 发送请求 得到响应 验证响应结果 API 功能测试设计 设计理论\n正面 负面 异常处理 内部逻辑 …… 测试方法\n等价类划分 边界值 错误推断 …… API 非功能测试设计 安全测试\n随机测试 SQL 注入 XSS …… 性能测试\n性能瓶颈 稳定性测试 …… API 测试工具 API 请求工具\nCURL Soap UI Postman Swagger UI …… Http proxy 工具\nFiddler Charles …… API 性能测试工具\nab(apache bench) Jmeter …… ","permalink":"https://naodeng.com.cn/posts/api-automation-testing/introduction_of_api_test/","summary":"文章介绍接口测试的简介，类型和工具","title":"接口测试简介"},{"content":"Google Bard Google Bard 进入公开测试版。测试申请中~~~\n申请链接：https://bard.google.com/\n谷歌发布 Bard，这是其在创建人工智能竞赛中的竞争对手推出 ChatGPT 之后的放的大招。\n经过多年的谨慎开发，这家互联网巨头将授予用户访问聊天机器人的权限，以追逐竞争对手 OpenAI 和微软的引人注目的首次亮相之后的惊艳表现。\n百度文心一言 百度于 3 月 16 日正式公布大语言模型“文心一言”，这是一款基于人工智能技术的智能对话系统，可进行语义理解、智能问答和情感交流等多种形式的对话。\n3 月 16 日起，首批用户即可通过邀请测试码在文心一言官网体验产品，后续将陆续开放给更多用户。 此外，百度智能云即将面向企业客户开放文心一言 API 接口调用服务。\n3 月 16 日起正式开放预约，搜索“百度智能云”进入官网，可申请加入文心一言云服务测试。\n申请链接：https://yiyan.baidu.com/welcome\n合作申请链接：https://cloud.baidu.com/survey_summit/wenxin.html?track=C856571\n","permalink":"https://naodeng.com.cn/posts/others/different-types-of-ai-join-waiting-list/","summary":"Google Bard Google Bard 进入公开测试版。测试申请中~~~\n申请链接：https://bard.google.com/\n谷歌发布 Bard，这是其在创建人工智能竞赛中的竞争对手推出 ChatGPT 之后的放的大招。\n经过多年的谨慎开发，这家互联网巨头将授予用户访问聊天机器人的权限，以追逐竞争对手 OpenAI 和微软的引人注目的首次亮相之后的惊艳表现。\n百度文心一言 百度于 3 月 16 日正式公布大语言模型“文心一言”，这是一款基于人工智能技术的智能对话系统，可进行语义理解、智能问答和情感交流等多种形式的对话。\n3 月 16 日起，首批用户即可通过邀请测试码在文心一言官网体验产品，后续将陆续开放给更多用户。 此外，百度智能云即将面向企业客户开放文心一言 API 接口调用服务。\n3 月 16 日起正式开放预约，搜索“百度智能云”进入官网，可申请加入文心一言云服务测试。\n申请链接：https://yiyan.baidu.com/welcome\n合作申请链接：https://cloud.baidu.com/survey_summit/wenxin.html?track=C856571","title":"不同类型 AI 申请加入等待列表入口"},{"content":" 打开 edge 浏览器 在地址栏输入命令 edge://flags/ 在 flags 的页面输入 11 进行搜索 在搜索结果下选择“Show Windows 11 visual effects in title bar and toolbar”将状态变更为启用 重启浏览器，即可看到新的 edge 浏览器 UI ","permalink":"https://naodeng.com.cn/posts/others/edge-enablenew-ui/","summary":" 打开 edge 浏览器 在地址栏输入命令 edge://flags/ 在 flags 的页面输入 11 进行搜索 在搜索结果下选择“Show Windows 11 visual effects in title bar and toolbar”将状态变更为启用 重启浏览器，即可看到新的 edge 浏览器 UI ","title":"新技术分享：Mac OS 下 edge 浏览器开启新 UI"},{"content":"如果你的项目是采用敏捷测试，那么欢迎加入很棒的 30 天敏捷测试挑战。\n以下是 30 个挑战的列表，每月每天一个，打印下面的列表，把它保存在某个地方。打印出来。把它贴在墙上。让我们这样做吧！\n规则是什么？ 目标是尽可能多地的完成挑战。您可以在自己的时间范围和能力范围内做到这一点。\n您可能有图像可以分享，博客文章，视频，状态更新，无论它是什么！来参加吧！\n以下是分享进度的方法：\n在微博和朋友圈上 - 使用**#30DaysOfTesting**标签 30 天敏捷测试列表 Day 1 Buy an agile testing related book and share something you\u0026rsquo;ve learnt by day 30 买一本敏捷测试相关的书，并在第 30 天结束时分享你的所学 Day 2 Create a mindmap, document, diagram or sketchnote about what you think agile testing is\n用图表或文档的方式列出你理解的敏捷测试 Day 3 Find a video on YouTuBe about agile testing, then watch it!\n看一个敏捷测试的视频 Day 4 Read the agile manifesto and reflect on the implications for your role\n读敏捷宣言，并反思对你角色的影响 Day 5 Pair with a developer on a feature\n跟 Dev pair Day 6 Map out what your exploratory testing looks like, compare it to what other testers do\n列出你理解的探索式测试，并与其他人员的进行比较 Day 7 Find a visual way of representing your tests - e.g. A mind map, diagram, model, etc\n找一个可视化的方式展示你的测试 Day 8 Speak to a developer about a bug you found instead of loging it in the tracking system\n跟 dev 直接说你发现的 bug，而不是在 bug 管理系统里记录 Day 9 Pair whth a developer on a code review. Can you identify any risks?\n参加 dev 的 code review。你能定位任何的风险吗？ Day 10 Learn where the application logs are and how to read them.\n了解应用程序的 log 记录在哪里，并学习看 log。 Day 11 Find out what customers are saying about your product. What did you learn?\n了解客户对你的产品的评价。从中学到了什么？ Day 12 What test documentation does your team have? How can you improve it?\n你的团队有什么样的测试文档？你觉得可以怎么改进一下？ Day 13 Learn to use a tool that your developers use - e.g. an IDE\n学习使用 Dev 在用的工具 Day 14 How can you deliver greater value to your customer?\n如何能够交付更多的价值给客户？ Day 15 How can you make your testing processes (more) lean?\n如何能让你的测试流程更加精益？ Day 16 What barriers do you feel exist in testing in agile?\n你感觉敏捷测试中存在什么障碍？ Day 17 Map out your current team structure. How does it compare to other teams?\n绘制出您当前的团队结构。它与其他团队相比如何？ Day 18 How can you make testing jobs easier?\n如何让测试工作变得更轻松？ Day 19 How can you make jobs for your team easier?\n如何让你的团队工作更轻松？ Day 20 Investigate what is in your and your team\u0026rsquo;s tool kit\n调查你和你团队使用的工具有哪些 Day 21 How are you managing your testing, is it really agile?\n你如何管理你的测试，真的敏捷吗？ Day 22 Find out what testing is being done by other team members.\n了解其他团队成员正在进行的测试 Day 23 What agile strategies are there for managing tests?\n有哪些管理测试的敏捷策略？ Day 24 Look for a task that can be automated.\n找一个可以自动化的 task. Day 25 What can\u0026rsquo;t you automate? Communicate that to your team\n什么是你不能自动化的？跟团队沟通一下 Day 26 What does your Test Plan look like, what format do you use?\n你的测试计划什么样的，使用的什么格式？ Day 27 Look into zero bug tolerance, is this something your team could do?\n了解 bug 零容忍，这是你的团队可以做的吗？ Day 28 What learning culture exist in your company? How can you contribute to it?\n公司的学习文化是什么样的？你如何为此贡献？ Day 29 What columns do you have on your work tracker or kanban board?\n你们的看板上有哪些 column？ Day 30 What action does your team take on a red build?\nbuild 红了团队会采取什么 action？ Day 31 BONUS: Debrief your whole team on your last session of testing\n跟整个团队汇报你的测试 ","permalink":"https://naodeng.com.cn/posts/others/30-days-of-agile-testing/","summary":"如果你的项目是采用敏捷测试，那么欢迎加入很棒的 30 天敏捷测试挑战。\n以下是 30 个挑战的列表，每月每天一个，打印下面的列表，把它保存在某个地方。打印出来。把它贴在墙上。让我们这样做吧！\n规则是什么？ 目标是尽可能多地的完成挑战。您可以在自己的时间范围和能力范围内做到这一点。\n您可能有图像可以分享，博客文章，视频，状态更新，无论它是什么！来参加吧！\n以下是分享进度的方法：\n在微博和朋友圈上 - 使用**#30DaysOfTesting**标签 30 天敏捷测试列表 Day 1 Buy an agile testing related book and share something you\u0026rsquo;ve learnt by day 30 买一本敏捷测试相关的书，并在第 30 天结束时分享你的所学 Day 2 Create a mindmap, document, diagram or sketchnote about what you think agile testing is\n用图表或文档的方式列出你理解的敏捷测试 Day 3 Find a video on YouTuBe about agile testing, then watch it!\n看一个敏捷测试的视频 Day 4 Read the agile manifesto and reflect on the implications for your role","title":"敏捷测试的 30 天挑战"},{"content":"下面的信息是对 playwright 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\n安装 Install 非 VS Code 编辑器安装 新建项目文件 使用命令行工具进入新建的项目文件夹 输入命令进行项目初始化 npm init playwright@latest 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo VS Code 编辑器安装 新建项目文件 使用 VS Code 编辑器打开新建的项目文件夹 在 VS Code 编辑器安装 Playwright Test for VSCode 插件 然后在 VS Code 编辑器的命令面板上输入 Install Playwright 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo 运行测试 Run test VS Code 运行 通过 Playwright Test for VSCode 插件运行 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击绿色三角形就可以运行 demo 测试用例了 可以点击是否选中'show browser'来控制是否无头浏览器运行用例和打开浏览器运行用例 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 点击测试块旁边的绿色三角形 就可以运行测试来运行单个测试 命令行运行 运行所有测试\nnpx playwright test 运行单个测试文件\nnpx playwright test landing-page.spec.ts 运行一组测试文件\nnpx playwright test tests/todo-page/ tests/landing-page/ 运行文件名中有landing或login的文件\nnpx playwright test landing login 运行带有标题的测试\nnpx playwright test -g \u0026#34;add a todo item\u0026#34; 在引导模式 (打开浏览器) 下运行测试\nnpx playwright test landing-page.spec.ts --headed 在特定项目上运行测试\nnpx playwright test landing-page.ts --project=chromium 调试 Debug 由于 Playwright 在 Node.js 中运行，您可以使用您选择的调试器对其进行调试，例如使用console.log或在您的 IDE 内部或直接在 VS 代码中使用[VS 代码扩展](https://playwright.dev/docs/getting-started-vscode)。Playwright 带有[Playwright Inspector](https://playwright.dev/docs/debug#playwright-inspector)，它允许您单步执行 Playwright API 调用，查看他们的调试日志并探索[选择器](https://playwright.dev/docs/selectors)。\n命令行调试 调试所有测试： npx playwright test --debug 调试一个测试文件： npx playwright test example.spec.ts --debug 从test(..定义的行号调试测试： npx playwright test example.spec.ts:42 --debug VS code 调试 通过 Playwright Test for VSCode 插件调试 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击第二个运行按钮就可以调试 demo 测试用例了 可以之前在想要调试的测试脚本文件中提前打一些断点 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 选中测试代码块，然后右键选择 debug test 就可以调试测试用例了 测试报告 Test report 命令行输入如下命令，就可以打开 html 版本的测试报告 npx playwright show-report ","permalink":"https://naodeng.com.cn/posts/others/playwright-get-started/","summary":"下面的信息是对 playwright 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\n安装 Install 非 VS Code 编辑器安装 新建项目文件 使用命令行工具进入新建的项目文件夹 输入命令进行项目初始化 npm init playwright@latest 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo VS Code 编辑器安装 新建项目文件 使用 VS Code 编辑器打开新建的项目文件夹 在 VS Code 编辑器安装 Playwright Test for VSCode 插件 然后在 VS Code 编辑器的命令面板上输入 Install Playwright 按照提示进行项目初始化 安装完成后的目录结构为 playwright.config.ts //playwright.config.ts的配置文件 package.json //node项目的配置文件 package-lock.json //node项目的配置文件 tests/ example.spec.ts //测试demo tests-examples/ demo-todo-app.spec.ts //todo app的测试demo 运行测试 Run test VS Code 运行 通过 Playwright Test for VSCode 插件运行 通过 VS Code 打开项目文件后 点击 VS Code 左侧的 Testing(漏斗) 按钮 Testing 页面下会展示所有的 demo 测试用例 点击绿色三角形就可以运行 demo 测试用例了 可以点击是否选中'show browser'来控制是否无头浏览器运行用例和打开浏览器运行用例 测试文件运行 通过 VS Code 打开项目文件后 点击打开 demo 测试文件 点击测试块旁边的绿色三角形 就可以运行测试来运行单个测试 命令行运行 运行所有测试","title":"Playwright 自动化框架入门"},{"content":"Cypress Studio 提供了一种在测试运行程序中生成测试的可视化方法，通过记录与被测应用程序的交互。支持.click（）、.type（）、.check（）、.uncheck（）和.select（）Cypress 命令，这些命令将在与 Cypress Studio 内部的 DOM 交互时生成测试代码\n通过阅读文章你会学到什么：\n如何使用 Cypress Studio 以交互方式扩展测试\n如何使用 Cypress Studio 以交互方式添加新测试\n概述 Cypress Studio 通过记录与 被测应用程序的交互，提供了一种在 Test Runner 中生成测试的可视化方式。\n支持、.click()、.type()、和 Cypress 命令 .check() ，并在与 Cypress Studio 内部的 DOM 交互时生成测试代码。您还可以通过右键单击要断言的元素来生成断言。 .uncheck() .select()\n使用 Cypress Studio Cypress Studio 是一项实验性功能，可以通过将 experimentalStudio 属性添加到您的配置文件来启用（ cypress.json 默认情况下）。\n{ \u0026#34;experimentalStudio\u0026#34;: true} Cypress Real World App (RWA) 是一个开源项目，它实现了一个支付应用程序，以展示 Cypress 测试方法、模式和工作流程的实际使用情况。下面将使用它来演示 Cypress Studio 的功能。\n扩展测试 您可以扩展任何预先存在的测试，或者通过使用以下测试脚手架在您的 integrationFolder（默认情况下）中创建一个新测试来开始。\n第 1 步 - 运行用例 我们将使用 Cypress Studio 执行“新交易”用户流程。首先，启动 Test Runner 并运行在上一步中创建的用例。\n[image:F5CF37A4-27C0-4A6A-82DA-52C19191EB41-665-000000B8AF4F75E1/640.jpeg]\n第 2 步 - 启动 Cypress Studio 测试完成运行后，将鼠标悬停在命令日志中的测试上以显示“Add commands to Test”按钮。\n单击“Add Commands to Test”将启动 Cypress Studio。\nCypress Studio 直接与 命令日志集成。\n[image:7C04963F-638B-492C-B6D1-0C2C6FD31021-665-000000B8AF4F2B69/_640.jpeg]\nCypress 将自动执行所有挂钩和当前存在的测试代码，然后可以从该点开始扩展测试（例如，我们登录到 beforeEach 块内的应用程序）。\n接下来，Test Runner 将单独执行测试，并在测试中的最后一条命令后暂停。\n[image:E57D4269-75B6-49C2-9EC7-CB2BA527070D-665-000000B8AF4ECFAF/__640.jpeg]\n现在，我们可以开始更新测试以在用户之间创建新事务。\n第 3 步 - 与应用程序交互 要记录操作，请开始与应用程序交互。在这里，我们将单击标题右侧的“新建”按钮，结果我们将看到我们的单击记录在命令日志中。\n[image:B55CC01A-E8EF-4B70-9687-CC8A6423AD9A-665-000000B8AF4E893E/___640.jpeg]\n接下来，我们可以开始输入我们想要支付的用户名。\n[image:F647E6CB-2456-4602-84CB-B37B2B313DCF-665-000000B8AF4E4B07/____640.jpeg]\n一旦我们看到名字出现在结果中，我们想要添加一个断言来确保我们的搜索功能正常工作。右键单击用户名将弹出一个菜单，我们可以从中添加断言以检查元素是否包含正确的文本（用户名）。\n[image:F347B11C-142A-4EFC-821F-9B3F36B68119-665-000000B8AF4E15D4/_____640.jpeg] 然后，我们可以单击该用户以进入下一个屏幕。我们将通过单击并输入金额和描述输入来完成交易表格。\n[image:1A5CFBED-CD31-4912-90A1-960E05992DC7-665-000000B8AF4DE240/______640.jpeg]\n注意命令日志中生成的命令。\n现在是时候完成交易了。您可能已经注意到，在我们输入输入之前，“支付”按钮已被禁用。为了确保我们的表单验证正常工作，让我们添加一个断言以确保启用“支付”按钮。\n[image:F3E5EBF7-FB37-4A50-AF65-607939F664F0-665-000000B8AF4DAF00/_______640.jpeg]\n最后，我们将单击“支付”按钮，并显示我们新交易的确认页面。\n[image:AFF8F1D8-4FDC-42DF-BEEA-EDB769B0588A-665-000000B8AF4D783F/________640.jpeg]\n要放弃交互，请单击“取消”按钮退出 Cypress Studio。如果对与应用程序的交互感到满意，请单击“保存命令”，测试代码将保存到您的规范文件中。或者，您可以选择“复制”按钮以将生成的命令复制到剪贴板。\n生成的测试代码 查看我们的测试代码，我们可以看到在点击“Save Commands”后测试更新了我们在 Cypress Studio 中记录的操作。\n添加新测试 您可以通过单击我们定义的块上的“Add New Test”来向任何现有 describe 或块添加新测试。 context describe\n[image:0A8CA77E-9AEF-45B9-9B70-F15C01983DFF-665-000000B8AF4D4166/_________640.jpeg]\n我们被启动到 Cypress Studio 并可以开始与我们的应用程序交互以生成测试。\n对于此测试，我们将添加一个新的银行帐户。我们的互动如下：\n点击左侧导航中的“银行账户” [image:02219635-D587-4A52-BD45-738DA52F08E2-665-000000B8AF4D0E28/__________640.jpeg]\n点击银行账户页面上的“创建”按钮 [image:42C66725-A8B3-4ED6-9472-C0A0FF5AB64A-665-000000B8AF4CD946/___________640.jpeg]\n填写银行账户信息 [image:2E4443DE-C9A6-4D7A-84BB-6E6A5AA3F476-665-000000B8AF4CA262/____________640.jpeg]\n点击“保存”按钮 [image:655AAC92-065E-438E-B62C-145A771AD889-665-000000B8AF4C6D6F/_____________640.jpeg]\n要放弃交互，请单击“取消”按钮退出 Cypress Studio。\n如果对与应用程序的交互感到满意，请单击“保存命令”，提示将询问测试名称。单击“保存测试”，测试将保存到文件中。\n[image:A9CFD28A-A32C-42B5-97D7-7BD34A46D85F-665-000000B8AF4C390B/______________640.jpeg]\n保存后，该文件将在 Cypress 中再次运行。\n[image:560BE965-9C4C-4E9A-A17F-4992200B053B-665-000000B8AF4BF3D8/_______________640.jpeg]\n最后，查看我们的测试代码，我们可以看到点击“Save Commands”后测试更新了我们在 Cypress Studio 中记录的操作。\n","permalink":"https://naodeng.com.cn/posts/others/cypress-demo6/","summary":"Cypress Studio 提供了一种在测试运行程序中生成测试的可视化方法，通过记录与被测应用程序的交互。支持.click（）、.type（）、.check（）、.uncheck（）和.select（）Cypress 命令，这些命令将在与 Cypress Studio 内部的 DOM 交互时生成测试代码\n通过阅读文章你会学到什么：\n如何使用 Cypress Studio 以交互方式扩展测试\n如何使用 Cypress Studio 以交互方式添加新测试\n概述 Cypress Studio 通过记录与 被测应用程序的交互，提供了一种在 Test Runner 中生成测试的可视化方式。\n支持、.click()、.type()、和 Cypress 命令 .check() ，并在与 Cypress Studio 内部的 DOM 交互时生成测试代码。您还可以通过右键单击要断言的元素来生成断言。 .uncheck() .select()\n使用 Cypress Studio Cypress Studio 是一项实验性功能，可以通过将 experimentalStudio 属性添加到您的配置文件来启用（ cypress.json 默认情况下）。\n{ \u0026#34;experimentalStudio\u0026#34;: true} Cypress Real World App (RWA) 是一个开源项目，它实现了一个支付应用程序，以展示 Cypress 测试方法、模式和工作流程的实际使用情况。下面将使用它来演示 Cypress Studio 的功能。\n扩展测试 您可以扩展任何预先存在的测试，或者通过使用以下测试脚手架在您的 integrationFolder（默认情况下）中创建一个新测试来开始。\n第 1 步 - 运行用例 我们将使用 Cypress Studio 执行“新交易”用户流程。首先，启动 Test Runner 并运行在上一步中创建的用例。","title":"Cypress UI 自动化测试框架学习（6）- 用例编辑和脚本录制工具 Cypress Studio 介绍"},{"content":"Cypress UI 自动化测试框架学习（5）- 命令大全 命令大全 and：创建断言 as：创建别名 blur：失去焦点 check：选中 check 或者 radio children：获取一组 DOM 元素中每个元素的子元素 clear：清除 input 或者 textarea 的值 clearCookie：清除特定的浏览器 cookie clearCookies：清除浏览器的所有 cookie clearLocalStorage：清除 localstorage 的数据 click：点击 DOM 元素 clock：覆盖全局与时间相关的函数 closest：获取与选择器匹配的第一个 DOM 元素 contains：获取包含文本的 DOM 元素 dblclick：双击 DOM 元素 debug：设置调试器并记录上一个命令产生的内容 document：获取 window.document 对象 each：迭代数组结构 end：结束一系列命令 eq：在元素数组中获取特定索引的 DOM 元素 exec：执行系统命令 filter：获取特定选择器匹配的元素 find：查找特定选择器的特定后代元素 first：获取一组 DOM 元素中的第一个 DOM 元素 fixture：加载文件中的数据集 focus：使一个 DOM 元素获取焦点 focused：获取当前获取焦点的 DOM 元素 get：通过选择器或者别名获取一个或者多个 DOM 元素 getCookie：获取浏览器的特定 cookie getCookies：获取浏览器的所有 cookie go：前进或者后退 hash：获取当前页面地址的哈希值 hover：不存在这个命令 invoke：在前边生成的主题上调用函数 its：获取前边生成的主题的属性值 last：获取一组 DOM 元素的最后一个 DOM 元素 location：获取活动页面的 window.location 对象 log：打印 cypress 日志信息 next：获取紧接的下一个兄弟 DOM 元素 nextAll：获取所有兄弟 DOM 元素 nextUntil：获取一组匹配的 DOM 元素中的每个后续兄弟元素，不包括提供的元素 not：过滤 DOM 元素 parent：获取父元素 parents：获取所有的父元素 parentsUntil：获取所有的父元素，不包括提供的元素 pause：暂停执行 cypress 命令 prev：获取前一个兄弟节点 prevAll：获取前边的所有兄弟节点 prevUntil：获取前边所有的兄弟节点，不包括提供的元素 readFile：读取文件内容 reload：重新加载页面 request：发送 HTTP 请求 root：获取页面根节点 route：管理网络请求的行为 screenshot：生成截图 scrollIntoView：将元素滚动到视图中 scrollTo：滚动到特定位置 select：选择 select 中的 option server：启动服务器开始讲响应路由到 cy.route() 和 cy.request() setCookie：设置浏览器 cookie should：创建断言，同 and() siblings：获取兄弟 DOM 元素 spread：将数组扩展为多个参数 spy：包装方法，记录函数的调用和参数 stub：替换函数，记录其用法并控制其行为 submit：提交一个表单 task：通过 task 插件，在 Node.js 中执行代码 then：使用上一个命令产生的结果 tick：移动时间 title：获取活动页面的 document.title trigger：触发 DOM 元素上的事件 type：给 DOM 元素输入内容 uncheck：取消选中复选框 url：获取当前活动页面的 URL viewport：控制应用程序的屏幕大小和方向 visit：访问远程 URL wait：等待方法 window：获取当前活动窗口的 window 对象 within：将后续命令限制在此元素内 wrap：产生传递给 .wrap() 的对象 writeFile：写入指定内容到文件 ","permalink":"https://naodeng.com.cn/posts/others/cypress-demo5/","summary":"Cypress UI 自动化测试框架学习（5）- 命令大全 命令大全 and：创建断言 as：创建别名 blur：失去焦点 check：选中 check 或者 radio children：获取一组 DOM 元素中每个元素的子元素 clear：清除 input 或者 textarea 的值 clearCookie：清除特定的浏览器 cookie clearCookies：清除浏览器的所有 cookie clearLocalStorage：清除 localstorage 的数据 click：点击 DOM 元素 clock：覆盖全局与时间相关的函数 closest：获取与选择器匹配的第一个 DOM 元素 contains：获取包含文本的 DOM 元素 dblclick：双击 DOM 元素 debug：设置调试器并记录上一个命令产生的内容 document：获取 window.document 对象 each：迭代数组结构 end：结束一系列命令 eq：在元素数组中获取特定索引的 DOM 元素 exec：执行系统命令 filter：获取特定选择器匹配的元素 find：查找特定选择器的特定后代元素 first：获取一组 DOM 元素中的第一个 DOM 元素 fixture：加载文件中的数据集 focus：使一个 DOM 元素获取焦点 focused：获取当前获取焦点的 DOM 元素 get：通过选择器或者别名获取一个或者多个 DOM 元素 getCookie：获取浏览器的特定 cookie getCookies：获取浏览器的所有 cookie go：前进或者后退 hash：获取当前页面地址的哈希值 hover：不存在这个命令 invoke：在前边生成的主题上调用函数 its：获取前边生成的主题的属性值 last：获取一组 DOM 元素的最后一个 DOM 元素 location：获取活动页面的 window.","title":"Cypress UI 自动化测试框架学习（5）- 命令大全"},{"content":"下面的信息是自动化测试框架学习第四篇数据驱动方法封装参数化和测试框架的介绍。 在自动化测试框架学习中，有很多方法可以用来驱动测试框架。例如，数据驱动方法封装参数化和测试框架。这两个方法都可以将测试框架的数据处理和预设环境等现有模型结合起来。这样就可以方便地开发、测试和运行新的测试框架。\n测试数据驱动 js 格式测试数据驱动 简介 数据以 js 格式存储，使用 js 的 import 方法导入使用\n使用方法 新建测试数据 js 文件 示例：在项目的 cypress/integration 文件夹下新建 testData 目录，然后在该目录下创建一个 js 文件，示例文件名为：testLogin.data.js\ntestLogin.data.js 示例代码如下：\nexport const testLoginUserEmail = [ { summary: \u0026#34;正确邮箱账号登录验证\u0026#34;, username:\u0026#34;dengnao.123@163.com\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserId = [ { summary: \u0026#34;正确id账号登录验证\u0026#34;, username:\u0026#34;waitnoww\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserMobilephone = [ { summary: \u0026#34;正确手机号账号登录验证\u0026#34;, username:\u0026#34;18888139031\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_js.js\n示例代码如下：\nimport { testLoginUserEmail, testLoginUserId, testLoginUserMobilephone } from \u0026#34;./testData/testLogin.data\u0026#34;; // 测试用例 describe(\u0026#34;光谷社区登录验证\u0026#34;, function () { // 执行用例执行用例之前先进入首页 beforeEach(function () { // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) //正确邮箱账号登录 it(testLoginUserEmail[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserEmail[0].username) //输入邮箱用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserEmail[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确ID账号登录 it(testLoginUserId[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserId[0].username) //输入ID用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserId[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确手机账号登录 it(testLoginUserMobilephone[0].summary, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(testLoginUserMobilephone[0].username) //输入手机号用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(testLoginUserMobilephone[0].password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }) // 执行用例执行用例之后清除登录信息 afterEach(function () { // 清除cookies cy.clearCookies() }) }) 运行测试用例 运行脚本：npm run cypress:open 点击运行 testLogin_guanggoo_data_by_js.js 用例 查看运行结果 (测试数据能正常获取到) fixture 测试数据驱动介绍 fixture 数据驱动方式是 cypress 框架推荐的方法，支持的格式也很多，如.json/txt/html/jpg/gif/mp3/zip 等，具体可参考：https://docs.cypress.io/api/commands/fixture\n简介 Cypress 使用 cypress/fixture 目录存放 json 文件数据，cy.fixture() 加载测试数据，如果不指定文件路径，默认从 cypress/fixtures 文件下去查找，也可以自己设置文件路径\n使用方法 以 json 格式读取举例介绍\n新建测试数据 json 文件 示例：在项目的 cypress/fixtures 文件夹下新建一个 json 文件，示例文件名为：testLoginData.json\ntestLoginData.json 示例代码如下（账号密码记得换成自己的）：\n\u0026#34;testLoginUserEmail\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确邮箱账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;dengnao.123@163.com\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; }, \u0026#34;testLoginUserId\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确 id 账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;waitnoww\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; }, \u0026#34;testLoginUserMobilephone\u0026#34;: { \u0026#34;summary\u0026#34;: \u0026#34;正确手机号账号登录验证\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;18888889031\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxx\u0026#34; } } 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_fixture.js\n示例代码如下：\ndescribe(\u0026#34;光谷社区登录验证\u0026#34;, function () { // 执行用例执行用例之前先进入首页 beforeEach(function () { // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 // 获取测试数据 cy.fixture(\u0026#39;testLoginData.json\u0026#39;).as(\u0026#39;loginData\u0026#39;) }) //正确邮箱账号登录 it(\u0026#34;正确邮箱账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserEmail.username) //输入邮箱用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserEmail.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确ID账号登录 it(\u0026#34;正确id账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserId.username) //输入ID用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserId.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }), //正确手机账号登录 it(\u0026#34;正确手机号账号登录验证\u0026#34;, function () { cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(this.loginData.testLoginUserMobilephone.username) //输入手机号用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(this.loginData.testLoginUserMobilephone.password) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;.ui-header \u0026gt; .username\u0026#39;) .should(\u0026#39;have.text\u0026#39;, \u0026#39;waitnoww\u0026#39;) //验证登录正确返回到首页，登录信息返回正确 }) // 执行用例执行用例之后清除登录信息 afterEach(function () { // 清除cookies cy.clearCookies() }) }) 运行测试用例 运行脚本：npm run cypress:open 点击运行 testLogin_guanggoo_data_by_fixture.js 用例 查看运行结果 (测试数据能正常获取到) 方法封装参数化 简介 cypress 框架提供了一个 commands.js 可以自定义各种命令，用来封装各种通用方法，参数化方法，常用脚本等；\n将常用的通用方法如登录方法在 cypress/support/commands.js 中编写完成之后，与 cy.get()/cy.visit() 一样，可以直接用 cy.xxx() 形式调用，非常方便，减少维护成本\n使用介绍 示例会介绍常用的参数化登录命令和进入首页命令\n登录参数化登录封装 代码编写 打开 cypress/support/commands.js 文件 输入如下代码： Cypress.Commands.add(\u0026#34;login\u0026#34;,(username,password) =\u0026gt; { cy.clearCookies() //清除 cookies,保证页面为未登录状态 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问 url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标 url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(username) //输入参数化的用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(password) //输入参数化的密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 cy.get(\u0026#39;:nth-child(2) \u0026gt; .nav-collapse\u0026#39;).should(\u0026#39;contain\u0026#39;, \u0026#39;设置\u0026#39;) //验证登录成功回到首页，设置按钮展示正确 }) 代码使用 在测试用例中可直接进行方法调用 cy.login(username,password) 换成自己的账号密码进行登录操作了 cy.login(\u0026#34;dengnao.123@163.com\u0026#34;,\u0026#34;xxxx\u0026#34;) 进入首页方法封装 代码编写 打开 cypress/support/commands.js 文件 输入如下代码： Cypress.Commands.add(\u0026#34;initHomePage\u0026#34;,() =\u0026gt; { cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问 url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标 url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) 代码使用 在测试用例中可直接进行方法调用 cy.initHomePage() 即可进入首页 cy.initHomePage() 测试框架介绍 简介 Cypress 框架采用了 Mocha 框架的语法，故 Mocha 框架的测试语法可在 cypress 上直接使用\n语法介绍 describe() 定义测试套件，里面还可以定义多个 context 或 it\ncontext() 定义测试套件，是 describe() 的别名，可以替代 describe\nit() 定义测试用例\nbefore() 在一个测试套件中的所有测试用例之前执行，设置一些运行 testcase 的前置条件\n// runs once before the first test in this block }); beforeEach() 在每个测试用例之前执行\n// 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;, \u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;, \u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 }) afterEach() 在每个测试用例之后执行，可以执行清除数据等操作\n// 清除 cookies cy.clearCookies() }) after() 在一个测试套件中的所有测试用例之后执行\n// runs once after the last test in this block }); .only() 设置只执行某个 testcase/testsuite\ndescribe.only(\u0026#39;#indexOf()\u0026#39;, function() { // ... }); }); .skip() 设置跳过执行某个 testcase/testsuite\ndescribe(\u0026#39;#indexOf()\u0026#39;, function() { it.skip(\u0026#39;should return -1 unless present\u0026#39;, function() { // this test will not be run }); it(\u0026#39;should return the index when present\u0026#39;, function() { // this test will be run }); }); }); 参考网址 https://docs.cypress.io/guides/references/bundled-tools#Mocha ","permalink":"https://naodeng.com.cn/posts/others/cypress-demo4/","summary":"下面的信息是自动化测试框架学习第四篇数据驱动方法封装参数化和测试框架的介绍。 在自动化测试框架学习中，有很多方法可以用来驱动测试框架。例如，数据驱动方法封装参数化和测试框架。这两个方法都可以将测试框架的数据处理和预设环境等现有模型结合起来。这样就可以方便地开发、测试和运行新的测试框架。\n测试数据驱动 js 格式测试数据驱动 简介 数据以 js 格式存储，使用 js 的 import 方法导入使用\n使用方法 新建测试数据 js 文件 示例：在项目的 cypress/integration 文件夹下新建 testData 目录，然后在该目录下创建一个 js 文件，示例文件名为：testLogin.data.js\ntestLogin.data.js 示例代码如下：\nexport const testLoginUserEmail = [ { summary: \u0026#34;正确邮箱账号登录验证\u0026#34;, username:\u0026#34;dengnao.123@163.com\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserId = [ { summary: \u0026#34;正确id账号登录验证\u0026#34;, username:\u0026#34;waitnoww\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] export const testLoginUserMobilephone = [ { summary: \u0026#34;正确手机号账号登录验证\u0026#34;, username:\u0026#34;18888139031\u0026#34;, password:\u0026#34;xxxx\u0026#34; } ] 编写测试用例 在项目 cypress/integration 文件夹下新建 js 测试用例文件，示例文件名为：testLogin_guanggoo_data_by_js.js\n示例代码如下：\nimport { testLoginUserEmail, testLoginUserId, testLoginUserMobilephone } from \u0026#34;.","title":"Cypress UI 自动化测试框架学习（4）- 数据驱动，方法封装参数化和测试框架"},{"content":"下面的信息是对于框架学习第 3 篇的介绍。在该篇文章中，我们学习了如何使用元素定位、操作和断言。该框架可以帮助用户定位相关的元素，并且可以帮助用户进行操作。这些操作可以帮助用户断言事件。\n元素定位 谈到 UI 自动化测试，不管是 web 端还是移动端，页面元素的各种操作在编写测试脚本时都会涉及，如果想写出高通过率和高健壮性的自动化测试用例，必须要确保正确高效的页面元素识别和使用。\ncypress 框架除了支持常用的元素定位，还提供了好用的 JQuery css 选择器。\n下面会介绍常用的元素定位方法，常用的定位方式，以及框架自带可视化自助元素定位方法\n常用元素定位 #id 定位 描述：通过元素的 id 属性来定位\n前提：定位的元素 css 样式须存在 id 属性且唯一\n//元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码 cy.get('#email') .class 定位 描述：通过元素的 class 属性来定位\n前提：定位的元素 css 样式存在 class 属性且唯一\n//元素前端代码示例 \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;img width=\u0026quot;150\u0026quot; height=\u0026quot;28\u0026quot; border=\u0026quot;0\u0026quot; align=\u0026quot;default\u0026quot; alt=\u0026quot;光谷社区\u0026quot; src=\u0026quot;http://cdn.guanggoo.com//static/images/guanggoonew.png\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\n示例代码 cy.get('.navbar-brand')\nname 定位 描述：通过元素 name 定位\n前提：定位的元素 css 样式存在 name 属性且唯一 //元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码\ncy.get('input[name=\u0026quot;email\u0026quot;]')\n常用定位方式 .get() 描述：使用 get() 定位元素，定位元素用 CSS selectors，跟 jQuery 一样 示例代码 cy.get('#email')\n.contains() 描述：可以使用 cy.contains（）根据元素的内容找到元素\n示例代码\ncy.contains(‘value’) cy.get(‘div[name=“div_name”]’).contains(‘value’)\n.within() 描述：可以在特定的 DOM 元素中找到元素\n示例代码\ncy.get('.query-form').within(() =\u0026gt; { cy.get('input:first').should('have.attr', 'placeholder', 'Email') cy.get('input:last').should('have.attr', 'placeholder', 'Password') })\nCypress.$ 描述：Cypress 也提供了 JQuery 选择器，调用 Cypress.$(\u0026lsquo;button\u0026rsquo;）会自动在您的窗口中查询元素。换句话说，Cypress 会自动将文档设置为您当前通过 cy.visit() 导航到的任何内容，这是从开发人员工具调试时同步查询元素的好方法。\n示例代码\nCypress.$(selector) // other proxied jQuery methods Cypress.$.Event Cypress.$.Deferred Cypress.$.ajax Cypress.$.get Cypress.$.getJSON Cypress.$.getScript Cypress.$.post\n框架自带可视化自助元素定位 1.前提：demo 代码已经跑起来 (运行脚本：npm run cypress:open) 2.点击运行调试用例，进入定位元素对应的页面 3.在页面上选择瞄准镜标识（open selector playground）\n4.选择页面上的元素区域，元素的定位信息就会展示在定位信息展示区域，点击复制就可使用\n元素常用操作 .click() 描述：单击\n示例代码\ncy.get('.btn-success').click()\n.type(value) 描述：输入内容\n示例代码 cy.get(‘input[name=“username”]’).type(\u0026lsquo;dengnao.123@163.com\u0026rsquo;)``\n.clear() 描述：清空输入内容\n示例代码\ncy.get(‘[type=“text”]’).clear()\n.submit() 描述：提交表单\n示例代码\ncy.get(‘.ant-input’).submit()\n.dbclick()/.rightclick() 描述：鼠标双击操作/鼠标右击操作\n示例代码\ncy.get('.menu').rightclick() // 鼠标右击 .menu 菜单元素\n.select() 描述：针对元素选择一个选项\n示例代码\ncy.get('color').select('red') // 颜色选项中选择红色\n.check()/.uncheck() 描述：单选或多选进行勾选/取消选中 (反选)\n示例代码\ncy.get('[type=\u0026quot;checkbox\u0026quot;]').check() // 对 checkbox 进行选中操作 cy.get('[type=\u0026quot;checkbox\u0026quot;]').uncheck() // 对 checkbox 进行取消选中操作\n.focus()/.blur() 描述：对选项进行聚焦/失焦操作\n示例代码\ncy.get(‘input[name=“username”]’).focus() //对于用户名输入框进行聚焦操作\n断言 BDD 断言 断言类型 .should()： 描述：创建断言，断言会自动重试，直到它们通过或超时。\n示例代码\ncy.get(‘.ant-checkbox).should(‘be.checked’)\n.expect()： 描述：预期结果\n示例代码\nexpect(name).to.not.equal(‘dengnao.123@163.com’)\n常用断言 可参考官网文档:https://docs.cypress.io/guides/references/assertions#BDD-Assertions\nTDD 断言 断言类型 .assert()： 描述：断言\n示例代码\nassert.equal(3,3,’vals equal’)\n常用断言 可参考官网文档:https://docs.cypress.io/guides/references/assertions#TDD-Assertions\n常用断言 针对长度（length）的断言 `//重试，直到找到 3 个匹配的\u0026lt;li.selected\u0026gt; cy.get('li.selected').should('have.length',3)` 针对类（Class）的断言 `//重试，直到 input 元素没有类被 disabled 为止（或者超时为止） cy.get('from').fijd('input').should('not.have.class','disabled')` 针对值（Value）断言 `//重试，直到 textarea 的值为‘iTesting’ cy.get('textarea').should('have.value','iTesting')` 针对文本内容（Text Content）的断言 //重试，直到这个 span 不包含“click me”字样 cy.get('a').parent('span.help').should('not.contain','click me') //重试，直到这个 span 包含“click me”字样 cy.get('a').parent('span.help').should('contain','click me')\n针对元素可见与否（Visibility）的断言 //重试，直到这个 button 是可为止 cy.get('button').should('be.visible')\n针对元素存在与否（Existence）的断言 //重试，直到 id 为 loading 的 spinner 不在存在 cy.get('#loading').should('not.exist')\n针对元素状态的（status）的断言 `//重试，直到这个 radio button 是选中状态 cy.get('：radio').should('be.checked')` 针对 CSS 的断言 `//重试，直到 completed 这个类有匹配的 css 为止 cy.get('.completed').should('have.css','text-decoration','line-through')` 运行出错问题记录 运行 npm run cypress:open 报错，提示 No version of Cypress is installed 报错截图如下： 修复方式 //项目根目录下运行如下命令即可解决 ./node_modules/.bin/cypress install\n原因 电脑使用过清理软件，安装的 cypress 缓存信息被删除了，重新安装就好\n运行 npm run cypress:open 报错，提示 Cypress verification timed out 报错截图如下： 修复方式 重新运行 npm run cypress:open 尝试即可\n原因 电脑 cypress 验证超时了，一般重新操作即可恢复\n","permalink":"https://naodeng.com.cn/posts/others/cypress-demo3/","summary":"下面的信息是对于框架学习第 3 篇的介绍。在该篇文章中，我们学习了如何使用元素定位、操作和断言。该框架可以帮助用户定位相关的元素，并且可以帮助用户进行操作。这些操作可以帮助用户断言事件。\n元素定位 谈到 UI 自动化测试，不管是 web 端还是移动端，页面元素的各种操作在编写测试脚本时都会涉及，如果想写出高通过率和高健壮性的自动化测试用例，必须要确保正确高效的页面元素识别和使用。\ncypress 框架除了支持常用的元素定位，还提供了好用的 JQuery css 选择器。\n下面会介绍常用的元素定位方法，常用的定位方式，以及框架自带可视化自助元素定位方法\n常用元素定位 #id 定位 描述：通过元素的 id 属性来定位\n前提：定位的元素 css 样式须存在 id 属性且唯一\n//元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;\n示例代码 cy.get('#email') .class 定位 描述：通过元素的 class 属性来定位\n前提：定位的元素 css 样式存在 class 属性且唯一\n//元素前端代码示例 \u0026lt;a class=\u0026quot;navbar-brand\u0026quot; href=\u0026quot;/\u0026quot;\u0026gt;\u0026lt;img width=\u0026quot;150\u0026quot; height=\u0026quot;28\u0026quot; border=\u0026quot;0\u0026quot; align=\u0026quot;default\u0026quot; alt=\u0026quot;光谷社区\u0026quot; src=\u0026quot;http://cdn.guanggoo.com//static/images/guanggoonew.png\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\n示例代码 cy.get('.navbar-brand')\nname 定位 描述：通过元素 name 定位\n前提：定位的元素 css 样式存在 name 属性且唯一 //元素前端代码示例 \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;email\u0026quot; name=\u0026quot;email\u0026quot; placeholder=\u0026quot;\u0026quot; class=\u0026quot;form-control\u0026quot;\u0026gt;","title":"Cypress UI 自动化测试框架学习（3）- 元素定位，操作和断言"},{"content":"下面的信息是介绍 cypress 自动化测试框架学习第 3 篇的测试报告的内容 主要介绍一下如何去使用不同格式的 cypress 自动化测试报告模版\n写在前面 由于 Cypress 测试报告是建立在 Mocha 测试报告之上的，这意味着任何为 Mocha 构建的报告程序都可以与 Cypress 一起使用。\n以下是内置的 Mocha 测试类型列表（Cypress 也同样支持）：https://mochajs.org/#reporters\n前置准备工作 在 package.json 文件的 scripts 模块加入了如下脚本：\u0026ldquo;cypress:run\u0026rdquo;:\u0026ldquo;cypress run\u0026rdquo;，便于后面生成报告\n不同运行脚本的区别：\ncypress run：是以无头浏览器模式跑测试用例文件夹下的所有测试用例 cypress open：会打开测试用例集的界面，需要手动运行 常用报告类型 spec 格式报告 运行命令 $ npm run cypress:run --reporter=spec 报告截图 Dot 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026quot;: \u0026ldquo;dot\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 json 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;json\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 List 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;list\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 NYAN 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;nyan\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 高大上报告类型 Mochawesome 格式报告 前置：安装 Mocha、Mochawesome 至项目中 npm install --save-dev mocha npm install --save-dev mochawesome 在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;mochawesome\u0026quot;信息\n运行命令\n$ npm run cypress:run 报告截图 allure 格式报告 前置：安装 allure（推荐使用 brew 安装） $ brew install allure 在 cypress.json 文件新增如下信息 \u0026#34;reporter\u0026#34;: \u0026#34;junit\u0026#34;, \u0026#34;reporterOptions\u0026#34;: { \u0026#34;mochaFile\u0026#34;: \u0026#34;results/test_report_[hash].xml\u0026#34;, \u0026#34;toConsole\u0026#34;: true } 运行命令 $ npm run cypress:run 生成报告 $ allure serve results 报告截图 Dashboard 格式报告 待完善，参考资料：https://docs.cypress.io/guides/dashboard/introduction#Features\n运行命令 $ npx cypress run --record --key 7aaee33b-f67b-4993-8d6c-2c392a1bd1c8 报告截图 ","permalink":"https://naodeng.com.cn/posts/others/cypress-demo2/","summary":"下面的信息是介绍 cypress 自动化测试框架学习第 3 篇的测试报告的内容 主要介绍一下如何去使用不同格式的 cypress 自动化测试报告模版\n写在前面 由于 Cypress 测试报告是建立在 Mocha 测试报告之上的，这意味着任何为 Mocha 构建的报告程序都可以与 Cypress 一起使用。\n以下是内置的 Mocha 测试类型列表（Cypress 也同样支持）：https://mochajs.org/#reporters\n前置准备工作 在 package.json 文件的 scripts 模块加入了如下脚本：\u0026ldquo;cypress:run\u0026rdquo;:\u0026ldquo;cypress run\u0026rdquo;，便于后面生成报告\n不同运行脚本的区别：\ncypress run：是以无头浏览器模式跑测试用例文件夹下的所有测试用例 cypress open：会打开测试用例集的界面，需要手动运行 常用报告类型 spec 格式报告 运行命令 $ npm run cypress:run --reporter=spec 报告截图 Dot 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026quot;: \u0026ldquo;dot\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 json 格式报告 前置：在 cypress.json 文件新增\u0026quot;reporter\u0026rdquo;: \u0026ldquo;json\u0026quot;信息\n运行方式：\n$ npm run cypress:run 报告截图 List 格式报告 前置：在 cypress.","title":"Cypress UI 自动化测试框架学习（2）- 测试报告"},{"content":"下面的信息是对 Cypress 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\nIntroduction 基于 JavaScript 的前端自动化测试工具，可以对浏览器中运行的任何内容进行快速、简单、可靠的测试\nCypress 是自集成的，提供了一套完整的端到端测试，无须借助其他外部工具，安装后即可快速地创建、编写、运行测试用例，且对每一步操作都支持回看\n不同于其他只能测试 UI 层的前端测试工具，Cypress 允许编写所有类型的测试，覆盖了测试金字塔模型的所有测试类型【界面测试，集成测试，单元测试】\nCypress 官网：https://www.cypress.io/\nGetting Started 下面以 MacOS 来进行介绍，其他系统可参考官网信息\nOperating System macOS 10.9 and above (64-bit only) Node.js 12 or 14 and above Before Started 已安装好 node.js 和 npm 已安装好 vs code 或者其他代码编辑器 Started and Run Step1：通过 npm 新建项目 # 新建项目文件夹 $ mkdir cypress-demo # 进入项目文件夹 $ cd cypress-demo # npm项目环境准备 $ npm init Step2：安装 cypress # 项目安装cypress包 $ npm install cypress --save-dev Step3：运行 cypress 程序 若提示：npm ERR! missing script: cypress:open，可在项目根目录 package.json 文件的 scripts 下新增\u0026quot;cypress:open\u0026quot;: \u0026ldquo;cypress open\u0026rdquo;，保存后再次运行命令即可\n# 启动demo $ npm run cypress:open Started Screenshot 运行截图 demo 用例执行截图 Try First Testscript Testcase 1.访问光谷社区主页http://www.guanggoo.com/ 2.验证是否正确跳转到光谷社区页面 3.验证网页标题是否正确 4.点击登录按钮，验证正确跳转到登录页面 5.在登录页面输入用户名和输入密码 6.点击登录按钮，验证登录成功 Testscript 在项目 cypress/integration 下新建 demo 文件夹\n在 demo 文件夹下新建 demo-guanggoo.js\ndemo-guanggoo.js 编写测试脚本\n脚本中账号密码需换成自己的账号密码\ndescribe(\u0026#39;first testcase for cypress\u0026#39;,function(){ it(\u0026#39;visit guanggoo homepage and login for guanggoo:\u0026#39;,function(){ // 访问并登录光谷社区 cy.visit(\u0026#39;http://www.guanggoo.com/\u0026#39;) //访问url cy.url().should(\u0026#39;include\u0026#39;,\u0026#39;www.guanggoo.com\u0026#39;) //验证目标url 是否正确包含光谷社区正确域名 验证是否正确跳转到光谷社区页面 cy.title().should(\u0026#39;contain\u0026#39;,\u0026#39;光谷社区\u0026#39;) //验证页面 title 是否正确 cy.get(\u0026#39;:nth-child(1) \u0026gt; .nav-collapse\u0026#39;).click() //点击登录按钮 cy.url().should(\u0026#39;include\u0026#39;,\u0026#39;login\u0026#39;) //验证正确跳转到登录页面 cy.get(\u0026#39;#email\u0026#39;) //根据 css 定位用户名输入框 .type(\u0026#39;dengnao.123@163.com\u0026#39;) //输入用户名 cy.get(\u0026#39;#password\u0026#39;) //根据 css 定位密码输入框 .type(\u0026#39;xxxxxxx\u0026#39;) //输入密码 cy.get(\u0026#39;.btn-success\u0026#39;).click() //点击登录按钮 }) }) Run Screenshot 运行 cypress 程序 # 启动 $ npm run cypress:open 页面上选择点击运行 demo-guanggoo.js 即可 运行通过无报错，代表用例编写成功 ","permalink":"https://naodeng.com.cn/posts/others/cypress-demo1/","summary":"下面的信息是对 Cypress 自动化测试框架的新手入门介绍。如果你想要学习更多关于 playwright 自动化测试框架的信息，请参阅它的文档。运行测试：打开测试界面，选择\u0026quot;运行测试\u0026quot;。下面会显示一个非常简单的测试画面。你可以选择任何一个测试项目。你可以通过键盘或者鼠标来调试测试。查看测试报告：在测试结束后，单击\u0026quot;查看测试报告\u0026quot;按钮。测试报告会显示在测试结束后的浏览器中。\nIntroduction 基于 JavaScript 的前端自动化测试工具，可以对浏览器中运行的任何内容进行快速、简单、可靠的测试\nCypress 是自集成的，提供了一套完整的端到端测试，无须借助其他外部工具，安装后即可快速地创建、编写、运行测试用例，且对每一步操作都支持回看\n不同于其他只能测试 UI 层的前端测试工具，Cypress 允许编写所有类型的测试，覆盖了测试金字塔模型的所有测试类型【界面测试，集成测试，单元测试】\nCypress 官网：https://www.cypress.io/\nGetting Started 下面以 MacOS 来进行介绍，其他系统可参考官网信息\nOperating System macOS 10.9 and above (64-bit only) Node.js 12 or 14 and above Before Started 已安装好 node.js 和 npm 已安装好 vs code 或者其他代码编辑器 Started and Run Step1：通过 npm 新建项目 # 新建项目文件夹 $ mkdir cypress-demo # 进入项目文件夹 $ cd cypress-demo # npm项目环境准备 $ npm init Step2：安装 cypress # 项目安装cypress包 $ npm install cypress --save-dev Step3：运行 cypress 程序 若提示：npm ERR!","title":"Cypress UI 自动化测试框架学习（1）- 上手"}]